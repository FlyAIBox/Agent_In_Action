## 🎯 课程简介

AI Agent（智能体）正在成为 2025 年最炙手可热的技术方向。如何快速入场？本课程将通过 **5 周实战行动营**，带你从零构建企业级 AI 智能体系统。

基于 **DeepSeek、GPT** 等最新大模型，采用 **LangGraph、MCP、LlamaFactory、Langfuse** 等前沿技术栈，通过真实项目实战，掌握智能体开发的完整技能链路。


---

## 💡 课程设计思路

### 这门课是讲给谁的？

**主要目标群体：**

* 有 1-3 年开发经验的工程师（Python/JavaScript）

* 希望学习大模型和智能体应用开发的技术人员

* 对 Agentic AI 技术感兴趣的后端/全栈工程师

* 希望从传统软件开发转向 AI 应用开发的工程师

**基础要求：**

* 具备 Python 或 JavaScript 编程基础，能够阅读和编写代码

* 了解基本的 Web 开发知识（API、HTTP 协议等）

* 对深度学习和大语言模型有初步了解

* 熟悉 Linux 基本操作和 Docker 容器技术（加分项）


---

## 🎓 学习目标

通过 5 周的系统学习和实战训练，你将掌握：

✅ **智能体构建**：从单一工具调用到多角色协作的完整开发能力  

✅ **系统部署**：容器化部署、生产环境运维的工程化实践  

✅ **质量评估**：建立评估监控体系，持续优化智能体性能  

✅ **模型微调**：垂直领域模型定制，提升专业场景表现  

✅ **项目实战**：获得 6 个企业级智能体项目经验


---

## 📋 课程特点

### 🔥 实战驱动

* **20 天**实战带练，每天完成一个明显的技术进度

* **10+ 小时**视频课，分步骤实现核心功能

* **5 次直播课**，串讲知识点、作业点评、总结复盘

* **2 个大作业**，闭环学习，深化技能

### 🚀 技术前沿

* 展示开源 LLM（DeepSeek、GPT）和 AI Agent 开发的最新成果

* 展示 MCP、LangGraph、vLLM、LlamaFactory 等前沿技术

* 展示智能体在旅游规划、深度研究等场景的实际应用

### 💼 工程化实践

* 基于真实业务需求和实战案例驱动

* 涵盖从开发到部署的完整工程链路

* 提供可直接用于商业项目的代码和部署方案

* 掌握 AI 应用开发技能，提升职场竞争力


---

## 📚 课程大纲

### 📦 课程总览

| 周次        | 模块名称             | 核心技术                                | 交付成果             | 配套代码                      |
| :---------- | :------------------- | :-------------------------------------- | :------------------- | :---------------------------- |
| **第 1 周** | 工具调用与MCP协议    | Function Call, MCP, Context Engineering | 让智能体接入外部工具 | 01-agent-tool-mcp/            |
| **第 2 周** | 多角色智能体系统     | LangGraph, LangChain                    | 构建多角色协作智能体 | 02-agent-multi-role/          |
| **第 3 周** | 系统构建与容器化部署 | FastAPI, Streamlit, Docker              | 完整的前后端系统     | 03-agent-build-docker-deploy/ |
| **第 4 周** | 智能体评估与监控     | Langfuse, LangSmith                     | 质量评估和安全监控   | 04-agent-evaluation/          |
| **第 5 周** | 模型微调与优化       | LlamaFactory, LoRA, vLLM                | 垂直领域定制化模型   | 05-agent-model-finetuning/    |


---

## 📅 详细课程安排

### 🔧 第 1 周：工具调用与 MCP 协议

**本周目标：**

* 掌握 Function Calling 的原理和实现方法

* 理解 MCP 协议，实现标准化工具集成

* 掌握提示词工程和上下文管理技巧

* 不使用框架构建一个简单的 Agent

**📂 配套代码：** `01-agent-tool-mcp/`


---

#### 任务 01 | 大模型知识过时？Function Call 让智能体实时获取外部信息

**核心痛点：** 大模型的知识有时效性，无法获取实时信息，如何突破知识边界？

**解决方案：** 通过 Function Calling 机制，让大模型能够调用外部工具和 API，获取实时数据。

**知识点：**

* Function Calling 的工作原理和机制

* 工具函数的定义和参数设计

* 工具调用的流程和最佳实践

* 多工具组合和链式调用

* 错误处理和容错机制

**实战内容：**

* 实现文件搜索工具

* 构建简单的工具调用 Agent

**配套代码：**

* `tool-use/01-AgentWithTools.ipynb` - 带工具的智能体

* `tool-use/02-AgentLoopWithFunctionCalling.ipynb` - 函数调用循环

**时长：** 40 分钟


---

#### 任务 02 | 实战项目：工具接口五花八门？MCP 协议统一标准化接入

**核心痛点：** 不同工具的接口各异，集成成本高，如何标准化管理外部工具？

**解决方案：** 使用 MCP（Model Context Protocol）协议，实现标准化的工具接入和管理。

**知识点：**

* MCP 协议的设计理念和架构

* Server-Client 模式的工作原理

* 资源(Resources)、工具(Tools)、提示(Prompts) 三大核心概念

* stdio 模式 vs sse 模式的选择

* MCP 服务端开发实践

* MCP 客户端集成方法

**实战内容：**

* 构建 MCP 天气服务器

* 实现 MCP 客户端与 DeepSeek 集成

* MCP 与 LangChain 的整合

* 不使用框架构建简单 Agent

**配套代码：**

* `mcp-demo/server/weather_server.py` - MCP 服务端

* `mcp-demo/client/mcp_client_deepseek.py` - DeepSeek 集成

* `mcp-demo/client/mcp_client_langchain.py` - LangChain 集成

**时长：** 40 分钟


---

#### 任务 03  | 实战项目：框架黑盒难调试？手搓可复用的智能体最小框架

**核心痛点：** 

* LangChain、LangGraph 等框架功能强大，但"黑盒"难以理解底层原理？

* 遇到问题不知道如何调试和定制？

* 如何从零构建一个清晰可控的智能体架构？

**解决方案：** 基于 GAME 设计法，手搓一个最小可复用的智能体框架，深入理解智能体的核心运行机制。

**知识点：**

**GAME 架构设计：**

* **G (Goals)**: 目标与指令 - 定义智能体要实现的结果和策略

* **A (Actions)**: 动作/工具 - 定义智能体可调用的能力接口

* **M (Memory)**: 记忆 - 跨回合保留上下文，支持多轮对话

* **E (Environment)**: 环境 - 动作在真实世界的执行载体

**智能体循环 (Agent Loop)：**

* Prompt 构造：整合 Goals、Actions Schema、Memory 历史

* LLM 调用：发送 Prompt 并获取工具调用决策

* 环境执行：在 Environment 中执行动作并获取结果

* 记忆更新：将决策和结果写入 Memory

* 终止判断：检查是否执行了终止型动作

**架构设计原则：**

* 职责分离：Goals/Actions/Memory/Environment 各司其职

* 可插拔设计：可替换不同的工具、环境、LLM

* 统一接口：标准化的数据流和错误处理

* 可扩展性：支持自定义工具和执行策略

**实战内容：**

* 实现 Prompt 数据结构和 LLM 调用封装

* 实现 Goal（目标）和 Action（动作）抽象

* 实现 ActionRegistry（工具注册表）

* 实现 Memory（记忆管理）

* 实现 Environment（环境执行器）

* 实现 AgentLanguage（提示词生成器）

* 实现完整的 Agent Loop（智能体主循环）

* 测试文件操作场景：列出文件、读取文件、终止会话

**配套代码：**

* `ASimpleAgentFramework.ipynb` - GAME 框架完整实现

**学习收获：**

* 深入理解智能体的底层运行机制

* 掌握工具调用的完整流程

* 理解记忆管理和上下文传递

* 具备自定义智能体框架的能力

* 为后续使用 LangGraph 等框架打下坚实基础

**时长：** 40 分钟


#### 任务 04（直播）| 提示词工程与上下文管理：如何让大模型精准理解需求？

**核心痛点：** 

* 模型理解偏差，如何精准表达需求？

* 对话越长越乱，如何管理上下文窗口？

**解决方案：** 

* 系统化的提示词工程方法论

* 高效的上下文管理策略

**知识点：**

**提示词工程：**

* 提示词的基本原则：清晰性、具体性、结构化

* 零样本(Zero-shot)、少样本(Few-shot) 提示技巧

* 思维链(Chain-of-Thought) 提示方法

* 角色扮演和情境设定技巧

* 提示词模板化和复用

**上下文工程：**

* 上下文窗口的限制和优化策略

* 长文本的分块和检索方法

* 上下文的压缩和精简技巧

* 记忆管理和对话历史优化

**实战案例：**

* 从简单对话到复杂任务的提示词演进

* 多轮对话的上下文优化

**作业布置：** 

* 构建一个带工具调用的智能助手（自选场景）

**时长：** 60分钟（直播）


---

### 🤖 第 2 周：多角色智能体系统

**本周目标：**

* 掌握 LangGraph 的核心概念和开发方法

* 理解状态管理、记忆持久化、路由决策

* 掌握人机协同和并行协作的设计模式

* 完成深度研究助手项目的部署和测试

**📂 配套代码：** `02-agent-multi-role/`


---

#### 任务 05 | 单一调用到复杂系统？LangGraph 构建多角色协作智能体

**核心痛点：** 单一 LLM 调用无法处理复杂任务，如何构建多角色协作系统？

**解决方案：** 使用 LangGraph 框架，通过图状态机实现复杂的智能体协作。

**知识点：**

* LangChain 的核心概念：Chain、Agent、Memory、Tools

* LangGraph 的设计理念：从链式到图状态

* 节点(Node)和边(Edge)的定义

* 状态管理和数据流转

* 路由决策和条件分支

* 记忆持久化和外部存储

**实战内容：**

* 构建第一个简单的 LangGraph 应用

* 实现条件路由和动态决策

* 实现对话记忆和状态持久化

* 理解状态机的工作原理

**配套代码：**

* `langgraph/1-Base/01-simple-graph.ipynb` - 简单图构建

* `langgraph/1-Base/02-chain.ipynb` - 链式执行

* `langgraph/1-Base/03-router.ipynb` - 路由机制

* `langgraph/1-Base/04-agent-memory.ipynb` - Agent 记忆

* `langgraph/1-Base/05-chatbot-external-memory.ipynb` - 外部记忆

**时长：** 40 分钟


---

#### 任务 06 | 智能体决策失误？人机协同与并行协作深度实战

**核心痛点：** 

* 智能体决策失误，如何让人类介入？

* 多个智能体同时工作，如何避免混乱？

**解决方案：** 

* 实现人机协同的中断和断点机制

* 设计并行协作的子图架构

**知识点：**

**人机协同：**

* 中断(Interrupt)机制的原理

* 断点(Breakpoint)的设置方法

* 状态编辑和人工干预

* 动态断点的实现

* Time Travel 和状态回溯

**并行协作：**

* 角色分工的设计原则

* 并行执行 vs 串行执行

* 子图(Sub-graph)的组织方法

* Agent 间的通信机制

* 冲突解决和决策融合

**实战内容：**

* 实现旅行方案的人工审核

* 实现预算超支的确认机制

* 实现多角色并行协作

* 构建 AI 旅行规划多角色系统（预览）

**配套代码：**

* `langgraph/2-Advance/01-breakpoints.ipynb` - 断点设置

* `langgraph/2-Advance/02-dynamic-breakpoints.ipynb` - 动态断点

* `langgraph/2-Advance/03-time-travel.ipynb` - 时间旅行

* `langgraph/2-Advance/05-sub-graph.ipynb` - 子图构建

**时长：** 40 分钟


---

#### 任务 07 | 实战项目：DeepResearch 深度研究助手部署与测试

**核心痛点：** 如何构建一个能够自主进行文献调研和深度分析的智能体系统？

**解决方案：** 使用 LangGraph 构建多角色协作的深度研究助手，并部署到生产环境。

**系统设计：**

* **需求场景**：研究人员需要快速了解某个领域的研究现状

* **核心能力**：

  * 自动搜索相关文献和资料

  * 智能筛选和排序信息

  * 深度分析和总结归纳

  * 生成结构化研究报告

  * 支持多轮交互式提问


**智能体架构：**

1. **搜索智能体**：负责在多个数据源搜索相关信息

2. **分析智能体**：对搜索结果进行深度分析和评估

3. **总结智能体**：将分析结果整合为结构化报告

4. **交互智能体**：处理用户的追问和深入探讨

**实战步骤：**

* 步骤 1：使用 LangGraph 创建研究助手应用

* 步骤 2：配置多角色协作工作流

* 步骤 3：使用 Docker Compose 容器化部署

* 步骤 4：通过 API 连接和测试智能体

* 步骤 5：评估研究报告的质量并优化

**配套代码：**

* `deepresearch/01-deploy-deepresearch-creating.ipynb` - 创建研究助手

* `deepresearch/02-deploy-deepresearch-connecting.ipynb` - 连接和测试

* `deepresearch/deployment/research_assistant.py` - 核心代码

* `deepresearch/deployment/docker-compose.yml` - Docker 配置

**作业 1 布置：** 

* 基于 LangGraph 构建一个多角色智能体系统（自选场景：客服、教育、医疗等）

* 要求：至少 3 个角色、状态管理、工具调用、记忆持久化

**时长：** 60-90 分钟

#### 任务 08（直播）| LangGraph 的 Map-Reduce 模式：大规模并行处理实战

**核心痛点：** 

* 如何高效处理需要并行执行的大量任务？

* 如何将大任务拆分为多个子任务并行处理？

* 如何收集和聚合并行任务的结果？

**解决方案：** 使用 LangGraph 的 Map-Reduce 模式，实现任务的并行处理和结果聚合。

**知识点：**

**Map-Reduce 核心概念：**

* Map 阶段：将大任务拆分为多个可并行处理的小任务

* Reduce 阶段：收集所有并行任务的结果并进行聚合

* LangGraph 中的实现方式（使用 Send 和 Join）

* 适用场景：批量数据处理、多源信息聚合、并行搜索等

**Send 机制详解：**

* `Send` 的作用：动态创建并行执行流

* 如何向目标节点传递局部状态

* 局部状态 vs 全局状态的区别

* 动态并行数量的处理

**状态管理进阶：**

* 全局状态（OverallState）设计

* 局部状态（JokeState）设计

* 使用 `Annotated[list, operator.add]` 实现列表聚合

* 状态归约器（Reducer）的工作原理

* 结构化输出与 Pydantic 模型

**Join 节点机制：**

* Join 节点如何等待所有并行任务完成

* 自动汇聚多个并行流

* 与 Reduce 节点的配合

**实战案例：智能笑话生成与评选系统**

**实际应用场景：**

* **多文档摘要**：并行处理多个文档，最后生成综合摘要

* **多源信息搜索**：同时搜索多个数据源，聚合结果

* **批量内容生成**：并行生成多个创意内容，筛选最佳

* **分布式任务处理**：将大任务拆分为小任务并行执行

* **多角度分析**：从多个角度分析问题，综合结论

**技术要点：**

* `Send(node_name, local_state)` 语法

* `operator.add` 作为列表归约器

* 结构化输出确保数据格式一致

* 使用 `with_structured_output` 方法

* LangSmith 追踪并行执行过程

**配套代码：**

* `map-reduce.ipynb` - Map-Reduce 完整实现

**学习收获：**

* 掌握 LangGraph 的 Map-Reduce 模式

* 理解并行任务的调度和管理

* 掌握状态聚合的高级用法

* 能够设计和实现大规模并行处理系统

* 为构建深度研究助手打下基础

**时长：** 60 分钟（直播）


---

### 🏗️ 第 3 周 | 实战项目：Agentic AI 智能体系统构建与容器化部署

**本周目标：**

* 掌握智能体系统的架构设计方法

* 使用 FastAPI 构建高性能后端服务

* 使用 Streamlit 构建交互式前端界面

* 掌握 Docker 容器化部署和生产环境运维

**📂 配套代码：** `03-agent-build-docker-deploy/`


---

#### 任务 09 | 系统杂乱无章？从架构设计到前后端全栈开发

**核心痛点：** 

* Demo 能跑通，但系统混乱，如何设计可扩展的企业级架构？

* 后端接口复杂，如何高效开发和管理？

* 前端界面简陋，如何快速构建美观交互界面？

**解决方案：** 采用分层架构设计，使用 FastAPI 构建标准化后端服务，使用 Streamlit 快速构建前端界面。

**知识点：**

**架构设计：**

* 分层架构设计：前端、后端、智能体层、工具层

* 模块化设计原则

* API 接口设计规范(RESTful)

* 数据模型设计

* 配置管理和环境隔离

**后端开发（FastAPI）：**

* FastAPI 框架基础和核心特性

* API 路由和请求处理

* 异步编程和并发处理

* 数据验证和错误处理

* API 文档自动生成（Swagger UI）

* WebSocket 实时通信

**前端开发（Streamlit）：**

* Streamlit 框架基础

* 交互组件的使用（输入框、按钮、选择器、滑块等）

* 状态管理和会话管理

* 流式输出和实时反馈

* 界面布局和样式定制

* 与后端 API 的集成

**实战内容：**

**Part 1：架构设计与后端开发**

* 设计 AI 旅行规划智能体系统架构

* 实现智能体 API 接口（规划、查询、修改）

* 开发配置管理系统

* 集成工具调用层（天气、地图、酒店、搜索）

* 定义数据模型和状态管理

* 实现异步任务处理

**Part 2：前端开发与系统集成**

* 设计用户输入界面（目的地、预算、偏好等）

* 实现对话历史展示和管理

* 实现旅行方案可视化展示

* 实现实时状态反馈和进度条

* 集成后端 API 接口

* 实现流式输出和动态更新

**配套代码：**

**后端代码：**

* `backend/api_server.py` - API 服务器主程序

* `backend/agents/` - 智能体实现

  * `travel_agent.py` - 旅行规划智能体

  * `coordinator.py` - 协调器

  * `tools_agent.py` - 工具调用智能体

* `backend/tools/` - 工具集成

  * `weather_tool.py` - 天气查询

  * `search_tool.py` - 搜索工具

* `backend/config/` - 配置管理

* `backend/models/` - 数据模型

**前端代码：**

* `frontend/streamlit_app.py` - 前端主程序

* `frontend/components/` - UI 组件

  * `chat_interface.py` - 对话界面

  * `plan_viewer.py` - 方案展示

* `frontend/utils/` - 工具函数

  * `api_client.py` - API 客户端


**文档：**

* `docs/architecture_diagram.md` - 架构设计文档

* `docs/api_documentation.md` - API 接口文档

**时长：** 40 分钟


---

#### 任务 10 | 环境依赖混乱？Docker 容器化一键部署到生产环境

**核心痛点：** 

* 本地开发环境正常，部署到服务器就出问题？

* 环境依赖混乱，如何实现一键部署？

* 生产环境如何保障高可用和稳定性？

**解决方案：** 

* 使用 Docker 容器化技术实现环境隔离

* 使用 Docker Compose 实现多容器编排

* 建立生产环境的运维体系

**知识点：**

**容器化部署：**

* Docker 基础概念和命令

* Dockerfile 编写最佳实践

* Docker Compose 多容器编排

* 环境变量和配置注入

* 容器网络和数据卷

* 镜像优化和分层构建

**实战内容：**

* 编写后端服务 Dockerfile

* 编写前端服务 Dockerfile

* 配置 Docker Compose 一键部署

* 设置环境变量和配置管理

* 测试容器化部署

* 生产环境最佳实践讲解

**配套代码：**

* `backend/Dockerfile` - 后端容器配置

* `frontend/Dockerfile` - 前端容器配置

* `docker-compose.yml` - 编排配置

**时长：** 40 分钟


---

#### 任务 11（直播）| 生产环境部署实战与作业点评

**核心痛点：** 

* 容器化部署遇到各种问题，如何排查和解决？

* 生产环境如何实现高可用和自动化运维？

* 作业实现中的常见问题和优化方向？

**解决方案：** 

* 系统讲解生产环境部署的最佳实践

* 演示完整的部署流程和问题排查

* 点评优秀作业，分享实现经验

**知识点：**

**生产环境实战：**

* 负载均衡和自动扩缩容

* 日志收集和监控告警

* 数据备份和容灾方案

**问题排查：**

* 常见部署问题及解决方案

* 容器日志查看和分析

* 网络连接问题排查

* 性能瓶颈定位

**作业 1 点评：** 

* 点评学员提交的多角色智能体系统作业

* 分享优秀实现案例和创新设计

* 讲解常见问题和优化建议

* 架构设计的最佳实践

* 代码质量和工程化规范

## **时长：** 60 分钟（直播）

### 📊 第 4 周：智能体评估与监控

**本周目标：**

* 建立智能体评估体系和指标设计方法

* 掌握 Langfuse 追踪和评估技术

* 构建 LLM 安全监控系统

* 实现生产环境的持续监控和优化

**📂 配套代码：** `04-agent-evaluation/`


---

#### 任务 12 | 效果好坏难判断？建立智能体评估体系与 Langfuse 集成

**核心痛点：** 智能体上线后不知道效果如何，如何科学评估和持续优化？

**解决方案：** 建立完整的评估体系，使用 Langfuse 进行追踪和评估。

**知识点：**

**评估体系：**

* 评估的必要性和价值

* 评估指标体系设计

* 评估 vs 监控 vs 调试

* 端到端评估框架

**Langfuse 集成：**

* Langfuse 的核心概念：Trace、Span、Generation

* OpenAI SDK 集成方法

* LangChain 集成方法

* LangGraph 集成方法

* 追踪数据的结构和分析

**实战内容：**

* 设计智能体评估指标体系

* 集成 Langfuse 到智能体系统

* 追踪多轮对话的执行过程

* 分析工具调用的性能

* 评估旅行方案质量

**配套代码：**

* `langfuse/01_01_integration_openai_sdk.ipynb` - OpenAI 集成

* `langfuse/01_02_integration_langchain.ipynb` - LangChain 集成

* `langfuse/01_03_integration_langgraph.ipynb` - LangGraph 集成

* `langfuse/02_evaluation_with_langchain.ipynb` - LangChain 评估

**时长：** 40 分钟


---

#### 任务 13  | 实战项目： 恶意攻击频发？构建 LLM 安全监控与实时告警系统

**核心痛点：** 

* 如何防范 Prompt 注入攻击？

* 如何避免敏感信息泄露？

* 如何监控异常行为并实时告警？

**解决方案：** 构建完整的 LLM 安全监控系统，实时检测和防范安全风险。

**知识点：**

**安全监控：**

* Prompt 注入攻击检测

* 敏感信息泄露防护

* 有害内容过滤

* 异常行为检测

* 实时告警机制

**评估指标：**

* 准确性(Accuracy)评估

* 相关性(Relevance)评估

* 安全性(Safety)评估

* 成本(Cost)评估

* 延迟(Latency)评估

* 自定义评估器的开发

**实战内容：**

* 构建 LLM 安全监控系统

* 实时检测恶意输入

* 敏感信息脱敏处理

* 设置告警规则

* 分析用户行为数据

**配套代码：**

* `langfuse/04_example_llm_security_monitoring.ipynb` - 安全监控

* `langfuse/03_example_langgraph_agents.ipynb` - LangGraph Agent 监控

**时长：** 40 分钟


---

#### 任务 14（直播）| 生产环境持续监控与性能优化实战

**核心痛点：** 智能体上线后性能劣化，用户投诉增多，如何持续监控和优化？

**解决方案：** 建立完整的生产环境监控体系，实现持续优化闭环。

**知识点：**

* 实时监控仪表盘

* 性能指标采集

* 异常检测和告警

* 用户反馈收集

* 持续优化迭代

* A/B 测试和效果对比

**实战内容：**

* 构建智能体监控仪表盘

* 设置性能告警规则

* 分析性能瓶颈

* 优化工具调用延迟

* 优化 Prompt 和上下文

* 降低 API 调用成本

**课程答疑：**

* 解答学员在评估和监控方面的疑问

* 分享生产环境的实战经验

**时长：** 60 分钟（直播）


---

### 🎯 第 5 周： | 实战项目：垂直领域模型的微调和部署

**本周目标：**

* 理解模型微调的适用场景和价值

* 掌握 LoRA/PEFT 高效微调技术

* 使用 LlamaFactory 进行模型微调

* 掌握微调数据集构建和效果评估

* 完成垂直领域模型的微调和部署

**📂 配套代码：** `05-agent-model-finetuning/`


---

#### 任务 15 | 通用模型效果差？LoRA 高效微调打造垂直领域专家

**核心痛点：** 通用大模型在特定领域表现不佳，全量微调成本太高，如何低成本优化？

**解决方案：** 使用 LoRA/PEFT 技术进行参数高效微调，只训练少量参数即可获得优秀效果。

**知识点：**

**微调决策：**

* 通用模型 vs 垂直领域模型

* 微调的适用场景和价值

* 微调 vs Prompt Engineering vs RAG

* 成本收益分析

* 微调策略选择

**高效微调：**

* 全量微调 vs 参数高效微调(PEFT)

* LoRA(Low-Rank Adaptation)原理

* QLoRA 量化微调技术

* Adapter、Prefix Tuning 等其他 PEFT 方法

* 微调显存优化策略

**实战内容：**

* GPT-2 模型的 LoRA 微调实践

* 垃圾短信分类任务微调

* 显存优化和参数调整

* 微调效果对比

**配套代码：**

* `lora-demo.ipynb` - LoRA 微调示例

**时长：** 40 分钟


---

#### 任务 16 | 训练数据不足？LlamaFactory 快速构建高质量微调数据集

**核心痛点：** 

* 微调工具复杂，上手困难？

* 训练数据不足，如何准备高质量数据？

**解决方案：** 

* 使用 Easy Dataset 方法高效构建领域知识数据集

* 使用 LlamaFactory 框架快速进行模型微调

**知识点：**

**数据集构建：**

* 数据集格式：Alpaca、ShareGPT 等

* 数据清洗和预处理

* 数据增强技术

* 数据质量评估

**LlamaFactory 实战：**

* LlamaFactory 框架介绍和架构

* 配置文件的编写方法

* 训练参数的调整策略

* 多 GPU 训练和分布式训练

* 模型合并和导出

**实战内容：**

* 使用 Easy Dataset 构建医疗领域数据集

* 使用 LlamaFactory 微调 Qwen/DeepSeek 模型

* 评估微调效果

**配套代码：**

* `llamafactory/01-llm-fine-tuning/llamafactory/configs/` - 配置文件

* `llamafactory/01-llm-fine-tuning/dataset/` - 数据集目录

**配套文档：**

* `llamafactory/00-docs/02-LLaMA Factory：Easy Dataset 让大模型高效学习领域知识.md`

**作业 2 布置：** 

* 选择一个垂直领域（医疗、金融、教育、法律等），完成以下任务：

  * 构建至少 500 条高质量训练数据

  * 使用 LlamaFactory 进行模型微调

  * 评估微调效果（提供对比测试）

  * 将微调模型部署为 API 服务

  * 将微调模型集成到智能体系统中


**时长：** 40 分钟


---

#### 任务 17（直播）| 微调模型部署与生产环境优化实战

**核心痛点：** 

* 微调完成后不知道效果如何？

* 如何将微调模型部署到生产环境？

* 如何优化推理性能和降低成本？

* 如何将微调模型集成到智能体系统？

**解决方案：** 

* 建立科学的微调效果评估方法

* 使用 vLLM 进行高性能推理部署

* 优化推理性能和成本

* 完成端到端的智能体微调项目

**知识点：**

**效果评估：**

* 评估指标选择：Loss、Perplexity、BLEU、ROUGE 等

* 测试集设计和验证方法

* 对比测试：微调前 vs 微调后

* 过拟合和欠拟合的诊断

* 超参数调优策略

* 模型版本管理

**模型部署：**

* 模型导出和格式转换

* LoRA 权重的合并与加载

* vLLM 推理服务的部署方式

* 推理服务器配置优化

* 性能优化和加速技巧

* 推理成本优化

* 测试推理性能和吞吐量

**作业 2 总结：**

* 回顾作业 2 的完成情况和要求

* 讲解优秀作业的实现思路

* 分享微调和部署的最佳实践

* 课程总结和后续学习建议

**时长：** 60 分钟（直播）


---

## 📦 作业设计

### 作业 1：多角色智能体系统开发（第 2 周后）

**作业目标：** 基于 LangGraph 构建一个多角色协作的智能体系统

**功能要求：**

* 至少包含 3 个不同角色的智能体

* 实现状态管理和数据传递

* 集成至少 2 个外部工具（可使用 MCP）

* 实现记忆持久化（支持多轮对话）

* 实现条件路由和动态决策

* （可选）实现人机协同交互

**场景参考：**

* 客服系统：接待员、问题分析师、解决方案专家

* 教育系统：课程顾问、学习规划师、作业批改助手

* 医疗系统：问诊助手、诊断分析师、健康建议专家

* 或自选其他场景

**提交内容：**

1. 完整的代码实现（GitHub 仓库）

2. 系统架构设计文档

3. 演示视频（3-5 分钟）

4. 项目 README（包含安装和运行说明）

**评分标准：**

* 功能完整性（40%）

* 代码质量（20%）

* 架构设计（20%）

* 创新性（10%）

* 文档完善度（10%）


---

### 作业 2：垂直领域智能体微调与部署（第 5 周后）

**作业目标：** 为特定领域构建定制化智能体，包含数据构建、模型微调、部署上线全流程

**功能要求：**

* 选择一个垂直领域（医疗、金融、教育、法律等）

* 构建至少 500 条高质量训练数据

* 使用 LlamaFactory 进行模型微调

* 评估微调效果（提供对比测试）

* 将微调模型部署为 API 服务

* 将微调模型集成到智能体系统中

* （可选）集成 Langfuse 进行评估和监控

**提交内容：**

1. 完整的代码实现（包含数据集）

2. 微调配置文件和训练日志

3. 效果评估报告（微调前后对比）

4. 部署文档和 API 接口说明

5. 演示视频（3-5 分钟）

**评分标准：**

* 数据质量（25%）

* 微调效果（25%）

* 部署完整性（20%）

* 评估科学性（15%）

* 系统集成（10%）

* 文档完善度（5%）


---

## 🛠️ 技术栈与环境要求

### 💻 开发环境

| 组件         | 推荐配置                    | 最低配置                                |
| :----------- | :-------------------------- | :-------------------------------------- |
| **操作系统** | Ubuntu 22.04 LTS            | Ubuntu 20.04+ / Windows 10+ / macOS 12+ |
| **CPU**      | 8 核心                      | 4 核心                                  |
| **内存**     | 16 GB                       | 8 GB                                    |
| **存储**     | 200 GB SSD                  | 100 GB                                  |
| **GPU**      | NVIDIA RTX 3090/4090 (24GB) | NVIDIA GTX 1080 (8GB) 或无 GPU          |
| **Python**   | 3.10.x                      | 3.10+                                   |

### 🔑 API 密钥准备

| API 服务         | 用途             | 获取方式                                                     | 是否必需    |
| :--------------- | :--------------- | :----------------------------------------------------------- | :---------- |
| **OpenAI API**   | GPT-4/GPT-3.5    | [https://platform.openai.com](https://platform.openai.com/)  | 可选        |
| **DeepSeek API** | DeepSeek-R1/Chat | [https://platform.deepseek.com](https://platform.deepseek.com/) | 推荐        |
| **和风天气 API** | MCP 天气工具     | [https://dev.qweather.com](https://dev.qweather.com/)        | 第 1 周必需 |
| **Tavily API**   | LangGraph 搜索   | [https://tavily.com](https://tavily.com/)                    | 第 2 周推荐 |
| **Langfuse**     | 评估监控         | [https://cloud.langfuse.com](https://cloud.langfuse.com/)    | 第 4 周必需 |
| **LangSmith**    | LangChain 监控   | [https://smith.langchain.com](https://smith.langchain.com/)  | 第 4 周可选 |


---

## 🎓 学习目标检查清单

### ✅ 第 1 周：工具调用与 MCP 协议

*  掌握 Function Calling，能够集成外部工具

*  理解 MCP 协议，能够开发 MCP 服务端和客户端

*  掌握提示词工程的基本原则和方法

*  掌握上下文管理和优化策略

### ✅ 第 2 周：多角色智能体系统

*  理解 LangGraph 的核心概念和设计理念

*  能够设计和实现复杂的状态管理方案

*  掌握记忆持久化技术

*  能够实现条件路由和动态决策

*  掌握人机协同的中断机制

*  能够构建多角色并行协作的智能体系统

*  完成深度研究助手项目部署

*  完成作业 1：多角色智能体系统开发

### ✅ 第 3 周：系统构建与容器化部署

*  能够设计可扩展的智能体系统架构

*  掌握 FastAPI 后端开发

*  掌握 Streamlit 前端开发

*  能够使用 Docker 进行容器化部署

*  理解企业级部署的最佳实践

*  完成完整系统的部署和上线

### ✅ 第 4 周：智能体评估与监控

*  理解评估体系的必要性和价值

*  能够集成 Langfuse 进行追踪和评估

*  掌握各类评估指标的定义和计算

*  能够构建 LLM 安全监控系统

*  掌握生产环境的持续监控和优化方法

### ✅ 第 5 周：模型微调与优化

*  理解模型微调的适用场景

*  掌握 LoRA 和 PEFT 技术

*  能够使用 LlamaFactory 进行模型微调

*  掌握微调数据集的构建方法

*  能够评估微调效果并进行优化

*  能够将微调模型部署到生产环境

*  完成作业 2：垂直领模型微调与部署


---

## 🎯 课程总结与职业发展

### 🏆 课程收获

通过 5 周的系统学习和实战训练，你将获得：

**1. 核心技能**

* ✅ 工具集成能力：掌握 Function Call、MCP 协议、上下文工程

* ✅ 系统设计能力：掌握 LangGraph 多角色协作、状态管理、人机交互

* ✅ 工程实践能力：掌握 FastAPI、Streamlit、Docker 等技术栈

* ✅ 评估优化能力：掌握 Langfuse 评估、LLM 安全监控

* ✅ 模型定制能力：掌握 LoRA/LlamaFactory 微调技术

**2. 实战项目**（6 个完整项目）

**第 1 周实战项目：**
- ✅ **MCP 天气工具系统**：基于 Model Context Protocol 的标准化工具集成
  - 技术栈：MCP SDK、和风天气 API、Python
  - 学习收获：掌握 MCP 协议的 Server-Client 模式、工具标准化接入

- ✅ **GAME 智能体框架**：手搓可复用的最小智能体框架
  - 技术栈：OpenAI API、纯 Python 实现
  - 学习收获：深入理解 Goals/Actions/Memory/Environment 四大组件

**第 2 周实战项目：**
- ✅ **DeepResearch 深度研究助手**：多角色协作的文献研究系统
  - 技术栈：LangGraph、LangChain、Tavily Search API
  - 学习收获：掌握多智能体协作、状态管理、人机协同

**第 3 周实战项目：**
- ✅ **AI 旅行规划智能体**：企业级全栈智能体系统
  - 技术栈：FastAPI、Streamlit、Docker、LangGraph
  - 学习收获：掌握前后端开发、容器化部署、生产环境运维

**第 4 周实战项目：**
- ✅ **LLM 安全监控系统**：智能体评估与风险防控平台
  - 技术栈：Langfuse、Prompt 注入检测、实时告警
  - 学习收获：掌握评估体系设计、安全监控、性能优化

**第 5 周实战项目：**
- ✅ **垂直领域微调模型**：医疗/金融领域定制化智能体
  - 技术栈：LlamaFactory、LoRA/PEFT、vLLM
  - 学习收获：掌握数据集构建、模型微调、推理部署

**课程作业：**
- ✅ **作业 1**：多角色智能体系统开发（自选场景）
- ✅ **作业 2**：垂直领域智能体微调与部署（完整链路）

**3. 职业能力**

* ✅ **AI 工程师岗位**：能够独立开发和部署 AI 应用

* ✅ **智能体架构师**：能够设计复杂的多角色协作系统

* ✅ **AI 产品经理**：深度理解 AI 技术实现和商业化路径

* ✅ **技术团队负责人**：能够评估技术方案和管理 AI 项目

* ✅ **AI 创业者**：掌握从 0 到 1 构建 AI 产品的完整技能


---

## ❓ 常见问题 FAQ

### Q1: 我没有 GPU，能学习这门课程吗？

**A:** 可以！大部分内容都可以在 CPU 环境下学习：

* 第 1-4 周：完全不需要 GPU，使用云端 API 即可

* 第 5 周（微调）：需要使用 GPU

### Q2: 这门课需要多长时间学完？

**A:** 课程设计为 5 周行动营：

* **全职学习**：5 周完成全部内容

* **业余学习**（每天 1-2 小时）：7-8 周完成核心内容

* **深度实践**：建议预留 2-3 个月时间，结合作业深化理解

### Q3: 课程代码支持哪些大模型？

**A:** 课程设计具有很好的模型兼容性：

* **支持的 LLM**：OpenAI GPT 系列、DeepSeek、Claude、Qwen、Llama、GLM 等

* **推荐使用**：DeepSeek（性价比高，中文友好）或 GPT-4（效果最好）

* **替换方式**：代码采用统一的 LLM 接口，切换模型只需修改配置

### Q4: 作业必须完成吗？

**A:** 强烈建议完成：

* 作业是学习闭环的重要环节

* 通过实战巩固知识，深化理解

* 获得可写入简历的项目经验

* 作业会在直播课中点评和答疑

### Q5: 课程项目能否用于商业项目？

**A:** 可以！但需要注意：

* **代码许可**：项目采用 MIT 协议，可自由使用和修改

* **API 费用**：生产环境需要自行承担 API 调用费用

* **模型许可**：确认使用的大模型支持商业使用

* **数据合规**：确保用户数据处理符合隐私法规

### Q6: 如何获得学习支持？

**A:** 多种支持渠道：

* **GitHub Issues**：技术问题和 Bug 报告

* **直播答疑**：每周直播课进行集中答疑

* **代码注释**：项目代码有详细的中文注释

* **配套文档**：每个模块都有完整的技术文档


---

## 📚 推荐学习资源

### 官方文档

* **LangChain 文档**: [https://python.langchain.com/docs](https://python.langchain.com/docs)

* **LangGraph 文档**: [https://langchain-ai.github.io/langgraph](https://langchain-ai.github.io/langgraph)

* **MCP 规范**: [https://modelcontextprotocol.io](https://modelcontextprotocol.io/)

* **vLLM 文档**: [https://docs.vllm.ai](https://docs.vllm.ai/)

* **LlamaFactory 文档**: [https://github.com/hiyouga/LLaMA-Factory](https://github.com/hiyouga/LLaMA-Factory)

* **Langfuse 文档**: [https://langfuse.com/docs](https://langfuse.com/docs)

## 

