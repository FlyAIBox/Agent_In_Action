{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/FlyAIBox/Agent-101/blob/main/chapter03-llm-deploy/vllm/deepseek_r1_distill_qwen_fast_api.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gPVYg0Z9SxCq"
   },
   "source": [
    "# åŸºäºvLLMéƒ¨ç½²DeepSeek-R1-Distill-Qwen-1.5B\n",
    "## ğŸ“– å…³äº DeepSeek R1 è’¸é¦ç‰ˆ Qwen 1.5B æ¨¡å‹\n",
    "\n",
    "### ğŸ§  æ¨¡å‹ç‰¹ç‚¹\n",
    "- **æ¨¡å‹åç§°**: `deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B`\n",
    "- **å‚æ•°è§„æ¨¡**: 15äº¿å‚æ•°ï¼Œé€‚åˆåœ¨æ˜¾å­˜æœ‰é™çš„GPUï¼ˆå¦‚Nvidia T4/4090ï¼‰ ä¸Šè¿è¡Œ\n",
    "- **æ¨ç†èƒ½åŠ›**: ç»§æ‰¿äº† DeepSeek R1 çš„å¼ºå¤§æ¨ç†èƒ½åŠ›\n",
    "- **è’¸é¦æŠ€æœ¯**: é€šè¿‡çŸ¥è¯†è’¸é¦è·å¾—æ›´å°ä½†é«˜æ•ˆçš„æ¨¡å‹\n",
    "\n",
    "### ğŸ” æ¨¡å‹ä¼˜åŠ¿\n",
    "1. **è½»é‡åŒ–**: 15äº¿å‚æ•°ï¼Œå†…å­˜å ç”¨å°\n",
    "2. **é«˜æ•ˆæ¨ç†**: ä¼˜åŒ–çš„æ¨ç†é€Ÿåº¦\n",
    "3. **å¼ºå¤§èƒ½åŠ›**: ä¿æŒäº†å¤§æ¨¡å‹çš„æ¨ç†èƒ½åŠ›\n",
    "4. **å…è´¹éƒ¨ç½²**: é€‚åˆåœ¨ Colabä¸Šå…è´¹çš„Nvidia T4 GPU ä¸Šè¿è¡Œ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ojg0UqLRnp1i",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## ğŸ¯ å®éªŒç›®æ ‡\n",
    "\n",
    "æœ¬å®éªŒæ—¨åœ¨å¸®åŠ©å¤§æ¨¡å‹æŠ€æœ¯åˆå­¦è€…ï¼š\n",
    "\n",
    "### ğŸ“š å­¦ä¹ å†…å®¹\n",
    "1. **ç¯å¢ƒå‡†å¤‡**: äº†è§£å¦‚ä½•æ£€æŸ¥å’Œé…ç½® Colab ç¯å¢ƒ\n",
    "2. **ä¾èµ–å®‰è£…**: å­¦ä¹ å®‰è£… VLLMã€FastAPI ç­‰å…³é”®åº“\n",
    "3. **æ¨¡å‹éƒ¨ç½²**: æŒæ¡ä½¿ç”¨ VLLM éƒ¨ç½²å¤§è¯­è¨€æ¨¡å‹çš„æ–¹æ³•\n",
    "4. **API å¼€å‘**: åˆ›å»º RESTful API æ¥å£æœåŠ¡\n",
    "5. **å®æ—¶äº¤äº’**: å®ç°æµå¼è¾“å‡ºå’Œå®æ—¶å¯¹è¯åŠŸèƒ½\n",
    "\n",
    "### ğŸ’° æˆæœ¬ä¼˜åŠ¿\n",
    "- **å®Œå…¨å…è´¹**: ä½¿ç”¨ Google Colab å…è´¹ T4 GPU (15GB æ˜¾å­˜)\n",
    "- **é›¶é…ç½®**: æ— éœ€æœ¬åœ°ç¯å¢ƒé…ç½®ï¼Œæµè§ˆå™¨å³å¯è¿è¡Œ\n",
    "- **å³å¼€å³ç”¨**: ä¸€é”®å¯åŠ¨ï¼Œå¿«é€Ÿä½“éªŒå¤§æ¨¡å‹éƒ¨ç½²\n",
    "\n",
    "### ğŸš€ æœŸæœ›æ”¶è·\n",
    "é€šè¿‡æœ¬å®éªŒï¼Œä½ å°†æŒæ¡ï¼š\n",
    "- å¤§è¯­è¨€æ¨¡å‹çš„åŸºæœ¬éƒ¨ç½²æµç¨‹\n",
    "- VLLM æ¨ç†å¼•æ“çš„ä½¿ç”¨æ–¹æ³•\n",
    "- FastAPI Web æœåŠ¡çš„å¼€å‘æŠ€å·§\n",
    "- æ¨¡å‹ API çš„è®¾è®¡å’Œå®ç°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0LtZRZL_7jzo"
   },
   "source": [
    "## ğŸ”§ ç¬¬ä¸€æ­¥ï¼šç¯å¢ƒä¿¡æ¯æ£€æŸ¥\n",
    "\n",
    "åœ¨å¼€å§‹éƒ¨ç½²æ¨¡å‹ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦äº†è§£å½“å‰çš„è¿è¡Œç¯å¢ƒã€‚è¿™ä¸ªæ­¥éª¤éå¸¸é‡è¦ï¼Œå› ä¸ºï¼š\n",
    "\n",
    "### ğŸ¯ æ£€æŸ¥ç›®çš„\n",
    "1. **ç¡¬ä»¶ç¡®è®¤**: ç¡®ä¿æœ‰è¶³å¤Ÿçš„ GPU æ˜¾å­˜è¿è¡Œæ¨¡å‹\n",
    "2. **ç³»ç»Ÿå…¼å®¹**: éªŒè¯æ“ä½œç³»ç»Ÿå’Œ Python ç‰ˆæœ¬\n",
    "3. **èµ„æºè¯„ä¼°**: äº†è§£å¯ç”¨çš„ CPUã€å†…å­˜å’Œå­˜å‚¨ç©ºé—´\n",
    "4. **ç¯å¢ƒé…ç½®**: æ£€æŸ¥ CUDA ç‰ˆæœ¬å’Œç›¸å…³ä¾èµ–\n",
    "\n",
    "### ğŸ“Š æ£€æŸ¥å†…å®¹\n",
    "- **æ“ä½œç³»ç»Ÿ**: Linux å‘è¡Œç‰ˆå’Œç‰ˆæœ¬\n",
    "- **CPU ä¿¡æ¯**: å¤„ç†å™¨å‹å·å’Œæ ¸å¿ƒæ•°\n",
    "- **å†…å­˜çŠ¶æ€**: æ€»å†…å­˜å’Œå¯ç”¨å†…å­˜\n",
    "- **GPU é…ç½®**: æ˜¾å¡å‹å·å’Œæ˜¾å­˜å¤§å°\n",
    "- **CUDA ç‰ˆæœ¬**: æ·±åº¦å­¦ä¹ æ¡†æ¶æ”¯æŒ\n",
    "- **Python ç¯å¢ƒ**: è§£é‡Šå™¨ç‰ˆæœ¬\n",
    "- **ç£ç›˜ç©ºé—´**: å¯ç”¨å­˜å‚¨ç©ºé—´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================\n",
      "== Conda ç¯å¢ƒæ£€æŸ¥æŠ¥å‘Š (ä»…é’ˆå¯¹å½“å‰ Bash å­è¿›ï¿½ï¿½) ==\n",
      "=========================================\n",
      "âœ… å½“å‰å•å…ƒæ ¼å·²æˆåŠŸæ¿€æ´»åˆ° agent101 ç¯å¢ƒã€‚\n",
      "âœ… æ­£åœ¨ä½¿ç”¨çš„ç¯å¢ƒè·¯å¾„: /root/miniconda3/envs/agent101\n",
      "\n",
      "ğŸ’¡ æç¤º: åç»­çš„Pythonå•å…ƒæ ¼å°†ä½¿ç”¨Notebookå½“å‰é€‰æ‹©çš„Jupyterï¿½ï¿½æ ¸ã€‚\n",
      "   å¦‚æœéœ€è¦åç»­å•å…ƒæ ¼ä¹Ÿä½¿ç”¨æ­¤ç¯å¢ƒï¼Œè¯·æ‰§è¡Œä»¥ä¸‹æ“ä½œ:\n",
      "   1. æ£€æŸ¥ Notebook å³ä¸Šè§’æ˜¯å¦å·²é€‰æ‹© 'python(agent101)'ã€‚\n",
      "=========================================\n"
     ]
    }
   ],
   "source": [
    "%%script bash\n",
    "\n",
    "# 1. æ¿€æ´» conda ç¯å¢ƒ (ä»…å¯¹å½“å‰å•å…ƒæ ¼æœ‰æ•ˆ)\n",
    "eval \"$(conda shell.bash hook)\"\n",
    "conda activate agent101\n",
    "\n",
    "echo \"=========================================\"\n",
    "echo \"== Conda ç¯å¢ƒæ£€æŸ¥æŠ¥å‘Š (ä»…é’ˆå¯¹å½“å‰ Bash å­è¿›ç¨‹) ==\"\n",
    "echo \"=========================================\"\n",
    "\n",
    "# 2. æ£€æŸ¥å½“å‰æ¿€æ´»çš„ç¯å¢ƒ\n",
    "CURRENT_ENV_NAME=$(basename $CONDA_PREFIX)\n",
    "\n",
    "if [ \"$CURRENT_ENV_NAME\" = \"agent101\" ]; then\n",
    "    echo \"âœ… å½“å‰å•å…ƒæ ¼å·²æˆåŠŸæ¿€æ´»åˆ° agent101 ç¯å¢ƒã€‚\"\n",
    "    echo \"âœ… æ­£åœ¨ä½¿ç”¨çš„ç¯å¢ƒè·¯å¾„: $CONDA_PREFIX\"\n",
    "    echo \"\"\n",
    "    echo \"ğŸ’¡ æç¤º: åç»­çš„Pythonå•å…ƒæ ¼å°†ä½¿ç”¨Notebookå½“å‰é€‰æ‹©çš„Jupyterå†…æ ¸ã€‚\"\n",
    "    echo \"   å¦‚æœéœ€è¦åç»­å•å…ƒæ ¼ä¹Ÿä½¿ç”¨æ­¤ç¯å¢ƒï¼Œè¯·æ‰§è¡Œä»¥ä¸‹æ“ä½œ:\"\n",
    "    echo \"   1. æ£€æŸ¥ Notebook å³ä¸Šè§’æ˜¯å¦å·²é€‰æ‹© 'python(agent101)'ã€‚\"\n",
    "else\n",
    "    echo \"âŒ æ¿€æ´»å¤±è´¥æˆ–ç¯å¢ƒåç§°ä¸åŒ¹é…ã€‚å½“å‰ç¯å¢ƒ: $CURRENT_ENV_NAME\"\n",
    "    echo \"\"\n",
    "    echo \"âš ï¸ ä¸¥é‡æç¤º: å»ºè®®å°† Notebook çš„ Jupyter **å†…æ ¸ (Kernel)** åˆ‡æ¢ä¸º 'python(agent101)'ã€‚\"\n",
    "    echo \"   (é€šå¸¸ä½äº Notebook å³ä¸Šè§’æˆ– 'å†…æ ¸' èœå•ä¸­)\"\n",
    "    echo \"\"\n",
    "    echo \"ğŸ“š å¤‡ç”¨æ–¹æ³• (ä¸æ¨è): å¦‚æœæ— æ³•åˆ‡æ¢å†…æ ¸ï¼Œåˆ™å¿…é¡»åœ¨**æ¯ä¸ª**ä»£ç å•å…ƒæ ¼çš„å¤´éƒ¨é‡å¤ä»¥ä¸‹å‘½ä»¤:\"\n",
    "    echo \"\"\n",
    "    echo \"%%script bash\"\n",
    "    echo \"# å¿…é¡»åœ¨æ¯ä¸ªå•å…ƒæ ¼éƒ½æ‰§è¡Œ\"\n",
    "    echo \"eval \\\"\\$(conda shell.bash hook)\\\"\"\n",
    "    echo \"conda activate agent101\"\n",
    "fi\n",
    "\n",
    "echo \"=========================================\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to /root/.config/pip/pip.conf\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[31mERROR: Need an action (debug, edit, get, list, set, unset) to perform.\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# 2. è®¾ç½®pip ä¸ºæ¸…åæº\n",
    "%pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "%pip config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: HF_ENDPOINT=https://hf-mirror.com\n",
      "https://hf-mirror.com\n"
     ]
    }
   ],
   "source": [
    "# 3. è®¾ç½®HuggingFaceä»£ç†\n",
    "%env HF_ENDPOINT=https://hf-mirror.com\n",
    "# éªŒè¯ï¼šä½¿ç”¨shellå‘½ä»¤æ£€æŸ¥\n",
    "!echo $HF_ENDPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VQMi5m-R7fLB",
    "outputId": "4d26085f-078f-4acb-954c-a4eb3ea31b3e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: pandas==2.2.2 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from pandas==2.2.2) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from pandas==2.2.2) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from pandas==2.2.2) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from pandas==2.2.2) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas==2.2.2) (1.17.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m### ç¯å¢ƒä¿¡æ¯\n",
      "| é¡¹ç›®         | ä¿¡æ¯                                                                               |\n",
      "|:-------------|:-----------------------------------------------------------------------------------|\n",
      "| æ“ä½œç³»ç»Ÿ     | Linux Ubuntu 22.04.4 LTS                                                           |\n",
      "| CPU ä¿¡æ¯     | 11th Gen Intel(R) Core(TM) i5-1135G7 @ 2.40GHz (1 physical cores, 2 logical cores) |\n",
      "| å†…å­˜ä¿¡æ¯     | 3.78 GB (Available: 2.87 GB)                                                       |\n",
      "| GPU ä¿¡æ¯     | No GPU found (nvidia-smi not found)                                                |\n",
      "| CUDA ä¿¡æ¯    | CUDA not found                                                                     |\n",
      "| Python ç‰ˆæœ¬  | 3.10.18                                                                            |\n",
      "| Conda ç‰ˆæœ¬   | conda 24.4.0                                                                       |\n",
      "| ç‰©ç†ç£ç›˜ç©ºé—´ | Total: 56.91 GB, Used: 13.98 GB, Free: 40.31 GB                                    |\n"
     ]
    }
   ],
   "source": [
    "# ğŸ” ç¯å¢ƒä¿¡æ¯æ£€æŸ¥è„šæœ¬\n",
    "#\n",
    "# æœ¬è„šæœ¬çš„ä½œç”¨ï¼š\n",
    "# 1. å®‰è£… pandas åº“ç”¨äºæ•°æ®è¡¨æ ¼å±•ç¤º\n",
    "# 2. æ£€æŸ¥ç³»ç»Ÿçš„å„é¡¹é…ç½®ä¿¡æ¯\n",
    "# 3. ç”Ÿæˆè¯¦ç»†çš„ç¯å¢ƒæŠ¥å‘Šè¡¨æ ¼\n",
    "#\n",
    "# å¯¹äºåˆå­¦è€…æ¥è¯´ï¼Œè¿™ä¸ªæ­¥éª¤å¸®åŠ©ä½ ï¼š\n",
    "# - äº†è§£å½“å‰è¿è¡Œç¯å¢ƒçš„ç¡¬ä»¶é…ç½®\n",
    "# - ç¡®è®¤æ˜¯å¦æ»¡è¶³æ¨¡å‹è¿è¡Œçš„æœ€ä½è¦æ±‚\n",
    "# - å­¦ä¹ å¦‚ä½•é€šè¿‡ä»£ç è·å–ç³»ç»Ÿä¿¡æ¯\n",
    "\n",
    "# å®‰è£… pandas åº“ - ç”¨äºåˆ›å»ºå’Œå±•ç¤ºæ•°æ®è¡¨æ ¼\n",
    "# pandas æ˜¯ Python ä¸­æœ€æµè¡Œçš„æ•°æ®å¤„ç†å’Œåˆ†æåº“\n",
    "!pip install pandas==2.2.2\n",
    "\n",
    "import platform # å¯¼å…¥ platform æ¨¡å—ä»¥è·å–ç³»ç»Ÿä¿¡æ¯\n",
    "import os # å¯¼å…¥ os æ¨¡å—ä»¥ä¸æ“ä½œç³»ç»Ÿäº¤äº’\n",
    "import subprocess # å¯¼å…¥ subprocess æ¨¡å—ä»¥è¿è¡Œå¤–éƒ¨å‘½ä»¤\n",
    "import pandas as pd # å¯¼å…¥ pandas æ¨¡å—ï¼Œé€šå¸¸ç”¨äºæ•°æ®å¤„ç†ï¼Œè¿™é‡Œç”¨äºåˆ›å»ºè¡¨æ ¼\n",
    "import shutil # å¯¼å…¥ shutil æ¨¡å—ä»¥è·å–ç£ç›˜ç©ºé—´ä¿¡æ¯\n",
    "\n",
    "# è·å– CPU ä¿¡æ¯çš„å‡½æ•°ï¼ŒåŒ…æ‹¬æ ¸å¿ƒæ•°é‡\n",
    "def get_cpu_info():\n",
    "    cpu_info = \"\" # åˆå§‹åŒ– CPU ä¿¡æ¯å­—ç¬¦ä¸²\n",
    "    physical_cores = \"N/A\"\n",
    "    logical_cores = \"N/A\"\n",
    "\n",
    "    if platform.system() == \"Windows\": # å¦‚æœæ˜¯ Windows ç³»ç»Ÿ\n",
    "        cpu_info = platform.processor() # ä½¿ç”¨ platform.processor() è·å– CPU ä¿¡æ¯\n",
    "        try:\n",
    "            # è·å– Windows ä¸Šçš„æ ¸å¿ƒæ•°é‡ (éœ€è¦ WMI)\n",
    "            import wmi\n",
    "            c = wmi.WMI()\n",
    "            for proc in c.Win32_Processor():\n",
    "                physical_cores = proc.NumberOfCores\n",
    "                logical_cores = proc.NumberOfLogicalProcessors\n",
    "        except:\n",
    "            pass # å¦‚æœ WMI ä¸å¯ç”¨ï¼Œå¿½ç•¥é”™è¯¯\n",
    "\n",
    "    elif platform.system() == \"Darwin\": # å¦‚æœæ˜¯ macOS ç³»ç»Ÿ\n",
    "        # åœ¨ macOS ä¸Šä½¿ç”¨ sysctl å‘½ä»¤è·å– CPU ä¿¡æ¯å’Œæ ¸å¿ƒæ•°é‡\n",
    "        os.environ['PATH'] = os.environ['PATH'] + os.pathsep + '/usr/sbin' # æ›´æ–° PATH ç¯å¢ƒå˜é‡\n",
    "        try:\n",
    "            process_brand = subprocess.Popen(['sysctl', \"machdep.cpu.brand_string\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            stdout_brand, stderr_brand = process_brand.communicate()\n",
    "            cpu_info = stdout_brand.decode().split(': ')[1].strip() if stdout_brand else \"Could not retrieve CPU info\"\n",
    "\n",
    "            process_physical = subprocess.Popen(['sysctl', \"hw.physicalcpu\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            stdout_physical, stderr_physical = process_physical.communicate()\n",
    "            physical_cores = stdout_physical.decode().split(': ')[1].strip() if stdout_physical else \"N/A\"\n",
    "\n",
    "            process_logical = subprocess.Popen(['sysctl', \"hw.logicalcpu\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            stdout_logical, stderr_logical = process_logical.communicate()\n",
    "            logical_cores = stdout_logical.decode().split(': ')[1].strip() if stdout_logical else \"N/A\"\n",
    "\n",
    "        except:\n",
    "            cpu_info = \"Could not retrieve CPU info\"\n",
    "            physical_cores = \"N/A\"\n",
    "            logical_cores = \"N/A\"\n",
    "\n",
    "    else:  # Linux ç³»ç»Ÿ\n",
    "        try:\n",
    "            # åœ¨ Linux ä¸Šè¯»å– /proc/cpuinfo æ–‡ä»¶è·å– CPU ä¿¡æ¯å’Œæ ¸å¿ƒæ•°é‡\n",
    "            with open('/proc/cpuinfo') as f:\n",
    "                physical_cores_count = 0\n",
    "                logical_cores_count = 0\n",
    "                cpu_info_lines = []\n",
    "                for line in f:\n",
    "                    if line.startswith('model name'): # æŸ¥æ‰¾ä»¥ 'model name'å¼€å¤´çš„è¡Œ\n",
    "                        if not cpu_info: # åªè·å–ç¬¬ä¸€ä¸ª model name\n",
    "                            cpu_info = line.split(': ')[1].strip()\n",
    "                    elif line.startswith('cpu cores'): # æŸ¥æ‰¾ä»¥ 'cpu cores' å¼€å¤´çš„è¡Œ\n",
    "                        physical_cores_count = int(line.split(': ')[1].strip())\n",
    "                    elif line.startswith('processor'): # æŸ¥æ‰¾ä»¥ 'processor' å¼€å¤´çš„è¡Œ\n",
    "                        logical_cores_count += 1\n",
    "                physical_cores = str(physical_cores_count) if physical_cores_count > 0 else \"N/A\"\n",
    "                logical_cores = str(logical_cores_count) if logical_cores_count > 0 else \"N/A\"\n",
    "                if not cpu_info:\n",
    "                     cpu_info = \"Could not retrieve CPU info\"\n",
    "\n",
    "        except:\n",
    "            cpu_info = \"Could not retrieve CPU info\"\n",
    "            physical_cores = \"N/A\"\n",
    "            logical_cores = \"N/A\"\n",
    "\n",
    "    return f\"{cpu_info} ({physical_cores} physical cores, {logical_cores} logical cores)\" # è¿”å› CPU ä¿¡æ¯å’Œæ ¸å¿ƒæ•°é‡\n",
    "\n",
    "\n",
    "# è·å–å†…å­˜ä¿¡æ¯çš„å‡½æ•°\n",
    "def get_memory_info():\n",
    "    mem_info = \"\" # åˆå§‹åŒ–å†…å­˜ä¿¡æ¯å­—ç¬¦ä¸²\n",
    "    if platform.system() == \"Windows\":\n",
    "        # åœ¨ Windows ä¸Šä¸å®¹æ˜“é€šè¿‡æ ‡å‡†åº“è·å–ï¼Œéœ€è¦å¤–éƒ¨åº“æˆ– PowerShell\n",
    "        mem_info = \"Requires external tools on Windows\" # è®¾ç½®æç¤ºä¿¡æ¯\n",
    "    elif platform.system() == \"Darwin\": # å¦‚æœæ˜¯ macOS ç³»ç»Ÿ\n",
    "        # åœ¨ macOS ä¸Šä½¿ç”¨ sysctl å‘½ä»¤è·å–å†…å­˜å¤§å°\n",
    "        process = subprocess.Popen(['sysctl', \"hw.memsize\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE) # è¿è¡Œ sysctl å‘½ä»¤\n",
    "        stdout, stderr = process.communicate() # è·å–æ ‡å‡†è¾“å‡ºå’Œæ ‡å‡†é”™è¯¯\n",
    "        mem_bytes = int(stdout.decode().split(': ')[1].strip()) # è§£æè¾“å‡ºï¼Œè·å–å†…å­˜å¤§å°ï¼ˆå­—èŠ‚ï¼‰\n",
    "        mem_gb = mem_bytes / (1024**3) # è½¬æ¢ä¸º GB\n",
    "        mem_info = f\"{mem_gb:.2f} GB\" # æ ¼å¼åŒ–è¾“å‡º\n",
    "    else:  # Linux ç³»ç»Ÿ\n",
    "        try:\n",
    "            # åœ¨ Linux ä¸Šè¯»å– /proc/meminfo æ–‡ä»¶è·å–å†…å­˜ä¿¡æ¯\n",
    "            with open('/proc/meminfo') as f:\n",
    "                total_mem_kb = 0\n",
    "                available_mem_kb = 0\n",
    "                for line in f:\n",
    "                    if line.startswith('MemTotal'): # æŸ¥æ‰¾ä»¥ 'MemTotal' å¼€å¤´çš„è¡Œ\n",
    "                        total_mem_kb = int(line.split(':')[1].strip().split()[0]) # è§£æè¡Œï¼Œè·å–æ€»å†…å­˜ï¼ˆKBï¼‰\n",
    "                    elif line.startswith('MemAvailable'): # æŸ¥æ‰¾ä»¥ 'MemAvailable' å¼€å¤´çš„è¡Œ\n",
    "                         available_mem_kb = int(line.split(':')[1].strip().split()[0]) # è§£æè¡Œï¼Œè·å–å¯ç”¨å†…å­˜ï¼ˆKBï¼‰\n",
    "\n",
    "                if total_mem_kb > 0:\n",
    "                    total_mem_gb = total_mem_kb / (1024**2) # è½¬æ¢ä¸º GB\n",
    "                    mem_info = f\"{total_mem_gb:.2f} GB\" # æ ¼å¼åŒ–è¾“å‡ºæ€»å†…å­˜\n",
    "                    if available_mem_kb > 0:\n",
    "                        available_mem_gb = available_mem_kb / (1024**2)\n",
    "                        mem_info += f\" (Available: {available_mem_gb:.2f} GB)\" # æ·»åŠ å¯ç”¨å†…å­˜ä¿¡æ¯\n",
    "                else:\n",
    "                     mem_info = \"Could not retrieve memory info\" # å¦‚æœè¯»å–æ–‡ä»¶å‡ºé”™ï¼Œè®¾ç½®é”™è¯¯ä¿¡æ¯\n",
    "\n",
    "        except:\n",
    "            mem_info = \"Could not retrieve memory info\" # å¦‚æœè¯»å–æ–‡ä»¶å‡ºé”™ï¼Œè®¾ç½®é”™è¯¯ä¿¡æ¯\n",
    "    return mem_info # è¿”å›å†…å­˜ä¿¡æ¯\n",
    "\n",
    "# è·å– GPU ä¿¡æ¯çš„å‡½æ•°ï¼ŒåŒ…æ‹¬æ˜¾å­˜\n",
    "def get_gpu_info():\n",
    "    try:\n",
    "        # å°è¯•ä½¿ç”¨ nvidia-smi è·å– NVIDIA GPU ä¿¡æ¯å’Œæ˜¾å­˜\n",
    "        result = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total', '--format=csv,noheader'], capture_output=True, text=True)\n",
    "        if result.returncode == 0: # å¦‚æœå‘½ä»¤æˆåŠŸæ‰§è¡Œ\n",
    "            gpu_lines = result.stdout.strip().split('\\n') # è§£æè¾“å‡ºï¼Œè·å– GPU åç§°å’Œæ˜¾å­˜\n",
    "            gpu_info_list = []\n",
    "            for line in gpu_lines:\n",
    "                name, memory = line.split(', ')\n",
    "                gpu_info_list.append(f\"{name} ({memory})\") # æ ¼å¼åŒ– GPU ä¿¡æ¯\n",
    "            return \", \".join(gpu_info_list) if gpu_info_list else \"NVIDIA GPU found, but info not listed\" # è¿”å› GPU ä¿¡æ¯æˆ–æç¤ºä¿¡æ¯\n",
    "        else:\n",
    "             # å°è¯•ä½¿ç”¨ lshw è·å–å…¶ä»– GPU ä¿¡æ¯ (éœ€è¦å®‰è£… lshw)\n",
    "            try:\n",
    "                result_lshw = subprocess.run(['lshw', '-C', 'display'], capture_output=True, text=True)\n",
    "                if result_lshw.returncode == 0: # å¦‚æœå‘½ä»¤æˆåŠŸæ‰§è¡Œ\n",
    "                     # ç®€å•è§£æè¾“å‡ºä¸­çš„ product åç§°å’Œæ˜¾å­˜\n",
    "                    gpu_info_lines = []\n",
    "                    current_gpu = {}\n",
    "                    for line in result_lshw.stdout.splitlines():\n",
    "                        if 'product:' in line:\n",
    "                             if current_gpu:\n",
    "                                 gpu_info_lines.append(f\"{current_gpu.get('product', 'GPU')} ({current_gpu.get('memory', 'N/A')})\")\n",
    "                             current_gpu = {'product': line.split('product:')[1].strip()}\n",
    "                        elif 'size:' in line and 'memory' in line:\n",
    "                             current_gpu['memory'] = line.split('size:')[1].strip()\n",
    "\n",
    "                    if current_gpu: # æ·»åŠ æœ€åä¸€ä¸ª GPU çš„ä¿¡æ¯\n",
    "                        gpu_info_lines.append(f\"{current_gpu.get('product', 'GPU')} ({current_gpu.get('memory', 'N/A')})\")\n",
    "\n",
    "                    return \", \".join(gpu_info_lines) if gpu_info_lines else \"GPU found (via lshw), but info not parsed\" # å¦‚æœæ‰¾åˆ° GPU ä½†ä¿¡æ¯æ— æ³•è§£æï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "                else:\n",
    "                    return \"No GPU found (checked nvidia-smi and lshw)\" # å¦‚æœä¸¤ä¸ªå‘½ä»¤éƒ½æ‰¾ä¸åˆ° GPUï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "            except FileNotFoundError:\n",
    "                 return \"No GPU found (checked nvidia-smi, lshw not found)\" # å¦‚æœæ‰¾ä¸åˆ° lshw å‘½ä»¤ï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "    except FileNotFoundError:\n",
    "        return \"No GPU found (nvidia-smi not found)\" # å¦‚æœæ‰¾ä¸åˆ° nvidia-smi å‘½ä»¤ï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "\n",
    "\n",
    "# è·å– CUDA ç‰ˆæœ¬çš„å‡½æ•°\n",
    "def get_cuda_version():\n",
    "    try:\n",
    "        # å°è¯•ä½¿ç”¨ nvcc --version è·å– CUDA ç‰ˆæœ¬\n",
    "        result = subprocess.run(['nvcc', '--version'], capture_output=True, text=True)\n",
    "        if result.returncode == 0: # å¦‚æœå‘½ä»¤æˆåŠŸæ‰§è¡Œ\n",
    "            for line in result.stdout.splitlines():\n",
    "                if 'release' in line: # æŸ¥æ‰¾åŒ…å« 'release' çš„è¡Œ\n",
    "                    return line.split('release ')[1].split(',')[0] # è§£æè¡Œï¼Œæå–ç‰ˆæœ¬å·\n",
    "        return \"CUDA not found or version not parsed\" # å¦‚æœæ‰¾ä¸åˆ° CUDA æˆ–ç‰ˆæœ¬æ— æ³•è§£æï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "    except FileNotFoundError:\n",
    "        return \"CUDA not found\" # å¦‚æœæ‰¾ä¸åˆ° nvcc å‘½ä»¤ï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "\n",
    "# è·å– Python ç‰ˆæœ¬çš„å‡½æ•°\n",
    "def get_python_version():\n",
    "    return platform.python_version() # è·å– Python ç‰ˆæœ¬\n",
    "\n",
    "# è·å– Conda ç‰ˆæœ¬çš„å‡½æ•°\n",
    "def get_conda_version():\n",
    "    try:\n",
    "        # å°è¯•ä½¿ç”¨ conda --version è·å– Conda ç‰ˆæœ¬\n",
    "        result = subprocess.run(['conda', '--version'], capture_output=True, text=True)\n",
    "        if result.returncode == 0: # å¦‚æœå‘½ä»¤æˆåŠŸæ‰§è¡Œ\n",
    "            return result.stdout.strip() # è¿”å› Conda ç‰ˆæœ¬\n",
    "        return \"Conda not found or version not parsed\" # å¦‚æœæ‰¾ä¸åˆ° Conda æˆ–ç‰ˆæœ¬æ— æ³•è§£æï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "    except FileNotFoundError:\n",
    "        return \"Conda not found\" # å¦‚æœæ‰¾ä¸åˆ° conda å‘½ä»¤ï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "\n",
    "# è·å–ç‰©ç†ç£ç›˜ç©ºé—´ä¿¡æ¯çš„å‡½æ•°\n",
    "def get_disk_space():\n",
    "    try:\n",
    "        total, used, free = shutil.disk_usage(\"/\") # è·å–æ ¹ç›®å½•çš„ç£ç›˜ä½¿ç”¨æƒ…å†µ\n",
    "        total_gb = total / (1024**3) # è½¬æ¢ä¸º GB\n",
    "        used_gb = used / (1024**3) # è½¬æ¢ä¸º GB\n",
    "        free_gb = free / (1024**3) # è½¬æ¢ä¸º GB\n",
    "        return f\"Total: {total_gb:.2f} GB, Used: {used_gb:.2f} GB, Free: {free_gb:.2f} GB\" # æ ¼å¼åŒ–è¾“å‡º\n",
    "    except Exception as e:\n",
    "        return f\"Could not retrieve disk info: {e}\" # å¦‚æœè·å–ä¿¡æ¯å‡ºé”™ï¼Œè®¾ç½®é”™è¯¯ä¿¡æ¯\n",
    "\n",
    "# è·å–ç¯å¢ƒä¿¡æ¯\n",
    "os_name = platform.system() # è·å–æ“ä½œç³»ç»Ÿåç§°\n",
    "os_version = platform.release() # è·å–æ“ä½œç³»ç»Ÿç‰ˆæœ¬\n",
    "if os_name == \"Linux\":\n",
    "    try:\n",
    "        # åœ¨ Linux ä¸Šå°è¯•è·å–å‘è¡Œç‰ˆå’Œç‰ˆæœ¬\n",
    "        lsb_info = subprocess.run(['lsb_release', '-a'], capture_output=True, text=True)\n",
    "        if lsb_info.returncode == 0: # å¦‚æœå‘½ä»¤æˆåŠŸæ‰§è¡Œ\n",
    "            for line in lsb_info.stdout.splitlines():\n",
    "                if 'Description:' in line: # æŸ¥æ‰¾åŒ…å« 'Description:' çš„è¡Œ\n",
    "                    os_version = line.split('Description:')[1].strip() # æå–æè¿°ä¿¡æ¯ä½œä¸ºç‰ˆæœ¬\n",
    "                    break # æ‰¾åˆ°åé€€å‡ºå¾ªç¯\n",
    "                elif 'Release:' in line: # æŸ¥æ‰¾åŒ…å« 'Release:' çš„è¡Œ\n",
    "                     os_version = line.split('Release:')[1].strip() # æå–ç‰ˆæœ¬å·\n",
    "                     # å°è¯•è·å– codename\n",
    "                     try:\n",
    "                         codename_info = subprocess.run(['lsb_release', '-c'], capture_output=True, text=True)\n",
    "                         if codename_info.returncode == 0:\n",
    "                             os_version += f\" ({codename_info.stdout.split(':')[1].strip()})\" # å°† codename æ·»åŠ åˆ°ç‰ˆæœ¬ä¿¡æ¯ä¸­\n",
    "                     except:\n",
    "                         pass # å¦‚æœè·å– codename å¤±è´¥åˆ™å¿½ç•¥\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        pass # lsb_release å¯èƒ½æœªå®‰è£…ï¼Œå¿½ç•¥é”™è¯¯\n",
    "\n",
    "full_os_info = f\"{os_name} {os_version}\" # ç»„åˆå®Œæ•´çš„æ“ä½œç³»ç»Ÿä¿¡æ¯\n",
    "cpu_info = get_cpu_info() # è°ƒç”¨å‡½æ•°è·å– CPU ä¿¡æ¯å’Œæ ¸å¿ƒæ•°é‡\n",
    "memory_info = get_memory_info() # è°ƒç”¨å‡½æ•°è·å–å†…å­˜ä¿¡æ¯\n",
    "gpu_info = get_gpu_info() # è°ƒç”¨å‡½æ•°è·å– GPU ä¿¡æ¯å’Œæ˜¾å­˜\n",
    "cuda_version = get_cuda_version() # è°ƒç”¨å‡½æ•°è·å– CUDA ç‰ˆæœ¬\n",
    "python_version = get_python_version() # è°ƒç”¨å‡½æ•°è·å– Python ç‰ˆæœ¬\n",
    "conda_version = get_conda_version() # è°ƒç”¨å‡½æ•°è·å– Conda ç‰ˆæœ¬\n",
    "disk_info = get_disk_space() # è°ƒç”¨å‡½æ•°è·å–ç‰©ç†ç£ç›˜ç©ºé—´ä¿¡æ¯\n",
    "\n",
    "\n",
    "# åˆ›å»ºç”¨äºå­˜å‚¨æ•°æ®çš„å­—å…¸\n",
    "env_data = {\n",
    "    \"é¡¹ç›®\": [ # é¡¹ç›®åç§°åˆ—è¡¨\n",
    "        \"æ“ä½œç³»ç»Ÿ\",\n",
    "        \"CPU ä¿¡æ¯\",\n",
    "        \"å†…å­˜ä¿¡æ¯\",\n",
    "        \"GPU ä¿¡æ¯\",\n",
    "        \"CUDA ä¿¡æ¯\",\n",
    "        \"Python ç‰ˆæœ¬\",\n",
    "        \"Conda ç‰ˆæœ¬\",\n",
    "        \"ç‰©ç†ç£ç›˜ç©ºé—´\" # æ·»åŠ ç‰©ç†ç£ç›˜ç©ºé—´\n",
    "    ],\n",
    "    \"ä¿¡æ¯\": [ # å¯¹åº”çš„ä¿¡æ¯åˆ—è¡¨\n",
    "        full_os_info,\n",
    "        cpu_info,\n",
    "        memory_info,\n",
    "        gpu_info,\n",
    "        cuda_version,\n",
    "        python_version,\n",
    "        conda_version,\n",
    "        disk_info # æ·»åŠ ç‰©ç†ç£ç›˜ç©ºé—´ä¿¡æ¯\n",
    "    ]\n",
    "}\n",
    "\n",
    "# åˆ›å»ºä¸€ä¸ª pandas DataFrame\n",
    "df = pd.DataFrame(env_data)\n",
    "\n",
    "# æ‰“å°è¡¨æ ¼\n",
    "print(\"### ç¯å¢ƒä¿¡æ¯\") # æ‰“å°æ ‡é¢˜\n",
    "print(df.to_markdown(index=False)) # å°† DataFrame è½¬æ¢ä¸º Markdown æ ¼å¼å¹¶æ‰“å°ï¼Œä¸åŒ…å«ç´¢å¼•"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bj_P8PUQjFFT"
   },
   "source": [
    "## ğŸ“¦ ç¬¬äºŒæ­¥ï¼šå®‰è£…ä¾èµ–åŒ…\n",
    "\n",
    "ç°åœ¨æˆ‘ä»¬éœ€è¦å®‰è£…è¿è¡Œæ¨¡å‹æ‰€éœ€çš„å…³é”® Python åŒ…ï¼š\n",
    "\n",
    "### ğŸ”§ æ ¸å¿ƒä¾èµ–è¯´æ˜\n",
    "\n",
    "#### 1. **FastAPI (0.116.0)**\n",
    "- **ä½œç”¨**: ç°ä»£åŒ–çš„ Python Web æ¡†æ¶\n",
    "- **ç”¨é€”**: åˆ›å»º RESTful API æ¥å£æœåŠ¡\n",
    "- **ç‰¹ç‚¹**: è‡ªåŠ¨ç”Ÿæˆ API æ–‡æ¡£ï¼Œæ”¯æŒå¼‚æ­¥å¤„ç†\n",
    "\n",
    "#### 2. **nest-asyncio (1.6.0)**\n",
    "- **ä½œç”¨**: å…è®¸åœ¨å·²æœ‰äº‹ä»¶å¾ªç¯ä¸­è¿è¡Œå¼‚æ­¥ä»£ç \n",
    "- **ç”¨é€”**: è§£å†³ Jupyter ç¯å¢ƒä¸­çš„å¼‚æ­¥å…¼å®¹é—®é¢˜\n",
    "- **é‡è¦æ€§**: ç¡®ä¿ FastAPI åœ¨ Colab ä¸­æ­£å¸¸è¿è¡Œ\n",
    "\n",
    "#### 3. **pyngrok (7.2.12)**\n",
    "- **ä½œç”¨**: Python ç‰ˆæœ¬çš„ ngrok å®¢æˆ·ç«¯\n",
    "- **ç”¨é€”**: åˆ›å»ºå…¬ç½‘éš§é“ï¼Œè®©å¤–éƒ¨è®¿é—®æœ¬åœ°æœåŠ¡\n",
    "- **åœºæ™¯**: å°† Colab ä¸­çš„ API æœåŠ¡æš´éœ²ç»™å¤–éƒ¨\n",
    "\n",
    "#### 4. **uvicorn (0.35.0)**\n",
    "- **ä½œç”¨**: é«˜æ€§èƒ½çš„ ASGI æœåŠ¡å™¨\n",
    "- **ç”¨é€”**: è¿è¡Œ FastAPI åº”ç”¨ç¨‹åº\n",
    "- **ç‰¹ç‚¹**: æ”¯æŒå¼‚æ­¥å¤„ç†ï¼Œæ€§èƒ½ä¼˜å¼‚\n",
    "\n",
    "#### 5. **vllm (0.9.2)**\n",
    "- **ä½œç”¨**: é«˜æ€§èƒ½å¤§è¯­è¨€æ¨¡å‹æ¨ç†å¼•æ“\n",
    "- **ç”¨é€”**: åŠ è½½å’Œè¿è¡Œ DeepSeek æ¨¡å‹\n",
    "- **ä¼˜åŠ¿**: å†…å­˜é«˜æ•ˆï¼Œæ¨ç†é€Ÿåº¦å¿«\n",
    "\n",
    "### âš¡ å®‰è£…è¿‡ç¨‹\n",
    "ä¸‹é¢çš„å‘½ä»¤ä¼šå®‰è£…æ‰€æœ‰å¿…éœ€çš„ä¾èµ–åŒ…ï¼Œè¯·è€å¿ƒç­‰å¾…å®‰è£…å®Œæˆã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ebACUjhXSwzJ",
    "outputId": "128ed3db-53aa-48c7-ae04-2b2e4dc500de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fastapi==0.116.0\n",
      "  Using cached fastapi-0.116.0-py3-none-any.whl.metadata (28 kB)\n",
      "Requirement already satisfied: nest-asyncio==1.6.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (1.6.0)\n",
      "Collecting pyngrok==7.2.12\n",
      "  Using cached pyngrok-7.2.12-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting uvicorn==0.35.0\n",
      "  Using cached uvicorn-0.35.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting vllm==0.9.2\n",
      "  Using cached vllm-0.9.2-cp38-abi3-manylinux1_x86_64.whl.metadata (15 kB)\n",
      "Collecting starlette<0.47.0,>=0.40.0 (from fastapi==0.116.0)\n",
      "  Using cached starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from fastapi==0.116.0) (2.11.10)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from fastapi==0.116.0) (4.15.0)\n",
      "Collecting PyYAML>=5.1 (from pyngrok==7.2.12)\n",
      "  Using cached pyyaml-6.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)\n",
      "Collecting click>=7.0 (from uvicorn==0.35.0)\n",
      "  Using cached click-8.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: h11>=0.8 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from uvicorn==0.35.0) (0.16.0)\n",
      "Requirement already satisfied: regex in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from vllm==0.9.2) (2025.9.18)\n",
      "Collecting cachetools (from vllm==0.9.2)\n",
      "  Using cached cachetools-6.2.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: psutil in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from vllm==0.9.2) (7.1.0)\n",
      "Collecting sentencepiece (from vllm==0.9.2)\n",
      "  Using cached sentencepiece-0.2.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from vllm==0.9.2) (2.2.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from vllm==0.9.2) (2.32.5)\n",
      "Requirement already satisfied: tqdm in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from vllm==0.9.2) (4.67.1)\n",
      "Collecting blake3 (from vllm==0.9.2)\n",
      "  Using cached blake3-1.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (217 bytes)\n",
      "Collecting py-cpuinfo (from vllm==0.9.2)\n",
      "  Using cached py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Collecting transformers>=4.51.1 (from vllm==0.9.2)\n",
      "  Using cached transformers-4.57.0-py3-none-any.whl.metadata (41 kB)\n",
      "Collecting huggingface-hub>=0.33.0 (from huggingface-hub[hf_xet]>=0.33.0->vllm==0.9.2)\n",
      "  Using cached huggingface_hub-0.35.3-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting tokenizers>=0.21.1 (from vllm==0.9.2)\n",
      "  Using cached tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting protobuf (from vllm==0.9.2)\n",
      "  Using cached protobuf-6.32.1-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Collecting aiohttp (from vllm==0.9.2)\n",
      "  Using cached aiohttp-3.13.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)\n",
      "Collecting openai<=1.90.0,>=1.52.0 (from vllm==0.9.2)\n",
      "  Using cached openai-1.90.0-py3-none-any.whl.metadata (26 kB)\n",
      "Collecting prometheus_client>=0.18.0 (from vllm==0.9.2)\n",
      "  Using cached prometheus_client-0.23.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: pillow in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from vllm==0.9.2) (11.3.0)\n",
      "Collecting prometheus-fastapi-instrumentator>=7.0.0 (from vllm==0.9.2)\n",
      "  Using cached prometheus_fastapi_instrumentator-7.1.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: tiktoken>=0.6.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from vllm==0.9.2) (0.11.0)\n",
      "Collecting lm-format-enforcer<0.11,>=0.10.11 (from vllm==0.9.2)\n",
      "  Using cached lm_format_enforcer-0.10.12-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting llguidance<0.8.0,>=0.7.11 (from vllm==0.9.2)\n",
      "  Using cached llguidance-0.7.30-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Collecting outlines==0.1.11 (from vllm==0.9.2)\n",
      "  Using cached outlines-0.1.11-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting lark==1.2.2 (from vllm==0.9.2)\n",
      "  Using cached lark-1.2.2-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting xgrammar==0.1.19 (from vllm==0.9.2)\n",
      "  Using cached xgrammar-0.1.19-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Collecting filelock>=3.16.1 (from vllm==0.9.2)\n",
      "  Using cached filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting partial-json-parser (from vllm==0.9.2)\n",
      "  Using cached partial_json_parser-0.2.1.1.post6-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: pyzmq>=25.0.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from vllm==0.9.2) (27.1.0)\n",
      "Collecting msgspec (from vllm==0.9.2)\n",
      "  Using cached msgspec-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
      "Collecting gguf>=0.13.0 (from vllm==0.9.2)\n",
      "  Using cached gguf-0.17.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting mistral_common>=1.6.2 (from mistral_common[opencv]>=1.6.2->vllm==0.9.2)\n",
      "  Using cached mistral_common-1.8.5-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting opencv-python-headless>=4.11.0 (from vllm==0.9.2)\n",
      "  Using cached opencv_python_headless-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (19 kB)\n",
      "Collecting einops (from vllm==0.9.2)\n",
      "  Using cached einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting compressed-tensors==0.10.2 (from vllm==0.9.2)\n",
      "  Using cached compressed_tensors-0.10.2-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting depyf==0.18.0 (from vllm==0.9.2)\n",
      "  Using cached depyf-0.18.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting cloudpickle (from vllm==0.9.2)\n",
      "  Using cached cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting watchfiles (from vllm==0.9.2)\n",
      "  Using cached watchfiles-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting python-json-logger (from vllm==0.9.2)\n",
      "  Using cached python_json_logger-4.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting scipy (from vllm==0.9.2)\n",
      "  Using cached scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting ninja (from vllm==0.9.2)\n",
      "  Using cached ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.1 kB)\n",
      "Collecting pybase64 (from vllm==0.9.2)\n",
      "  Using cached pybase64-1.4.2-cp310-cp310-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n",
      "Collecting numba==0.61.2 (from vllm==0.9.2)\n",
      "  Using cached numba-0.61.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)\n",
      "Collecting ray!=2.44.*,>=2.43.0 (from ray[cgraph]!=2.44.*,>=2.43.0->vllm==0.9.2)\n",
      "  Using cached ray-2.49.2-cp310-cp310-manylinux2014_x86_64.whl.metadata (21 kB)\n",
      "Collecting torch==2.7.0 (from vllm==0.9.2)\n",
      "  Using cached torch-2.7.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
      "Collecting torchaudio==2.7.0 (from vllm==0.9.2)\n",
      "  Using cached torchaudio-2.7.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting torchvision==0.22.0 (from vllm==0.9.2)\n",
      "  Using cached torchvision-0.22.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
      "Collecting xformers==0.0.30 (from vllm==0.9.2)\n",
      "  Using cached xformers-0.0.30-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
      "Collecting astor (from depyf==0.18.0->vllm==0.9.2)\n",
      "  Using cached astor-0.8.1-py2.py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting dill (from depyf==0.18.0->vllm==0.9.2)\n",
      "  Using cached dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting llvmlite<0.45,>=0.44.0dev0 (from numba==0.61.2->vllm==0.9.2)\n",
      "  Using cached llvmlite-0.44.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
      "Collecting interegular (from outlines==0.1.11->vllm==0.9.2)\n",
      "  Using cached interegular-0.3.3-py37-none-any.whl.metadata (3.0 kB)\n",
      "Collecting jinja2 (from outlines==0.1.11->vllm==0.9.2)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting diskcache (from outlines==0.1.11->vllm==0.9.2)\n",
      "  Using cached diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting referencing (from outlines==0.1.11->vllm==0.9.2)\n",
      "  Using cached referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting jsonschema (from outlines==0.1.11->vllm==0.9.2)\n",
      "  Using cached jsonschema-4.25.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting pycountry (from outlines==0.1.11->vllm==0.9.2)\n",
      "  Using cached pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting airportsdata (from outlines==0.1.11->vllm==0.9.2)\n",
      "  Using cached airportsdata-20250909-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting outlines_core==0.1.26 (from outlines==0.1.11->vllm==0.9.2)\n",
      "  Using cached outlines_core-0.1.26-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting sympy>=1.13.3 (from torch==2.7.0->vllm==0.9.2)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch==2.7.0->vllm==0.9.2)\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting fsspec (from torch==2.7.0->vllm==0.9.2)\n",
      "  Using cached fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch==2.7.0->vllm==0.9.2)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch==2.7.0->vllm==0.9.2)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch==2.7.0->vllm==0.9.2)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch==2.7.0->vllm==0.9.2)\n",
      "  Using cached nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.6.4.1 (from torch==2.7.0->vllm==0.9.2)\n",
      "  Using cached nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch==2.7.0->vllm==0.9.2)\n",
      "  Using cached nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.7.77 (from torch==2.7.0->vllm==0.9.2)\n",
      "  Using cached nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch==2.7.0->vllm==0.9.2)\n",
      "  Using cached nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch==2.7.0->vllm==0.9.2)\n",
      "  Using cached nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch==2.7.0->vllm==0.9.2)\n",
      "  Using cached nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-nccl-cu12==2.26.2 (from torch==2.7.0->vllm==0.9.2)\n",
      "  Using cached nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.6.77 (from torch==2.7.0->vllm==0.9.2)\n",
      "  Using cached nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch==2.7.0->vllm==0.9.2)\n",
      "  Using cached nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufile-cu12==1.11.1.6 (from torch==2.7.0->vllm==0.9.2)\n",
      "  Using cached nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.3.0 (from torch==2.7.0->vllm==0.9.2)\n",
      "  Using cached triton-3.3.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from triton==3.3.0->torch==2.7.0->vllm==0.9.2) (78.1.1)\n",
      "Requirement already satisfied: packaging in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from lm-format-enforcer<0.11,>=0.10.11->vllm==0.9.2) (25.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from openai<=1.90.0,>=1.52.0->vllm==0.9.2) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from openai<=1.90.0,>=1.52.0->vllm==0.9.2) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from openai<=1.90.0,>=1.52.0->vllm==0.9.2) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from openai<=1.90.0,>=1.52.0->vllm==0.9.2) (0.11.0)\n",
      "Requirement already satisfied: sniffio in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from openai<=1.90.0,>=1.52.0->vllm==0.9.2) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<=1.90.0,>=1.52.0->vllm==0.9.2) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<=1.90.0,>=1.52.0->vllm==0.9.2) (3.10)\n",
      "Requirement already satisfied: certifi in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai<=1.90.0,>=1.52.0->vllm==0.9.2) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai<=1.90.0,>=1.52.0->vllm==0.9.2) (1.0.9)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi==0.116.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi==0.116.0) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi==0.116.0) (0.4.2)\n",
      "Collecting fastapi-cli>=0.0.8 (from fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2)\n",
      "  Using cached fastapi_cli-0.0.13-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting python-multipart>=0.0.18 (from fastapi[standard]>=0.115.0->vllm==0.9.2)\n",
      "  Using cached python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting email-validator>=2.0.0 (from fastapi[standard]>=0.115.0->vllm==0.9.2)\n",
      "  Using cached email_validator-2.3.0-py3-none-any.whl.metadata (26 kB)\n",
      "Collecting dnspython>=2.0.0 (from email-validator>=2.0.0->fastapi[standard]>=0.115.0->vllm==0.9.2)\n",
      "  Using cached dnspython-2.8.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting typer>=0.15.1 (from fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2)\n",
      "  Using cached typer-0.19.2-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting rich-toolkit>=0.14.8 (from fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2)\n",
      "  Using cached rich_toolkit-0.15.1-py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting fastapi-cloud-cli>=0.1.1 (from fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2)\n",
      "  Using cached fastapi_cloud_cli-0.3.1-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting rignore>=0.5.1 (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2)\n",
      "  Downloading rignore-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting sentry-sdk>=2.20.0 (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2)\n",
      "  Downloading sentry_sdk-2.41.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub>=0.33.0->huggingface-hub[hf_xet]>=0.33.0->vllm==0.9.2)\n",
      "  Downloading hf_xet-1.1.10-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->outlines==0.1.11->vllm==0.9.2)\n",
      "  Downloading markupsafe-3.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.7 kB)\n",
      "Collecting pydantic-extra-types>=2.10.5 (from pydantic-extra-types[pycountry]>=2.10.5->mistral_common>=1.6.2->mistral_common[opencv]>=1.6.2->vllm==0.9.2)\n",
      "  Downloading pydantic_extra_types-2.10.6-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=22.2.0 (from jsonschema->outlines==0.1.11->vllm==0.9.2)\n",
      "  Downloading attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema->outlines==0.1.11->vllm==0.9.2)\n",
      "  Downloading jsonschema_specifications-2025.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema->outlines==0.1.11->vllm==0.9.2)\n",
      "  Downloading rpds_py-0.27.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting msgpack<2.0.0,>=1.0.0 (from ray!=2.44.*,>=2.43.0->ray[cgraph]!=2.44.*,>=2.43.0->vllm==0.9.2)\n",
      "  Downloading msgpack-1.1.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)\n",
      "Collecting cupy-cuda12x (from ray[cgraph]!=2.44.*,>=2.43.0->vllm==0.9.2)\n",
      "  Downloading cupy_cuda12x-13.6.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from requests>=2.26.0->vllm==0.9.2) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from requests>=2.26.0->vllm==0.9.2) (2.5.0)\n",
      "Collecting rich>=13.7.1 (from rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2)\n",
      "  Downloading rich-14.2.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2)\n",
      "  Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2) (2.19.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch==2.7.0->vllm==0.9.2)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers>=4.51.1->vllm==0.9.2)\n",
      "  Downloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer>=0.15.1->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2)\n",
      "  Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2) (1.1.1)\n",
      "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2)\n",
      "  Downloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2)\n",
      "  Downloading websockets-15.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp->vllm==0.9.2)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp->vllm==0.9.2)\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp->vllm==0.9.2)\n",
      "  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->vllm==0.9.2)\n",
      "  Downloading frozenlist-1.8.0-cp310-cp310-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (20 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->vllm==0.9.2)\n",
      "  Downloading multidict-6.7.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->vllm==0.9.2)\n",
      "  Downloading propcache-0.4.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->vllm==0.9.2)\n",
      "  Downloading yarl-1.22.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (75 kB)\n",
      "Collecting fastrlock>=0.5 (from cupy-cuda12x->ray[cgraph]!=2.44.*,>=2.43.0->vllm==0.9.2)\n",
      "  Downloading fastrlock-0.8.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl.metadata (7.7 kB)\n",
      "Downloading fastapi-0.116.0-py3-none-any.whl (95 kB)\n",
      "Downloading pyngrok-7.2.12-py3-none-any.whl (26 kB)\n",
      "Downloading uvicorn-0.35.0-py3-none-any.whl (66 kB)\n",
      "Downloading vllm-0.9.2-cp38-abi3-manylinux1_x86_64.whl (383.4 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m383.4/383.4 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m  \u001b[33m0:01:36\u001b[0mm0:00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading compressed_tensors-0.10.2-py3-none-any.whl (169 kB)\n",
      "Downloading depyf-0.18.0-py3-none-any.whl (38 kB)\n",
      "Downloading lark-1.2.2-py3-none-any.whl (111 kB)\n",
      "Downloading numba-0.61.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.8 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading outlines-0.1.11-py3-none-any.whl (87 kB)\n",
      "Downloading outlines_core-0.1.26-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (343 kB)\n",
      "Downloading torch-2.7.0-cp310-cp310-manylinux_2_28_x86_64.whl (865.2 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m865.2/865.2 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m  \u001b[33m0:03:05\u001b[0mm0:00:01\u001b[0m00:06\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m  \u001b[33m0:01:25\u001b[0mm0:00:01\u001b[0m00:03\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m eta \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m  \u001b[33m0:00:05\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m696.8 kB/s\u001b[0m  \u001b[33m0:00:01\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m  \u001b[33m0:02:29\u001b[0mm0:00:01\u001b[0m00:05\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m  \u001b[33m0:01:29\u001b[0mm0:00:01\u001b[0m00:03\u001b[0mm\n",
      "\u001b[?25hDownloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m  \u001b[33m0:00:18\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m  \u001b[33m0:01:05\u001b[0mm0:00:01\u001b[0m00:03\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m  \u001b[33m0:01:39\u001b[0mm0:00:01\u001b[0m00:03\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m  \u001b[33m0:01:03\u001b[0mm0:00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m  \u001b[33m0:01:13\u001b[0mm0:00:01\u001b[0m00:03\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m  \u001b[33m0:00:07\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Downloading torchaudio-2.7.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.4 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.22.0-cp310-cp310-manylinux_2_28_x86_64.whl (7.4 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading triton-3.3.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (156.4 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m156.4/156.4 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m  \u001b[33m0:00:56\u001b[0mm0:00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading xformers-0.0.30-cp310-cp310-manylinux_2_28_x86_64.whl (31.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m31.5/31.5 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m  \u001b[33m0:00:12\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading xgrammar-0.1.19-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading llguidance-0.7.30-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.0 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m15.0/15.0 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m  \u001b[33m0:00:05\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading llvmlite-0.44.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.4 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m  \u001b[33m0:00:17\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading lm_format_enforcer-0.10.12-py3-none-any.whl (44 kB)\n",
      "Downloading openai-1.90.0-py3-none-any.whl (734 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m734.6/734.6 kB\u001b[0m \u001b[31m513.8 kB/s\u001b[0m  \u001b[33m0:00:01\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
      "Downloading click-8.3.0-py3-none-any.whl (107 kB)\n",
      "Downloading email_validator-2.3.0-py3-none-any.whl (35 kB)\n",
      "Downloading dnspython-2.8.0-py3-none-any.whl (331 kB)\n",
      "Downloading fastapi_cli-0.0.13-py3-none-any.whl (11 kB)\n",
      "Downloading fastapi_cloud_cli-0.3.1-py3-none-any.whl (19 kB)\n",
      "Downloading filelock-3.20.0-py3-none-any.whl (16 kB)\n",
      "Downloading gguf-0.17.1-py3-none-any.whl (96 kB)\n",
      "Downloading huggingface_hub-0.35.3-py3-none-any.whl (564 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m564.3/564.3 kB\u001b[0m \u001b[31m227.2 kB/s\u001b[0m  \u001b[33m0:00:02\u001b[0mm-:--:--\u001b[0m\n",
      "\u001b[?25hDownloading hf_xet-1.1.10-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m314.5 kB/s\u001b[0m  \u001b[33m0:00:10\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\n",
      "Downloading interegular-0.3.3-py37-none-any.whl (23 kB)\n",
      "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading markupsafe-3.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (20 kB)\n",
      "Downloading mistral_common-1.8.5-py3-none-any.whl (6.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m580.0 kB/s\u001b[0m  \u001b[33m0:00:11\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading jsonschema-4.25.1-py3-none-any.whl (90 kB)\n",
      "Downloading attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "Downloading jsonschema_specifications-2025.9.1-py3-none-any.whl (18 kB)\n",
      "Downloading opencv_python_headless-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (54.0 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.0/54.0 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m  \u001b[33m0:00:36\u001b[0mm0:00:01\u001b[0m00:02\u001b[0mm\n",
      "\u001b[?25hDownloading prometheus_client-0.23.1-py3-none-any.whl (61 kB)\n",
      "Downloading prometheus_fastapi_instrumentator-7.1.0-py3-none-any.whl (19 kB)\n",
      "Downloading pydantic_extra_types-2.10.6-py3-none-any.whl (40 kB)\n",
      "Downloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Downloading pyyaml-6.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (770 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m770.3/770.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m36m-:--:--\u001b[0m\n",
      "\u001b[?25hDownloading ray-2.49.2-cp310-cp310-manylinux2014_x86_64.whl (69.9 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m69.9/69.9 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m  \u001b[33m0:00:32\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading msgpack-1.1.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (406 kB)\n",
      "Downloading protobuf-6.32.1-cp39-abi3-manylinux2014_x86_64.whl (322 kB)\n",
      "Downloading referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "Downloading rich_toolkit-0.15.1-py3-none-any.whl (29 kB)\n",
      "Downloading rich-14.2.0-py3-none-any.whl (243 kB)\n",
      "Downloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading rignore-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (951 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m951.3/951.3 kB\u001b[0m \u001b[31m389.4 kB/s\u001b[0m  \u001b[33m0:00:02\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading rpds_py-0.27.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (384 kB)\n",
      "Downloading sentry_sdk-2.41.0-py2.py3-none-any.whl (370 kB)\n",
      "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m666.6 kB/s\u001b[0m  \u001b[33m0:00:09\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m703.4 kB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm-:--:--\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m807.9 kB/s\u001b[0m  \u001b[33m0:00:04\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.57.0-py3-none-any.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m793.6 kB/s\u001b[0m  \u001b[33m0:00:15\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (485 kB)\n",
      "Downloading typer-0.19.2-py3-none-any.whl (46 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (442 kB)\n",
      "Downloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m484.4 kB/s\u001b[0m  \u001b[33m0:00:08\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading watchfiles-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (453 kB)\n",
      "Downloading websockets-15.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (181 kB)\n",
      "Downloading aiohttp-3.13.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m865.8 kB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Downloading multidict-6.7.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (241 kB)\n",
      "Downloading yarl-1.22.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (346 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading frozenlist-1.8.0-cp310-cp310-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (219 kB)\n",
      "Downloading propcache-0.4.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (196 kB)\n",
      "Downloading airportsdata-20250909-py3-none-any.whl (914 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m914.4/914.4 kB\u001b[0m \u001b[31m407.0 kB/s\u001b[0m  \u001b[33m0:00:02\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Downloading blake3-1.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (387 kB)\n",
      "Downloading cachetools-6.2.0-py3-none-any.whl (11 kB)\n",
      "Downloading cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading cupy_cuda12x-13.6.0-cp310-cp310-manylinux2014_x86_64.whl (112.2 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m112.2/112.2 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m  \u001b[33m0:01:16\u001b[0mm0:00:01\u001b[0m00:02\u001b[0mm\n",
      "\u001b[?25hDownloading fastrlock-0.8.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl (53 kB)\n",
      "Downloading dill-0.4.0-py3-none-any.whl (119 kB)\n",
      "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "Downloading einops-0.8.1-py3-none-any.whl (64 kB)\n",
      "Downloading msgspec-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (211 kB)\n",
      "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m259.3 kB/s\u001b[0m  \u001b[33m0:00:06\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (180 kB)\n",
      "Downloading partial_json_parser-0.2.1.1.post6-py3-none-any.whl (10 kB)\n",
      "Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Downloading pybase64-1.4.2-cp310-cp310-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (68 kB)\n",
      "Downloading python_json_logger-4.0.0-py3-none-any.whl (15 kB)\n",
      "Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.7 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m37.7/37.7 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m  \u001b[33m0:00:43\u001b[0mm0:00:01\u001b[0m00:02\u001b[0m0m\n",
      "\u001b[?25hDownloading sentencepiece-0.2.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: py-cpuinfo, nvidia-cusparselt-cu12, mpmath, fastrlock, websockets, uvloop, triton, sympy, shellingham, sentry-sdk, sentencepiece, scipy, safetensors, rpds-py, rignore, PyYAML, python-multipart, python-json-logger, pycountry, pybase64, protobuf, propcache, prometheus_client, partial-json-parser, opencv-python-headless, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ninja, networkx, multidict, msgspec, msgpack, mdurl, MarkupSafe, llvmlite, llguidance, lark, interegular, httptools, hf-xet, fsspec, frozenlist, filelock, einops, dnspython, diskcache, dill, cupy-cuda12x, cloudpickle, click, cachetools, blake3, attrs, async-timeout, astor, airportsdata, aiohappyeyeballs, yarl, uvicorn, referencing, pyngrok, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, numba, markdown-it-py, jinja2, huggingface-hub, gguf, email-validator, depyf, aiosignal, watchfiles, tokenizers, starlette, rich, pydantic-extra-types, nvidia-cusolver-cu12, lm-format-enforcer, jsonschema-specifications, aiohttp, typer, transformers, torch, rich-toolkit, prometheus-fastapi-instrumentator, openai, jsonschema, fastapi, xgrammar, xformers, torchvision, torchaudio, ray, outlines_core, mistral_common, fastapi-cloud-cli, fastapi-cli, compressed-tensors, outlines, vllm\n",
      "\u001b[2K  Attempting uninstall: openaiâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”\u001b[0m \u001b[32m 90/108\u001b[0m [torch]ormers]er-cu12]2]2]\n",
      "\u001b[2K    Found existing installation: openai 1.107.0\u001b[0m\u001b[90mâ”â”â”â”â”â”\u001b[0m \u001b[32m 90/108\u001b[0m [torch]\n",
      "\u001b[2K    Uninstalling openai-1.107.0:â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”\u001b[0m \u001b[32m 93/108\u001b[0m [openai]\n",
      "\u001b[2K      Successfully uninstalled openai-1.107.0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”\u001b[0m \u001b[32m 93/108\u001b[0m [openai]\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m108/108\u001b[0m [vllm]0m [vllm]nes]mistral_common]\n",
      "\u001b[1A\u001b[2KSuccessfully installed MarkupSafe-3.0.3 PyYAML-6.0.3 aiohappyeyeballs-2.6.1 aiohttp-3.13.0 aiosignal-1.4.0 airportsdata-20250909 astor-0.8.1 async-timeout-5.0.1 attrs-25.4.0 blake3-1.0.7 cachetools-6.2.0 click-8.3.0 cloudpickle-3.1.1 compressed-tensors-0.10.2 cupy-cuda12x-13.6.0 depyf-0.18.0 dill-0.4.0 diskcache-5.6.3 dnspython-2.8.0 einops-0.8.1 email-validator-2.3.0 fastapi-0.116.0 fastapi-cli-0.0.13 fastapi-cloud-cli-0.3.1 fastrlock-0.8.3 filelock-3.20.0 frozenlist-1.8.0 fsspec-2025.9.0 gguf-0.17.1 hf-xet-1.1.10 httptools-0.6.4 huggingface-hub-0.35.3 interegular-0.3.3 jinja2-3.1.6 jsonschema-4.25.1 jsonschema-specifications-2025.9.1 lark-1.2.2 llguidance-0.7.30 llvmlite-0.44.0 lm-format-enforcer-0.10.12 markdown-it-py-4.0.0 mdurl-0.1.2 mistral_common-1.8.5 mpmath-1.3.0 msgpack-1.1.2 msgspec-0.19.0 multidict-6.7.0 networkx-3.4.2 ninja-1.13.0 numba-0.61.2 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 openai-1.90.0 opencv-python-headless-4.12.0.88 outlines-0.1.11 outlines_core-0.1.26 partial-json-parser-0.2.1.1.post6 prometheus-fastapi-instrumentator-7.1.0 prometheus_client-0.23.1 propcache-0.4.1 protobuf-6.32.1 py-cpuinfo-9.0.0 pybase64-1.4.2 pycountry-24.6.1 pydantic-extra-types-2.10.6 pyngrok-7.2.12 python-json-logger-4.0.0 python-multipart-0.0.20 ray-2.49.2 referencing-0.36.2 rich-14.2.0 rich-toolkit-0.15.1 rignore-0.7.0 rpds-py-0.27.1 safetensors-0.6.2 scipy-1.15.3 sentencepiece-0.2.1 sentry-sdk-2.41.0 shellingham-1.5.4 starlette-0.46.2 sympy-1.14.0 tokenizers-0.22.1 torch-2.7.0 torchaudio-2.7.0 torchvision-0.22.0 transformers-4.57.0 triton-3.3.0 typer-0.19.2 uvicorn-0.35.0 uvloop-0.21.0 vllm-0.9.2 watchfiles-1.1.0 websockets-15.0.1 xformers-0.0.30 xgrammar-0.1.19 yarl-1.22.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# ğŸ“¦ æ‰¹é‡å®‰è£…ä¾èµ–åŒ…\n",
    "#\n",
    "# è¿™é‡Œä½¿ç”¨ pip install å‘½ä»¤ä¸€æ¬¡æ€§å®‰è£…æ‰€æœ‰å¿…éœ€çš„åŒ…\n",
    "# ä½¿ç”¨ \\ ç¬¦å·å¯ä»¥å°†é•¿å‘½ä»¤åˆ†æˆå¤šè¡Œï¼Œæé«˜å¯è¯»æ€§\n",
    "#\n",
    "# å®‰è£…è¿‡ç¨‹å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿæ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…\n",
    "# å¦‚æœå‡ºç°ç‰ˆæœ¬å†²çªï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨å¤„ç†ä¾èµ–å…³ç³»\n",
    "\n",
    "!pip install --index-url https://pypi.org/simple \\\n",
    "    fastapi==0.116.0 \\\n",
    "    nest-asyncio==1.6.0 \\\n",
    "    pyngrok==7.2.12 \\\n",
    "    uvicorn==0.35.0 \\\n",
    "    vllm==0.9.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jFI6d95RjNzd"
   },
   "source": [
    "## ğŸš€ ç¬¬ä¸‰æ­¥ï¼šå¯åŠ¨ VLLM æ¨¡å‹æœåŠ¡\n",
    "\n",
    "ç°åœ¨æˆ‘ä»¬å°†ä½¿ç”¨ VLLM åœ¨åå°å¯åŠ¨ DeepSeek R1 è’¸é¦ç‰ˆæ¨¡å‹æœåŠ¡ã€‚\n",
    "\n",
    "### ğŸ¯ VLLM æœåŠ¡å¯åŠ¨è¯´æ˜\n",
    "\n",
    "#### ğŸ” æ¨¡å‹é€‰æ‹©\n",
    "- **æ¨¡å‹æ¥æº**: [Hugging Face DeepSeek AI](https://huggingface.co/deepseek-ai/DeepSeek-R1#3-model-downloads)\n",
    "- **å½“å‰æ¨¡å‹**: `deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B`\n",
    "- **å‚æ•°è§„æ¨¡**: 15äº¿å‚æ•°ï¼Œé€‚åˆ T4 GPU è¿è¡Œ\n",
    "- **æ›¿æ¢é€‰é¡¹**: å¯ä»¥æ›¿æ¢ä¸ºå…¶ä»– DeepSeek R1 ç³»åˆ—æ¨¡å‹\n",
    "\n",
    "#### âš™ï¸ VLLM å‚æ•°è§£é‡Š\n",
    "- `serve`: VLLM çš„æœåŠ¡æ¨¡å¼å‘½ä»¤\n",
    "- `--trust-remote-code`: å…è®¸æ‰§è¡Œè¿œç¨‹ä»£ç ï¼ˆæ¨¡å‹é…ç½®ï¼‰\n",
    "- `--dtype half`: ä½¿ç”¨åŠç²¾åº¦æµ®ç‚¹æ•°ï¼ŒèŠ‚çœæ˜¾å­˜\n",
    "- `--max-model-len 16384`: æœ€å¤§åºåˆ—é•¿åº¦ä¸º 16K tokens\n",
    "- `--tensor-parallel-size 1`: ä½¿ç”¨å•å¡æ¨ç†\n",
    "\n",
    "#### ğŸ”„ åå°è¿è¡Œ\n",
    "æ¨¡å‹å°†åœ¨åå°å¯åŠ¨ï¼Œä¸ä¼šé˜»å¡å½“å‰è¿›ç¨‹ï¼Œè¿™æ ·æˆ‘ä»¬å¯ä»¥ç»§ç»­æ‰§è¡Œå…¶ä»–ä»£ç ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E4FjRHNbcFYl",
    "outputId": "8373be37-9270-4159-c8e3-9e0ee77a1f24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ æ­£åœ¨å¯åŠ¨ VLLM æœåŠ¡ï¼Œæ¨¡å‹: deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\n",
      "â³ é¦–æ¬¡è¿è¡Œéœ€è¦ä¸‹è½½æ¨¡å‹ï¼Œè¯·è€å¿ƒç­‰å¾…...\n",
      "âœ… VLLM æœåŠ¡å¯åŠ¨å‘½ä»¤å·²æ‰§è¡Œï¼Œæ­£åœ¨åå°åŠ è½½æ¨¡å‹...\n",
      "ğŸ“¡ æœåŠ¡å°†åœ¨ http://localhost:8000 ä¸Šè¿è¡Œ\n"
     ]
    }
   ],
   "source": [
    "# ğŸš€ å¯åŠ¨ VLLM æ¨¡å‹æœåŠ¡\n",
    "#\n",
    "# è¿™ä¸ªå•å…ƒæ ¼çš„ä½œç”¨ï¼š\n",
    "# 1. å¯¼å…¥å¿…è¦çš„ Python æ¨¡å—\n",
    "# 2. é…ç½®æ¨¡å‹å‚æ•°\n",
    "# 3. ä½¿ç”¨ subprocess åœ¨åå°å¯åŠ¨ VLLM æœåŠ¡\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "# ğŸ“ å¯é€‰ï¼šé…ç½® Hugging Face é•œåƒæº\n",
    "# å¦‚æœåœ¨ä¸­å›½å¤§é™†è®¿é—® Hugging Face è¾ƒæ…¢ï¼Œå¯ä»¥å¯ç”¨ä¸‹é¢è¿™è¡Œ\n",
    "os.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com\"\n",
    "\n",
    "# ğŸ¯ æ¨¡å‹é…ç½®\n",
    "# æŒ‡å®šè¦ä½¿ç”¨çš„æ¨¡å‹åç§°\n",
    "# è¿™é‡Œä½¿ç”¨çš„æ˜¯ DeepSeek R1 çš„è’¸é¦ç‰ˆæœ¬ï¼Œå‚æ•°é‡ä¸º 15äº¿\n",
    "model = 'deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B'\n",
    "\n",
    "# ğŸ”§ å¯åŠ¨ VLLM æœåŠ¡å™¨\n",
    "# ä½¿ç”¨ subprocess.Popen åœ¨åå°å¯åŠ¨æœåŠ¡ï¼Œè¿™æ ·ä¸ä¼šé˜»å¡å½“å‰è¿›ç¨‹\n",
    "print(f\"ğŸš€ æ­£åœ¨å¯åŠ¨ VLLM æœåŠ¡ï¼Œæ¨¡å‹: {model}\")\n",
    "print(\"â³ é¦–æ¬¡è¿è¡Œéœ€è¦ä¸‹è½½æ¨¡å‹ï¼Œè¯·è€å¿ƒç­‰å¾…...\")\n",
    "\n",
    "vllm_process = subprocess.Popen([\n",
    "    'vllm',                      # VLLM å‘½ä»¤\n",
    "    'serve',                     # æœåŠ¡æ¨¡å¼\n",
    "    model,                       # æ¨¡å‹åç§°\n",
    "    '--trust-remote-code',       # ä¿¡ä»»è¿œç¨‹ä»£ç \n",
    "    '--dtype', 'half',           # ä½¿ç”¨åŠç²¾åº¦æµ®ç‚¹æ•°\n",
    "    '--max-model-len', '16384',  # æœ€å¤§åºåˆ—é•¿åº¦\n",
    "    '--tensor-parallel-size', '1' # å•å¡æ¨ç†\n",
    "], stdout=subprocess.PIPE, stderr=subprocess.PIPE, start_new_session=True)\n",
    "\n",
    "print(\"âœ… VLLM æœåŠ¡å¯åŠ¨å‘½ä»¤å·²æ‰§è¡Œï¼Œæ­£åœ¨åå°åŠ è½½æ¨¡å‹...\")\n",
    "print(\"ğŸ“¡ æœåŠ¡å°†åœ¨ http://localhost:8000 ä¸Šè¿è¡Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BCR-O8i9lEbb"
   },
   "source": [
    "## ğŸ” ç¬¬å››æ­¥ï¼šç›‘æ§ VLLM æœåŠ¡çŠ¶æ€\n",
    "\n",
    "ç”±äº VLLM åœ¨åå°è¿è¡Œï¼Œæˆ‘ä»¬éœ€è¦ç›‘æ§å…¶å¯åŠ¨çŠ¶æ€ã€‚\n",
    "\n",
    "### ğŸ¯ ç›‘æ§çš„é‡è¦æ€§\n",
    "\n",
    "#### ğŸ”„ ä¸ºä»€ä¹ˆéœ€è¦ç›‘æ§ï¼Ÿ\n",
    "- **å¼‚æ­¥å¯åŠ¨**: VLLM åœ¨åå°å¯åŠ¨ï¼Œéœ€è¦æ—¶é—´åŠ è½½æ¨¡å‹\n",
    "- **çŠ¶æ€ç¡®è®¤**: ç¡®ä¿æœåŠ¡æ­£å¸¸è¿è¡Œåå†è¿›è¡Œåç»­æ“ä½œ\n",
    "- **é”™è¯¯è¯Šæ–­**: åŠæ—¶å‘ç°å’Œå¤„ç†å¯åŠ¨è¿‡ç¨‹ä¸­çš„é—®é¢˜\n",
    "- **èµ„æºç®¡ç†**: ç›‘æ§è¿›ç¨‹çŠ¶æ€ï¼Œé¿å…èµ„æºæ³„æ¼\n",
    "\n",
    "#### â±ï¸ å¯åŠ¨æ—¶é—´è¯´æ˜\n",
    "- **é¦–æ¬¡è¿è¡Œ**: éœ€è¦ä¸‹è½½æ¨¡å‹æ–‡ä»¶ï¼Œå¯èƒ½éœ€è¦ 5-10 åˆ†é’Ÿ\n",
    "- **åç»­è¿è¡Œ**: æ¨¡å‹å·²ç¼“å­˜ï¼Œå¯åŠ¨æ—¶é—´çº¦ 1-2 åˆ†é’Ÿ\n",
    "- **æ£€æŸ¥é¢‘ç‡**: æ¯ 5 ç§’æ£€æŸ¥ä¸€æ¬¡æœåŠ¡çŠ¶æ€\n",
    "\n",
    "#### ğŸš¦ çŠ¶æ€æ£€æŸ¥æœºåˆ¶\n",
    "- **å¥åº·æ£€æŸ¥**: é€šè¿‡ HTTP è¯·æ±‚æ£€æŸ¥æœåŠ¡æ˜¯å¦å¯ç”¨\n",
    "- **è¿›ç¨‹ç›‘æ§**: ç›‘æ§ VLLM è¿›ç¨‹çš„è¿è¡ŒçŠ¶æ€\n",
    "- **æ—¥å¿—è¾“å‡º**: æ˜¾ç¤ºå¯åŠ¨è¿‡ç¨‹ä¸­çš„å…³é”®ä¿¡æ¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "bx5v9mXkvqPo"
   },
   "outputs": [],
   "source": [
    "# ğŸ” VLLM æœåŠ¡ç›‘æ§å‡½æ•°\n",
    "#\n",
    "# è¿™ä¸ªå•å…ƒæ ¼å®šä¹‰äº†ä¸¤ä¸ªé‡è¦çš„ç›‘æ§å‡½æ•°ï¼š\n",
    "# 1. check_vllm_status: æ£€æŸ¥ VLLM æœåŠ¡æ˜¯å¦å¯ç”¨\n",
    "# 2. monitor_vllm_process: æŒç»­ç›‘æ§ VLLM è¿›ç¨‹çŠ¶æ€\n",
    "\n",
    "import requests\n",
    "import time\n",
    "from typing import Tuple\n",
    "import sys\n",
    "\n",
    "def check_vllm_status(url: str = \"http://localhost:8000/health\") -> bool:\n",
    "    \"\"\"\n",
    "    ğŸ¥ æ£€æŸ¥ VLLM æœåŠ¡å™¨å¥åº·çŠ¶æ€\n",
    "\n",
    "    å‚æ•°:\n",
    "        url: å¥åº·æ£€æŸ¥çš„ URL åœ°å€\n",
    "\n",
    "    è¿”å›:\n",
    "        bool: True è¡¨ç¤ºæœåŠ¡æ­£å¸¸ï¼ŒFalse è¡¨ç¤ºæœåŠ¡ä¸å¯ç”¨\n",
    "\n",
    "    å·¥ä½œåŸç†:\n",
    "        å‘ VLLM çš„å¥åº·æ£€æŸ¥ç«¯ç‚¹å‘é€ GET è¯·æ±‚\n",
    "        å¦‚æœè¿”å› 200 çŠ¶æ€ç ï¼Œè¯´æ˜æœåŠ¡æ­£å¸¸è¿è¡Œ\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(url, timeout=5)\n",
    "        return response.status_code == 200\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        return False\n",
    "    except requests.exceptions.Timeout:\n",
    "        return False\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def monitor_vllm_process(vllm_process: subprocess.Popen, check_interval: int = 5) -> Tuple[bool, str, str]:\n",
    "    \"\"\"\n",
    "    ğŸ“Š ç›‘æ§ VLLM è¿›ç¨‹çš„å¯åŠ¨çŠ¶æ€\n",
    "\n",
    "    å‚æ•°:\n",
    "        vllm_process: VLLM è¿›ç¨‹å¯¹è±¡\n",
    "        check_interval: æ£€æŸ¥é—´éš”æ—¶é—´ï¼ˆç§’ï¼‰\n",
    "\n",
    "    è¿”å›:\n",
    "        Tuple[bool, str, str]: (æ˜¯å¦æˆåŠŸ, æ ‡å‡†è¾“å‡º, æ ‡å‡†é”™è¯¯)\n",
    "\n",
    "    å·¥ä½œæµç¨‹:\n",
    "        1. å¾ªç¯æ£€æŸ¥è¿›ç¨‹æ˜¯å¦è¿˜åœ¨è¿è¡Œ\n",
    "        2. å®šæœŸæ£€æŸ¥æœåŠ¡å¥åº·çŠ¶æ€\n",
    "        3. è¾“å‡ºè¿›ç¨‹çš„æ—¥å¿—ä¿¡æ¯\n",
    "        4. è¿”å›æœ€ç»ˆçŠ¶æ€\n",
    "    \"\"\"\n",
    "    print(\"ğŸ” å¼€å§‹ VLLM æœåŠ¡å™¨ç›‘æ§...\")\n",
    "    print(\"â³ æ­£åœ¨ç­‰å¾…æœåŠ¡å¯åŠ¨ï¼Œè¯·è€å¿ƒç­‰å¾…...\")\n",
    "\n",
    "    while vllm_process.poll() is None:  # å½“è¿›ç¨‹ä»åœ¨è¿è¡Œæ—¶\n",
    "        # æ£€æŸ¥æœåŠ¡æ˜¯å¦å·²ç»å¯ç”¨\n",
    "        if check_vllm_status():\n",
    "            print(\"âœ… VLLM æœåŠ¡å™¨å·²å¯åŠ¨å¹¶è¿è¡Œï¼\")\n",
    "            print(\"ğŸ‰ æœåŠ¡åœ°å€: http://localhost:8000\")\n",
    "            return True, \"\", \"\"\n",
    "\n",
    "        print(\"â³ ç­‰å¾… VLLM æœåŠ¡å™¨å¯åŠ¨...\")\n",
    "        time.sleep(check_interval)\n",
    "\n",
    "        # æ£€æŸ¥å¹¶è¾“å‡ºè¿›ç¨‹æ—¥å¿—\n",
    "        if vllm_process.stdout and vllm_process.stdout.readable():\n",
    "            try:\n",
    "                stdout = vllm_process.stdout.read1(1024).decode('utf-8')\n",
    "                if stdout.strip():\n",
    "                    print(\"ğŸ“ æ ‡å‡†è¾“å‡º:\", stdout.strip())\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        if vllm_process.stderr and vllm_process.stderr.readable():\n",
    "            try:\n",
    "                stderr = vllm_process.stderr.read1(1024).decode('utf-8')\n",
    "                if stderr.strip():\n",
    "                    print(\"âš ï¸ æ ‡å‡†é”™è¯¯:\", stderr.strip())\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    # å¦‚æœåˆ°è¾¾è¿™é‡Œï¼Œè¿›ç¨‹å·²ç»“æŸï¼ˆå¯èƒ½æ˜¯é”™è¯¯ï¼‰\n",
    "    print(\"âŒ VLLM è¿›ç¨‹å·²ç»“æŸ\")\n",
    "    try:\n",
    "        stdout, stderr = vllm_process.communicate(timeout=5)\n",
    "        return False, stdout.decode('utf-8'), stderr.decode('utf-8')\n",
    "    except Exception:\n",
    "        return False, \"\", \"è¿›ç¨‹é€šä¿¡è¶…æ—¶\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qEbWUS2nvRJo",
    "outputId": "7b5c34c2-a741-41e3-fde4-30da45a703cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ å¼€å§‹ç›‘æ§ VLLM æœåŠ¡å¯åŠ¨çŠ¶æ€...\n",
      "ğŸ’¡ æç¤ºï¼šé¦–æ¬¡è¿è¡Œå¯èƒ½éœ€è¦ 5-10 åˆ†é’Ÿä¸‹è½½æ¨¡å‹\n",
      "âŒ¨ï¸  æŒ‰ Ctrl+C å¯ä»¥ä¸­æ–­ç›‘æ§ï¼ˆä½†ä¸ä¼šåœæ­¢ VLLM æœåŠ¡ï¼‰\n",
      "ğŸ” å¼€å§‹ VLLM æœåŠ¡å™¨ç›‘æ§...\n",
      "â³ æ­£åœ¨ç­‰å¾…æœåŠ¡å¯åŠ¨ï¼Œè¯·è€å¿ƒç­‰å¾…...\n",
      "âŒ VLLM è¿›ç¨‹å·²ç»“æŸ\n",
      "\n",
      "âŒ VLLM æœåŠ¡å™¨å¯åŠ¨å¤±è´¥ï¼\n",
      "\n",
      "ğŸ“‹ å®Œæ•´æ ‡å‡†è¾“å‡º:\n",
      "INFO 10-10 12:05:21 [__init__.py:248] No platform detected, vLLM is running on UnspecifiedPlatform\n",
      "\n",
      "\n",
      "ğŸš¨ å®Œæ•´æ ‡å‡†é”™è¯¯:\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/envs/agent101/bin/vllm\", line 3, in <module>\n",
      "    from vllm.entrypoints.cli.main import main\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/vllm/entrypoints/cli/__init__.py\", line 3, in <module>\n",
      "    from vllm.entrypoints.cli.benchmark.latency import BenchmarkLatencySubcommand\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/vllm/entrypoints/cli/benchmark/latency.py\", line 5, in <module>\n",
      "    from vllm.benchmarks.latency import add_cli_args, main\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/vllm/benchmarks/latency.py\", line 16, in <module>\n",
      "    from vllm import LLM, SamplingParams\n",
      "  File \"<frozen importlib._bootstrap>\", line 1075, in _handle_fromlist\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/vllm/__init__.py\", line 64, in __getattr__\n",
      "    module = import_module(module_name, __package__)\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/importlib/__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/vllm/entrypoints/llm.py\", line 20, in <module>\n",
      "    from vllm.config import (CompilationConfig, ModelDType, TokenizerMode,\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/vllm/config.py\", line 37, in <module>\n",
      "    from vllm.transformers_utils.config import (\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/vllm/transformers_utils/config.py\", line 33, in <module>\n",
      "    from vllm.transformers_utils.configs import (ChatGLMConfig, Cohere2Config,\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/vllm/transformers_utils/configs/__init__.py\", line 26, in <module>\n",
      "    from vllm.transformers_utils.configs.ovis import OvisConfig\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/vllm/transformers_utils/configs/ovis.py\", line 76, in <module>\n",
      "    AutoConfig.register(\"aimv2\", AIMv2Config)\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py\", line 1402, in register\n",
      "    CONFIG_MAPPING.register(model_type, config, exist_ok=exist_ok)\n",
      "  File \"/root/miniconda3/envs/agent101/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py\", line 1082, in register\n",
      "    raise ValueError(f\"'{key}' is already used by a Transformers config, pick another name.\")\n",
      "ValueError: 'aimv2' is already used by a Transformers config, pick another name.\n",
      "\n",
      "\n",
      "ğŸ”§ å¯èƒ½çš„è§£å†³æ–¹æ¡ˆ:\n",
      "1. æ£€æŸ¥ GPU å†…å­˜æ˜¯å¦è¶³å¤Ÿ\n",
      "2. ç¡®è®¤æ¨¡å‹åç§°æ˜¯å¦æ­£ç¡®\n",
      "3. é‡æ–°è¿è¡Œå®‰è£…ä¾èµ–åŒ…çš„å•å…ƒæ ¼\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 1\n"
     ]
    }
   ],
   "source": [
    "# ğŸš€ æ‰§è¡Œ VLLM æœåŠ¡ç›‘æ§\n",
    "#\n",
    "# è¿™ä¸ªå•å…ƒæ ¼çš„ä½œç”¨ï¼š\n",
    "# 1. è°ƒç”¨ç›‘æ§å‡½æ•°ï¼Œç­‰å¾… VLLM æœåŠ¡å¯åŠ¨\n",
    "# 2. å¤„ç†å¯åŠ¨æˆåŠŸå’Œå¤±è´¥çš„æƒ…å†µ\n",
    "# 3. æ”¯æŒç”¨æˆ·ä¸­æ–­æ“ä½œ\n",
    "\n",
    "print(\"ğŸ¯ å¼€å§‹ç›‘æ§ VLLM æœåŠ¡å¯åŠ¨çŠ¶æ€...\")\n",
    "print(\"ğŸ’¡ æç¤ºï¼šé¦–æ¬¡è¿è¡Œå¯èƒ½éœ€è¦ 5-10 åˆ†é’Ÿä¸‹è½½æ¨¡å‹\")\n",
    "print(\"âŒ¨ï¸  æŒ‰ Ctrl+C å¯ä»¥ä¸­æ–­ç›‘æ§ï¼ˆä½†ä¸ä¼šåœæ­¢ VLLM æœåŠ¡ï¼‰\")\n",
    "\n",
    "try:\n",
    "    # è°ƒç”¨ç›‘æ§å‡½æ•°ï¼Œç­‰å¾…æœåŠ¡å¯åŠ¨\n",
    "    success, stdout, stderr = monitor_vllm_process(vllm_process)\n",
    "\n",
    "    if not success:\n",
    "        print(\"\\nâŒ VLLM æœåŠ¡å™¨å¯åŠ¨å¤±è´¥ï¼\")\n",
    "        print(\"\\nğŸ“‹ å®Œæ•´æ ‡å‡†è¾“å‡º:\")\n",
    "        print(stdout)\n",
    "        print(\"\\nğŸš¨ å®Œæ•´æ ‡å‡†é”™è¯¯:\")\n",
    "        print(stderr)\n",
    "        print(\"\\nğŸ”§ å¯èƒ½çš„è§£å†³æ–¹æ¡ˆ:\")\n",
    "        print(\"1. æ£€æŸ¥ GPU å†…å­˜æ˜¯å¦è¶³å¤Ÿ\")\n",
    "        print(\"2. ç¡®è®¤æ¨¡å‹åç§°æ˜¯å¦æ­£ç¡®\")\n",
    "        print(\"3. é‡æ–°è¿è¡Œå®‰è£…ä¾èµ–åŒ…çš„å•å…ƒæ ¼\")\n",
    "        sys.exit(1)\n",
    "    else:\n",
    "        print(\"\\nğŸ‰ VLLM æœåŠ¡å¯åŠ¨æˆåŠŸï¼\")\n",
    "        print(\"ğŸ“¡ API æœåŠ¡åœ°å€: http://localhost:8000\")\n",
    "        print(\"ğŸ“š API æ–‡æ¡£åœ°å€: http://localhost:8000/docs\")\n",
    "        print(\"âœ… ç°åœ¨å¯ä»¥ç»§ç»­è¿è¡Œåç»­å•å…ƒæ ¼\")\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nâš ï¸ ç”¨æˆ·ä¸­æ–­ç›‘æ§\")\n",
    "    print(\"ğŸ’¡ æ³¨æ„ï¼šVLLM æœåŠ¡ä»åœ¨åå°è¿è¡Œ\")\n",
    "    print(\"ğŸ”„ å¦‚æœéœ€è¦åœæ­¢ VLLM æœåŠ¡ï¼Œè¯·é‡å¯ Colab è¿è¡Œæ—¶\")\n",
    "\n",
    "    # å¯é€‰ï¼šå¼ºåˆ¶åœæ­¢ VLLM è¿›ç¨‹\n",
    "    # å–æ¶ˆä¸‹é¢çš„æ³¨é‡Šå¯ä»¥åœ¨ä¸­æ–­æ—¶åœæ­¢æœåŠ¡\n",
    "    # print(\"ğŸ›‘ æ­£åœ¨åœæ­¢ VLLM æœåŠ¡...\")\n",
    "    # vllm_process.terminate()\n",
    "    # try:\n",
    "    #     vllm_process.wait(timeout=5)\n",
    "    #     print(\"âœ… VLLM æœåŠ¡å·²åœæ­¢\")\n",
    "    # except subprocess.TimeoutExpired:\n",
    "    #     vllm_process.kill()\n",
    "    #     print(\"âš¡ å¼ºåˆ¶ç»ˆæ­¢ VLLM æœåŠ¡\")\n",
    "\n",
    "    # è¾“å‡ºæœ€ç»ˆæ—¥å¿—ä¿¡æ¯\n",
    "    try:\n",
    "        stdout, stderr = vllm_process.communicate(timeout=2)\n",
    "        if stdout:\n",
    "            print(\"\\nğŸ“ æœ€ç»ˆæ ‡å‡†è¾“å‡º:\")\n",
    "            print(stdout.decode('utf-8'))\n",
    "        if stderr:\n",
    "            print(\"\\nâš ï¸ æœ€ç»ˆæ ‡å‡†é”™è¯¯:\")\n",
    "            print(stderr.decode('utf-8'))\n",
    "    except:\n",
    "        print(\"ğŸ“ æ— æ³•è·å–æœ€ç»ˆæ—¥å¿—\")\n",
    "\n",
    "    sys.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qb6UVM067WHp",
    "outputId": "6a6e3888-3c22-4805-e7bc-5040dfb05d47"
   },
   "outputs": [],
   "source": [
    "# ğŸ§ª æ¨¡å‹æ¨ç†æµ‹è¯•å‡½æ•°\n",
    "#\n",
    "# è¿™ä¸ªå•å…ƒæ ¼å®šä¹‰äº†ä¸¤ä¸ªæ ¸å¿ƒå‡½æ•°ï¼š\n",
    "# 1. ask_model: å‘é€é—®é¢˜å¹¶è·å–å®Œæ•´å›ç­”\n",
    "# 2. stream_llm_response: å®ç°æµå¼å“åº”åŠŸèƒ½\n",
    "\n",
    "import requests\n",
    "import json\n",
    "from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel\n",
    "from fastapi.responses import StreamingResponse\n",
    "\n",
    "# ğŸ“ å®šä¹‰è¯·æ±‚æ•°æ®æ¨¡å‹\n",
    "class QuestionRequest(BaseModel):\n",
    "    \"\"\"\n",
    "    API è¯·æ±‚çš„æ•°æ®æ¨¡å‹\n",
    "\n",
    "    å±æ€§:\n",
    "        question (str): ç”¨æˆ·æå‡ºçš„é—®é¢˜\n",
    "\n",
    "    è¯´æ˜:\n",
    "        ä½¿ç”¨ Pydantic æ¨¡å‹ç¡®ä¿æ•°æ®ç±»å‹å®‰å…¨\n",
    "        åç»­ FastAPI ä¼šè‡ªåŠ¨éªŒè¯è¯·æ±‚æ•°æ®\n",
    "    \"\"\"\n",
    "    question: str\n",
    "\n",
    "def ask_model(question: str):\n",
    "    \"\"\"\n",
    "    ğŸ¤– å‘ VLLM æ¨¡å‹å‘é€é—®é¢˜å¹¶è·å–å®Œæ•´å›ç­”\n",
    "\n",
    "    å‚æ•°:\n",
    "        question (str): ç”¨æˆ·æå‡ºçš„é—®é¢˜\n",
    "\n",
    "    è¿”å›:\n",
    "        dict: åŒ…å«æ¨¡å‹å›ç­”çš„ JSON å“åº”\n",
    "\n",
    "    å·¥ä½œæµç¨‹:\n",
    "        1. æ„é€ ç¬¦åˆ OpenAI API æ ¼å¼çš„è¯·æ±‚\n",
    "        2. å‘é€ POST è¯·æ±‚åˆ° VLLM æœåŠ¡\n",
    "        3. å¤„ç†å“åº”å¹¶è¿”å›ç»“æœ\n",
    "    \"\"\"\n",
    "    # VLLM çš„ OpenAI å…¼å®¹ API ç«¯ç‚¹\n",
    "    url = \"http://localhost:8000/v1/chat/completions\"\n",
    "\n",
    "    # è®¾ç½®è¯·æ±‚å¤´\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "    # æ„é€ è¯·æ±‚æ•°æ®ï¼ˆOpenAI æ ¼å¼ï¼‰\n",
    "    data = {\n",
    "        \"model\": model,  # ä½¿ç”¨å…¨å±€æ¨¡å‹å˜é‡\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": question\n",
    "            }\n",
    "        ],\n",
    "        \"max_tokens\": 2048,  # æœ€å¤§ç”Ÿæˆé•¿åº¦\n",
    "        \"temperature\": 0.7,  # ç”Ÿæˆçš„éšæœºæ€§\n",
    "        \"top_p\": 0.9         # æ ¸é‡‡æ ·å‚æ•°\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # å‘é€è¯·æ±‚\n",
    "        response = requests.post(url, headers=headers, json=data, timeout=60)\n",
    "        response.raise_for_status()  # æ£€æŸ¥ HTTP é”™è¯¯\n",
    "        return response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"âŒ è¯·æ±‚å¤±è´¥: {e}\")\n",
    "        return None\n",
    "\n",
    "def stream_llm_response(question: str):\n",
    "    \"\"\"\n",
    "    ğŸŒŠ æµå¼å“åº”ç”Ÿæˆå™¨ - å®æ—¶è·å–æ¨¡å‹è¾“å‡º\n",
    "\n",
    "    å‚æ•°:\n",
    "        question (str): ç”¨æˆ·æå‡ºçš„é—®é¢˜\n",
    "\n",
    "    ç”Ÿæˆ:\n",
    "        str: é€è¡Œè¿”å›æ¨¡å‹çš„ç”Ÿæˆå†…å®¹\n",
    "\n",
    "    ç‰¹ç‚¹:\n",
    "        - å®æ—¶æ˜¾ç¤ºç”Ÿæˆè¿‡ç¨‹\n",
    "        - é™ä½ç­‰å¾…æ—¶é—´\n",
    "        - æä¾›æ›´å¥½çš„ç”¨æˆ·ä½“éªŒ\n",
    "    \"\"\"\n",
    "    url = \"http://localhost:8000/v1/chat/completions\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "    # å¯ç”¨æµå¼ä¼ è¾“\n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": question}],\n",
    "        \"stream\": True,      # ğŸ”¥ å…³é”®ï¼šå¯ç”¨æµå¼ä¼ è¾“\n",
    "        \"max_tokens\": 2048,\n",
    "        \"temperature\": 0.7\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        with requests.post(url, headers=headers, json=data, stream=True, timeout=60) as response:\n",
    "            response.raise_for_status()\n",
    "\n",
    "            for line in response.iter_lines():\n",
    "                if line:\n",
    "                    # OpenAI é£æ ¼çš„æµå¼å“åº”ä»¥ \"data: \" ä¸ºå‰ç¼€\n",
    "                    decoded_line = line.decode(\"utf-8\")\n",
    "                    if decoded_line.startswith(\"data: \"):\n",
    "                        decoded_line = decoded_line[6:]  # ç§»é™¤ \"data: \" å‰ç¼€\n",
    "                    yield decoded_line + \"\\n\"\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        yield f\"âŒ æµå¼è¯·æ±‚å¤±è´¥: {e}\\n\"\n",
    "\n",
    "# ğŸ§ª æµ‹è¯•åŸºç¡€æ¨ç†åŠŸèƒ½\n",
    "print(\"ğŸ§ª æµ‹è¯•æ¨¡å‹æ¨ç†åŠŸèƒ½...\")\n",
    "print(\"ğŸ“ å‘é€æµ‹è¯•é—®é¢˜: æ³•å›½çš„é¦–éƒ½æ˜¯ä»€ä¹ˆï¼Ÿ\")\n",
    "\n",
    "try:\n",
    "    result = ask_model(\"æ³•å›½çš„é¦–éƒ½æ˜¯ä»€ä¹ˆï¼Ÿ\")\n",
    "    if result:\n",
    "        print(\"\\nâœ… æ¨¡å‹æ¨ç†æˆåŠŸï¼\")\n",
    "        print(\"ğŸ“‹ å®Œæ•´å“åº”:\")\n",
    "        print(json.dumps(result, indent=2, ensure_ascii=False))\n",
    "\n",
    "        # æå–å¹¶æ˜¾ç¤ºæ¨¡å‹å›ç­”\n",
    "        if \"choices\" in result and len(result[\"choices\"]) > 0:\n",
    "            answer = result[\"choices\"][0][\"message\"][\"content\"]\n",
    "            print(f\"\\nğŸ¤– æ¨¡å‹å›ç­”: {answer}\")\n",
    "    else:\n",
    "        print(\"âŒ æ¨¡å‹æ¨ç†å¤±è´¥\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"âœ… æ¨ç†å‡½æ•°å®šä¹‰å®Œæˆï¼Œå¯ä»¥ç»§ç»­ä¸‹ä¸€æ­¥ï¼\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RZ0mnu1nl9Ko"
   },
   "source": [
    "## ğŸŒ ç¬¬å…­æ­¥ï¼šåˆ›å»º FastAPI Web æœåŠ¡\n",
    "\n",
    "ç°åœ¨æˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ª FastAPI Web æœåŠ¡ï¼Œå°† VLLM æ¨¡å‹å°è£…æˆæ˜“äºä½¿ç”¨çš„ REST APIã€‚\n",
    "\n",
    "### ğŸ¯ FastAPI æœåŠ¡è¯´æ˜\n",
    "\n",
    "#### ğŸ”§ æ ¸å¿ƒåŠŸèƒ½\n",
    "1. **RESTful API**: æä¾›æ ‡å‡†çš„ HTTP æ¥å£\n",
    "2. **è‡ªåŠ¨æ–‡æ¡£**: è‡ªåŠ¨ç”Ÿæˆ Swagger UI æ–‡æ¡£\n",
    "3. **æ•°æ®éªŒè¯**: ä½¿ç”¨ Pydantic è¿›è¡Œè¯·æ±‚éªŒè¯\n",
    "4. **å¼‚æ­¥æ”¯æŒ**: æ”¯æŒé«˜å¹¶å‘è¯·æ±‚å¤„ç†\n",
    "\n",
    "#### ğŸ“¡ API ç«¯ç‚¹è®¾è®¡\n",
    "- **æ ¹è·¯å¾„** (`/`): å¥åº·æ£€æŸ¥ç«¯ç‚¹\n",
    "- **ç”Ÿæˆå›ç­”** (`/api/v1/generate-response`): è·å–å®Œæ•´å›ç­”\n",
    "- **æµå¼å›ç­”** (`/api/v1/generate-response-stream`): å®æ—¶æµå¼è¾“å‡º\n",
    "\n",
    "#### ğŸ”’ CORS é…ç½®\n",
    "- å…è®¸è·¨åŸŸè®¿é—®ï¼Œæ”¯æŒå‰ç«¯è°ƒç”¨\n",
    "- æ”¯æŒæ‰€æœ‰ HTTP æ–¹æ³•å’Œå¤´éƒ¨\n",
    "- ä¾¿äºä¸ä¸åŒå‰ç«¯æ¡†æ¶é›†æˆ\n",
    "\n",
    "### ğŸš€ æœåŠ¡ç‰¹ç‚¹\n",
    "- **é«˜æ€§èƒ½**: åŸºäº ASGI çš„å¼‚æ­¥æ¡†æ¶\n",
    "- **æ˜“ç”¨æ€§**: ç®€æ´çš„ API è®¾è®¡\n",
    "- **å¯æ‰©å±•**: æ”¯æŒæ·»åŠ æ›´å¤šåŠŸèƒ½\n",
    "- **æ ‡å‡†åŒ–**: éµå¾ª REST API è®¾è®¡è§„èŒƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2lAE878DSaSk",
    "outputId": "1a97ba07-13b3-42d5-d7c8-14f88559899e"
   },
   "outputs": [],
   "source": [
    "# ğŸŒ åˆ›å»º FastAPI Web æœåŠ¡\n",
    "#\n",
    "# è¿™ä¸ªå•å…ƒæ ¼çš„ä½œç”¨ï¼š\n",
    "# 1. åˆå§‹åŒ– FastAPI åº”ç”¨\n",
    "# 2. é…ç½® CORS è·¨åŸŸæ”¯æŒ\n",
    "# 3. å®šä¹‰ API ç«¯ç‚¹å’Œè·¯ç”±\n",
    "\n",
    "from fastapi import FastAPI\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "import nest_asyncio\n",
    "from pyngrok import ngrok\n",
    "import uvicorn\n",
    "\n",
    "# ğŸš€ åˆ›å»º FastAPI åº”ç”¨å®ä¾‹\n",
    "app = FastAPI(\n",
    "    title=\"DeepSeek R1 API æœåŠ¡\",\n",
    "    description=\"åŸºäº VLLM çš„ DeepSeek R1 è’¸é¦ç‰ˆæ¨¡å‹ API æœåŠ¡\",\n",
    "    version=\"1.0.0\",\n",
    "    docs_url=\"/docs\",  # Swagger UI æ–‡æ¡£åœ°å€\n",
    "    redoc_url=\"/redoc\"  # ReDoc æ–‡æ¡£åœ°å€\n",
    ")\n",
    "\n",
    "# ğŸ”’ é…ç½® CORS è·¨åŸŸä¸­é—´ä»¶\n",
    "# å…è®¸å‰ç«¯åº”ç”¨ä»ä¸åŒåŸŸåè®¿é—® API\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=['*'],        # å…è®¸æ‰€æœ‰åŸŸåï¼ˆç”Ÿäº§ç¯å¢ƒåº”é™åˆ¶ï¼‰\n",
    "    allow_credentials=True,     # å…è®¸æºå¸¦å‡­æ®\n",
    "    allow_methods=['*'],        # å…è®¸æ‰€æœ‰ HTTP æ–¹æ³•\n",
    "    allow_headers=['*'],        # å…è®¸æ‰€æœ‰è¯·æ±‚å¤´\n",
    ")\n",
    "\n",
    "# ğŸ  æ ¹è·¯å¾„ - å¥åº·æ£€æŸ¥ç«¯ç‚¹\n",
    "@app.get('/')\n",
    "async def root():\n",
    "    \"\"\"\n",
    "    ğŸ¥ å¥åº·æ£€æŸ¥ç«¯ç‚¹\n",
    "\n",
    "    è¿”å›:\n",
    "        dict: åŒ…å«æœåŠ¡çŠ¶æ€ä¿¡æ¯\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'status': 'healthy',\n",
    "        'message': 'DeepSeek R1 API æœåŠ¡æ­£åœ¨è¿è¡Œ',\n",
    "        'model': model,\n",
    "        'version': '1.0.0'\n",
    "    }\n",
    "\n",
    "# ğŸ¤– ç”Ÿæˆå®Œæ•´å›ç­”çš„ API ç«¯ç‚¹\n",
    "@app.post(\"/api/v1/generate-response\")\n",
    "def generate_response(request: QuestionRequest):\n",
    "    \"\"\"\n",
    "    ğŸ“ ç”Ÿæˆå®Œæ•´å›ç­”çš„ API ç«¯ç‚¹\n",
    "\n",
    "    å‚æ•°:\n",
    "        request (QuestionRequest): åŒ…å«ç”¨æˆ·é—®é¢˜çš„è¯·æ±‚å¯¹è±¡\n",
    "\n",
    "    è¿”å›:\n",
    "        dict: åŒ…å«æ¨¡å‹å›ç­”çš„å“åº”\n",
    "\n",
    "    å¼‚å¸¸:\n",
    "        HTTPException: å½“æ¨¡å‹æ¨ç†å¤±è´¥æ—¶æŠ›å‡º 500 é”™è¯¯\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"ğŸ“ æ”¶åˆ°é—®é¢˜: {request.question}\")\n",
    "\n",
    "        # è°ƒç”¨æ¨¡å‹æ¨ç†å‡½æ•°\n",
    "        response = ask_model(request.question)\n",
    "\n",
    "        if response is None:\n",
    "            raise HTTPException(status_code=500, detail=\"æ¨¡å‹æ¨ç†å¤±è´¥\")\n",
    "\n",
    "        print(\"âœ… æ¨ç†å®Œæˆ\")\n",
    "        return {\"response\": response}\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ æ¨ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}\")\n",
    "        raise HTTPException(status_code=500, detail=f\"æ¨ç†å¤±è´¥: {str(e)}\")\n",
    "\n",
    "# ğŸŒŠ æµå¼å“åº”çš„ API ç«¯ç‚¹\n",
    "@app.post(\"/api/v1/generate-response-stream\")\n",
    "def stream_response(request: QuestionRequest):\n",
    "    \"\"\"\n",
    "    ğŸŒŠ æµå¼å“åº” API ç«¯ç‚¹\n",
    "\n",
    "    å‚æ•°:\n",
    "        request (QuestionRequest): åŒ…å«ç”¨æˆ·é—®é¢˜çš„è¯·æ±‚å¯¹è±¡\n",
    "\n",
    "    è¿”å›:\n",
    "        StreamingResponse: å®æ—¶æµå¼å“åº”\n",
    "\n",
    "    ç‰¹ç‚¹:\n",
    "        - å®æ—¶è¿”å›ç”Ÿæˆå†…å®¹\n",
    "        - é™ä½ç”¨æˆ·ç­‰å¾…æ—¶é—´\n",
    "        - æä¾›æ›´å¥½çš„äº¤äº’ä½“éªŒ\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"ğŸŒŠ æ”¶åˆ°æµå¼è¯·æ±‚: {request.question}\")\n",
    "\n",
    "        # è°ƒç”¨æµå¼å“åº”ç”Ÿæˆå™¨\n",
    "        response_generator = stream_llm_response(request.question)\n",
    "\n",
    "        return StreamingResponse(\n",
    "            response_generator,\n",
    "            media_type=\"text/event-stream\",\n",
    "            headers={\n",
    "                \"Cache-Control\": \"no-cache\",\n",
    "                \"Connection\": \"keep-alive\",\n",
    "                \"Access-Control-Allow-Origin\": \"*\"\n",
    "            }\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ æµå¼å“åº”è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}\")\n",
    "        raise HTTPException(status_code=500, detail=f\"æµå¼å“åº”å¤±è´¥: {str(e)}\")\n",
    "\n",
    "print(\"âœ… FastAPI åº”ç”¨åˆ›å»ºå®Œæˆï¼\")\n",
    "print(\"ğŸ“š API æ–‡æ¡£å°†åœ¨å¯åŠ¨åè®¿é—®: http://localhost:8081/docs\")\n",
    "print(\"ğŸ”„ å‡†å¤‡å¯åŠ¨ Web æœåŠ¡...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uYuy3A6HmCma"
   },
   "source": [
    "## ğŸŒ ç¬¬å…­æ­¥ï¼šNgrok æ³¨å†Œä¸é…ç½®\n",
    "\n",
    "### ğŸ¯ ä»€ä¹ˆæ˜¯ Ngrokï¼Ÿ\n",
    "\n",
    "Ngrok æ˜¯ä¸€ä¸ªå¼ºå¤§çš„å†…ç½‘ç©¿é€å·¥å…·ï¼Œå¯ä»¥å°†æœ¬åœ°è¿è¡Œçš„æœåŠ¡æš´éœ²åˆ°å…¬ç½‘ä¸Šï¼Œè®©å¤–éƒ¨ç”¨æˆ·å¯ä»¥è®¿é—®ã€‚åœ¨æˆ‘ä»¬çš„åœºæ™¯ä¸­ï¼Œå®ƒå¯ä»¥è®©å…¶ä»–äººé€šè¿‡å…¬ç½‘ URL è®¿é—®ä½ åœ¨ Colab ä¸­éƒ¨ç½²çš„æ¨¡å‹ APIã€‚\n",
    "\n",
    "### ğŸ”§ Ngrok çš„ä½œç”¨\n",
    "\n",
    "#### ğŸ“¡ æ ¸å¿ƒåŠŸèƒ½\n",
    "1. **å†…ç½‘ç©¿é€**: å°†æœ¬åœ°æœåŠ¡æ˜ å°„åˆ°å…¬ç½‘åŸŸå\n",
    "2. **HTTPS æ”¯æŒ**: è‡ªåŠ¨æä¾› HTTPS åŠ å¯†è¿æ¥\n",
    "3. **åŸŸååˆ†é…**: åˆ†é…ä¸€ä¸ªä¸´æ—¶çš„å…¬ç½‘åŸŸå\n",
    "4. **æµé‡ç›‘æ§**: æä¾›è¯·æ±‚æ—¥å¿—å’Œç›‘æ§åŠŸèƒ½\n",
    "\n",
    "#### ğŸ¯ ä½¿ç”¨åœºæ™¯\n",
    "- **API åˆ†äº«**: ä¸å›¢é˜Ÿæˆå‘˜åˆ†äº« API æ¥å£\n",
    "- **è¿œç¨‹æµ‹è¯•**: åœ¨ä¸åŒè®¾å¤‡ä¸Šæµ‹è¯•æœåŠ¡\n",
    "- **æ¼”ç¤ºå±•ç¤º**: å‘å®¢æˆ·å±•ç¤ºé¡¹ç›®æ•ˆæœ\n",
    "- **Webhook æ¥æ”¶**: æ¥æ”¶ç¬¬ä¸‰æ–¹æœåŠ¡çš„å›è°ƒ\n",
    "\n",
    "### ğŸ“ Ngrok æ³¨å†Œæµç¨‹\n",
    "\n",
    "#### æ­¥éª¤ 1ï¼šè®¿é—®å®˜ç½‘æ³¨å†Œ\n",
    "1. æ‰“å¼€ Ngrok å®˜ç½‘ï¼š[https://ngrok.com/](https://ngrok.com/)\n",
    "2. ç‚¹å‡»å³ä¸Šè§’çš„ **\"Sign up\"** æŒ‰é’®\n",
    "3. é€‰æ‹©æ³¨å†Œæ–¹å¼ï¼š\n",
    "   - **GitHub è´¦å·**: æ¨èï¼Œä¸€é”®ç™»å½•\n",
    "   - **Google è´¦å·**: æ–¹ä¾¿å¿«æ·\n",
    "   - **é‚®ç®±æ³¨å†Œ**: ä¼ ç»Ÿæ–¹å¼\n",
    "\n",
    "#### æ­¥éª¤ 2ï¼šéªŒè¯é‚®ç®±ï¼ˆå¦‚æœä½¿ç”¨é‚®ç®±æ³¨å†Œï¼‰\n",
    "1. å¡«å†™é‚®ç®±åœ°å€å’Œå¯†ç \n",
    "2. æŸ¥æ”¶éªŒè¯é‚®ä»¶\n",
    "3. ç‚¹å‡»é‚®ä»¶ä¸­çš„éªŒè¯é“¾æ¥\n",
    "\n",
    "#### æ­¥éª¤ 3ï¼šå®Œæˆè´¦å·è®¾ç½®\n",
    "1. å¡«å†™åŸºæœ¬ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰\n",
    "2. é€‰æ‹©ä½¿ç”¨ç›®çš„ï¼ˆä¸ªäºº/å•†ä¸šï¼‰\n",
    "3. å®Œæˆæ³¨å†Œæµç¨‹\n",
    "\n",
    "### ğŸ”‘ è·å– Authtoken\n",
    "\n",
    "#### æ–¹æ³• 1ï¼šDashboard è·å–\n",
    "1. ç™»å½•åè¿›å…¥ [Ngrok Dashboard](https://dashboard.ngrok.com/)\n",
    "2. åœ¨å·¦ä¾§å¯¼èˆªæ æ‰¾åˆ° **\"Your Authtoken\"** æˆ– **\"Getting Started\"**\n",
    "3. å¤åˆ¶æ˜¾ç¤ºçš„ authtokenï¼ˆæ ¼å¼ç±»ä¼¼ï¼š`1ABC2def3GHI4jkl5MNO6pqr7STU8vwx9YZ`ï¼‰\n",
    "\n",
    "#### æ–¹æ³• 2ï¼šç›´æ¥è®¿é—®é“¾æ¥\n",
    "è®¿é—®ï¼š[https://dashboard.ngrok.com/get-started/your-authtoken](https://dashboard.ngrok.com/get-started/your-authtoken)\n",
    "\n",
    "### âš ï¸ Authtoken å®‰å…¨æç¤º\n",
    "\n",
    "#### ğŸ”’ å®‰å…¨æ³¨æ„äº‹é¡¹\n",
    "1. **ä¿å¯†æ€§**: Token ç›¸å½“äºä½ çš„è´¦å·å¯†ç ï¼Œä¸è¦å…¬å¼€åˆ†äº«\n",
    "2. **å®šæœŸæ›´æ¢**: å»ºè®®å®šæœŸé‡ç½® token ä»¥ç¡®ä¿å®‰å…¨\n",
    "3. **æƒé™æ§åˆ¶**: å…è´¹è´¦å·æœ‰ä½¿ç”¨é™åˆ¶ï¼Œä»˜è´¹è´¦å·åŠŸèƒ½æ›´å¤š\n",
    "4. **ç›‘æ§ä½¿ç”¨**: å®šæœŸæ£€æŸ¥ Dashboard ä¸­çš„ä½¿ç”¨æƒ…å†µ\n",
    "\n",
    "#### ğŸ“Š å…è´¹è´¦å·é™åˆ¶\n",
    "- **å¹¶å‘éš§é“**: 1ä¸ª\n",
    "- **è¿æ¥æ•°**: 40ä¸ª/åˆ†é’Ÿ\n",
    "- **åŸŸå**: éšæœºåˆ†é…\n",
    "- **ä¼šè¯æ—¶é•¿**: 8å°æ—¶\n",
    "\n",
    "### ğŸ› ï¸ Token é…ç½®æ–¹æ³•\n",
    "\n",
    "ä¸‹é¢çš„å•å…ƒæ ¼å°†æ¼”ç¤ºå¦‚ä½•é…ç½®ä½ çš„ authtokenï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HG8QGlyjU61y",
    "outputId": "083a64f2-4d3d-4616-be83-3f161e2e4fd0"
   },
   "outputs": [],
   "source": [
    "# ğŸ”‘ é…ç½® Ngrok Authtoken\n",
    "#\n",
    "# âš ï¸ é‡è¦æç¤ºï¼šè¯·å°†ä¸‹é¢çš„ YOUR_AUTHTOKEN_HERE æ›¿æ¢ä¸ºä½ ä» Ngrok Dashboard è·å–çš„çœŸå® token\n",
    "#\n",
    "# ğŸ”— è·å– token çš„æ­¥éª¤ï¼š\n",
    "# 1. è®¿é—®ï¼šhttps://dashboard.ngrok.com/get-started/your-authtoken\n",
    "# 2. ç™»å½•ä½ çš„ Ngrok è´¦å·\n",
    "# 3. å¤åˆ¶æ˜¾ç¤ºçš„ authtoken\n",
    "# 4. æ›¿æ¢ä¸‹é¢ä»£ç ä¸­çš„ YOUR_AUTHTOKEN_HERE\n",
    "\n",
    "# ğŸ“ ç¤ºä¾‹ token æ ¼å¼ï¼ˆè¯·æ›¿æ¢ä¸ºä½ çš„çœŸå® tokenï¼‰ï¼š\n",
    "# YOUR_AUTHTOKEN = \"1ABC2def3GHI4jkl5MNO6pqr7STU8vwx9YZ\"\n",
    "\n",
    "# ğŸš¨ è¯·åœ¨ä¸‹é¢å¡«å…¥ä½ çš„çœŸå® authtoken\n",
    "YOUR_AUTHTOKEN = \"Your Ngrok AuthToken\"  # ğŸ‘ˆ è¯·æ›¿æ¢è¿™é‡Œ\n",
    "\n",
    "# éªŒè¯ token æ˜¯å¦å·²è®¾ç½®\n",
    "if YOUR_AUTHTOKEN == \"YOUR_AUTHTOKEN_HERE\":\n",
    "    print(\"âŒ è¯·å…ˆè®¾ç½®ä½ çš„ Ngrok authtokenï¼\")\n",
    "    print(\"ğŸ“ æ­¥éª¤ï¼š\")\n",
    "    print(\"1. è®¿é—® https://dashboard.ngrok.com/get-started/your-authtoken\")\n",
    "    print(\"2. ç™»å½•å¹¶å¤åˆ¶ä½ çš„ authtoken\")\n",
    "    print(\"3. å°†ä¸Šé¢çš„ YOUR_AUTHTOKEN_HERE æ›¿æ¢ä¸ºä½ çš„çœŸå® token\")\n",
    "    print(\"4. é‡æ–°è¿è¡Œæ­¤å•å…ƒæ ¼\")\n",
    "else:\n",
    "    # é…ç½® authtoken\n",
    "    import subprocess\n",
    "    result = subprocess.run(['ngrok', 'config', 'add-authtoken', YOUR_AUTHTOKEN],\n",
    "                          capture_output=True, text=True)\n",
    "    if result.returncode == 0:\n",
    "        print(\"âœ… Ngrok authtoken é…ç½®æˆåŠŸï¼\")\n",
    "        print(\"ğŸ‰ ç°åœ¨å¯ä»¥åˆ›å»ºå…¬ç½‘éš§é“äº†\")\n",
    "    else:\n",
    "        print(f\"âŒ é…ç½®å¤±è´¥: {result.stderr}\")\n",
    "        print(\"ğŸ’¡ è¯·æ£€æŸ¥ token æ˜¯å¦æ­£ç¡®\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "W3T6xnsWRuI9",
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## ğŸš€ ç¬¬ä¸ƒæ­¥ï¼šå¯åŠ¨ Ngrok éš§é“\n",
    "\n",
    "### ğŸŒ åˆ›å»ºå…¬ç½‘éš§é“\n",
    "\n",
    "é…ç½®å¥½ authtoken åï¼Œæˆ‘ä»¬å°±å¯ä»¥åˆ›å»º ngrok éš§é“ï¼Œå°†æœ¬åœ°çš„ FastAPI æœåŠ¡æš´éœ²åˆ°å…¬ç½‘ã€‚\n",
    "\n",
    "### ğŸ”§ Ngrok éš§é“å·¥ä½œåŸç†\n",
    "\n",
    "#### ğŸ“¡ éš§é“æœºåˆ¶\n",
    "1. **æœ¬åœ°æœåŠ¡**: FastAPI åœ¨ localhost:8081 è¿è¡Œ\n",
    "2. **Ngrok å®¢æˆ·ç«¯**: è¿æ¥åˆ° Ngrok æœåŠ¡å™¨\n",
    "3. **å…¬ç½‘åŸŸå**: Ngrok åˆ†é…ä¸€ä¸ªä¸´æ—¶åŸŸå\n",
    "4. **æµé‡è½¬å‘**: å¤–éƒ¨è¯·æ±‚é€šè¿‡åŸŸåè½¬å‘åˆ°æœ¬åœ°æœåŠ¡\n",
    "\n",
    "#### ğŸŒ è®¿é—®æµç¨‹\n",
    "```\n",
    "å¤–éƒ¨ç”¨æˆ· â†’ https://abc123.ngrok.io â†’ NgrokæœåŠ¡å™¨ â†’ æœ¬åœ°FastAPIæœåŠ¡\n",
    "```\n",
    "\n",
    "### ğŸ“Š Ngrok åŠŸèƒ½ç‰¹æ€§\n",
    "\n",
    "#### âœ¨ ä¸»è¦åŠŸèƒ½\n",
    "- **HTTPS åŠ å¯†**: è‡ªåŠ¨æä¾› SSL è¯ä¹¦\n",
    "- **å®æ—¶ç›‘æ§**: Web ç•Œé¢æŸ¥çœ‹è¯·æ±‚æ—¥å¿—\n",
    "- **å¤šç§åè®®**: æ”¯æŒ HTTPã€HTTPSã€TCP ç­‰\n",
    "- **è‡ªå®šä¹‰åŸŸå**: ä»˜è´¹ç‰ˆæ”¯æŒè‡ªå®šä¹‰åŸŸå\n",
    "\n",
    "#### ğŸ¯ é€‚ç”¨åœºæ™¯\n",
    "- **API æµ‹è¯•**: è®©å‰ç«¯å¼€å‘è€…æµ‹è¯• API\n",
    "- **ç§»åŠ¨ç«¯è°ƒè¯•**: æ‰‹æœºç›´æ¥è®¿é—®æœ¬åœ°æœåŠ¡\n",
    "- **ç¬¬ä¸‰æ–¹é›†æˆ**: æ¥æ”¶ Webhook å›è°ƒ\n",
    "- **ä¸´æ—¶æ¼”ç¤º**: å¿«é€Ÿåˆ†äº«é¡¹ç›®æˆæœ\n",
    "\n",
    "### âš ï¸ æ³¨æ„äº‹é¡¹\n",
    "\n",
    "#### ğŸ”’ å®‰å…¨æé†’\n",
    "1. **ä¸´æ—¶ä½¿ç”¨**: éš§é“åŸŸåæ˜¯ä¸´æ—¶çš„ï¼Œé‡å¯åä¼šå˜åŒ–\n",
    "2. **æµé‡é™åˆ¶**: å…è´¹ç‰ˆæœ‰å¹¶å‘å’Œæµé‡é™åˆ¶\n",
    "3. **å®‰å…¨é£é™©**: å…¬ç½‘å¯è®¿é—®ï¼Œæ³¨æ„æ•°æ®å®‰å…¨\n",
    "4. **ç›‘æ§è®¿é—®**: å®šæœŸæ£€æŸ¥è®¿é—®æ—¥å¿—\n",
    "\n",
    "#### ğŸ“ˆ æ€§èƒ½è€ƒè™‘\n",
    "- **å»¶è¿Ÿå¢åŠ **: é€šè¿‡ Ngrok ä¼šå¢åŠ ç½‘ç»œå»¶è¿Ÿ\n",
    "- **å¸¦å®½é™åˆ¶**: å…è´¹ç‰ˆæœ‰å¸¦å®½é™åˆ¶\n",
    "- **ç¨³å®šæ€§**: ç½‘ç»œä¸ç¨³å®šå¯èƒ½å¯¼è‡´è¿æ¥ä¸­æ–­\n",
    "\n",
    "ä¸‹é¢çš„å•å…ƒæ ¼å°†åˆ›å»º Ngrok éš§é“ï¼š\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SHI9RCHdmJDf"
   },
   "source": [
    "### ğŸŒ åˆ›å»º Ngrok éš§é“å’Œå¯åŠ¨æœåŠ¡\n",
    "\n",
    "ç°åœ¨æˆ‘ä»¬å°†åŒæ—¶ï¼š\n",
    "1. åˆ›å»º Ngrok éš§é“ï¼Œå°†æœ¬åœ°æœåŠ¡æš´éœ²åˆ°å…¬ç½‘\n",
    "2. å¯åŠ¨ FastAPI æœåŠ¡ï¼Œæä¾› API æ¥å£\n",
    "\n",
    "#### ğŸ”„ æ‰§è¡Œé¡ºåº\n",
    "- å…ˆåˆ›å»º Ngrok éš§é“ï¼ˆè·å–å…¬ç½‘ URLï¼‰\n",
    "- ç„¶åå¯åŠ¨ FastAPI æœåŠ¡ï¼ˆåœ¨æŒ‡å®šç«¯å£è¿è¡Œï¼‰\n",
    "- å¤–éƒ¨ç”¨æˆ·å¯ä»¥é€šè¿‡å…¬ç½‘ URL è®¿é—® API\n",
    "\n",
    "#### ğŸ’¡ ä½¿ç”¨æç¤º\n",
    "- éš§é“åˆ›å»ºæˆåŠŸåä¼šæ˜¾ç¤ºå…¬ç½‘ URL\n",
    "- è¯·ä¿å­˜è¿™ä¸ª URLï¼Œç”¨äºå¤–éƒ¨è®¿é—®\n",
    "- æœåŠ¡å¯åŠ¨åä¼šé˜»å¡å½“å‰å•å…ƒæ ¼ï¼Œè¿™æ˜¯æ­£å¸¸ç°è±¡\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QQ3NYyCgTUdj",
    "outputId": "2b6b6d33-c18c-46db-8169-eeff6322f211"
   },
   "outputs": [],
   "source": [
    "# ğŸŒ åˆ›å»º Ngrok éš§é“\n",
    "#\n",
    "# è¿™ä¸ªå•å…ƒæ ¼çš„ä½œç”¨ï¼š\n",
    "# 1. è®¾ç½® FastAPI æœåŠ¡çš„ç«¯å£\n",
    "# 2. åˆ›å»º Ngrok éš§é“è¿æ¥åˆ°è¯¥ç«¯å£\n",
    "# 3. è·å–å…¬ç½‘è®¿é—® URL\n",
    "\n",
    "import time\n",
    "from pyngrok import ngrok\n",
    "\n",
    "# ğŸ“¡ è®¾ç½®æœåŠ¡ç«¯å£\n",
    "port = 8081\n",
    "print(f\"ğŸš€ å‡†å¤‡åœ¨ç«¯å£ {port} ä¸Šå¯åŠ¨æœåŠ¡...\")\n",
    "\n",
    "try:\n",
    "    # ğŸŒ åˆ›å»º Ngrok éš§é“\n",
    "    print(\"ğŸ”— æ­£åœ¨åˆ›å»º Ngrok éš§é“...\")\n",
    "\n",
    "    # åˆ›å»º HTTP éš§é“\n",
    "    public_url = ngrok.connect(port).public_url\n",
    "\n",
    "    print(\"âœ… Ngrok éš§é“åˆ›å»ºæˆåŠŸï¼\")\n",
    "    print(f\"ğŸŒ å…¬ç½‘è®¿é—®åœ°å€: {public_url}\")\n",
    "    print(f\"ğŸ”— æœ¬åœ°åœ°å€: http://127.0.0.1:{port}\")\n",
    "    print()\n",
    "    print(\"ğŸ“š API æ–‡æ¡£åœ°å€:\")\n",
    "    print(f\"   â€¢ Swagger UI: {public_url}/docs\")\n",
    "    print(f\"   â€¢ ReDoc: {public_url}/redoc\")\n",
    "    print()\n",
    "    print(\"ğŸ§ª API ç«¯ç‚¹:\")\n",
    "    print(f\"   â€¢ å¥åº·æ£€æŸ¥: {public_url}/\")\n",
    "    print(f\"   â€¢ ç”Ÿæˆå›ç­”: {public_url}/api/v1/generate-response\")\n",
    "    print(f\"   â€¢ æµå¼å›ç­”: {public_url}/api/v1/generate-response-stream\")\n",
    "    print()\n",
    "    print(\"ğŸ’¡ æç¤ºï¼šè¯·ä¿å­˜ä¸Šé¢çš„å…¬ç½‘åœ°å€ï¼Œç”¨äºå¤–éƒ¨è®¿é—®\")\n",
    "\n",
    "    # ğŸ” æ˜¾ç¤º Ngrok ç›‘æ§ä¿¡æ¯\n",
    "    tunnels = ngrok.get_tunnels()\n",
    "    if tunnels:\n",
    "        print(\"\\nğŸ“Š å½“å‰æ´»è·ƒéš§é“:\")\n",
    "        for tunnel in tunnels:\n",
    "            print(f\"   â€¢ {tunnel.name}: {tunnel.public_url} -> {tunnel.config['addr']}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âŒ åˆ›å»º Ngrok éš§é“å¤±è´¥: {e}\")\n",
    "    print(\"ğŸ”§ å¯èƒ½çš„è§£å†³æ–¹æ¡ˆ:\")\n",
    "    print(\"1. æ£€æŸ¥ authtoken æ˜¯å¦æ­£ç¡®é…ç½®\")\n",
    "    print(\"2. ç¡®è®¤ç½‘ç»œè¿æ¥æ­£å¸¸\")\n",
    "    print(\"3. æ£€æŸ¥æ˜¯å¦è¶…å‡ºå…è´¹ç‰ˆé™åˆ¶\")\n",
    "    print(\"4. é‡æ–°è¿è¡Œ authtoken é…ç½®å•å…ƒæ ¼\")\n",
    "\n",
    "    # æ˜¾ç¤ºå½“å‰é…ç½®çš„ authtokenï¼ˆéƒ¨åˆ†é®è”½ï¼‰\n",
    "    try:\n",
    "        import subprocess\n",
    "        result = subprocess.run(['ngrok', 'config', 'check'], capture_output=True, text=True)\n",
    "        if result.returncode == 0:\n",
    "            print(\"\\nğŸ“‹ å½“å‰ Ngrok é…ç½®çŠ¶æ€: æ­£å¸¸\")\n",
    "        else:\n",
    "            print(f\"\\nâŒ Ngrok é…ç½®æ£€æŸ¥å¤±è´¥: {result.stderr}\")\n",
    "    except:\n",
    "        print(\"\\nâš ï¸ æ— æ³•æ£€æŸ¥ Ngrok é…ç½®çŠ¶æ€\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H_3xOk2mY55g",
    "outputId": "408ad98f-6044-4f4d-d683-31ecf6b3d6cf"
   },
   "outputs": [],
   "source": [
    "# ğŸš€ å¯åŠ¨ FastAPI Web æœåŠ¡\n",
    "#\n",
    "# è¿™ä¸ªå•å…ƒæ ¼çš„ä½œç”¨ï¼š\n",
    "# 1. åº”ç”¨ nest_asyncio è§£å†³ Jupyter ç¯å¢ƒçš„å¼‚æ­¥é—®é¢˜\n",
    "# 2. ä½¿ç”¨ uvicorn å¯åŠ¨ FastAPI åº”ç”¨\n",
    "# 3. åœ¨æŒ‡å®šç«¯å£ä¸Šè¿è¡Œ Web æœåŠ¡ï¼Œé€šè¿‡ Ngrok éš§é“å¯¹å¤–æä¾›æœåŠ¡\n",
    "\n",
    "print(\"ğŸš€ å¯åŠ¨ FastAPI Web æœåŠ¡...\")\n",
    "print(f\"ğŸ“¡ æœ¬åœ°æœåŠ¡ç«¯å£: {port}\")\n",
    "if 'public_url' in globals():\n",
    "    print(f\"ğŸŒ å…¬ç½‘è®¿é—®åœ°å€: {public_url}\")\n",
    "    print(f\"ğŸ“š API æ–‡æ¡£: {public_url}/docs\")\n",
    "else:\n",
    "    print(\"âš ï¸ æœªæ£€æµ‹åˆ° Ngrok éš§é“ï¼Œè¯·å…ˆè¿è¡Œä¸Šä¸€ä¸ªå•å…ƒæ ¼\")\n",
    "\n",
    "print()\n",
    "print(\"ğŸ¯ æœåŠ¡åŠŸèƒ½:\")\n",
    "print(\"   â€¢ å¥åº·æ£€æŸ¥ API\")\n",
    "print(\"   â€¢ æ¨¡å‹é—®ç­” APIï¼ˆåŒæ­¥ï¼‰\")\n",
    "print(\"   â€¢ æ¨¡å‹é—®ç­” APIï¼ˆæµå¼ï¼‰\")\n",
    "print(\"   â€¢ è‡ªåŠ¨ç”Ÿæˆçš„ API æ–‡æ¡£\")\n",
    "print()\n",
    "print(\"ğŸ’¡ æç¤ºï¼š\")\n",
    "print(\"   â€¢ æœåŠ¡å¯åŠ¨åä¼šé˜»å¡å½“å‰å•å…ƒæ ¼ï¼ˆè¿™æ˜¯æ­£å¸¸ç°è±¡ï¼‰\")\n",
    "print(\"   â€¢ å¯ä»¥åœ¨æ–°æ ‡ç­¾é¡µä¸­è®¿é—® API æ–‡æ¡£è¿›è¡Œæµ‹è¯•\")\n",
    "print(\"   â€¢ æŒ‰ Ctrl+C æˆ–ä¸­æ–­å†…æ ¸å¯ä»¥åœæ­¢æœåŠ¡\")\n",
    "print(\"   â€¢ åœæ­¢æœåŠ¡å Ngrok éš§é“ä¹Ÿä¼šå…³é—­\")\n",
    "\n",
    "# åº”ç”¨ nest_asyncio ä»¥åœ¨ Jupyter ç¯å¢ƒä¸­è¿è¡Œå¼‚æ­¥ä»£ç \n",
    "nest_asyncio.apply()\n",
    "\n",
    "try:\n",
    "    # å¯åŠ¨ FastAPI åº”ç”¨\n",
    "    # host=\"0.0.0.0\" å…è®¸å¤–éƒ¨è®¿é—®ï¼ˆé€šè¿‡ Ngrok éš§é“ï¼‰\n",
    "    # port=port ä½¿ç”¨ä¹‹å‰å®šä¹‰çš„ç«¯å£\n",
    "    print(f\"\\nğŸ”„ æ­£åœ¨å¯åŠ¨æœåŠ¡...\")\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=port)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nğŸ›‘ æœåŠ¡å·²åœæ­¢\")\n",
    "    print(\"ğŸ’¡ å¦‚éœ€é‡æ–°å¯åŠ¨ï¼Œè¯·é‡æ–°è¿è¡Œæ­¤å•å…ƒæ ¼\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ æœåŠ¡å¯åŠ¨å¤±è´¥: {e}\")\n",
    "    print(\"ğŸ”§ å¯èƒ½çš„è§£å†³æ–¹æ¡ˆ:\")\n",
    "    print(\"1. æ£€æŸ¥ç«¯å£æ˜¯å¦è¢«å ç”¨\")\n",
    "    print(\"2. ç¡®è®¤ VLLM æœåŠ¡æ­£åœ¨è¿è¡Œ\")\n",
    "    print(\"3. é‡æ–°è¿è¡Œä¾èµ–å®‰è£…å•å…ƒæ ¼\")\n",
    "finally:\n",
    "    # æ¸…ç† Ngrok éš§é“\n",
    "    try:\n",
    "        ngrok.kill()\n",
    "        print(\"ğŸ§¹ Ngrok éš§é“å·²æ¸…ç†\")\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-YRmAQ7Emovh"
   },
   "source": [
    "## ğŸ§ª ç¬¬å…«æ­¥ï¼šAPI ä½¿ç”¨ç¤ºä¾‹\n",
    "\n",
    "æœåŠ¡å¯åŠ¨æˆåŠŸåï¼Œä½ å¯ä»¥é€šè¿‡å¤šç§æ–¹å¼è°ƒç”¨ APIã€‚\n",
    "\n",
    "### ğŸ“¡ API è°ƒç”¨æ–¹å¼\n",
    "\n",
    "#### 1. ğŸŒ æµè§ˆå™¨è®¿é—®\n",
    "- **æœ¬åœ°è®¿é—®**:\n",
    "  - API æ–‡æ¡£: `http://localhost:8081/docs` (Swagger UI)\n",
    "  - å¥åº·æ£€æŸ¥: `http://localhost:8081/`\n",
    "- **å…¬ç½‘è®¿é—®**ï¼ˆé€šè¿‡ Ngrokï¼‰:\n",
    "  - API æ–‡æ¡£: `https://ä½ çš„ngrokåœ°å€/docs`\n",
    "  - å¥åº·æ£€æŸ¥: `https://ä½ çš„ngrokåœ°å€/`\n",
    "\n",
    "#### 2. ğŸ“± å‘½ä»¤è¡Œè°ƒç”¨ (cURL)\n",
    "ä½¿ç”¨ cURL å‘½ä»¤è¡Œå·¥å…·æµ‹è¯• API æ¥å£\n",
    "\n",
    "#### 3. ğŸ Python è°ƒç”¨\n",
    "ä½¿ç”¨ requests åº“æˆ–å…¶ä»– HTTP å®¢æˆ·ç«¯\n",
    "\n",
    "#### 4. ğŸŒ ç§»åŠ¨ç«¯/è¿œç¨‹è®¿é—®\n",
    "é€šè¿‡ Ngrok æä¾›çš„å…¬ç½‘ URLï¼Œå¯ä»¥åœ¨ä»»ä½•è®¾å¤‡ä¸Šè®¿é—®\n",
    "\n",
    "### ğŸ”§ è¯·æ±‚æ ¼å¼è¯´æ˜\n",
    "- **Content-Type**: `application/json`\n",
    "- **è¯·æ±‚ä½“**: JSON æ ¼å¼ï¼ŒåŒ…å« `question` å­—æ®µ\n",
    "- **å“åº”**: JSON æ ¼å¼ï¼ŒåŒ…å«æ¨¡å‹å›ç­”\n",
    "\n",
    "### ğŸŒ Ngrok å…¬ç½‘è®¿é—®ä¼˜åŠ¿\n",
    "\n",
    "#### âœ¨ ä¸»è¦ä¼˜åŠ¿\n",
    "1. **è·¨è®¾å¤‡è®¿é—®**: æ‰‹æœºã€å¹³æ¿ã€å…¶ä»–ç”µè„‘éƒ½å¯ä»¥è®¿é—®\n",
    "2. **å›¢é˜Ÿåä½œ**: å›¢é˜Ÿæˆå‘˜å¯ä»¥ç›´æ¥æµ‹è¯•ä½ çš„ API\n",
    "3. **çœŸå®ç¯å¢ƒ**: æ¨¡æ‹ŸçœŸå®çš„ç½‘ç»œç¯å¢ƒå’Œå»¶è¿Ÿ\n",
    "4. **HTTPS æ”¯æŒ**: è‡ªåŠ¨æä¾› SSL åŠ å¯†ï¼Œå®‰å…¨å¯é \n",
    "\n",
    "#### ğŸ“± ä½¿ç”¨åœºæ™¯\n",
    "- **ç§»åŠ¨ç«¯æµ‹è¯•**: åœ¨æ‰‹æœºä¸Šç›´æ¥æµ‹è¯• API\n",
    "- **è¿œç¨‹æ¼”ç¤º**: å‘å®¢æˆ·æˆ–åŒäº‹å±•ç¤ºé¡¹ç›®\n",
    "- **å‰ç«¯é›†æˆ**: å‰ç«¯å¼€å‘è€…å¯ä»¥ç›´æ¥è°ƒç”¨ API\n",
    "- **ç¬¬ä¸‰æ–¹é›†æˆ**: æ”¯æŒ Webhook ç­‰ç¬¬ä¸‰æ–¹æœåŠ¡\n",
    "\n",
    "### ğŸ’¡ ä½¿ç”¨æç¤º\n",
    "- ä¼˜å…ˆä½¿ç”¨ Ngrok æä¾›çš„ HTTPS åœ°å€\n",
    "- æœ¬åœ°æµ‹è¯•å¯ä»¥ä½¿ç”¨ localhost åœ°å€\n",
    "- æ³¨æ„è¯·æ±‚å’Œå“åº”çš„ JSON æ ¼å¼\n",
    "- å¯ä»¥é€šè¿‡ Swagger UI è¿›è¡Œäº¤äº’å¼æµ‹è¯•\n",
    "- Ngrok åœ°å€æ¯æ¬¡é‡å¯éƒ½ä¼šå˜åŒ–ï¼Œæ³¨æ„æ›´æ–°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SE5HRXATmrWa"
   },
   "source": [
    "### ğŸ“± cURL å‘½ä»¤ç¤ºä¾‹\n",
    "\n",
    "#### ğŸŒ æœ¬åœ°è®¿é—® - ç”Ÿæˆå®Œæ•´å›ç­”\n",
    "```bash\n",
    "curl --location 'http://localhost:8081/api/v1/generate-response' \\\n",
    "--header 'Content-Type: application/json' \\\n",
    "--data '{\n",
    "    \"question\": \"å·´é»åœ¨å“ªé‡Œï¼Ÿ\"\n",
    "}'\n",
    "```\n",
    "\n",
    "#### ğŸŒ å…¬ç½‘è®¿é—®ç¤ºä¾‹ï¼ˆéœ€è¦æ›¿æ¢ä¸ºå®é™…çš„ ngrok åœ°å€ï¼‰\n",
    "```bash\n",
    "curl --location 'https://ä½ çš„ngrokåœ°å€/api/v1/generate-response' \\\n",
    "--header 'Content-Type: application/json' \\\n",
    "--data '{\n",
    "    \"question\": \"å·´é»åœ¨å“ªé‡Œï¼Ÿ\"\n",
    "}'\n",
    "```\n",
    "\n",
    "#### ğŸŒŠ æµå¼å“åº”ç¤ºä¾‹\n",
    "```bash\n",
    "curl --location 'http://localhost:8081/api/v1/generate-response-stream' \\\n",
    "--header 'Content-Type: application/json' \\\n",
    "--data '{\n",
    "    \"question\": \"è¯·è¯¦ç»†ä»‹ç»ä¸€ä¸‹äººå·¥æ™ºèƒ½çš„å‘å±•å†å²\"\n",
    "}'\n",
    "```\n",
    "\n",
    "#### ğŸ”§ å‚æ•°è¯´æ˜\n",
    "- `--location`: è·Ÿéš HTTP é‡å®šå‘\n",
    "- `--header`: è®¾ç½®è¯·æ±‚å¤´ï¼ŒæŒ‡å®šå†…å®¹ç±»å‹\n",
    "- `--data`: å‘é€ JSON æ ¼å¼çš„è¯·æ±‚ä½“"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZYXWde1knE2T"
   },
   "source": [
    "## ğŸ“‹ API å“åº”ç¤ºä¾‹\n",
    "\n",
    "### ğŸ¤– å®Œæ•´å“åº”æ ¼å¼\n",
    "\n",
    "å½“ä½ è°ƒç”¨ `/api/v1/generate-response` ç«¯ç‚¹æ—¶ï¼Œä¼šæ”¶åˆ°å¦‚ä¸‹æ ¼å¼çš„ JSON å“åº”ï¼š\n",
    "\n",
    "#### ğŸ“Š å“åº”ç»“æ„è¯´æ˜\n",
    "- **id**: è¯·æ±‚çš„å”¯ä¸€æ ‡è¯†ç¬¦\n",
    "- **object**: å“åº”å¯¹è±¡ç±»å‹\n",
    "- **created**: å“åº”åˆ›å»ºæ—¶é—´æˆ³\n",
    "- **model**: ä½¿ç”¨çš„æ¨¡å‹åç§°\n",
    "- **choices**: æ¨¡å‹ç”Ÿæˆçš„é€‰æ‹©åˆ—è¡¨\n",
    "  - **index**: é€‰æ‹©çš„ç´¢å¼•\n",
    "  - **message**: æ¶ˆæ¯å†…å®¹\n",
    "    - **role**: è§’è‰²ï¼ˆassistantï¼‰\n",
    "    - **content**: æ¨¡å‹ç”Ÿæˆçš„å›ç­”\n",
    "  - **finish_reason**: å®ŒæˆåŸå› ï¼ˆstop è¡¨ç¤ºæ­£å¸¸ç»“æŸï¼‰\n",
    "- **usage**: ä»¤ç‰Œä½¿ç”¨ç»Ÿè®¡\n",
    "  - **prompt_tokens**: è¾“å…¥ä»¤ç‰Œæ•°\n",
    "  - **completion_tokens**: ç”Ÿæˆä»¤ç‰Œæ•°\n",
    "  - **total_tokens**: æ€»ä»¤ç‰Œæ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EXziLO52nH1e"
   },
   "outputs": [],
   "source": [
    "{\n",
    "  \"response\": {\n",
    "    \"id\": \"chatcmpl-13e29c35212b486ead18d91aa0668886\",\n",
    "    \"object\": \"chat.completion\",\n",
    "    \"created\": 1752386782,\n",
    "    \"model\": \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\n",
    "    \"choices\": [\n",
    "      {\n",
    "        \"index\": 0,\n",
    "        \"message\": {\n",
    "          \"role\": \"assistant\",\n",
    "          \"reasoning_content\": null,\n",
    "          \"content\": \"å¥½ï¼Œç”¨æˆ·å‘æ¥â€œå‘¦å‘¦é¹¿é¸£â€è¿™ä¸ªè¯ï¼Œçœ‹èµ·æ¥åƒæ˜¯åœ¨ç©æ‰‹æœºçš„è¯­éŸ³åˆæˆåŠŸèƒ½ã€‚æˆ‘åº”è¯¥å›å¤ç”¨æˆ·ä¸€ä¸ªå‹å¥½åˆæœ‰è¶£çš„å›åº”ï¼Œæ¯”å¦‚â€œå—¯ï¼Œçœ‹åˆ°ä½ è¿™ä¹ˆè¯´ï¼Œæˆ‘å¥½åƒä¹Ÿå¬åˆ°äº†ï¼Œé¹¿é¸£çš„å£°éŸ³å¾ˆæ¸©æŸ”å•Šï¼â€è¿™æ ·æ—¢å›åº”äº†ä»–ä»¬çš„æé—®ï¼Œåˆè®©è¯­æ°”æ›´ç”ŸåŠ¨ã€‚å¦å¤–ï¼Œå¯ä»¥ç”¨ä¸€äº›è½»æ¾çš„è¯­æ°”ï¼Œè®©ç”¨æˆ·è§‰å¾—æœ‰è¶£åˆä¸è§‰å¾—å‹åŠ›ã€‚å¯èƒ½ç”¨æˆ·æƒ³äº†è§£è¿™å¥è¯çš„å«ä¹‰ï¼Œæˆ–è€…åªæ˜¯æƒ³åœ¨èŠå¤©ã€‚æ‰€ä»¥ï¼Œæˆ‘éœ€è¦ä¿æŒè‡ªç„¶ï¼Œä¸æ˜¾å¾—å¤ªç”Ÿç¡¬ã€‚å¦å¤–ï¼Œå¯èƒ½ç”¨æˆ·æ˜¯æƒ³æµ‹è¯•ä¸€ä¸‹è¯­éŸ³åˆæˆçš„åŠŸèƒ½ï¼Œæˆ–è€…æ˜¯æƒ³äº†è§£ä¸€äº›æœ‰è¶£çš„è¯é¢˜ã€‚ä¸ç®¡æ€æ ·ï¼Œå›åº”è¦å‹å¥½ï¼ŒåŒæ—¶å¸¦ç‚¹è¶£å‘³ï¼Œè®©ç”¨æˆ·æ„Ÿåˆ°æ„‰å¿«ã€‚\\n</think>\\n\\nå—¯ï¼Œçœ‹åˆ°ä½ è¿™ä¹ˆè¯´ï¼Œæˆ‘å¥½åƒä¹Ÿå¬åˆ°äº†ï¼Œé¹¿é¸£çš„å£°éŸ³å¾ˆæ¸©æŸ”å•Šï¼\",\n",
    "          \"tool_calls\": []\n",
    "        },\n",
    "        \"logprobs\": null,\n",
    "        \"finish_reason\": \"stop\",\n",
    "        \"stop_reason\": null\n",
    "      }\n",
    "    ],\n",
    "    \"usage\": {\n",
    "      \"prompt_tokens\": 9,\n",
    "      \"total_tokens\": 176,\n",
    "      \"completion_tokens\": 167,\n",
    "      \"prompt_tokens_details\": null\n",
    "    },\n",
    "    \"prompt_logprobs\": null,\n",
    "    \"kv_transfer_params\": null\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eRer8bosm041"
   },
   "source": [
    "### ğŸŒŠ æµå¼å“åº”æ ¼å¼\n",
    "\n",
    "å½“ä½ è°ƒç”¨ `/api/v1/generate-response-stream` ç«¯ç‚¹æ—¶ï¼Œä¼šæ”¶åˆ°ä¸€ç³»åˆ— JSON å¯¹è±¡ï¼Œæ¯ä¸ªå¯¹è±¡ä»£è¡¨ç”Ÿæˆè¿‡ç¨‹ä¸­çš„ä¸€ä¸ªæ­¥éª¤ï¼š\n",
    "\n",
    "#### ğŸ“¡ æµå¼å“åº”ç‰¹ç‚¹\n",
    "- **å®æ—¶æ€§**: é€æ­¥è¿”å›ç”Ÿæˆå†…å®¹ï¼Œæ— éœ€ç­‰å¾…å®Œæ•´å›ç­”\n",
    "- **ä½å»¶è¿Ÿ**: ç”¨æˆ·å¯ä»¥ç«‹å³çœ‹åˆ°æ¨¡å‹å¼€å§‹ç”Ÿæˆ\n",
    "- **æ›´å¥½ä½“éªŒ**: é€‚åˆé•¿æ–‡æœ¬ç”Ÿæˆå’Œå®æ—¶å¯¹è¯\n",
    "\n",
    "#### ğŸ”„ æµå¼æ•°æ®æ ¼å¼\n",
    "æ¯è¡Œæ•°æ®éƒ½æ˜¯ä¸€ä¸ªç‹¬ç«‹çš„ JSON å¯¹è±¡ï¼ŒåŒ…å«ï¼š\n",
    "- **id**: è¯·æ±‚æ ‡è¯†ç¬¦ï¼ˆæ•´ä¸ªæµä¸­ä¿æŒä¸€è‡´ï¼‰\n",
    "- **object**: \"chat.completion.chunk\"\n",
    "- **created**: æ—¶é—´æˆ³\n",
    "- **model**: æ¨¡å‹åç§°\n",
    "- **choices**: å½“å‰ç”Ÿæˆçš„å†…å®¹å—\n",
    "  - **index**: é€‰æ‹©ç´¢å¼•\n",
    "  - **delta**: å¢é‡å†…å®¹\n",
    "    - **content**: æ–°ç”Ÿæˆçš„æ–‡æœ¬ç‰‡æ®µ\n",
    "  - **finish_reason**: ç»“æŸåŸå› ï¼ˆnull è¡¨ç¤ºç»§ç»­ï¼Œ\"stop\" è¡¨ç¤ºç»“æŸï¼‰\n",
    "\n",
    "#### ğŸ’¡ ä½¿ç”¨å»ºè®®\n",
    "- é€‚åˆéœ€è¦å®æ—¶åé¦ˆçš„åº”ç”¨åœºæ™¯\n",
    "- å¯ä»¥å®ç°æ‰“å­—æœºæ•ˆæœçš„ç”¨æˆ·ç•Œé¢\n",
    "- å¯¹äºé•¿æ–‡æœ¬ç”Ÿæˆç‰¹åˆ«æœ‰ç”¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l51K5q5Cmwu_"
   },
   "outputs": [],
   "source": [
    "{\"id\":\"chatcmpl-72594106be2541269cc68e8b37123051\",\"object\":\"chat.completion.chunk\",\"created\":1752386825,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
    "{\"id\":\"chatcmpl-72594106be2541269cc68e8b37123051\",\"object\":\"chat.completion.chunk\",\"created\":1752386825,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"å—¯\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
    "{\"id\":\"chatcmpl-72594106be2541269cc68e8b37123051\",\"object\":\"chat.completion.chunk\",\"created\":1752386825,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"ï¼Œ\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
    "{\"id\":\"chatcmpl-72594106be2541269cc68e8b37123051\",\"object\":\"chat.completion.chunk\",\"created\":1752386825,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"æˆ‘ç°åœ¨\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
    "{\"id\":\"chatcmpl-72594106be2541269cc68e8b37123051\",\"object\":\"chat.completion.chunk\",\"created\":1752386825,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"åœ¨\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
    "{\"id\":\"chatcmpl-72594106be2541269cc68e8b37123051\",\"object\":\"chat.completion.chunk\",\"created\":1752386825,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"å­¦ä¹ \"},\"logprobs\":null,\"finish_reason\":null}]}\n",
    "{\"id\":\"chatcmpl-72594106be2541269cc68e8b37123051\",\"object\":\"chat.completion.chunk\",\"created\":1752386825,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"å¤§\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
    "{\"id\":\"chatcmpl-72594106be2541269cc68e8b37123051\",\"object\":\"chat.completion.chunk\",\"created\":1752386825,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"æ¨¡å‹\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
    "{\"id\":\"chatcmpl-72594106be2541269cc68e8b37123051\",\"object\":\"chat.completion.chunk\",\"created\":1752386825,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"ï¼Œ\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
    "{\"id\":\"chatcmpl-72594106be2541269cc68e8b37123051\",\"object\":\"chat.completion.chunk\",\"created\":1752386825,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"æ¯”å¦‚\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
    "...\n",
    "[DONE]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZbY6mDWCmTsf"
   },
   "source": [
    "### Kill the VLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MQbgsTX83j8i"
   },
   "outputs": [],
   "source": [
    "vllm_process.terminate()\n",
    "vllm_process.wait()  # Wait for process to terminate"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python (agent101)",
   "language": "python",
   "name": "agent101"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
