{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FlyAIBox/Agent_In_Action/blob/main/01-agent-llm-mcp/prompt-enginner/AgentWithTools.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "826g9MUI5EFg"
      },
      "source": [
        "# 智能体工具调用系统 - 详细说明\n",
        "\n",
        "## 项目概述\n",
        "这是一个基于大语言模型（LLM）的智能体系统，演示了如何让AI智能体使用工具来执行具体任务。该系统展示了现代AI智能体的核心概念：**工具调用（Tool Calling）**。\n",
        "\n",
        "## 核心功能\n",
        "1. **智能体循环（Agent Loop）**：智能体能够持续思考和行动，直到完成任务\n",
        "2. **工具调用机制**：智能体可以调用预定义的工具（如文件操作）\n",
        "3. **结构化响应解析**：将LLM的自然语言响应解析为结构化的工具调用指令\n",
        "4. **记忆管理**：维护对话历史，让智能体能够基于之前的交互做出决策\n",
        "\n",
        "## 技术架构\n",
        "- **LLM引擎**：使用LiteLLM调用OpenAI GPT-4o模型\n",
        "- **工具系统**：预定义的工具函数（list_files, read_file, terminate）\n",
        "- **解析器**：将LLM响应解析为JSON格式的工具调用\n",
        "- **循环控制**：防止无限循环的安全机制\n",
        "\n",
        "## 学习价值\n",
        "这个示例非常适合我们来理解：\n",
        "- 智能体如何与外部工具交互\n",
        "- LLM如何生成结构化的工具调用指令\n",
        "- 如何构建一个完整的智能体工作流\n",
        "- 现代AI应用的基本架构模式\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KEYrzG2vB8Ip",
        "outputId": "717160c7-7cce-45b4-cd98-712136fead31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Collecting openai==1.107.0',\n",
              " '  Downloading openai-1.107.0-py3-none-any.whl.metadata (29 kB)',\n",
              " 'Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai==1.107.0) (4.11.0)',\n",
              " 'Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai==1.107.0) (1.9.0)',\n",
              " 'Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai==1.107.0) (0.28.1)',\n",
              " 'Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai==1.107.0) (0.11.1)',\n",
              " 'Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai==1.107.0) (2.11.10)',\n",
              " 'Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai==1.107.0) (1.3.1)',\n",
              " 'Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai==1.107.0) (4.67.1)',\n",
              " 'Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai==1.107.0) (4.15.0)',\n",
              " 'Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai==1.107.0) (3.11)',\n",
              " 'Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai==1.107.0) (2025.10.5)',\n",
              " 'Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai==1.107.0) (1.0.9)',\n",
              " 'Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.107.0) (0.16.0)',\n",
              " 'Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai==1.107.0) (0.7.0)',\n",
              " 'Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai==1.107.0) (2.33.2)',\n",
              " 'Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai==1.107.0) (0.4.2)',\n",
              " 'Downloading openai-1.107.0-py3-none-any.whl (950 kB)',\n",
              " '\\x1b[?25l   \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m0.0/951.0 kB\\x1b[0m \\x1b[31m?\\x1b[0m eta \\x1b[36m-:--:--\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m942.1/951.0 kB\\x1b[0m \\x1b[31m28.2 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m951.0/951.0 kB\\x1b[0m \\x1b[31m14.2 MB/s\\x1b[0m eta \\x1b[36m0:00:00\\x1b[0m',\n",
              " '\\x1b[?25hInstalling collected packages: openai',\n",
              " '  Attempting uninstall: openai',\n",
              " '    Found existing installation: openai 1.109.1',\n",
              " '    Uninstalling openai-1.109.1:',\n",
              " '      Successfully uninstalled openai-1.109.1',\n",
              " 'Successfully installed openai-1.107.0']"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# 安装必要的依赖包\n",
        "!!pip install openai==1.107.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 导入必要的模块\n",
        "import os, getpass\n",
        "\n",
        "def _set_env(var: str):\n",
        "    \"\"\"\n",
        "    设置环境变量的辅助函数\n",
        "\n",
        "    参数:\n",
        "        var (str): 要设置的环境变量名称\n",
        "\n",
        "    功能:\n",
        "        - 检查环境变量是否已存在\n",
        "        - 如果不存在，则提示用户输入并设置\n",
        "    \"\"\"\n",
        "    if not os.environ.get(var):  # 检查环境变量是否已设置\n",
        "        os.environ[var] = getpass.getpass(f\"{var}: \")  # 安全地获取用户输入\n",
        "\n",
        "# 设置 OpenAI API 密钥\n",
        "# 这是使用 OpenAI 模型所必需的\n",
        "_set_env(\"OPENAI_API_KEY\")\n",
        "# 设置 OpenAI API代理地址 (例如：https://api.apiyi.com/v1）\n",
        "_set_env(\"OPENAI_BASE_URL\")"
      ],
      "metadata": {
        "id": "3vX9MGgw6_Xk",
        "outputId": "33bc90b0-361b-4058-9fcd-40ed195f1a3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OPENAI_API_KEY: ··········\n",
            "OPENAI_BASE_URL: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mwe2eeOQB0cC",
        "outputId": "5aa97079-b278-43f9-b555-fc00bd35761b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What would you like me to do? 告诉我当前目录里有什么内容\n",
            "Agent thinking...\n",
            "Agent response: 为了提供准确的信息，我将列出当前目录中的所有文件。\n",
            "Action result: {'error': 'Invalid JSON response. You must respond with a JSON tool invocation.'}\n",
            "Agent thinking...\n",
            "Agent response: ```action\n",
            "{\n",
            "    \"tool_name\": \"list_files\",\n",
            "    \"args\": {}\n",
            "}\n",
            "```\n",
            "Action result: {'result': ['.config', 'sample_data']}\n",
            "Agent thinking...\n",
            "Agent response: 当前目录中包含两个项目：一个名为“.config”的项目和另一个名为“sample_data”的项目。如果你需要进一步的信息或需要查看其中的某个内容，请告诉我。我可以帮助读取或探索这些项目内的内容。\n",
            "Action result: {'error': 'Invalid JSON response. You must respond with a JSON tool invocation.'}\n",
            "Agent thinking...\n",
            "Agent response: ```action\n",
            "{\n",
            "    \"tool_name\": \"terminate\",\n",
            "    \"args\": {\n",
            "        \"message\": \"当前目录中包含两个项目：一个名为“.config”的项目和另一个名为“sample_data”的项目。\"\n",
            "    }\n",
            "}\n",
            "```\n",
            "当前目录中包含两个项目：一个名为“.config”的项目和另一个名为“sample_data”的项目。\n"
          ]
        }
      ],
      "source": [
        "# ===== 导入必要的库 =====\n",
        "import json  # 用于JSON数据处理\n",
        "import os    # 用于操作系统相关操作\n",
        "import sys   # 用于系统相关操作\n",
        "from typing import List, Dict   # 类型提示，提高代码可读性\n",
        "from openai import OpenAI       # 用于调用OpenAI API\n",
        "# ===== 核心工具函数定义 =====\n",
        "\n",
        "def extract_markdown_block(response: str, block_type: str = \"json\") -> str:\n",
        "    \"\"\"\n",
        "    从LLM响应中提取代码块内容\n",
        "\n",
        "    参数:\n",
        "        response: LLM的原始响应文本\n",
        "        block_type: 要提取的代码块类型，默认为\"json\"\n",
        "\n",
        "    返回:\n",
        "        提取出的代码块内容\n",
        "    \"\"\"\n",
        "    # 检查响应中是否包含代码块标记\n",
        "    if not '```' in response:\n",
        "        return response\n",
        "\n",
        "    # 分割响应并提取第一个代码块\n",
        "    code_block = response.split('```')[1].strip()\n",
        "\n",
        "    # 如果代码块以指定类型开头，则移除类型标识\n",
        "    if code_block.startswith(block_type):\n",
        "        code_block = code_block[len(block_type):].strip()\n",
        "\n",
        "    return code_block\n",
        "\n",
        "def generate_response(messages: List[Dict]) -> str:\n",
        "    \"\"\"\n",
        "    调用LLM生成响应\n",
        "\n",
        "    参数:\n",
        "        messages: 消息列表，包含系统提示和对话历史\n",
        "\n",
        "    返回:\n",
        "        LLM生成的响应文本\n",
        "    \"\"\"\n",
        "    # 使用LiteLLM调用OpenAI GPT-4o模型\n",
        "\n",
        "    client=OpenAI(\n",
        "        base_url=os.environ['OPENAI_BASE_URL'],\n",
        "        api_key=os.environ['OPENAI_API_KEY']\n",
        "    )\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",  # 指定使用的模型\n",
        "        messages=messages,      # 传入消息列表\n",
        "        max_tokens=1024         # 限制最大token数量\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "def parse_action(response: str) -> Dict:\n",
        "    \"\"\"\n",
        "    解析LLM响应，提取结构化的工具调用指令\n",
        "\n",
        "    参数:\n",
        "        response: LLM的响应文本\n",
        "\n",
        "    返回:\n",
        "        包含工具名称和参数的字典\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # 从响应中提取action代码块\n",
        "        response = extract_markdown_block(response, \"action\")\n",
        "\n",
        "        # 将JSON字符串解析为Python字典\n",
        "        response_json = json.loads(response)\n",
        "\n",
        "        # 验证响应格式是否正确\n",
        "        if \"tool_name\" in response_json and \"args\" in response_json:\n",
        "            return response_json\n",
        "        else:\n",
        "            # 如果格式不正确，返回错误信息\n",
        "            return {\"tool_name\": \"error\", \"args\": {\"message\": \"You must respond with a JSON tool invocation.\"}}\n",
        "    except json.JSONDecodeError:\n",
        "        # 如果JSON解析失败，返回错误信息\n",
        "        return {\"tool_name\": \"error\", \"args\": {\"message\": \"Invalid JSON response. You must respond with a JSON tool invocation.\"}}\n",
        "\n",
        "# ===== 智能体可用的工具函数 =====\n",
        "\n",
        "def list_files() -> List[str]:\n",
        "    \"\"\"\n",
        "    列出当前目录中的所有文件\n",
        "\n",
        "    返回:\n",
        "        文件名列表\n",
        "    \"\"\"\n",
        "    return os.listdir(\".\")\n",
        "\n",
        "def read_file(file_name: str) -> str:\n",
        "    \"\"\"\n",
        "    读取指定文件的内容\n",
        "\n",
        "    参数:\n",
        "        file_name: 要读取的文件名\n",
        "\n",
        "    返回:\n",
        "        文件内容或错误信息\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(file_name, \"r\") as file:\n",
        "            return file.read()\n",
        "    except FileNotFoundError:\n",
        "        return f\"Error: {file_name} not found.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "# ===== 智能体系统提示词定义 =====\n",
        "# 这个提示词定义了智能体的行为规则和可用工具\n",
        "agent_rules = [{\n",
        "    \"role\": \"system\",\n",
        "    \"content\": \"\"\"\n",
        "你是一个AI智能体，可以通过使用可用工具来执行任务。\n",
        "\n",
        "可用工具:\n",
        "\n",
        "```json\n",
        "{\n",
        "    \"list_files\": {\n",
        "        \"description\": \"列出当前目录中的所有文件。\",\n",
        "        \"parameters\": {}\n",
        "    },\n",
        "    \"read_file\": {\n",
        "        \"description\": \"读取文件的内容。\",\n",
        "        \"parameters\": {\n",
        "            \"file_name\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"要读取的文件名。\"\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"terminate\": {\n",
        "        \"description\": \"结束智能体循环并提供任务摘要。\",\n",
        "        \"parameters\": {\n",
        "            \"message\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"返回给用户的摘要消息。\"\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "```\n",
        "\n",
        "如果用户询问文件、文档或内容，请先列出文件，然后再读取它们。\n",
        "\n",
        "当你完成任务后，使用\"terminate\"工具结束对话，我将向用户提供结果。\n",
        "\n",
        "重要！！！每个响应都必须包含一个动作。\n",
        "你必须始终按照以下格式响应：\n",
        "\n",
        "<停下来逐步思考。参数映射到args。在这里插入你逐步思考的丰富描述。>\n",
        "\n",
        "```action\n",
        "{\n",
        "    \"tool_name\": \"插入工具名称\",\n",
        "    \"args\": {...在这里填入任何必需的参数...}\n",
        "}```\n",
        "\"\"\"\n",
        "}]\n",
        "\n",
        "# ===== 智能体主循环初始化 =====\n",
        "iterations = 0        # 当前迭代次数\n",
        "max_iterations = 10   # 最大迭代次数，防止无限循环\n",
        "\n",
        "# 获取用户任务\n",
        "user_task = input(\"What would you like me to do? \")\n",
        "\n",
        "# 初始化对话记忆，包含用户的任务\n",
        "memory = [{\"role\": \"user\", \"content\": user_task}]\n",
        "\n",
        "# ===== 智能体主循环 =====\n",
        "# 这是智能体的核心工作循环，持续执行直到任务完成或达到最大迭代次数\n",
        "while iterations < max_iterations:\n",
        "    # 1. 构建提示：将智能体规则与对话记忆结合\n",
        "    prompt = agent_rules + memory\n",
        "\n",
        "    # 2. 调用LLM生成响应\n",
        "    print(\"Agent thinking...\")\n",
        "    response = generate_response(prompt)\n",
        "    print(f\"Agent response: {response}\")\n",
        "\n",
        "    # 3. 解析响应以确定要执行的动作\n",
        "    action = parse_action(response)\n",
        "    result = \"Action executed\"  # 默认结果\n",
        "\n",
        "    # 4. 根据解析出的动作执行相应的工具函数\n",
        "    if action[\"tool_name\"] == \"list_files\":\n",
        "        result = {\"result\": list_files()}\n",
        "    elif action[\"tool_name\"] == \"read_file\":\n",
        "        result = {\"result\": read_file(action[\"args\"][\"file_name\"])}\n",
        "    elif action[\"tool_name\"] == \"error\":\n",
        "        result = {\"error\": action[\"args\"][\"message\"]}\n",
        "    elif action[\"tool_name\"] == \"terminate\":\n",
        "        print(action[\"args\"][\"message\"])\n",
        "        break  # 终止循环\n",
        "    else:\n",
        "        result = {\"error\": \"Unknown action: \" + action[\"tool_name\"]}\n",
        "\n",
        "    print(f\"Action result: {result}\")\n",
        "\n",
        "    # 5. 更新对话记忆，添加智能体响应和执行结果\n",
        "    memory.extend([\n",
        "        {\"role\": \"assistant\", \"content\": response},\n",
        "        {\"role\": \"user\", \"content\": json.dumps(result)}\n",
        "    ])\n",
        "\n",
        "    # 6. 检查终止条件\n",
        "    if action[\"tool_name\"] == \"terminate\":\n",
        "        break\n",
        "\n",
        "    iterations += 1  # 增加迭代计数\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}