{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 智能体工具调用系统 - 详细说明\n",
        "\n",
        "## 项目概述\n",
        "这是一个基于大语言模型（LLM）的智能体系统，演示了如何让AI智能体使用工具来执行具体任务。该系统展示了现代AI智能体的核心概念：**工具调用（Tool Calling）**。\n",
        "\n",
        "## 核心功能\n",
        "1. **智能体循环（Agent Loop）**：智能体能够持续思考和行动，直到完成任务\n",
        "2. **工具调用机制**：智能体可以调用预定义的工具（如文件操作）\n",
        "3. **结构化响应解析**：将LLM的自然语言响应解析为结构化的工具调用指令\n",
        "4. **记忆管理**：维护对话历史，让智能体能够基于之前的交互做出决策\n",
        "\n",
        "## 技术架构\n",
        "- **LLM引擎**：使用LiteLLM调用OpenAI GPT-4o模型\n",
        "- **工具系统**：预定义的工具函数（list_files, read_file, terminate）\n",
        "- **解析器**：将LLM响应解析为JSON格式的工具调用\n",
        "- **循环控制**：防止无限循环的安全机制\n",
        "\n",
        "## 学习价值\n",
        "这个示例非常适合初学者理解：\n",
        "- 智能体如何与外部工具交互\n",
        "- LLM如何生成结构化的工具调用指令\n",
        "- 如何构建一个完整的智能体工作流\n",
        "- 现代AI应用的基本架构模式\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KEYrzG2vB8Ip"
      },
      "outputs": [],
      "source": [
        "# 安装必要的依赖包\n",
        "# LiteLLM是一个统一的LLM调用库，支持多种模型提供商\n",
        "!!pip install litellm\n",
        "\n",
        "# ===== 重要配置说明 =====\n",
        "# \n",
        "# 1. 在Colab中设置API密钥：\n",
        "#    <---- 点击左侧的\"密钥\"图标，添加你的'OPENAI_API_KEY'\n",
        "#\n",
        "# 2. 添加示例文件：\n",
        "#    在左侧\"文件\"图标中添加一些示例文件\n",
        "#    当智能体询问要做什么时，可以从简单的问题开始\n",
        "#    比如：\"告诉我这个目录里有什么文件\"\n",
        "#\n",
        "# ===== 环境配置 =====\n",
        "\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# 从Colab的用户数据中获取OpenAI API密钥\n",
        "# 这是Colab特有的功能，用于安全地存储敏感信息\n",
        "api_key = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "# 将API密钥设置为环境变量，供后续的LLM调用使用\n",
        "os.environ['OPENAI_API_KEY'] = api_key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mwe2eeOQB0cC",
        "outputId": "820be328-a9a9-4510-80b1-cdb2ade9e835"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "What would you like me to do? tell me what is in the dir\n",
            "Agent thinking...\n",
            "Agent response: <To respond to the user's request to know what is in the current directory, the first step is to list all the files in the directory. I will proceed with listing the files.>\n",
            "\n",
            "```action\n",
            "{\n",
            "    \"tool_name\": \"list_files\",\n",
            "    \"args\": {}\n",
            "}\n",
            "```\n",
            "Action result: {'result': ['.config', 'sample_data']}\n",
            "Agent thinking...\n",
            "Agent response: <The list of files indicates two items in the directory: \".config\" and \"sample_data\". Since these could either be directories or files, further exploration might be needed depending on the user's request. However, at this point, my task of listing the contents of the directory is complete based on the user's query. To conclude, I will end the session with a summary.>\n",
            "\n",
            "```action\n",
            "{\n",
            "    \"tool_name\": \"terminate\",\n",
            "    \"args\": {\n",
            "        \"message\": \"The current directory contains a configuration directory labeled \\\".config\\\" and another directory or collection labeled \\\"sample_data\\\".\"\n",
            "    }\n",
            "}\n",
            "```\n",
            "The current directory contains a configuration directory labeled \".config\" and another directory or collection labeled \"sample_data\".\n"
          ]
        }
      ],
      "source": [
        "# ===== 导入必要的库 =====\n",
        "import json  # 用于JSON数据处理\n",
        "import os    # 用于操作系统相关操作\n",
        "import sys   # 用于系统相关操作\n",
        "from litellm import completion  # LiteLLM库，用于调用各种LLM模型\n",
        "from typing import List, Dict   # 类型提示，提高代码可读性\n",
        "\n",
        "# ===== 核心工具函数定义 =====\n",
        "\n",
        "def extract_markdown_block(response: str, block_type: str = \"json\") -> str:\n",
        "    \"\"\"\n",
        "    从LLM响应中提取代码块内容\n",
        "    \n",
        "    参数:\n",
        "        response: LLM的原始响应文本\n",
        "        block_type: 要提取的代码块类型，默认为\"json\"\n",
        "    \n",
        "    返回:\n",
        "        提取出的代码块内容\n",
        "    \"\"\"\n",
        "    # 检查响应中是否包含代码块标记\n",
        "    if not '```' in response:\n",
        "        return response\n",
        "\n",
        "    # 分割响应并提取第一个代码块\n",
        "    code_block = response.split('```')[1].strip()\n",
        "\n",
        "    # 如果代码块以指定类型开头，则移除类型标识\n",
        "    if code_block.startswith(block_type):\n",
        "        code_block = code_block[len(block_type):].strip()\n",
        "\n",
        "    return code_block\n",
        "\n",
        "def generate_response(messages: List[Dict]) -> str:\n",
        "    \"\"\"\n",
        "    调用LLM生成响应\n",
        "    \n",
        "    参数:\n",
        "        messages: 消息列表，包含系统提示和对话历史\n",
        "    \n",
        "    返回:\n",
        "        LLM生成的响应文本\n",
        "    \"\"\"\n",
        "    # 使用LiteLLM调用OpenAI GPT-4o模型\n",
        "    response = completion(\n",
        "        model=\"openai/gpt-4o\",  # 指定使用的模型\n",
        "        messages=messages,      # 传入消息列表\n",
        "        max_tokens=1024         # 限制最大token数量\n",
        "    )\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "def parse_action(response: str) -> Dict:\n",
        "    \"\"\"\n",
        "    解析LLM响应，提取结构化的工具调用指令\n",
        "    \n",
        "    参数:\n",
        "        response: LLM的响应文本\n",
        "    \n",
        "    返回:\n",
        "        包含工具名称和参数的字典\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # 从响应中提取action代码块\n",
        "        response = extract_markdown_block(response, \"action\")\n",
        "        \n",
        "        # 将JSON字符串解析为Python字典\n",
        "        response_json = json.loads(response)\n",
        "        \n",
        "        # 验证响应格式是否正确\n",
        "        if \"tool_name\" in response_json and \"args\" in response_json:\n",
        "            return response_json\n",
        "        else:\n",
        "            # 如果格式不正确，返回错误信息\n",
        "            return {\"tool_name\": \"error\", \"args\": {\"message\": \"You must respond with a JSON tool invocation.\"}}\n",
        "    except json.JSONDecodeError:\n",
        "        # 如果JSON解析失败，返回错误信息\n",
        "        return {\"tool_name\": \"error\", \"args\": {\"message\": \"Invalid JSON response. You must respond with a JSON tool invocation.\"}}\n",
        "\n",
        "# ===== 智能体可用的工具函数 =====\n",
        "\n",
        "def list_files() -> List[str]:\n",
        "    \"\"\"\n",
        "    列出当前目录中的所有文件\n",
        "    \n",
        "    返回:\n",
        "        文件名列表\n",
        "    \"\"\"\n",
        "    return os.listdir(\".\")\n",
        "\n",
        "def read_file(file_name: str) -> str:\n",
        "    \"\"\"\n",
        "    读取指定文件的内容\n",
        "    \n",
        "    参数:\n",
        "        file_name: 要读取的文件名\n",
        "    \n",
        "    返回:\n",
        "        文件内容或错误信息\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(file_name, \"r\") as file:\n",
        "            return file.read()\n",
        "    except FileNotFoundError:\n",
        "        return f\"Error: {file_name} not found.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "# ===== 智能体系统提示词定义 =====\n",
        "# 这个提示词定义了智能体的行为规则和可用工具\n",
        "agent_rules = [{\n",
        "    \"role\": \"system\",\n",
        "    \"content\": \"\"\"\n",
        "你是一个AI智能体，可以通过使用可用工具来执行任务。\n",
        "\n",
        "可用工具:\n",
        "\n",
        "```json\n",
        "{\n",
        "    \"list_files\": {\n",
        "        \"description\": \"列出当前目录中的所有文件。\",\n",
        "        \"parameters\": {}\n",
        "    },\n",
        "    \"read_file\": {\n",
        "        \"description\": \"读取文件的内容。\",\n",
        "        \"parameters\": {\n",
        "            \"file_name\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"要读取的文件名。\"\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"terminate\": {\n",
        "        \"description\": \"结束智能体循环并提供任务摘要。\",\n",
        "        \"parameters\": {\n",
        "            \"message\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"返回给用户的摘要消息。\"\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "```\n",
        "\n",
        "如果用户询问文件、文档或内容，请先列出文件，然后再读取它们。\n",
        "\n",
        "当你完成任务后，使用\"terminate\"工具结束对话，我将向用户提供结果。\n",
        "\n",
        "重要！！！每个响应都必须包含一个动作。\n",
        "你必须始终按照以下格式响应：\n",
        "\n",
        "<停下来逐步思考。参数映射到args。在这里插入你逐步思考的丰富描述。>\n",
        "\n",
        "```action\n",
        "{\n",
        "    \"tool_name\": \"插入工具名称\",\n",
        "    \"args\": {...在这里填入任何必需的参数...}\n",
        "}```\n",
        "\"\"\"\n",
        "}]\n",
        "\n",
        "# ===== 智能体主循环初始化 =====\n",
        "iterations = 0        # 当前迭代次数\n",
        "max_iterations = 10   # 最大迭代次数，防止无限循环\n",
        "\n",
        "# 获取用户任务\n",
        "user_task = input(\"What would you like me to do? \")\n",
        "\n",
        "# 初始化对话记忆，包含用户的任务\n",
        "memory = [{\"role\": \"user\", \"content\": user_task}]\n",
        "\n",
        "# ===== 智能体主循环 =====\n",
        "# 这是智能体的核心工作循环，持续执行直到任务完成或达到最大迭代次数\n",
        "while iterations < max_iterations:\n",
        "    # 1. 构建提示：将智能体规则与对话记忆结合\n",
        "    prompt = agent_rules + memory\n",
        "\n",
        "    # 2. 调用LLM生成响应\n",
        "    print(\"Agent thinking...\")\n",
        "    response = generate_response(prompt)\n",
        "    print(f\"Agent response: {response}\")\n",
        "\n",
        "    # 3. 解析响应以确定要执行的动作\n",
        "    action = parse_action(response)\n",
        "    result = \"Action executed\"  # 默认结果\n",
        "\n",
        "    # 4. 根据解析出的动作执行相应的工具函数\n",
        "    if action[\"tool_name\"] == \"list_files\":\n",
        "        result = {\"result\": list_files()}\n",
        "    elif action[\"tool_name\"] == \"read_file\":\n",
        "        result = {\"result\": read_file(action[\"args\"][\"file_name\"])}\n",
        "    elif action[\"tool_name\"] == \"error\":\n",
        "        result = {\"error\": action[\"args\"][\"message\"]}\n",
        "    elif action[\"tool_name\"] == \"terminate\":\n",
        "        print(action[\"args\"][\"message\"])\n",
        "        break  # 终止循环\n",
        "    else:\n",
        "        result = {\"error\": \"Unknown action: \" + action[\"tool_name\"]}\n",
        "\n",
        "    print(f\"Action result: {result}\")\n",
        "\n",
        "    # 5. 更新对话记忆，添加智能体响应和执行结果\n",
        "    memory.extend([\n",
        "        {\"role\": \"assistant\", \"content\": response},\n",
        "        {\"role\": \"user\", \"content\": json.dumps(result)}\n",
        "    ])\n",
        "\n",
        "    # 6. 检查终止条件\n",
        "    if action[\"tool_name\"] == \"terminate\":\n",
        "        break\n",
        "\n",
        "    iterations += 1  # 增加迭代计数\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
