#!/usr/bin/env python3
"""
OpenAI API é…ç½®ç®¡ç†æ¨¡å—

ğŸ¯ ä¸»è¦åŠŸèƒ½ï¼š
- å¤šæºé…ç½®ç®¡ç†ï¼šç¯å¢ƒå˜é‡ â†’ IPythonå­˜å‚¨ â†’ é»˜è®¤å€¼
- ä¸€é”®ç¯å¢ƒè®¾ç½®ï¼šè‡ªåŠ¨é…ç½®OpenAIå®¢æˆ·ç«¯å’Œä¾¿æ·å‡½æ•°
- å®‰å…¨å¯†é’¥å¤„ç†ï¼šè„±æ•æ˜¾ç¤ºã€å ä½ç¬¦æ£€æµ‹
- æ™ºèƒ½ç¯å¢ƒæ£€æµ‹ï¼šæ”¯æŒJupyter notebookå’Œæ™®é€šPythonç¯å¢ƒ

ğŸ”§ æ ¸å¿ƒç‰¹æ€§ï¼š
- é…ç½®ä¼˜å…ˆçº§ï¼šç¯å¢ƒå˜é‡ > IPythonå­˜å‚¨ > é»˜è®¤å€¼
- è‡ªåŠ¨ä¾èµ–å®‰è£…ï¼šæ£€æµ‹å¹¶å®‰è£…ç¼ºå¤±çš„ä¾èµ–åŒ…
- ä¼˜é›…é”™è¯¯å¤„ç†ï¼šè¯¦ç»†çš„é…ç½®æŒ‡å¯¼å’Œé”™è¯¯æç¤º
- æ¨¡å—åŒ–è®¾è®¡ï¼šæ¯ä¸ªå‡½æ•°èŒè´£å•ä¸€ï¼Œæ˜“äºç»´æŠ¤å’Œæ‰©å±•

ğŸš€ ä½¿ç”¨åœºæ™¯ï¼š
- å­¦ä¹ ç¯å¢ƒï¼šJupyter notebookäº¤äº’å¼é…ç½®
- å¼€å‘ç¯å¢ƒï¼š.envæ–‡ä»¶æœ¬åœ°é…ç½®
- ç”Ÿäº§ç¯å¢ƒï¼šç¯å¢ƒå˜é‡å®‰å…¨é…ç½®
- ä»£ç†æœåŠ¡ï¼šæ”¯æŒå›½å†…APIä»£ç†æœåŠ¡

ğŸ“‹ æ”¯æŒçš„é…ç½®æ–¹å¼ï¼š
1. ç¯å¢ƒå˜é‡ï¼šOPENAI_API_KEY, OPENAI_MODEL, OPENAI_BASE_URL
2. .envæ–‡ä»¶ï¼šé¡¹ç›®æ ¹ç›®å½•æˆ–æ¨¡å—ç›®å½•çš„.envæ–‡ä»¶
3. IPythonå­˜å‚¨ï¼š%store API_KEY, %store MODEL_NAME
4. é»˜è®¤å€¼ï¼šgpt-4oæ¨¡å‹ä½œä¸ºå…œåº•é…ç½®
"""

import os
import warnings
from pathlib import Path
from typing import Optional, Tuple


_DOTENV_LOADED = False


def _load_env_file() -> None:
    """Load .env from CWD first, then module directory, once, without overriding."""
    global _DOTENV_LOADED

    if _DOTENV_LOADED:
        return

    # Determine candidate .env locations (CWD first, then module directory)
    candidate_paths = []
    cwd_dotenv = Path.cwd() / ".env"
    if cwd_dotenv.is_file():
        candidate_paths.append(cwd_dotenv)

    module_dotenv = Path(__file__).resolve().parent / ".env"
    if module_dotenv.is_file() and module_dotenv not in candidate_paths:
        candidate_paths.append(module_dotenv)

    if not candidate_paths:
        _DOTENV_LOADED = True
        return

    try:
        from dotenv import load_dotenv
    except ImportError:
        warnings.warn(
            "python-dotenv æœªå®‰è£…ï¼Œæ— æ³•è‡ªåŠ¨è¯»å– .env æ–‡ä»¶ã€‚"
            "è¯·é€šè¿‡ `pip install python-dotenv` è¿›è¡Œå®‰è£…ï¼Œæˆ–æ‰‹åŠ¨è®¾ç½®ç¯å¢ƒå˜é‡ã€‚"
        )
        _DOTENV_LOADED = True
        return

    # Load found .env files in order; do not override already-set variables
    for path in candidate_paths:
        load_dotenv(dotenv_path=path, override=False)

    _DOTENV_LOADED = True


def get_openai_config() -> Tuple[Optional[str], Optional[str], Optional[str]]:
    """
    è·å–OpenAI APIé…ç½®ï¼ŒæŒ‰ä¼˜å…ˆçº§é¡ºåºï¼š
    1. ç¯å¢ƒå˜é‡ (æœ€é«˜ä¼˜å…ˆçº§)
    2. IPythonå­˜å‚¨å˜é‡ (ä¸­ç­‰ä¼˜å…ˆçº§)  
    3. é»˜è®¤å€¼ (å…œåº•é…ç½®)
    
    ç‰¹æ€§ï¼š
    - è‡ªåŠ¨åŠ è½½.envæ–‡ä»¶ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    - æ”¯æŒå¤šç§ç¯å¢ƒå˜é‡åï¼ˆå…¼å®¹æ€§å¤„ç†ï¼‰
    - æ™ºèƒ½IPythonç¯å¢ƒæ£€æµ‹
    - å®‰å…¨çš„é»˜è®¤å€¼è®¾ç½®
    
    è¿”å›:
        Tuple[api_key, model_name, base_url]: APIå¯†é’¥ã€æ¨¡å‹åç§°ã€APIåŸºç¡€URL
        
    ç¤ºä¾‹:
        >>> api_key, model, base_url = get_openai_config()
        >>> print(f"ä½¿ç”¨æ¨¡å‹: {model}")
    """
    _load_env_file()

    api_key = None
    model_name = None
    base_url = None
    
    # 1. ä¼˜å…ˆä»ç¯å¢ƒå˜é‡è¯»å–
    api_key = os.getenv('OPENAI_API_KEY')
    if not api_key:
        # å…¼å®¹å…¶ä»–å¸¸è§çš„ç¯å¢ƒå˜é‡å
        api_key = os.getenv('API_KEY')
    
    model_name = os.getenv('OPENAI_MODEL', os.getenv('MODEL_NAME'))
    
    # æ£€æŸ¥è‡ªå®šä¹‰APIåœ°å€ï¼ˆå›½å†…ä»£ç†ç­‰ï¼‰
    base_url = os.getenv('OPENAI_API_BASE') or os.getenv('OPENAI_BASE_URL')
    
    # 2. å¦‚æœç¯å¢ƒå˜é‡ä¸­æ²¡æœ‰ï¼Œå°è¯•ä»IPythonå­˜å‚¨è¯»å–
    if not api_key or not model_name:
        try:
            from IPython import get_ipython
            ipython = get_ipython()
            
            if ipython is not None:
                # å°è¯•ä»IPythonå­˜å‚¨ä¸­æ¢å¤å˜é‡
                if not api_key:
                    try:
                        ipython.magic('store -r API_KEY')
                        api_key = ipython.user_ns.get('API_KEY')
                    except:
                        pass
                
                if not model_name:
                    try:
                        ipython.magic('store -r MODEL_NAME')
                        model_name = ipython.user_ns.get('MODEL_NAME')
                    except:
                        pass
        except ImportError:
            # ä¸åœ¨IPythonç¯å¢ƒä¸­
            pass
    
    # 3. è®¾ç½®é»˜è®¤å€¼
    if not model_name:
        model_name = "gpt-4o"  # é»˜è®¤ä½¿ç”¨gpt-4oæ¨¡å‹
    
    return api_key, model_name, base_url


def setup_openai_client():
    """
    è®¾ç½®OpenAIå®¢æˆ·ç«¯ï¼Œå¤„ç†ç¯å¢ƒå˜é‡å’ŒIPythonå­˜å‚¨çš„é…ç½®
    
    åŠŸèƒ½ï¼š
    - è‡ªåŠ¨è·å–é…ç½®ä¿¡æ¯
    - éªŒè¯APIå¯†é’¥æœ‰æ•ˆæ€§
    - åˆ›å»ºOpenAIå®¢æˆ·ç«¯å®ä¾‹
    - æ”¯æŒè‡ªå®šä¹‰APIåœ°å€ï¼ˆä»£ç†æœåŠ¡ï¼‰
    - æä¾›è¯¦ç»†çš„é…ç½®æ¥æºä¿¡æ¯
    
    è¿”å›:
        tuple: (client, model_name, config_source)
            - client: é…ç½®å¥½çš„OpenAIå®¢æˆ·ç«¯
            - model_name: ä½¿ç”¨çš„æ¨¡å‹åç§°
            - config_source: é…ç½®æ¥æºæè¿°
            
    å¼‚å¸¸:
        ValueError: å½“APIå¯†é’¥æ— æ•ˆæˆ–ç¼ºå¤±æ—¶æŠ›å‡º
        
    ç¤ºä¾‹:
        >>> client, model, source = setup_openai_client()
        >>> print(f"é…ç½®æ¥æº: {source}")
    """
    import openai
    
    api_key, model_name, base_url = get_openai_config()
    
    # æ£€æŸ¥APIå¯†é’¥æ˜¯å¦å¯ç”¨
    if not api_key or api_key == "your_api_key_here":
        raise ValueError(
            "âŒ æœªæ‰¾åˆ°æœ‰æ•ˆçš„OpenAI APIå¯†é’¥ï¼\n\n"
            "è¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼ä¹‹ä¸€è®¾ç½®APIå¯†é’¥ï¼š\n\n"
            "æ–¹å¼ä¸€ï¼šç¯å¢ƒå˜é‡ï¼ˆæ¨èï¼‰\n"
            "export OPENAI_API_KEY='sk-your-api-key-here'\n\n"
            "æ–¹å¼äºŒï¼šåœ¨Jupyter notebookä¸­è®¾ç½®\n"
            "API_KEY = 'sk-your-api-key-here'\n"
            "%store API_KEY\n\n"
            "è·å–APIå¯†é’¥ï¼š\n"
            "- OpenAI: https://platform.openai.com/api-keys\n"
            "- DeepSeek: https://platform.deepseek.com/api-keys\n"
            "- å›½å†…ä»£ç†: https://www.apiyi.com/register/?aff_code=we80"
        )
    
    # ç¡®å®šé…ç½®æ¥æº
    config_source = []
    if os.getenv('OPENAI_API_KEY') or os.getenv('API_KEY'):
        config_source.append("ç¯å¢ƒå˜é‡")
    else:
        config_source.append("IPythonå­˜å‚¨")
    
    # åˆ›å»ºOpenAIå®¢æˆ·ç«¯
    client_kwargs = {'api_key': api_key}
    if base_url:
        client_kwargs['base_url'] = base_url
        config_source.append(f"è‡ªå®šä¹‰APIåœ°å€: {base_url}")
    
    client = openai.OpenAI(**client_kwargs)
    
    return client, model_name, " + ".join(config_source)


def get_completion_with_config(prompt: str, system_prompt: str = "", **kwargs):
    """
    ä½¿ç”¨è‡ªåŠ¨é…ç½®çš„å®¢æˆ·ç«¯è·å–GPTå®Œæˆå“åº”
    
    å‚æ•°:
        prompt (str): ç”¨æˆ·æç¤º
        system_prompt (str): ç³»ç»Ÿæç¤ºï¼ˆå¯é€‰ï¼‰
        **kwargs: å…¶ä»–OpenAI APIå‚æ•°
    
    è¿”å›:
        str: GPTçš„å“åº”æ–‡æœ¬
    """
    client, model_name, config_source = setup_openai_client()
    
    # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
    messages = []
    
    # å¦‚æœæœ‰ç³»ç»Ÿæç¤ºï¼Œæ·»åŠ ç³»ç»Ÿæ¶ˆæ¯
    if system_prompt:
        messages.append({"role": "system", "content": system_prompt})
    
    # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
    messages.append({"role": "user", "content": prompt})
    
    # è®¾ç½®é»˜è®¤å‚æ•°
    api_params = {
        'model': model_name,
        'messages': messages,
        'max_tokens': 2000,
        'temperature': 0.0
    }
    
    # æ›´æ–°ç”¨æˆ·æä¾›çš„å‚æ•°
    api_params.update(kwargs)
    
    # è°ƒç”¨OpenAI API
    response = client.chat.completions.create(**api_params)
    
    return response.choices[0].message.content


def print_config_info():
    """
    æ‰“å°å½“å‰é…ç½®ä¿¡æ¯
    """
    try:
        api_key, model_name, base_url = get_openai_config()
        client, model_name, config_source = setup_openai_client()
        
        print("ğŸ”§ OpenAI API é…ç½®ä¿¡æ¯:")
        print(f"  ğŸ“¡ é…ç½®æ¥æº: {config_source}")
        print(f"  ğŸ¤– æ¨¡å‹: {model_name}")
        if base_url:
            print(f"  ğŸŒ APIåœ°å€: {base_url}")
        print(f"  ğŸ”‘ APIå¯†é’¥: {api_key[:8]}...{api_key[-4:] if len(api_key) > 12 else '****'}")
        print()
        
    except Exception as e:
        print(f"âŒ é…ç½®æ£€æŸ¥å¤±è´¥: {e}")


def setup_notebook_environment():
    """
    ä¸ºnotebookç¯å¢ƒè®¾ç½®å®Œæ•´çš„OpenAIé…ç½®
    
    ä¸»è¦åŠŸèƒ½ï¼š
    - è‡ªåŠ¨æ£€æµ‹å¹¶å®‰è£…OpenAIä¾èµ–åŒ…
    - é…ç½®OpenAIå®¢æˆ·ç«¯
    - åˆ›å»ºä¾¿æ·çš„get_completionå‡½æ•°
    - æ˜¾ç¤ºé…ç½®ä¿¡æ¯å’ŒçŠ¶æ€
    - æä¾›å®Œæ•´çš„é”™è¯¯å¤„ç†
    
    ç‰¹æ€§ï¼š
    - ä¸€é”®å¼ç¯å¢ƒè®¾ç½®
    - æ™ºèƒ½ä¾èµ–ç®¡ç†
    - ç”¨æˆ·å‹å¥½çš„çŠ¶æ€åé¦ˆ
    - æ”¯æŒç³»ç»Ÿæç¤ºå’Œé¢„å¡«å……åŠŸèƒ½
    
    è¿”å›:
        tuple: (client, get_completionå‡½æ•°)
            - client: é…ç½®å¥½çš„OpenAIå®¢æˆ·ç«¯
            - get_completion: ä¾¿æ·çš„APIè°ƒç”¨å‡½æ•°
            
    ä½¿ç”¨ç¤ºä¾‹:
        >>> client, get_completion = setup_notebook_environment()
        >>> response = get_completion("ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±")
        >>> print(response)
    """
    # å®‰è£…ä¾èµ–
    try:
        import openai
    except ImportError:
        print("ğŸ“¦ æ­£åœ¨å®‰è£…OpenAIåº“...")
        import subprocess
        import sys
        subprocess.check_call([sys.executable, "-m", "pip", "install", "openai==1.107.0"])
        import openai
    
    # è®¾ç½®å®¢æˆ·ç«¯
    client, model_name, config_source = setup_openai_client()
    
    print("âœ… OpenAIç¯å¢ƒè®¾ç½®å®Œæˆ!")
    print_config_info()
    
    # åˆ›å»ºget_completionå‡½æ•°
    def get_completion(prompt: str, system_prompt: str = "", prefill: str = ""):
        """
        è·å–GPTçš„å®Œæˆå“åº” - ä¾¿æ·çš„APIè°ƒç”¨å‡½æ•°
        
        åŠŸèƒ½ç‰¹æ€§ï¼š
        - ç®€åŒ–çš„APIè°ƒç”¨æ¥å£
        - æ”¯æŒç³»ç»Ÿæç¤ºè®¾ç½®AIè¡Œä¸º
        - æ”¯æŒé¢„å¡«å……æ–‡æœ¬å¼•å¯¼å“åº”
        - è‡ªåŠ¨å¤„ç†æ¶ˆæ¯æ ¼å¼å’Œå‚æ•°
        
        å‚æ•°:
            prompt (str): ç”¨æˆ·æç¤ºå†…å®¹
            system_prompt (str): ç³»ç»Ÿæç¤ºï¼ˆå¯é€‰ï¼‰ï¼Œç”¨äºè®¾ç½®AIçš„è§’è‰²å’Œè¡Œä¸º
            prefill (str): é¢„å¡«å……æ–‡æœ¬ï¼ˆå¯é€‰ï¼‰ï¼Œç”¨äºå¼•å¯¼GPTçš„å“åº”å¼€å§‹
        
        è¿”å›:
            str: GPTçš„å“åº”æ–‡æœ¬
            
        ä½¿ç”¨ç¤ºä¾‹:
            >>> # åŸºç¡€ä½¿ç”¨
            >>> response = get_completion("è§£é‡Šä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ")
            
            >>> # å¸¦ç³»ç»Ÿæç¤º
            >>> response = get_completion(
            ...     "å†™ä¸€ä¸ªPythonå‡½æ•°", 
            ...     system_prompt="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„Pythonç¼–ç¨‹åŠ©æ‰‹"
            ... )
            
            >>> # å¸¦é¢„å¡«å……
            >>> response = get_completion(
            ...     "ç»§ç»­å®Œæˆè¿™ä¸ªå¥å­", 
            ...     prefill="Pythonæ˜¯ä¸€ç§"
            ... )
        """
        # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
        messages = []
        
        # å¦‚æœæœ‰ç³»ç»Ÿæç¤ºï¼Œæ·»åŠ ç³»ç»Ÿæ¶ˆæ¯
        if system_prompt:
            messages.append({"role": "system", "content": system_prompt})
        
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        messages.append({"role": "user", "content": prompt})
        
        # å¦‚æœæœ‰é¢„å¡«å……å†…å®¹ï¼Œæ·»åŠ åŠ©æ‰‹æ¶ˆæ¯æ¥æ¨¡æ‹Ÿé¢„å¡«å……æ•ˆæœ
        if prefill:
            messages.append({"role": "assistant", "content": prefill})
            # å†æ·»åŠ ä¸€ä¸ªç”¨æˆ·æ¶ˆæ¯è¯·æ±‚ç»§ç»­
            messages.append({"role": "user", "content": "è¯·ç»§ç»­å®Œæˆå“åº”ã€‚"})
        
        # è°ƒç”¨OpenAI API
        response = client.chat.completions.create(
            model=model_name,              # æ¨¡å‹åç§° (gpt-4o æˆ– deepseek-r1)
            messages=messages,             # æ¶ˆæ¯åˆ—è¡¨
            max_tokens=2000,              # æœ€å¤§tokenæ•°
            temperature=0.0               # æ¸©åº¦å‚æ•°ï¼Œ0è¡¨ç¤ºæ›´ç¡®å®šæ€§
        )
        
        # å¦‚æœæœ‰é¢„å¡«å……å†…å®¹ï¼Œå°†å…¶ä¸ç”Ÿæˆçš„å†…å®¹ç»„åˆ
        if prefill:
            return prefill + response.choices[0].message.content
        else:
            return response.choices[0].message.content
    
    return client, get_completion


# ä¸»è¦é…ç½®æ£€æŸ¥å‡½æ•°
def validate_config():
    """
    éªŒè¯OpenAI APIé…ç½®æ˜¯å¦æ­£ç¡®å’Œå®Œæ•´
    
    éªŒè¯é¡¹ç›®ï¼š
    - æ£€æŸ¥APIå¯†é’¥æ˜¯å¦å­˜åœ¨
    - éªŒè¯APIå¯†é’¥ä¸æ˜¯å ä½ç¬¦
    - ç¡®ä¿é…ç½®æ ¼å¼æ­£ç¡®
    - æä¾›è¯¦ç»†çš„éªŒè¯ç»“æœ
    
    è¿”å›:
        bool: é…ç½®éªŒè¯ç»“æœ
            - True: é…ç½®æœ‰æ•ˆ
            - False: é…ç½®æ— æ•ˆæˆ–ç¼ºå¤±
            
    åŠŸèƒ½ï¼š
    - è‡ªåŠ¨æ£€æµ‹é…ç½®é—®é¢˜
    - æä¾›å‹å¥½çš„é”™è¯¯æç¤º
    - æ”¯æŒé…ç½®çŠ¶æ€æ£€æŸ¥
    
    ä½¿ç”¨ç¤ºä¾‹:
        >>> if validate_config():
        ...     print("é…ç½®éªŒè¯é€šè¿‡ï¼Œå¯ä»¥å¼€å§‹ä½¿ç”¨")
        ... else:
        ...     print("éœ€è¦é…ç½®APIå¯†é’¥")
    """
    try:
        api_key, model_name, base_url = get_openai_config()
        
        if not api_key:
            print("âš ï¸  è­¦å‘Š: æœªè®¾ç½®APIå¯†é’¥")
            return False
            
        if api_key == "your_api_key_here":
            print("âš ï¸  è­¦å‘Š: è¯·æ›¿æ¢é»˜è®¤çš„APIå¯†é’¥å ä½ç¬¦")
            return False
            
        print("âœ… é…ç½®éªŒè¯é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"âŒ é…ç½®éªŒè¯å¤±è´¥: {e}")
        return False


if __name__ == "__main__":
    print("ğŸ”§ OpenAI API é…ç½®ç®¡ç†æ¨¡å—")
    print("=" * 50)
    print_config_info()
    validate_config() 
