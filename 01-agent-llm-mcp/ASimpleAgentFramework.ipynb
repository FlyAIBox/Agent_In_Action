{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FlyAIBox/Agent_In_Action/blob/main/01-agent-llm-mcp/ASimpleAgentFramework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8WI3so-YCs-"
      },
      "source": [
        "# GAME框架：AI智能体设计架构\n",
        "\n",
        "本笔记实现了一个“可复用的智能体（Agent）最小框架”，用来演示如何基于 GAME 设计法将智能体拆分为四个核心部件，并以可插拔方式组织：\n",
        "\n",
        "- **G（Goals / Instructions）**：目标与指令。描述智能体要实现的结果，以及实现策略/规则。\n",
        "- **A（Actions）**：动作/工具。定义智能体可以调用的能力（如读取文件、列目录、结束会话等）。\n",
        "- **M（Memory）**：记忆。跨回合保留上下文（用户输入、助手决策、工具执行结果），支持后续回合继续推理。\n",
        "- **E（Environment）**：环境。动作在真实世界中的执行载体，负责真正“落地执行”动作并返回结果（含时间戳与错误信息）。\n",
        "\n",
        "本框架通过一个统一的 **Agent** 循环（Loop）把 G/A/M/E 串起来：\n",
        "1. 构造 Prompt（包含 Goals、可用 Actions 的函数调用Schema、Memory 历史）。\n",
        "2. 发送给 LLM，得到“选择的动作以及参数”（函数调用）。」\n",
        "3. 在 **Environment** 中执行该动作，得到结果（或错误）。\n",
        "4. 将决策与结果写入 **Memory**，进入下一轮。\n",
        "5. 如果动作为终止类动作（如 `terminate`），则结束循环。\n",
        "\n",
        "你可以把 **Actions** 看成“能力接口”，把 **Environment** 看成“执行实现”。这种解耦使得：\n",
        "- 你可以替换不同环境（本地、云端、GitHub Actions、容器等），而无需修改智能体决策逻辑；\n",
        "- 你可以更换一组 Actions（比如从文件工具换成 Web API 工具），而无需修改主循环；\n",
        "- 你可以替换/扩展 **AgentLanguage**（Prompt 格式与解析逻辑），以适配“函数调用/纯文本解析”等不同LLM交互方式。\n",
        "\n",
        "本笔记下半部分提供了一个最小示例：\n",
        "- 定义了 3 个动作：`list_project_files`、`read_project_file`、`terminate`\n",
        "- 目标：读取项目文件并在结束时输出 README 内容（示例运行环境为空目录时会直接终止）\n",
        "- 使用 OpenAI 调用 `gpt-4o`，但可轻松替换为任意 LLM 提供商\n",
        "\n",
        "通过阅读与运行本笔记，你将能掌握：\n",
        "- 如何将智能体设计（GAME）直接映射为代码结构；\n",
        "- 如何注册工具、格式化 Prompt、解析 LLM 工具调用并在环境中执行；\n",
        "- 如何使用记忆把“决策 + 结果”闭环起来，形成稳健的 Agent Loop。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLUK5fflYeVS",
        "outputId": "528d95f7-2c38-4099-9dba-2df6a5eadebb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Collecting openai==1.107.0',\n",
              " '  Downloading openai-1.107.0-py3-none-any.whl.metadata (29 kB)',\n",
              " 'Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai==1.107.0) (4.11.0)',\n",
              " 'Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai==1.107.0) (1.9.0)',\n",
              " 'Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai==1.107.0) (0.28.1)',\n",
              " 'Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai==1.107.0) (0.11.1)',\n",
              " 'Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai==1.107.0) (2.11.10)',\n",
              " 'Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai==1.107.0) (1.3.1)',\n",
              " 'Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai==1.107.0) (4.67.1)',\n",
              " 'Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai==1.107.0) (4.15.0)',\n",
              " 'Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai==1.107.0) (3.11)',\n",
              " 'Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai==1.107.0) (2025.10.5)',\n",
              " 'Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai==1.107.0) (1.0.9)',\n",
              " 'Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.107.0) (0.16.0)',\n",
              " 'Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai==1.107.0) (0.7.0)',\n",
              " 'Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai==1.107.0) (2.33.2)',\n",
              " 'Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai==1.107.0) (0.4.2)',\n",
              " 'Downloading openai-1.107.0-py3-none-any.whl (950 kB)',\n",
              " '\\x1b[?25l   \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m0.0/951.0 kB\\x1b[0m \\x1b[31m?\\x1b[0m eta \\x1b[36m-:--:--\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m\\x1b[91m╸\\x1b[0m \\x1b[32m942.1/951.0 kB\\x1b[0m \\x1b[31m37.8 MB/s\\x1b[0m eta \\x1b[36m0:00:01\\x1b[0m',\n",
              " '\\x1b[2K   \\x1b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\x1b[0m \\x1b[32m951.0/951.0 kB\\x1b[0m \\x1b[31m24.7 MB/s\\x1b[0m eta \\x1b[36m0:00:00\\x1b[0m',\n",
              " '\\x1b[?25hInstalling collected packages: openai',\n",
              " '  Attempting uninstall: openai',\n",
              " '    Found existing installation: openai 1.109.1',\n",
              " '    Uninstalling openai-1.109.1:',\n",
              " '      Successfully uninstalled openai-1.109.1',\n",
              " 'Successfully installed openai-1.107.0']"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 安装必要的依赖包\n",
        "!!pip install openai==1.107.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEYrzG2vB8Ip",
        "outputId": "013bcd40-f64c-4366-fc49-c66da4c0614f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OPENAI_API_KEY: ··········\n",
            "OPENAI_BASE_URL: ··········\n"
          ]
        }
      ],
      "source": [
        "# 导入必要的模块\n",
        "import os, getpass\n",
        "\n",
        "def _set_env(var: str):\n",
        "    \"\"\"\n",
        "    设置环境变量的辅助函数\n",
        "\n",
        "    参数:\n",
        "        var (str): 要设置的环境变量名称\n",
        "\n",
        "    功能:\n",
        "        - 检查环境变量是否已存在\n",
        "        - 如果不存在，则提示用户输入并设置\n",
        "    \"\"\"\n",
        "    if not os.environ.get(var):  # 检查环境变量是否已设置\n",
        "        os.environ[var] = getpass.getpass(f\"{var}: \")  # 安全地获取用户输入\n",
        "\n",
        "# 设置 OpenAI API 密钥\n",
        "# 这是使用 OpenAI 模型所必需的\n",
        "_set_env(\"OPENAI_API_KEY\")\n",
        "# 设置 OpenAI API代理地址 (例如：https://api.apiyi.com/v1）\n",
        "_set_env(\"OPENAI_BASE_URL\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mwe2eeOQB0cC"
      },
      "outputs": [],
      "source": [
        "# =============================== 核心框架：导入与类型定义 ===============================\n",
        "# 说明：以下代码实现了一个最小可复用的智能体框架（面向函数调用工具）。\n",
        "# - 不修改任何原有逻辑，仅通过中文注释解释设计意图与用法。\n",
        "# - 关键模块：Prompt 数据结构、LLM 响应函数、Goal/Action/ActionRegistry、Memory、Environment、AgentLanguage、Agent。\n",
        "\n",
        "import json\n",
        "import time\n",
        "import traceback\n",
        "from openai import OpenAI # 用于调用OpenAI API\n",
        "from dataclasses import dataclass, field\n",
        "from typing import List, Callable, Dict, Any\n",
        "\n",
        "\n",
        "# 大语言模型\n",
        "client=OpenAI(\n",
        "    base_url=os.environ['OPENAI_BASE_URL'],\n",
        "    api_key=os.environ['OPENAI_API_KEY']\n",
        ")\n",
        "\n",
        "# Prompt：封装要发给 LLM 的消息与工具定义\n",
        "# - messages：对话上下文（系统/用户/助手三类）\n",
        "# - tools：工具（函数）调用的 JSON Schema 描述（让 LLM 能“看见”可用的动作）\n",
        "# - metadata：元数据（可选扩展，用 dict 保存）\n",
        "@dataclass\n",
        "class Prompt:\n",
        "    messages: List[Dict] = field(default_factory=list)\n",
        "    tools: List[Dict] = field(default_factory=list)\n",
        "    metadata: dict = field(default_factory=dict)  \n",
        "\n",
        "\n",
        "# generate_response：统一的 LLM 调用入口\n",
        "# - 入参是 Prompt，内部自动根据是否提供 tools 来决定是否启用函数调用能力\n",
        "# - 目标：把模型提供商与主循环解耦；将来切换模型时无需改 Agent 逻辑\n",
        "# - 返回：\n",
        "#   * 无工具时：直接返回助手文本\n",
        "#   * 有工具时：优先解析 tool_calls（并转为 {tool, args} 的 JSON 字符串）\n",
        "#               若无工具调用，则退化为普通文本回复\n",
        "def generate_response(prompt: Prompt) -> str:\n",
        "    \"\"\"调用大语言模型（LLM）生成响应：\n",
        "    - 当未提供 tools（函数调用能力）时，作为普通对话返回文本\n",
        "    - 当提供 tools 时，优先解析函数调用的结构化结果；若无函数调用则退化为普通文本\n",
        "    \"\"\"\n",
        "\n",
        "    messages = prompt.messages\n",
        "    tools = prompt.tools\n",
        "\n",
        "    result = None\n",
        "\n",
        "    if not tools:\n",
        "        # 无工具：普通对话\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o\",   # 指定使用的模型\n",
        "            messages=messages,  # 发送消息历史\n",
        "            max_tokens=1024   # 限制响应长度\n",
        "        )\n",
        "        result = response.choices[0].message.content\n",
        "    else:\n",
        "        # 有工具：提示模型按函数调用格式返回 tool_calls\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o\",\n",
        "            messages=messages,\n",
        "            tools=tools,\n",
        "            max_tokens=1024\n",
        "        )\n",
        "\n",
        "        if response.choices[0].message.tool_calls:\n",
        "            # 这里仅取第一个工具调用作为最小可运行演示\n",
        "            tool = response.choices[0].message.tool_calls[0]\n",
        "            result = {\n",
        "                \"tool\": tool.function.name,\n",
        "                \"args\": json.loads(tool.function.arguments),\n",
        "            }\n",
        "            # 将 dict 序列化为字符串，便于统一处理与存入记忆\n",
        "            result = json.dumps(result)\n",
        "        else:\n",
        "            # 即使提供了 tools，也可能返回纯文本（例如模型策略判断不调用工具）\n",
        "            result = response.choices[0].message.content\n",
        "\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "# Goal：目标对象\n",
        "# - priority：目标优先级（便于排序/裁剪）\n",
        "# - name/description：目标名称和详细说明（同时涵盖“要做什么/如何做”）\n",
        "# 使用 @dataclass 装饰器定义 Goal 为一个不可变的数据类（frozen=True），这意味着其实例一旦创建，其属性值就不能被修改，有助于保证数据安全和可靠性。\n",
        "@dataclass(frozen=True)\n",
        "class Goal:\n",
        "    priority: int\n",
        "    name: str\n",
        "    description: str\n",
        "\n",
        "\n",
        "# Action：动作/工具的抽象\n",
        "# - name：动作名（作为工具名暴露给 LLM）\n",
        "# - function：实际执行的 Python 函数\n",
        "# - description：工具说明，帮助 LLM 选择正确工具\n",
        "# - parameters：JSON Schema（决定 LLM 该如何拼好参数）\n",
        "# - terminal：是否为“终止型”动作（被选中后终止主循环）\n",
        "class Action:\n",
        "    def __init__(self,\n",
        "                 name: str,\n",
        "                 function: Callable,\n",
        "                 description: str,\n",
        "                 parameters: Dict,\n",
        "                 terminal: bool = False):\n",
        "        self.name = name\n",
        "        self.function = function\n",
        "        self.description = description\n",
        "        self.terminal = terminal\n",
        "        self.parameters = parameters\n",
        "\n",
        "    def execute(self, **args) -> Any:\n",
        "        \"\"\"执行该动作所绑定的底层函数，参数通过关键字形式解包传入\"\"\"\n",
        "        # 解包参数并调用底层实现函数\n",
        "        return self.function(**args)\n",
        "\n",
        "\n",
        "# ActionRegistry：动作/工具注册表\n",
        "# - 负责集中管理动作/工具对象，支持按名称检索与批量导出供 AgentLanguage 生成工具Schema\n",
        "class ActionRegistry:\n",
        "    def __init__(self):\n",
        "        self.actions = {}\n",
        "\n",
        "    def register(self, action: Action):\n",
        "        self.actions[action.name] = action\n",
        "\n",
        "    def get_action(self, name: str) -> [Action, None]:\n",
        "        return self.actions.get(name, None)\n",
        "\n",
        "    def get_actions(self) -> List[Action]:\n",
        "        \"\"\"获取所有已注册的动作，按注册顺序返回列表\"\"\"\n",
        "        return list(self.actions.values())\n",
        "\n",
        "\n",
        "# Memory：回合记忆\n",
        "# - items：统一存储“用户/助手/环境”等事件，形成对话历史\n",
        "# - 通过 get_memories 提供最近N条消息给提示构造使用\n",
        "# - 通过 copy_without_system_memories 可过滤掉系统消息（某些场景需要）\n",
        "class Memory:\n",
        "    def __init__(self):\n",
        "        self.items = []  # Basic conversation histor\n",
        "\n",
        "    def add_memory(self, memory: dict):\n",
        "        \"\"\"将一条记忆事件追加到工作记忆，用于后续提示词构造与推理\"\"\"\n",
        "        self.items.append(memory)\n",
        "\n",
        "    def get_memories(self, limit: int = None) -> List[Dict]:\n",
        "        \"\"\"获取用于提示词的对话历史；可通过 limit 限制条数以控制上下文长度\"\"\"\n",
        "        return self.items[:limit]\n",
        "\n",
        "    def copy_without_system_memories(self):\n",
        "        \"\"\"返回一份不包含系统类型（type==system）记忆的副本，用于部分提示场景\"\"\"\n",
        "        filtered_items = [m for m in self.items if m[\"type\"] != \"system\"]\n",
        "        memory = Memory()\n",
        "        memory.items = filtered_items\n",
        "        return memory\n",
        "\n",
        "\n",
        "# Environment：环境层（动作的真实执行者）\n",
        "# - execute_action：捕获执行异常，统一返回结构（是否执行成功/错误/traceback/时间戳）\n",
        "# - format_result：为成功结果补充元数据（时间戳），便于记录与日志化\n",
        "class Environment:\n",
        "    def execute_action(self, action: Action, args: dict) -> dict:\n",
        "        \"\"\"执行指定动作并返回标准化结果；捕获异常并提供错误与追踪信息\"\"\"\n",
        "        try:\n",
        "            result = action.execute(**args)\n",
        "            return self.format_result(result)\n",
        "        except Exception as e:\n",
        "            return {\n",
        "                \"tool_executed\": False,\n",
        "                \"error\": str(e),\n",
        "                \"traceback\": traceback.format_exc()\n",
        "            }\n",
        "\n",
        "    def format_result(self, result: Any) -> dict:\n",
        "        \"\"\"为执行结果补充元数据（如时间戳）并统一为标准结构\"\"\"\n",
        "        return {\n",
        "            \"tool_executed\": True,\n",
        "            \"result\": result,\n",
        "            \"timestamp\": time.strftime(\"%Y-%m-%dT%H:%M:%S%z\")\n",
        "        }\n",
        "\n",
        "\n",
        "# AgentLanguage：语言适配层\n",
        "# - 负责把（Goals/Actions/Memory）格式化为 LLM 需要的 Prompt\n",
        "# - 负责从 LLM 的原始输出中解析出“要调用的工具与参数”\n",
        "class AgentLanguage:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def construct_prompt(self,\n",
        "                         actions: List[Action],\n",
        "                         environment: Environment,\n",
        "                         goals: List[Goal],\n",
        "                         memory: Memory) -> Prompt:\n",
        "        raise NotImplementedError(\"Subclasses must implement this method\")\n",
        "\n",
        "\n",
        "    def parse_response(self, response: str) -> dict:\n",
        "        raise NotImplementedError(\"Subclasses must implement this method\")\n",
        "\n",
        "\n",
        "\n",
        "# AgentFunctionCallingActionLanguage：基于“函数调用”范式的语言适配实现\n",
        "# - 将 Goals 拼接为 system 消息\n",
        "# - 将 Memory 规范化映射为 user/assistant 消息\n",
        "# - 将 Actions 转换为符合 OpenAI 函数调用的 tools Schema\n",
        "class AgentFunctionCallingActionLanguage(AgentLanguage):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def format_goals(self, goals: List[Goal]) -> List:\n",
        "        # 把所有目标拼接为一个 system 消息，便于集中表达“要做什么/如何做”\n",
        "        sep = \"\\n-------------------\\n\"\n",
        "        goal_instructions = \"\\n\\n\".join([f\"{goal.name}:{sep}{goal.description}{sep}\" for goal in goals])\n",
        "        return [\n",
        "            {\"role\": \"system\", \"content\": goal_instructions}\n",
        "        ]\n",
        "\n",
        "    def format_memory(self, memory: Memory) -> List:\n",
        "        \"\"\"将 Memory 转换为对话消息格式，供 LLM 上下文使用\"\"\"\n",
        "        # 记忆格式化策略：\n",
        "        # - environment 的输出也作为 assistant 角色加入（让模型能“看到”工具执行结果）\n",
        "        # - user/assistant 原样映射\n",
        "        items = memory.get_memories()\n",
        "        mapped_items = []\n",
        "        for item in items:\n",
        "\n",
        "            content = item.get(\"content\", None)\n",
        "            if not content:\n",
        "                content = json.dumps(item, indent=4)\n",
        "\n",
        "            if item[\"type\"] == \"assistant\":\n",
        "                mapped_items.append({\"role\": \"assistant\", \"content\": content})\n",
        "            elif item[\"type\"] == \"environment\":\n",
        "                mapped_items.append({\"role\": \"assistant\", \"content\": content})\n",
        "            else:\n",
        "                mapped_items.append({\"role\": \"user\", \"content\": content})\n",
        "\n",
        "        return mapped_items\n",
        "\n",
        "    def format_actions(self, actions: List[Action]) -> [List,List]:\n",
        "        \"\"\"将已注册的动作转换为 OpenAI 函数调用所需的 tools Schema\"\"\"\n",
        "\n",
        "        # 将注册的 Action 转为 OpenAI 函数调用工具的 Schema 数组\n",
        "        tools = [\n",
        "            {\n",
        "                \"type\": \"function\",\n",
        "                \"function\": {\n",
        "                    \"name\": action.name,\n",
        "                    # 描述过长可能无效，限制到 1024 字符\n",
        "                    \"description\": action.description[:1024],\n",
        "                    \"parameters\": action.parameters,\n",
        "                },\n",
        "            } for action in actions\n",
        "        ]\n",
        "\n",
        "        return tools\n",
        "\n",
        "    def construct_prompt(self,\n",
        "                         actions: List[Action],\n",
        "                         environment: Environment,\n",
        "                         goals: List[Goal],\n",
        "                         memory: Memory) -> Prompt:\n",
        "\n",
        "        # 构造最终 Prompt：Goals（system）+ Memory（历史消息）+ Tools（函数Schema）\n",
        "        prompt = []\n",
        "        prompt += self.format_goals(goals)\n",
        "        prompt += self.format_memory(memory)\n",
        "\n",
        "        tools = self.format_actions(actions)\n",
        "\n",
        "        return Prompt(messages=prompt, tools=tools)\n",
        "\n",
        "    def adapt_prompt_after_parsing_error(self,\n",
        "                                         prompt: Prompt,\n",
        "                                         response: str,\n",
        "                                         traceback: str,\n",
        "                                         error: Any,\n",
        "                                         retries_left: int) -> Prompt:\n",
        "        # 解析失败后的“自适应 Prompt”策略（此处保留扩展点，演示版不做修改）\n",
        "        return prompt\n",
        "\n",
        "    def parse_response(self, response: str) -> dict:\n",
        "        \"\"\"将 LLM 的响应解析为结构化格式（优先尝试 JSON 解析，失败则回退为终止工具）\"\"\"\n",
        "\n",
        "        # 期望 LLM 返回 JSON 字符串：{\"tool\": 工具名, \"args\": {...}}\n",
        "        try:\n",
        "            return json.loads(response)\n",
        "\n",
        "        except Exception as e:\n",
        "            # 若无法解析，则将内容作为 message 交给终止工具，友好退出\n",
        "            return {\n",
        "                \"tool\": \"terminate\",\n",
        "                \"args\": {\"message\":response}\n",
        "            }\n",
        "\n",
        "\n",
        "# Agent：智能体主循环\n",
        "# - 维护并协调 G/A/M/E（目标/动作/记忆/环境）\n",
        "# - 统一的 prompt 构造、响应解析、动作执行、记忆更新、终止判断\n",
        "class Agent:\n",
        "    def __init__(self,\n",
        "                 goals: List[Goal],\n",
        "                 agent_language: AgentLanguage,\n",
        "                 action_registry: ActionRegistry,\n",
        "                 generate_response: Callable[[Prompt], str],\n",
        "                 environment: Environment):\n",
        "        \"\"\"\n",
        "        使用核心的 GAME 组件初始化智能体：\n",
        "        - goals：目标与指令集合\n",
        "        - agent_language：语言适配层（提示词构造与解析）\n",
        "        - action_registry：动作注册表（可调用工具）\n",
        "        - generate_response：LLM 调用函数\n",
        "        - environment：动作执行环境\n",
        "        \"\"\"\n",
        "        self.goals = goals\n",
        "        self.generate_response = generate_response\n",
        "        self.agent_language = agent_language\n",
        "        self.actions = action_registry\n",
        "        self.environment = environment\n",
        "\n",
        "    def construct_prompt(self, goals: List[Goal], memory: Memory, actions: ActionRegistry) -> Prompt:\n",
        "        \"\"\"基于当前目标、记忆与动作集合构造提示词（Prompt）\"\"\"\n",
        "        return self.agent_language.construct_prompt(\n",
        "            actions=actions.get_actions(),\n",
        "            environment=self.environment,\n",
        "            goals=goals,\n",
        "            memory=memory\n",
        "        )\n",
        "\n",
        "    def get_action(self, response):\n",
        "        # 解析 LLM 的返回，得到动作名与参数（invocation）\n",
        "        invocation = self.agent_language.parse_response(response)\n",
        "        action = self.actions.get_action(invocation[\"tool\"])\n",
        "        return action, invocation\n",
        "\n",
        "    def should_terminate(self, response: str) -> bool:\n",
        "        # 若当前选择的动作被标记为 terminal，则结束主循环\n",
        "        action_def, _ = self.get_action(response)\n",
        "        return action_def.terminal\n",
        "\n",
        "    def set_current_task(self, memory: Memory, task: str):\n",
        "        # 将用户输入写入记忆，作为本轮起始任务语境\n",
        "        memory.add_memory({\"type\": \"user\", \"content\": task})\n",
        "\n",
        "    def update_memory(self, memory: Memory, response: str, result: dict):\n",
        "        \"\"\"\n",
        "        使用“决策 + 执行结果”更新记忆：\n",
        "        - 将助手的决策（response）作为 assistant 事件存入\n",
        "        - 将环境执行结果（result）序列化为 JSON，作为 environment 事件存入\n",
        "        \"\"\"\n",
        "        # 统一把“助手的决策（response）”与“环境执行结果（result）”写入记忆\n",
        "        new_memories = [\n",
        "            {\"type\": \"assistant\", \"content\": response},\n",
        "            {\"type\": \"environment\", \"content\": json.dumps(result)}\n",
        "        ]\n",
        "        for m in new_memories:\n",
        "            memory.add_memory(m)\n",
        "\n",
        "    def prompt_llm_for_action(self, full_prompt: Prompt) -> str:\n",
        "        # 将 Prompt 发送给 LLM，得到“下一步动作/或文本回复”\n",
        "        response = self.generate_response(full_prompt)\n",
        "        return response\n",
        "\n",
        "    def run(self, user_input: str, memory=None, max_iterations: int = 50) -> Memory:\n",
        "        \"\"\"\n",
        "        执行该智能体的 GAME 主循环，可设置最大迭代次数：\n",
        "        - 每轮：构造 Prompt -> 让 LLM 决策 -> 解析动作 -> 环境执行 -> 写回记忆 -> 终止判断\n",
        "        \"\"\"\n",
        "        # 初始化记忆并写入用户任务\n",
        "        memory = memory or Memory()\n",
        "        self.set_current_task(memory, user_input)\n",
        "\n",
        "        for _ in range(max_iterations):\n",
        "            # 1) 用当前 Goals/Actions/Memory 构造 Prompt\n",
        "            prompt = self.construct_prompt(self.goals, memory, self.actions)\n",
        "\n",
        "            print(\"Agent thinking...\")\n",
        "            # 2) 发送给 LLM，得到“将要调用的动作及其参数”或普通文本\n",
        "            response = self.prompt_llm_for_action(prompt)\n",
        "            print(f\"Agent Decision: {response}\")\n",
        "\n",
        "            # 3) 解析动作与参数\n",
        "            action, invocation = self.get_action(response)\n",
        "\n",
        "            # 4) 在环境中真实执行动作\n",
        "            result = self.environment.execute_action(action, invocation[\"args\"])\n",
        "            print(f\"Action Result: {result}\")\n",
        "\n",
        "            # 5) 将“决策 + 结果”写回记忆，形成闭环\n",
        "            self.update_memory(memory, response, result)\n",
        "\n",
        "            # 6) 终止判断：如果动作为终止型，则跳出循环\n",
        "            if self.should_terminate(response):\n",
        "                break\n",
        "\n",
        "        return memory\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### OpenAI 函数调用（tools Schema）详解\n",
        "\n",
        "在 Chat Completions API 中，通过 `tools` 字段向模型暴露可调用的函数（工具）。每个工具定义如下：\n",
        "\n",
        "- `type`: 固定为 `function`\n",
        "- `function`:\n",
        "  - `name` (string): 工具名称（小写、下划线风格更稳妥，长度 ≤ 64 常见做法）\n",
        "  - `description` (string): 工具用途的自然语言描述（有助于模型选择正确工具，建议简洁清晰）\n",
        "  - `parameters` (object): 满足 JSON Schema Draft-07 的参数定义，用于指导模型正确组装入参\n",
        "    - `type`: 通常为 `object`\n",
        "    - `properties`: 各字段的类型与描述\n",
        "    - `required`: 必填字段名列表\n",
        "    - `additionalProperties`: 是否允许未声明字段（建议 `false` 以提高鲁棒性）\n",
        "\n",
        "示例（与本笔记 `Action` 转换保持一致）：\n",
        "```json\n",
        "{\n",
        "  \"type\": \"function\",\n",
        "  \"function\": {\n",
        "    \"name\": \"read_project_file\",\n",
        "    \"description\": \"Reads a file from the project.\",\n",
        "    \"parameters\": {\n",
        "      \"type\": \"object\",\n",
        "      \"properties\": {\n",
        "        \"name\": { \"type\": \"string\", \"description\": \"The file path to read\" }\n",
        "      },\n",
        "      \"required\": [\"name\"],\n",
        "      \"additionalProperties\": false\n",
        "    }\n",
        "  }\n",
        "}\n",
        "```\n",
        "\n",
        "模型返回时会在 `message.tool_calls` 中给出调用的 `function.name` 与 `function.arguments`（JSON 字符串）。你的代码需：\n",
        "- 解析 `arguments`（`json.loads`）\n",
        "- 路由到本地实现函数执行\n",
        "- 将执行结果写回对话历史（便于下一轮推理）\n",
        "\n",
        "可选高级配置（按实际接口版本支持情况使用）：\n",
        "- `tool_choice`: 强制使用某个工具或允许模型自由选择\n",
        "- `parallel_tool_calls`: 是否允许并行调用（若可用）\n",
        "- `response_format`: 强制 JSON 输出等（如需要结构化）\n",
        "\n",
        "参考文档（官方）：\n",
        "- OpenAI 工具/函数调用总览（Chat Completions）: [Function calling & tools](https://platform.openai.com/docs/guides/function-calling)\n",
        "- JSON Schema 规范（参考）: [JSON Schema](https://json-schema.org/)\n",
        "- Chat Completions 消息与工具调用字段说明: [Chat Completions API](https://platform.openai.com/docs/api-reference/chat)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PC3ncxezoJC",
        "outputId": "c4239222-ec0e-4f61-80b0-a0dbd1f9a212"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Agent thinking...\n",
            "Agent Decision: {\"tool\": \"list_project_files\", \"args\": {}}\n",
            "Action Result: {'tool_executed': True, 'result': [], 'timestamp': '2025-10-30T03:23:57+0000'}\n",
            "Agent thinking...\n",
            "Agent Decision: {\"tool\": \"terminate\", \"args\": {\"message\": \"It seems there are no files in the project directory, or there was an issue retrieving them. Since there is no content to base a README on, I'll need more information about the project to write an effective README file. Please provide details about the project such as its purpose, installation instructions, usage examples, and any other relevant information you would like to include.\"}}\n",
            "Action Result: {'tool_executed': True, 'result': \"It seems there are no files in the project directory, or there was an issue retrieving them. Since there is no content to base a README on, I'll need more information about the project to write an effective README file. Please provide details about the project such as its purpose, installation instructions, usage examples, and any other relevant information you would like to include.\\nTerminating...\", 'timestamp': '2025-10-30T03:23:59+0000'}\n",
            "[{'type': 'user', 'content': 'Write a README for this project.'}, {'type': 'assistant', 'content': '{\"tool\": \"list_project_files\", \"args\": {}}'}, {'type': 'environment', 'content': '{\"tool_executed\": true, \"result\": [], \"timestamp\": \"2025-10-30T03:23:57+0000\"}'}, {'type': 'assistant', 'content': '{\"tool\": \"terminate\", \"args\": {\"message\": \"It seems there are no files in the project directory, or there was an issue retrieving them. Since there is no content to base a README on, I\\'ll need more information about the project to write an effective README file. Please provide details about the project such as its purpose, installation instructions, usage examples, and any other relevant information you would like to include.\"}}'}, {'type': 'environment', 'content': '{\"tool_executed\": true, \"result\": \"It seems there are no files in the project directory, or there was an issue retrieving them. Since there is no content to base a README on, I\\'ll need more information about the project to write an effective README file. Please provide details about the project such as its purpose, installation instructions, usage examples, and any other relevant information you would like to include.\\\\nTerminating...\", \"timestamp\": \"2025-10-30T03:23:59+0000\"}'}]\n"
          ]
        }
      ],
      "source": [
        "# =============================== 示例：最小可运行 Agent ===============================\n",
        "# 1) 定义智能体目标（Goals）：\n",
        "#    - 读取项目中的每个文件\n",
        "#    - 当已读取完毕时调用 terminate，并在消息中提供 README 的内容（示例环境如为空目录会直接终止）\n",
        "goals = [\n",
        "    Goal(priority=1, name=\"Gather Information\", description=\"Read each file in the project\"),\n",
        "    Goal(priority=1, name=\"Terminate\", description=\"Call the terminate call when you have read all the files \"\n",
        "                                                   \"and provide the content of the README in the terminate message\")\n",
        "]\n",
        "\n",
        "# 2) 指定语言适配器（基于函数调用的 Prompt/解析策略）\n",
        "agent_language = AgentFunctionCallingActionLanguage()\n",
        "\n",
        "# 3) 实现底层动作：读取文件\n",
        "def read_project_file(name: str) -> str:\n",
        "    with open(name, \"r\") as f:\n",
        "        return f.read()\n",
        "\n",
        "# 4) 实现底层动作：列出当前目录下的 .py 文件（最小示例）\n",
        "def list_project_files() -> List[str]:\n",
        "    return sorted([file for file in os.listdir(\".\") if file.endswith(\".py\")])\n",
        "\n",
        "\n",
        "# 5) 注册动作：将 Python 函数“暴露”为可被 LLM 选择的工具\n",
        "action_registry = ActionRegistry()\n",
        "action_registry.register(Action(\n",
        "    name=\"list_project_files\",\n",
        "    function=list_project_files,\n",
        "    description=\"Lists all files in the project.\",\n",
        "    parameters={},\n",
        "    terminal=False\n",
        "))\n",
        "action_registry.register(Action(\n",
        "    name=\"read_project_file\",\n",
        "    function=read_project_file,\n",
        "    description=\"Reads a file from the project.\",\n",
        "    parameters={\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"name\": {\"type\": \"string\"}\n",
        "        },\n",
        "        \"required\": [\"name\"]\n",
        "    },\n",
        "    terminal=False\n",
        "))\n",
        "action_registry.register(Action(\n",
        "    name=\"terminate\",\n",
        "    function=lambda message: f\"{message}\\nTerminating...\",\n",
        "    description=\"Terminates the session and prints the message to the user.\",\n",
        "    parameters={\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"message\": {\"type\": \"string\"}\n",
        "        },\n",
        "        \"required\": []\n",
        "    },\n",
        "    terminal=True\n",
        "))\n",
        "\n",
        "# 6) 准备环境（负责真实执行动作并返回标准化结果）\n",
        "environment = Environment()\n",
        "\n",
        "# 7) 构建 Agent 实例（组装 G/A/M/E 与 LLM 响应函数）\n",
        "agent = Agent(goals, agent_language, action_registry, generate_response, environment)\n",
        "\n",
        "# 8) 运行智能体（输入一个自然语言任务），内部会进入循环直到触发终止或达到最大轮数\n",
        "user_input = \"Write a README for this project.\"\n",
        "final_memory = agent.run(user_input)\n",
        "\n",
        "# 9) 输出最终的记忆（包含用户任务、助手决策、环境执行结果等）\n",
        "print(final_memory.get_memories())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 项目结构与业务流程（Mermaid）\n",
        "\n",
        "以下通过 Mermaid 图展示本项目的高层目录结构与 GAME 智能体业务流程。\n",
        "\n",
        "### 项目结构概览\n",
        "```mermaid\n",
        "graph TD\n",
        "  A[Agent_In_Action 根目录] --> B01[01-agent-llm-mcp]\n",
        "  A --> B02[02-agent-multi-role]\n",
        "  A --> B03[03-agent-build-docker-deploy]\n",
        "  A --> B04[04-agent-evaluation]\n",
        "  A --> B05[05-agent-model-finetuning]\n",
        "  A --> B06[06-agent-model-inference]\n",
        "  A --> B07[07-agent-llm_benchmark]\n",
        "\n",
        "  B01 --> C011[ASimpleAgentFramework.ipynb]\n",
        "  B01 --> C012[context-engineer/]\n",
        "  B01 --> C013[mcp-demo/]\n",
        "\n",
        "  B03 --> C031[backend/]\n",
        "  B03 --> C032[frontend/]\n",
        "  B03 --> C033[docker-compose.yml]\n",
        "\n",
        "  C031 --> D031a[api_server.py]\n",
        "  C031 --> D031b[agents/]\n",
        "  C031 --> D031c[tools/]\n",
        "  C031 --> D031d[config/]\n",
        "  C031 --> D031e[data/]\n",
        "  C031 --> D031f[utils/]\n",
        "```\n",
        "\n",
        "### GAME 智能体业务流程\n",
        "```mermaid\n",
        "sequenceDiagram\n",
        "  participant U as 用户输入\n",
        "  participant G as Goals / 指令\n",
        "  participant M as Memory / 记忆\n",
        "  participant L as AgentLanguage / 提示与解析\n",
        "  participant A as Actions / 工具\n",
        "  participant E as Environment / 环境执行\n",
        "  participant LLM as 大语言模型\n",
        "\n",
        "  U->>G: 任务/指令\n",
        "  G->>L: 合并目标到 system 提示\n",
        "  M->>L: 历史对话（user/assistant/environment）\n",
        "  A->>L: 动作工具的 JSON Schema\n",
        "  L->>LLM: 构造 Prompt + tools 并请求\n",
        "  LLM-->>L: 工具调用/文本回复\n",
        "  L->>A: 解析调用 {tool, args}\n",
        "  A->>E: 在环境中执行对应函数\n",
        "  E-->>M: 记录执行结果（标准化 + 时间戳）\n",
        "  L->>M: 记录助手决策（response）\n",
        "  M->>L: 新一轮上下文（若未终止）\n",
        "  note over A: 若动作为终止型（terminal）则结束循环\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
