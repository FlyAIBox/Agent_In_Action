{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 本笔记的目的与框架总览（GAME 框架）\n",
        "本笔记实现了一个“可复用的智能体（Agent）最小框架”，用来演示如何基于 GAME 设计法将智能体拆分为四个核心部件，并以可插拔方式组织：\n",
        "\n",
        "- **G（Goals / Instructions）**：目标与指令。描述智能体要实现的结果，以及实现策略/规则。\n",
        "- **A（Actions）**：动作/工具。定义智能体可以调用的能力（如读取文件、列目录、结束会话等）。\n",
        "- **M（Memory）**：记忆。跨回合保留上下文（用户输入、助手决策、工具执行结果），支持后续回合继续推理。\n",
        "- **E（Environment）**：环境。动作在真实世界中的执行载体，负责真正“落地执行”动作并返回结果（含时间戳与错误信息）。\n",
        "\n",
        "本框架通过一个统一的 **Agent** 循环（Loop）把 G/A/M/E 串起来：\n",
        "1. 构造 Prompt（包含 Goals、可用 Actions 的函数调用Schema、Memory 历史）。\n",
        "2. 发送给 LLM，得到“选择的动作以及参数”（函数调用）。\n",
        "3. 在 **Environment** 中执行该动作，得到结果（或错误）。\n",
        "4. 将决策与结果写入 **Memory**，进入下一轮。\n",
        "5. 如果动作为终止类动作（如 `terminate`），则结束循环。\n",
        "\n",
        "你可以把 **Actions** 看成“能力接口”，把 **Environment** 看成“执行实现”。这种解耦使得：\n",
        "- 你可以替换不同环境（本地、云端、GitHub Actions、容器等），而无需修改智能体决策逻辑；\n",
        "- 你可以更换一组 Actions（比如从文件工具换成 Web API 工具），而无需修改主循环；\n",
        "- 你可以替换/扩展 **AgentLanguage**（Prompt 格式与解析逻辑），以适配“函数调用/纯文本解析”等不同LLM交互方式。\n",
        "\n",
        "本笔记下半部分提供了一个最小示例：\n",
        "- 定义了 3 个动作：`list_project_files`、`read_project_file`、`terminate`\n",
        "- 目标：读取项目文件并在结束时输出 README 内容（示例运行环境为空目录时会直接终止）\n",
        "- 使用 LiteLLM 调用 `openai/gpt-4o`，但可轻松替换为任意 LLM 提供商\n",
        "\n",
        "通过阅读与运行本笔记，你将能掌握：\n",
        "- 如何将智能体设计（GAME）直接映射为代码结构；\n",
        "- 如何注册工具、格式化 Prompt、解析 LLM 工具调用并在环境中执行；\n",
        "- 如何使用记忆把“决策 + 结果”闭环起来，形成稳健的 Agent Loop。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KEYrzG2vB8Ip"
      },
      "outputs": [],
      "source": [
        "# 安装 LiteLLM：一个兼容多家大模型提供商的轻量适配层\n",
        "# - 便于后续在不改动框架核心代码的前提下，切换/替换不同模型提供商\n",
        "!!pip install litellm\n",
        "\n",
        "# 重要提示（面向 Google Colab 环境）：\n",
        "# - 请将你的 OPENAI_API_KEY 通过 Colab 的“钥匙”图标以机密的形式设置\n",
        "# - 如需让智能体读取/分析文件，可通过“文件夹”图标上传/挂载相应文件到工作目录\n",
        "# - 以下代码只做安全读取与注入环境变量，不更改任何核心逻辑\n",
        "\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# 从 Colab 的用户机密存储中读取 OPENAI_API_KEY（避免把密钥直接写到代码里）\n",
        "api_key = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "# 将密钥注入到进程环境变量中，LiteLLM 会从环境变量读取对应的提供商密钥\n",
        "os.environ['OPENAI_API_KEY'] = api_key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mwe2eeOQB0cC"
      },
      "outputs": [],
      "source": [
        "# =============================== 核心框架：导入与类型定义 ===============================\n",
        "# 说明：以下代码实现了一个最小可复用的智能体框架（面向函数调用工具 / 初学者友好注释）。\n",
        "# - 不修改任何原有逻辑，仅通过中文注释解释设计意图与用法。\n",
        "# - 关键模块：Prompt 数据结构、LLM 响应函数、Goal/Action/ActionRegistry、Memory、Environment、AgentLanguage、Agent。\n",
        "\n",
        "import json\n",
        "import time\n",
        "import traceback\n",
        "from litellm import completion\n",
        "from dataclasses import dataclass, field\n",
        "from typing import List, Callable, Dict, Any\n",
        "\n",
        "# Prompt：封装要发给 LLM 的消息与工具定义\n",
        "# - messages：对话上下文（系统/用户/助手三类）\n",
        "# - tools：工具（函数）调用的 JSON Schema 描述（让 LLM 能“看见”可用的动作）\n",
        "# - metadata：元数据（可选扩展，用 dict 保存）\n",
        "@dataclass\n",
        "class Prompt:\n",
        "    messages: List[Dict] = field(default_factory=list)\n",
        "    tools: List[Dict] = field(default_factory=list)\n",
        "    metadata: dict = field(default_factory=dict)  # Fixing mutable default issue\n",
        "\n",
        "\n",
        "# generate_response：统一的 LLM 调用入口\n",
        "# - 入参是 Prompt，内部自动根据是否提供 tools 来决定是否启用函数调用能力\n",
        "# - 目标：把模型提供商与主循环解耦；将来切换模型时无需改 Agent 逻辑\n",
        "# - 返回：\n",
        "#   * 无工具时：直接返回助手文本\n",
        "#   * 有工具时：优先解析 tool_calls（并转为 {tool, args} 的 JSON 字符串）\n",
        "#               若无工具调用，则退化为普通文本回复\n",
        "\n",
        "def generate_response(prompt: Prompt) -> str:\n",
        "    \"\"\"Call LLM to get response\"\"\"\n",
        "\n",
        "    messages = prompt.messages\n",
        "    tools = prompt.tools\n",
        "\n",
        "    result = None\n",
        "\n",
        "    if not tools:\n",
        "        # 无工具：普通对话\n",
        "        response = completion(\n",
        "            model=\"openai/gpt-4o\",\n",
        "            messages=messages,\n",
        "            max_tokens=1024\n",
        "        )\n",
        "        result = response.choices[0].message.content\n",
        "    else:\n",
        "        # 有工具：提示模型按函数调用格式返回 tool_calls\n",
        "        response = completion(\n",
        "            model=\"openai/gpt-4o\",\n",
        "            messages=messages,\n",
        "            tools=tools,\n",
        "            max_tokens=1024\n",
        "        )\n",
        "\n",
        "        if response.choices[0].message.tool_calls:\n",
        "            # 这里仅取第一个工具调用作为最小可运行演示\n",
        "            tool = response.choices[0].message.tool_calls[0]\n",
        "            result = {\n",
        "                \"tool\": tool.function.name,\n",
        "                \"args\": json.loads(tool.function.arguments),\n",
        "            }\n",
        "            # 将 dict 序列化为字符串，便于统一处理与存入记忆\n",
        "            result = json.dumps(result)\n",
        "        else:\n",
        "            # 即使提供了 tools，也可能返回纯文本（例如模型策略判断不调用工具）\n",
        "            result = response.choices[0].message.content\n",
        "\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "# Goal：目标对象（冻结数据类）\n",
        "# - priority：目标优先级（便于排序/裁剪）\n",
        "# - name/description：目标名称和详细说明（同时涵盖“要做什么/如何做”）\n",
        "@dataclass(frozen=True)\n",
        "class Goal:\n",
        "    priority: int\n",
        "    name: str\n",
        "    description: str\n",
        "\n",
        "\n",
        "# Action：动作/工具的抽象\n",
        "# - name：动作名（作为工具名暴露给 LLM）\n",
        "# - function：实际执行的 Python 函数\n",
        "# - description：工具说明，帮助 LLM 选择正确工具\n",
        "# - parameters：JSON Schema（决定 LLM 该如何拼好参数）\n",
        "# - terminal：是否为“终止型”动作（被选中后终止主循环）\n",
        "class Action:\n",
        "    def __init__(self,\n",
        "                 name: str,\n",
        "                 function: Callable,\n",
        "                 description: str,\n",
        "                 parameters: Dict,\n",
        "                 terminal: bool = False):\n",
        "        self.name = name\n",
        "        self.function = function\n",
        "        self.description = description\n",
        "        self.terminal = terminal\n",
        "        self.parameters = parameters\n",
        "\n",
        "    def execute(self, **args) -> Any:\n",
        "        \"\"\"Execute the action's function\"\"\"\n",
        "        # 解包参数并调用底层实现函数\n",
        "        return self.function(**args)\n",
        "\n",
        "\n",
        "# ActionRegistry：动作注册表\n",
        "# - 负责集中管理动作对象，支持按名称检索与批量导出供 AgentLanguage 生成工具Schema\n",
        "class ActionRegistry:\n",
        "    def __init__(self):\n",
        "        self.actions = {}\n",
        "\n",
        "    def register(self, action: Action):\n",
        "        self.actions[action.name] = action\n",
        "\n",
        "    def get_action(self, name: str) -> [Action, None]:\n",
        "        return self.actions.get(name, None)\n",
        "\n",
        "    def get_actions(self) -> List[Action]:\n",
        "        \"\"\"Get all registered actions\"\"\"\n",
        "        return list(self.actions.values())\n",
        "\n",
        "\n",
        "# Memory：回合记忆\n",
        "# - items：统一存储“用户/助手/环境”等事件，形成对话历史\n",
        "# - 通过 get_memories 提供最近N条消息给提示构造使用\n",
        "# - 通过 copy_without_system_memories 可过滤掉系统消息（某些场景需要）\n",
        "class Memory:\n",
        "    def __init__(self):\n",
        "        self.items = []  # Basic conversation histor\n",
        "\n",
        "    def add_memory(self, memory: dict):\n",
        "        \"\"\"Add memory to working memory\"\"\"\n",
        "        self.items.append(memory)\n",
        "\n",
        "    def get_memories(self, limit: int = None) -> List[Dict]:\n",
        "        \"\"\"Get formatted conversation history for prompt\"\"\"\n",
        "        return self.items[:limit]\n",
        "\n",
        "    def copy_without_system_memories(self):\n",
        "        \"\"\"Return a copy of the memory without system memories\"\"\"\n",
        "        filtered_items = [m for m in self.items if m[\"type\"] != \"system\"]\n",
        "        memory = Memory()\n",
        "        memory.items = filtered_items\n",
        "        return memory\n",
        "\n",
        "\n",
        "# Environment：环境层（动作的真实执行者）\n",
        "# - execute_action：捕获执行异常，统一返回结构（是否执行成功/错误/traceback/时间戳）\n",
        "# - format_result：为成功结果补充元数据（时间戳），便于记录与日志化\n",
        "class Environment:\n",
        "    def execute_action(self, action: Action, args: dict) -> dict:\n",
        "        \"\"\"Execute an action and return the result.\"\"\"\n",
        "        try:\n",
        "            result = action.execute(**args)\n",
        "            return self.format_result(result)\n",
        "        except Exception as e:\n",
        "            return {\n",
        "                \"tool_executed\": False,\n",
        "                \"error\": str(e),\n",
        "                \"traceback\": traceback.format_exc()\n",
        "            }\n",
        "\n",
        "    def format_result(self, result: Any) -> dict:\n",
        "        \"\"\"Format the result with metadata.\"\"\"\n",
        "        return {\n",
        "            \"tool_executed\": True,\n",
        "            \"result\": result,\n",
        "            \"timestamp\": time.strftime(\"%Y-%m-%dT%H:%M:%S%z\")\n",
        "        }\n",
        "\n",
        "\n",
        "# AgentLanguage：语言适配层\n",
        "# - 负责把（Goals/Actions/Memory）格式化为 LLM 需要的 Prompt\n",
        "# - 负责从 LLM 的原始输出中解析出“要调用的工具与参数”\n",
        "class AgentLanguage:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def construct_prompt(self,\n",
        "                         actions: List[Action],\n",
        "                         environment: Environment,\n",
        "                         goals: List[Goal],\n",
        "                         memory: Memory) -> Prompt:\n",
        "        raise NotImplementedError(\"Subclasses must implement this method\")\n",
        "\n",
        "\n",
        "    def parse_response(self, response: str) -> dict:\n",
        "        raise NotImplementedError(\"Subclasses must implement this method\")\n",
        "\n",
        "\n",
        "\n",
        "# AgentFunctionCallingActionLanguage：基于“函数调用”范式的语言适配实现\n",
        "# - 将 Goals 拼接为 system 消息\n",
        "# - 将 Memory 规范化映射为 user/assistant 消息\n",
        "# - 将 Actions 转换为符合 OpenAI 函数调用的 tools Schema\n",
        "class AgentFunctionCallingActionLanguage(AgentLanguage):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def format_goals(self, goals: List[Goal]) -> List:\n",
        "        # 把所有目标拼接为一个 system 消息，便于集中表达“要做什么/如何做”\n",
        "        sep = \"\\n-------------------\\n\"\n",
        "        goal_instructions = \"\\n\\n\".join([f\"{goal.name}:{sep}{goal.description}{sep}\" for goal in goals])\n",
        "        return [\n",
        "            {\"role\": \"system\", \"content\": goal_instructions}\n",
        "        ]\n",
        "\n",
        "    def format_memory(self, memory: Memory) -> List:\n",
        "        \"\"\"Generate response from language model\"\"\"\n",
        "        # 记忆格式化策略：\n",
        "        # - environment 的输出也作为 assistant 角色加入（让模型能“看到”工具执行结果）\n",
        "        # - user/assistant 原样映射\n",
        "        items = memory.get_memories()\n",
        "        mapped_items = []\n",
        "        for item in items:\n",
        "\n",
        "            content = item.get(\"content\", None)\n",
        "            if not content:\n",
        "                content = json.dumps(item, indent=4)\n",
        "\n",
        "            if item[\"type\"] == \"assistant\":\n",
        "                mapped_items.append({\"role\": \"assistant\", \"content\": content})\n",
        "            elif item[\"type\"] == \"environment\":\n",
        "                mapped_items.append({\"role\": \"assistant\", \"content\": content})\n",
        "            else:\n",
        "                mapped_items.append({\"role\": \"user\", \"content\": content})\n",
        "\n",
        "        return mapped_items\n",
        "\n",
        "    def format_actions(self, actions: List[Action]) -> [List,List]:\n",
        "        \"\"\"Generate response from language model\"\"\"\n",
        "\n",
        "        # 将注册的 Action 转为 OpenAI 函数调用工具的 Schema 数组\n",
        "        tools = [\n",
        "            {\n",
        "                \"type\": \"function\",\n",
        "                \"function\": {\n",
        "                    \"name\": action.name,\n",
        "                    # 描述过长可能无效，限制到 1024 字符\n",
        "                    \"description\": action.description[:1024],\n",
        "                    \"parameters\": action.parameters,\n",
        "                },\n",
        "            } for action in actions\n",
        "        ]\n",
        "\n",
        "        return tools\n",
        "\n",
        "    def construct_prompt(self,\n",
        "                         actions: List[Action],\n",
        "                         environment: Environment,\n",
        "                         goals: List[Goal],\n",
        "                         memory: Memory) -> Prompt:\n",
        "\n",
        "        # 构造最终 Prompt：Goals（system）+ Memory（历史消息）+ Tools（函数Schema）\n",
        "        prompt = []\n",
        "        prompt += self.format_goals(goals)\n",
        "        prompt += self.format_memory(memory)\n",
        "\n",
        "        tools = self.format_actions(actions)\n",
        "\n",
        "        return Prompt(messages=prompt, tools=tools)\n",
        "\n",
        "    def adapt_prompt_after_parsing_error(self,\n",
        "                                         prompt: Prompt,\n",
        "                                         response: str,\n",
        "                                         traceback: str,\n",
        "                                         error: Any,\n",
        "                                         retries_left: int) -> Prompt:\n",
        "        # 解析失败后的“自适应 Prompt”策略（此处保留扩展点，演示版不做修改）\n",
        "        return prompt\n",
        "\n",
        "    def parse_response(self, response: str) -> dict:\n",
        "        \"\"\"Parse LLM response into structured format by extracting the ```json block\"\"\"\n",
        "\n",
        "        # 期望 LLM 返回 JSON 字符串：{\"tool\": 工具名, \"args\": {...}}\n",
        "        try:\n",
        "            return json.loads(response)\n",
        "\n",
        "        except Exception as e:\n",
        "            # 若无法解析，则将内容作为 message 交给终止工具，友好退出\n",
        "            return {\n",
        "                \"tool\": \"terminate\",\n",
        "                \"args\": {\"message\":response}\n",
        "            }\n",
        "\n",
        "\n",
        "# Agent：智能体主循环\n",
        "# - 维护并协调 G/A/M/E（目标/动作/记忆/环境）\n",
        "# - 统一的 prompt 构造、响应解析、动作执行、记忆更新、终止判断\n",
        "class Agent:\n",
        "    def __init__(self,\n",
        "                 goals: List[Goal],\n",
        "                 agent_language: AgentLanguage,\n",
        "                 action_registry: ActionRegistry,\n",
        "                 generate_response: Callable[[Prompt], str],\n",
        "                 environment: Environment):\n",
        "        \"\"\"\n",
        "        Initialize an agent with its core GAME components\n",
        "        \"\"\"\n",
        "        self.goals = goals\n",
        "        self.generate_response = generate_response\n",
        "        self.agent_language = agent_language\n",
        "        self.actions = action_registry\n",
        "        self.environment = environment\n",
        "\n",
        "    def construct_prompt(self, goals: List[Goal], memory: Memory, actions: ActionRegistry) -> Prompt:\n",
        "        \"\"\"Build prompt with memory context\"\"\"\n",
        "        return self.agent_language.construct_prompt(\n",
        "            actions=actions.get_actions(),\n",
        "            environment=self.environment,\n",
        "            goals=goals,\n",
        "            memory=memory\n",
        "        )\n",
        "\n",
        "    def get_action(self, response):\n",
        "        # 解析 LLM 的返回，得到动作名与参数（invocation）\n",
        "        invocation = self.agent_language.parse_response(response)\n",
        "        action = self.actions.get_action(invocation[\"tool\"])\n",
        "        return action, invocation\n",
        "\n",
        "    def should_terminate(self, response: str) -> bool:\n",
        "        # 若当前选择的动作被标记为 terminal，则结束主循环\n",
        "        action_def, _ = self.get_action(response)\n",
        "        return action_def.terminal\n",
        "\n",
        "    def set_current_task(self, memory: Memory, task: str):\n",
        "        # 将用户输入写入记忆，作为本轮起始任务语境\n",
        "        memory.add_memory({\"type\": \"user\", \"content\": task})\n",
        "\n",
        "    def update_memory(self, memory: Memory, response: str, result: dict):\n",
        "        \"\"\"\n",
        "        Update memory with the agent's decision and the environment's response.\n",
        "        \"\"\"\n",
        "        # 统一把“助手的决策（response）”与“环境执行结果（result）”写入记忆\n",
        "        new_memories = [\n",
        "            {\"type\": \"assistant\", \"content\": response},\n",
        "            {\"type\": \"environment\", \"content\": json.dumps(result)}\n",
        "        ]\n",
        "        for m in new_memories:\n",
        "            memory.add_memory(m)\n",
        "\n",
        "    def prompt_llm_for_action(self, full_prompt: Prompt) -> str:\n",
        "        # 将 Prompt 发送给 LLM，得到“下一步动作/或文本回复”\n",
        "        response = self.generate_response(full_prompt)\n",
        "        return response\n",
        "\n",
        "    def run(self, user_input: str, memory=None, max_iterations: int = 50) -> Memory:\n",
        "        \"\"\"\n",
        "        Execute the GAME loop for this agent with a maximum iteration limit.\n",
        "        \"\"\"\n",
        "        # 初始化记忆并写入用户任务\n",
        "        memory = memory or Memory()\n",
        "        self.set_current_task(memory, user_input)\n",
        "\n",
        "        for _ in range(max_iterations):\n",
        "            # 1) 用当前 Goals/Actions/Memory 构造 Prompt\n",
        "            prompt = self.construct_prompt(self.goals, memory, self.actions)\n",
        "\n",
        "            print(\"Agent thinking...\")\n",
        "            # 2) 发送给 LLM，得到“将要调用的动作及其参数”或普通文本\n",
        "            response = self.prompt_llm_for_action(prompt)\n",
        "            print(f\"Agent Decision: {response}\")\n",
        "\n",
        "            # 3) 解析动作与参数\n",
        "            action, invocation = self.get_action(response)\n",
        "\n",
        "            # 4) 在环境中真实执行动作\n",
        "            result = self.environment.execute_action(action, invocation[\"args\"])\n",
        "            print(f\"Action Result: {result}\")\n",
        "\n",
        "            # 5) 将“决策 + 结果”写回记忆，形成闭环\n",
        "            self.update_memory(memory, response, result)\n",
        "\n",
        "            # 6) 终止判断：如果动作为终止型，则跳出循环\n",
        "            if self.should_terminate(response):\n",
        "                break\n",
        "\n",
        "        return memory\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PC3ncxezoJC",
        "outputId": "564b75ed-bcc3-4f59-c51f-ed4e39d7bf90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Agent thinking...\n",
            "Agent Decision: {\"tool\": \"list_project_files\", \"args\": {}}\n",
            "Action Result: {'tool_executed': True, 'result': [], 'timestamp': '2025-03-10T20:50:18+0000'}\n",
            "Agent thinking...\n",
            "Agent Decision: {\"tool\": \"terminate\", \"args\": {\"message\": \"It seems there are no files in the project, as the list of files returned was empty. Consequently, I cannot generate a README file content for this project since there's nothing to describe or explain. If you have more details about the project or specific files you'd like to mention, please provide them. Otherwise, the current project state does not require a README.\"}}\n",
            "Action Result: {'tool_executed': True, 'result': \"It seems there are no files in the project, as the list of files returned was empty. Consequently, I cannot generate a README file content for this project since there's nothing to describe or explain. If you have more details about the project or specific files you'd like to mention, please provide them. Otherwise, the current project state does not require a README.\\nTerminating...\", 'timestamp': '2025-03-10T20:50:19+0000'}\n",
            "[{'type': 'user', 'content': 'Write a README for this project.'}, {'type': 'assistant', 'content': '{\"tool\": \"list_project_files\", \"args\": {}}'}, {'type': 'environment', 'content': '{\"tool_executed\": true, \"result\": [], \"timestamp\": \"2025-03-10T20:50:18+0000\"}'}, {'type': 'assistant', 'content': '{\"tool\": \"terminate\", \"args\": {\"message\": \"It seems there are no files in the project, as the list of files returned was empty. Consequently, I cannot generate a README file content for this project since there\\'s nothing to describe or explain. If you have more details about the project or specific files you\\'d like to mention, please provide them. Otherwise, the current project state does not require a README.\"}}'}, {'type': 'environment', 'content': '{\"tool_executed\": true, \"result\": \"It seems there are no files in the project, as the list of files returned was empty. Consequently, I cannot generate a README file content for this project since there\\'s nothing to describe or explain. If you have more details about the project or specific files you\\'d like to mention, please provide them. Otherwise, the current project state does not require a README.\\\\nTerminating...\", \"timestamp\": \"2025-03-10T20:50:19+0000\"}'}]\n"
          ]
        }
      ],
      "source": [
        "# =============================== 示例：最小可运行 Agent ===============================\n",
        "# 1) 定义智能体目标（Goals）：\n",
        "#    - 读取项目中的每个文件\n",
        "#    - 当已读取完毕时调用 terminate，并在消息中提供 README 的内容（示例环境如为空目录会直接终止）\n",
        "goals = [\n",
        "    Goal(priority=1, name=\"Gather Information\", description=\"Read each file in the project\"),\n",
        "    Goal(priority=1, name=\"Terminate\", description=\"Call the terminate call when you have read all the files \"\n",
        "                                                   \"and provide the content of the README in the terminate message\")\n",
        "]\n",
        "\n",
        "# 2) 指定语言适配器（基于函数调用的 Prompt/解析策略）\n",
        "agent_language = AgentFunctionCallingActionLanguage()\n",
        "\n",
        "# 3) 实现底层动作：读取文件\n",
        "def read_project_file(name: str) -> str:\n",
        "    with open(name, \"r\") as f:\n",
        "        return f.read()\n",
        "\n",
        "# 4) 实现底层动作：列出当前目录下的 .py 文件（最小示例）\n",
        "def list_project_files() -> List[str]:\n",
        "    return sorted([file for file in os.listdir(\".\") if file.endswith(\".py\")])\n",
        "\n",
        "\n",
        "# 5) 注册动作：将 Python 函数“暴露”为可被 LLM 选择的工具\n",
        "action_registry = ActionRegistry()\n",
        "action_registry.register(Action(\n",
        "    name=\"list_project_files\",\n",
        "    function=list_project_files,\n",
        "    description=\"Lists all files in the project.\",\n",
        "    parameters={},\n",
        "    terminal=False\n",
        "))\n",
        "action_registry.register(Action(\n",
        "    name=\"read_project_file\",\n",
        "    function=read_project_file,\n",
        "    description=\"Reads a file from the project.\",\n",
        "    parameters={\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"name\": {\"type\": \"string\"}\n",
        "        },\n",
        "        \"required\": [\"name\"]\n",
        "    },\n",
        "    terminal=False\n",
        "))\n",
        "action_registry.register(Action(\n",
        "    name=\"terminate\",\n",
        "    function=lambda message: f\"{message}\\nTerminating...\",\n",
        "    description=\"Terminates the session and prints the message to the user.\",\n",
        "    parameters={\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"message\": {\"type\": \"string\"}\n",
        "        },\n",
        "        \"required\": []\n",
        "    },\n",
        "    terminal=True\n",
        "))\n",
        "\n",
        "# 6) 准备环境（负责真实执行动作并返回标准化结果）\n",
        "environment = Environment()\n",
        "\n",
        "# 7) 构建 Agent 实例（组装 G/A/M/E 与 LLM 响应函数）\n",
        "agent = Agent(goals, agent_language, action_registry, generate_response, environment)\n",
        "\n",
        "# 8) 运行智能体（输入一个自然语言任务），内部会进入循环直到触发终止或达到最大轮数\n",
        "user_input = \"Write a README for this project.\"\n",
        "final_memory = agent.run(user_input)\n",
        "\n",
        "# 9) 输出最终的记忆（包含用户任务、助手决策、环境执行结果等）\n",
        "print(final_memory.get_memories())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
