{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangGraph è¿›é˜¶æ¦‚å¿µï¼šä¸­é—´ä»¶ (Middleware) & äººæœºäº¤äº’ (Human-in-the-Loop)\n",
    "\n",
    "æ¬¢è¿æ¥åˆ° LangGraph è¿›é˜¶è¯¾ç¨‹ï¼æœ¬ Notebook å»ºç«‹åœ¨ LangGraph 101 çš„åŸºç¡€ä¹‹ä¸Šï¼Œä»‹ç»æ„å»ºç”Ÿäº§çº§ Agent çš„ä¸¤ä¸ªå¼ºå¤§æ¨¡å¼ã€‚\n",
    "\n",
    "**ä½ å°†å­¦åˆ°ï¼š**\n",
    "- **Human-in-the-Loop (äººæœºäº¤äº’)** - æš‚åœ Agent ä»¥è¿›è¡Œäººå·¥å®¡æŸ¥å’Œæ‰¹å‡†\n",
    "- **Middleware (ä¸­é—´ä»¶)** - åœ¨æ‰§è¡Œçš„å…³é”®ç‚¹ä¿®æ”¹ Agent çš„è¡Œä¸º\n",
    "- **Tool Review (å·¥å…·å®¡æŸ¥)** - ä¸ºæ•æ„Ÿå·¥å…·æ·»åŠ å®¡æ‰¹å·¥ä½œæµ\n",
    "- **Dynamic Behavior (åŠ¨æ€è¡Œä¸º)** - æ ¹æ®ä¸Šä¸‹æ–‡è°ƒæ•´ Agent çš„å“åº”\n",
    "\n",
    "**å…ˆå†³æ¡ä»¶ï¼š** å®Œæˆ `langgraph_101.ipynb`\n",
    "</br>\n",
    "</br>\n",
    "\n",
    "---\n",
    "</br>\n",
    "\n",
    "> **æ³¨æ„ï¼š** è¿™äº›æ¨¡å¼å¯¹äºç”Ÿäº§çº§ Agent è‡³å…³é‡è¦ï¼Œå› ä¸ºåœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œå®‰å…¨æ€§ã€åˆè§„æ€§å’Œç”¨æˆ·æ§åˆ¶æ˜¯å¿…ä¸å¯å°‘çš„ã€‚LangGraph 1.0 å¼•å…¥äº† `interrupt` å’Œ `Command` ç­‰æ–°åŸè¯­ï¼Œè®©è¿™äº›æ¨¡å¼çš„å®ç°å˜å¾—æ›´åŠ ç›´è§‚å’Œå¼ºå¤§ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangGraph 1.0 å‡çº§æŒ‡å— - äººæœºäº¤äº’ä¸æ§åˆ¶æµ\n",
    "\n",
    "åœ¨ LangGraph 1.0 ä¸­ï¼Œ**Human-in-the-Loop** å’Œ **æ§åˆ¶æµ** å‘ç”Ÿäº†é‡å¤§å˜åŒ–ï¼Œå˜å¾—æ›´åŠ åŠ¨æ€å’Œçµæ´»ã€‚\n",
    "\n",
    "**ä¸»è¦åŒºåˆ«ï¼š**\n",
    "\n",
    "#### 1. ä¸­æ–­æœºåˆ¶ï¼š`interrupt()` vs é™æ€é…ç½®\n",
    "- **æ—§ç‰ˆ (0.x)**: éœ€è¦åœ¨ç¼–è¯‘ Graph æ—¶é€šè¿‡ `interrupt_before=[\"node_name\"]` é™æ€æŒ‡å®šåœ¨å“ªåœã€‚\n",
    "- **æ–°ç‰ˆ (1.0)**: å¼•å…¥äº†åŠ¨æ€ **`interrupt()`** å‡½æ•°ã€‚ä½ å¯ä»¥åœ¨ä»»ä½•èŠ‚ç‚¹æˆ–å·¥å…·å†…éƒ¨è°ƒç”¨å®ƒã€‚è¿™å…è®¸åŸºäºé€»è¾‘ï¼ˆå¦‚â€œç½®ä¿¡åº¦ä½æ—¶æ‰ä¸­æ–­â€ï¼‰åŠ¨æ€å†³å®šæ˜¯å¦æš‚åœã€‚\n",
    "\n",
    "#### 2. çŠ¶æ€æ›´æ–°ä¸å¯¼èˆªï¼š`Command` å¯¹è±¡\n",
    "- **æ—§ç‰ˆ (0.x)**: èŠ‚ç‚¹è¿”å›çŠ¶æ€æ›´æ–°ï¼Œè·¯ç”±ç”±å•ç‹¬çš„æ¡ä»¶è¾¹å‡½æ•°å¤„ç†ã€‚\n",
    "- **æ–°ç‰ˆ (1.0)**: å¼•å…¥ **`Command`** å¯¹è±¡ã€‚ä¸€ä¸ªèŠ‚ç‚¹å¯ä»¥åŒæ—¶è¿”å›çŠ¶æ€æ›´æ–° (`update`) å’Œè·¯ç”±æŒ‡ä»¤ (`goto`)ï¼Œæå¤§ç®€åŒ–äº†å¤æ‚é€»è¾‘çš„ç¼–å†™ã€‚\n",
    "\n",
    "æœ¬æ•™ç¨‹çš„â€œç¬¬ 1 éƒ¨åˆ†â€å’Œâ€œç¬¬ 2 éƒ¨åˆ†â€å°†è¯¦ç»†æ¼”ç¤ºè¿™äº›æ–°ç‰¹æ€§çš„ç”¨æ³•ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 ç¯å¢ƒé…ç½®ä¸å·¥å…·æ•´åˆ (Environment & Utils)\n",
    "\n",
    "ä¸ºäº†ä½¿æœ¬ Notebook è‡ªåŒ…å«ï¼Œæˆ‘ä»¬å°†åŸæœ¬åˆ†æ•£åœ¨ `utils` ç›®å½•å’Œ `.env` æ–‡ä»¶çš„é…ç½®æ•´åˆåˆ°è¿™é‡Œã€‚\n",
    "The following cells merged from `utils/models.py`, `utils/utils.py`, and `.env.example`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration: Set Environment Variables (derived from .env.example)\n",
    "# é…ç½®: è®¾ç½®ç¯å¢ƒå˜é‡ (æºè‡ª .env.example)\n",
    "import os\n",
    "\n",
    "# If using OpenAI \n",
    "\n",
    "# os.environ['OPENAI_API_KEY'] = \"<openai-api-key>\"\n",
    "# os.environ['OPENAI_BASE_URL'] = \"<openai-base-url>\" # Optional, if different from the default\"\n",
    "\n",
    "# Optional for LangSmith tracing and experiment tracking\n",
    "\n",
    "# os.environ['LANGSMITH_API_KEY'] = \"<langsmith-api-key>\"\n",
    "# os.environ['LANGSMITH_ENDPOINT'] = \"<langsmith-endpoint>\" #defaults to https://api.smith.langchain.com if using cloud\"\n",
    "# os.environ['LANGSMITH_TRACING'] = \"true\"\n",
    "# os.environ['LANGSMITH_PROJECT'] = \"langgraph-102\"\n",
    "\n",
    "# If using Azure OpenAI\n",
    "\n",
    "# os.environ['AZURE_OPENAI_API_KEY'] = \"<azure-openai-api-key>\"\n",
    "# os.environ['AZURE_OPENAI_ENDPOINT'] = \"<azure-openai-endpoint>\"\n",
    "# os.environ['AZURE_OPENAI_API_VERSION'] = \"\"\n",
    "\n",
    "# If using Anthropic\n",
    "\n",
    "# os.environ['ANTHROPIC_API_KEY'] = \"<anthropic-api-key>\"\n",
    "\n",
    "# If using AWS \n",
    "\n",
    "# os.environ['AWS_ACCESS_KEY_ID'] = \"\"\n",
    "# os.environ['AWS_SECRET_ACCESS_KEY'] = \"\"\n",
    "# os.environ['AWS_REGION_NAME'] = \"\"\n",
    "# os.environ['AWS_MODEL_ARN'] = \"\"\n",
    "\n",
    "# if using Google Vertex AI\n",
    "# os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = \"./vertexCred.json\" # replace with path to your vertex credentials\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Content from utils/utils.py\n",
    "import sqlite3\n",
    "import requests\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.pool import StaticPool\n",
    "\n",
    "def show_graph(graph, xray=False):\n",
    "    \"\"\"å±•ç¤º LangGraph çš„ Mermaid æµç¨‹å›¾ï¼Œå¦‚æœå¤±è´¥åˆ™ä½¿ç”¨ ASCII å›¾è¡¨ä½œä¸ºåå¤‡ã€‚\n",
    "    \n",
    "    å‚æ•°:\n",
    "        graph: æ‹¥æœ‰ get_graph() æ–¹æ³•çš„ LangGraph å¯¹è±¡\n",
    "        xray: æ˜¯å¦å±•ç¤ºå›¾çš„å†…éƒ¨ç»“æ„ (ä¾‹å¦‚å­å›¾)\n",
    "    \"\"\"\n",
    "    from IPython.display import Image\n",
    "    try:\n",
    "        return Image(graph.get_graph(xray=xray).draw_mermaid_png())\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸  å›¾ç‰‡æ¸²æŸ“å¤±è´¥: {e}\")\n",
    "        print(\"\\nğŸ“Š æ”¹ä¸ºå±•ç¤º ASCII å›¾è¡¨:\\n\")\n",
    "        ascii_diagram = graph.get_graph(xray=xray).draw_ascii()\n",
    "        print(ascii_diagram)\n",
    "        return None\n",
    "\n",
    "def get_engine_for_chinook_db():\n",
    "    \"\"\"ä¸‹è½½ SQL æ–‡ä»¶ï¼Œå¡«å……å†…å­˜æ•°æ®åº“ï¼Œå¹¶åˆ›å»º SQLAlchemy å¼•æ“ã€‚\"\"\"\n",
    "    url = \"https://raw.githubusercontent.com/lerocha/chinook-database/master/ChinookDatabase/DataSources/Chinook_Sqlite.sql\"\n",
    "    response = requests.get(url)\n",
    "    sql_script = response.text\n",
    "\n",
    "    connection = sqlite3.connect(\":memory:\", check_same_thread=False)\n",
    "    connection.executescript(sql_script)\n",
    "    return create_engine(\n",
    "        \"sqlite://\",\n",
    "        creator=lambda: connection,\n",
    "        poolclass=StaticPool,\n",
    "        connect_args={\"check_same_thread\": False},\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Content from utils/models.py\n",
    "\"\"\"\n",
    "æ¨¡å‹åˆå§‹åŒ–æ–‡ä»¶\n",
    "\n",
    "æ­¤æ–‡ä»¶é…ç½®åº”ç”¨ç¨‹åºä¸­ä½¿ç”¨çš„ LLM (å¤§è¯­è¨€æ¨¡å‹)ã€‚\n",
    "\n",
    "é»˜è®¤é…ç½®:\n",
    "- é»˜è®¤æä¾›å•†æ˜¯ OpenAI (ä½¿ç”¨ o3-mini æ¨¡å‹)\n",
    "- ä½ ä¹Ÿå¯ä»¥é€šè¿‡å–æ¶ˆæ³¨é‡Šç›¸åº”çš„è¡Œæ¥åˆ‡æ¢åˆ° Anthropic\n",
    "\n",
    "å¤‡é€‰æä¾›å•†:\n",
    "è¦ä½¿ç”¨ä¸åŒçš„ LLM æä¾›å•†ï¼Œè¯·æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤æ“ä½œ:\n",
    "1. æ³¨é‡Šæ‰ä¸‹æ–¹çš„ \"Default Models\" (é»˜è®¤æ¨¡å‹) éƒ¨åˆ†\n",
    "2. å–æ¶ˆæ³¨é‡Šä½ æƒ³è¦çš„æä¾›å•†éƒ¨åˆ†:\n",
    "   - Azure OpenAI: éœ€è¦è®¾ç½® AZURE_OPENAI_API_KEY å’Œ AZURE_OPENAI_ENDPOINT\n",
    "   - AWS Bedrock: éœ€è¦è®¾ç½® AWS å‡­è¯å’Œé…ç½®\n",
    "   - Google Vertex AI: éœ€è¦è®¾ç½® GOOGLE_APPLICATION_CREDENTIALS\n",
    "3. æŒ‰ç…§æ¯ä¸ªéƒ¨åˆ†å†…çš„è®¾ç½®è¯´æ˜è¿›è¡Œæ“ä½œ\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"é»˜è®¤æ¨¡å‹ (Default Models)\"\"\"\n",
    "from dotenv import load_dotenv\n",
    "# åŠ è½½ .env ç¯å¢ƒå˜é‡ï¼Œè¦†ç›–ç°æœ‰å˜é‡\n",
    "load_dotenv(dotenv_path=\"../../.env\", override=True)\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "# åˆå§‹åŒ–èŠå¤©æ¨¡å‹ï¼Œè¿™é‡Œä½¿ç”¨ OpenAI çš„ o3-mini\n",
    "model = init_chat_model(\"openai:o3-mini\")\n",
    "\n",
    "# ä½¿ç”¨ Anthropic æ›¿ä»£ OpenAI\n",
    "# model = init_chat_model(\"anthropic:claude-haiku-4-5\")\n",
    "\n",
    "# ... (rest of the file logic is commented out, keeping it simple)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## è®¾ç½®\n",
    "\n",
    "è®©æˆ‘ä»¬å¿«é€Ÿè®¾ç½®ç¯å¢ƒã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å°†é¡¹ç›®æ ¹ç›®å½•æ·»åŠ åˆ° Python è·¯å¾„\n",
    "import sys\n",
    "from pathlib import Path\n",
    "project_root = Path().resolve().parent.parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "# å¯¼å…¥æ¨¡å‹é…ç½®\n",
    "# from utils.models import model # Copied inline above\n",
    "\n",
    "# å¤‡é€‰æ–¹æ¡ˆï¼šå†…è”å®šä¹‰æ¨¡å‹\n",
    "# from dotenv import load_dotenv\n",
    "# load_dotenv(dotenv_path=\"../.env\", override=True)\n",
    "# from langchain.chat_models import init_chat_model\n",
    "# model = init_chat_model(\"openai:o3-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç¬¬ 1 éƒ¨åˆ†: ä½¿ç”¨ Interrupts å®ç°äººæœºäº¤äº’ (Human-in-the-Loop)\n",
    "\n",
    "### é—®é¢˜èƒŒæ™¯\n",
    "\n",
    "æƒ³è±¡ä¸€ä¸‹ï¼Œä½ æ­£åœ¨æ„å»ºä¸€ä¸ªå¯ä»¥å‘é€ç”µå­é‚®ä»¶æˆ–è¿›è¡Œè´­ä¹°çš„ Agentã€‚ä½ è‚¯å®šä¸å¸Œæœ›å®ƒè‡ªåŠ¨æ‰§è¡Œè¿™äº›æ“ä½œ â€”â€” ä½ å¸Œæœ›å…ˆç»è¿‡äººå·¥æ‰¹å‡†ï¼\n",
    "\n",
    "**Human-in-the-Loop** å…è®¸ä½ ï¼š\n",
    "- æš‚åœæ‰§è¡Œä»¥è¿›è¡Œå®¡æŸ¥\n",
    "- æ‰¹å‡†ã€æ‹’ç»æˆ–ç¼–è¾‘åŠ¨ä½œ\n",
    "- ä¸ºæ•æ„Ÿæ“ä½œæ·»åŠ å®‰å…¨æ§åˆ¶\n",
    "\n",
    "### å·¥ä½œåŸç† (LangGraph 1.0 æ–°ç‰¹æ€§)\n",
    "\n",
    "LangGraph 1.0 å¼•å…¥äº†åŠ¨æ€ `interrupt` å‡½æ•°ï¼Œæ›¿ä»£äº†æ—§ç‰ˆè¾ƒä¸ºé™æ€çš„é…ç½®æ–¹å¼ã€‚\n",
    "\n",
    "1. Agent é‡åˆ° `interrupt()` å‡½æ•° - æ‰§è¡Œæš‚åœ\n",
    "2. ç³»ç»Ÿå°†ä¿¡æ¯å±•ç¤ºç»™äººç±»\n",
    "3. äººç±»æä¾›è¾“å…¥ï¼ˆæ‰¹å‡†/æ‹’ç»/ç¼–è¾‘ï¼‰\n",
    "4. Agent ä½¿ç”¨ `Command(resume=...)` æ¢å¤æ‰§è¡Œï¼Œå¹¶å°†äººç±»è¾“å…¥ä½œä¸º `interrupt()` çš„è¿”å›å€¼ä¼ å›"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ç¤ºä¾‹ 1: ç®€å•çš„å®¡æ‰¹å·¥ä½œæµ\n",
    "\n",
    "è®©æˆ‘ä»¬ä»ä¸€ä¸ªç®€å•çš„ä¾‹å­å¼€å§‹â€”â€”åœ¨å‘é€ç”µå­é‚®ä»¶ä¹‹å‰è¯·æ±‚æ‰¹å‡†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.types import interrupt\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def send_email(to: str, subject: str, body: str) -> str:\n",
    "    \"\"\"å‘é€é‚®ä»¶ç»™æ¥æ”¶è€…ã€‚\"\"\"\n",
    "    \n",
    "    # æš‚åœä»¥ç­‰å¾…äººå·¥æ‰¹å‡†\n",
    "    # interrupt æ¥æ”¶çš„å‚æ•°ä¼šä½œä¸ºæš‚åœæ—¶çš„ä¿¡æ¯è¿”å›ç»™å‰ç«¯/ç”¨æˆ·\n",
    "    # ç¨‹åºä¼šåœ¨è¿™é‡ŒæŒ‚èµ·ï¼Œç›´åˆ°æ”¶åˆ° resume æŒ‡ä»¤\n",
    "    approval = interrupt({\n",
    "        \"action\": \"send_email\",\n",
    "        \"to\": to,\n",
    "        \"subject\": subject,\n",
    "        \"body\": body,\n",
    "        \"message\": \"Do you want to send this email?\"\n",
    "    })\n",
    "    \n",
    "    # æ¢å¤æ‰§è¡Œåï¼Œapproval å˜é‡å°†åŒ…å« resume æ—¶ä¼ å…¥çš„æ•°æ®\n",
    "    if approval.get(\"approved\"): # å¦‚æœé€šè¿‡æ‰¹å‡†ï¼ˆæ ¹æ®æˆ‘ä»¬å®šä¹‰çš„åè®®ï¼‰\n",
    "        # åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œè¿™é‡Œä¼šå®é™…å‘é€é‚®ä»¶\n",
    "        return f\" Email sent to {to} with subject '{subject}'\"\n",
    "    else:\n",
    "        return \"Email cancelled by user\"\n",
    "\n",
    "# æµ‹è¯•å·¥å…·å®šä¹‰\n",
    "print(\"Tool created successfully!\")\n",
    "print(f\"Tool name: {send_email.name}\")\n",
    "print(f\"Tool description: {send_email.description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### åˆ›å»ºå¸¦æœ‰ Human-in-the-Loop çš„ Agent\n",
    "\n",
    "ç°åœ¨è®©æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªä½¿ç”¨æ­¤å·¥å…·çš„ Agentã€‚**åˆ‡è®°ï¼š** Interrupts å¿…é¡»é…åˆ Checkpointer ä½¿ç”¨ï¼Œå¦åˆ™æ— æ³•ä¿å­˜æš‚åœæ—¶çš„çŠ¶æ€ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# åˆ›å»º Checkpointer ç”¨äºæŒä¹…åŒ–\n",
    "checkpointer = MemorySaver()\n",
    "\n",
    "# åˆ›å»ºå¸¦æœ‰é‚®ä»¶å·¥å…·çš„ Agent\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[send_email],\n",
    "    system_prompt=\"You are a helpful email assistant. When asked to send emails, use the send_email tool.\",\n",
    "    checkpointer=checkpointer  # å¿…é¡»é¡¹ï¼šç”¨äº interrupts\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### è¿è¡Œç›´åˆ°ä¸­æ–­ (Running Until Interrupt)\n",
    "\n",
    "è®©æˆ‘ä»¬è¿è¡Œ Agentï¼Œçœ‹çœ‹å®ƒå¦‚ä½•æš‚åœä»¥ç­‰å¾…æ‰¹å‡†ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.messages import HumanMessage\n",
    "from langsmith import uuid7\n",
    "\n",
    "# ä¸ºæ­¤å¯¹è¯åˆ›å»ºå”¯ä¸€çº¿ç¨‹\n",
    "config = {\"configurable\": {\"thread_id\": uuid7()}}\n",
    "\n",
    "# è¿è¡Œ Agent\n",
    "result = agent.invoke(\n",
    "    {\n",
    "        \"messages\": [HumanMessage(content=\"Send an email to alice@example.com with subject 'Meeting Tomorrow' and body 'Let's meet at 3pm.'\")]\n",
    "    },\n",
    "    config=config\n",
    ")\n",
    "\n",
    "# æ£€æŸ¥æ˜¯å¦è§¦å‘äº† interrupt\n",
    "# åœ¨ LangGraph 1.0 ä¸­ï¼Œå¦‚æœå›  interrupt æš‚åœï¼Œç»“æœä¸­ä¼šåŒ…å« __interrupt__ é”®\n",
    "if \"__interrupt__\" in result:\n",
    "    print(\"Agent paused for approval (Agent å·²æš‚åœç­‰å¾…æ‰¹å‡†)\\n\")\n",
    "\n",
    "    # è·å– interrupt çš„è¯¦ç»†ä¿¡æ¯\n",
    "    interrupt_info = result[\"__interrupt__\"][0]\n",
    "\n",
    "    print(\"Interrupt details:\")\n",
    "    print(f\"  To: {interrupt_info.value['to']}\")\n",
    "    print(f\"  Subject: {interrupt_info.value['subject']}\")\n",
    "    print(f\"  Body: {interrupt_info.value['body']}\")\n",
    "    print(f\"  Message: {interrupt_info.value['message']}\")\n",
    "else:\n",
    "    print(\"Agent completed without interrupt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æ‰¹å‡†å¹¶æ¢å¤æ‰§è¡Œ (Resuming with Approval)\n",
    "\n",
    "ç°åœ¨è®©æˆ‘ä»¬æ‰¹å‡†è¿™å°é‚®ä»¶ï¼Œå¹¶è®© Agent ç»§ç»­è¿è¡Œã€‚\n",
    "æˆ‘ä»¬ä½¿ç”¨ `Command` å¯¹è±¡å¹¶ä¼ å…¥ `resume` å‚æ•°ã€‚è¿™ä¸ªå€¼ä¼šç›´æ¥æˆä¸º `interrupt()` å‡½æ•°åœ¨å·¥å…·å†…éƒ¨çš„è¿”å›å€¼ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.types import Command\n",
    "\n",
    "# æ¢å¤æ‰§è¡Œå¹¶ç»™äºˆæ‰¹å‡†\n",
    "# è¿™é‡Œçš„ {\"approved\": True} å°†ä¼šæ˜¯å·¥å…·ä¸­ approval å˜é‡çš„å€¼\n",
    "result = agent.invoke(\n",
    "    Command(resume={\"approved\": True}),\n",
    "    config=config\n",
    ")\n",
    "\n",
    "# æ‰“å°æœ€ç»ˆå“åº”\n",
    "print(\"Final response:\")\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ç»ƒä¹ ï¼šå°è¯•æ‹’ç»é‚®ä»¶\n",
    "\n",
    "å†æ¬¡è¿è¡Œä¸Šé¢çš„æ­¥éª¤ï¼Œä½†è¿™æ¬¡é€šè¿‡ä¼ å…¥ `{\"approved\": False}` æ¥æ‹’ç»é‚®ä»¶ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¸ºæ‹’ç»ç¤ºä¾‹åˆ›å»ºä¸€ä¸ªæ–°çº¿ç¨‹\n",
    "config_2 = {\"configurable\": {\"thread_id\": uuid7()}}\n",
    "\n",
    "# è¿è¡Œç›´åˆ°ä¸­æ–­\n",
    "result = agent.invoke(\n",
    "    {\n",
    "        \"messages\": [HumanMessage(content=\"Send an email to bob@example.com saying 'Hello!'\")]\n",
    "    },\n",
    "    config=config_2\n",
    ")\n",
    "\n",
    "# æ¢å¤å¹¶æ‹’ç»\n",
    "result = agent.invoke(\n",
    "    Command(resume={\"approved\": False}),  # æ‹’ç»é‚®ä»¶\n",
    "    config=config_2\n",
    ")\n",
    "\n",
    "print(\"Final response:\")\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç¬¬ 2 éƒ¨åˆ†: è¿›é˜¶æ¨¡å¼ - æ‰§è¡Œå‰å…ˆç¼–è¾‘ (Edit Before Execution)\n",
    "\n",
    "æœ‰æ—¶ä½ ä¸ä»…ä»…æƒ³æ‰¹å‡†æˆ–æ‹’ç»ï¼Œè¿˜æƒ³**ç¼–è¾‘**å·¥å…·è°ƒç”¨çš„å‚æ•°ã€‚è®©æˆ‘ä»¬å‡çº§æˆ‘ä»¬çš„å·¥å…·ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def send_email_v2(to: str, subject: str, body: str) -> str:\n",
    "    \"\"\"å‘é€é‚®ä»¶ç»™æ¥æ”¶è€…ã€‚\"\"\"\n",
    "    \n",
    "    # æš‚åœç­‰å¾…äººå·¥å®¡æŸ¥\n",
    "    response = interrupt({\n",
    "        \"action\": \"send_email\",\n",
    "        \"to\": to,\n",
    "        \"subject\": subject,\n",
    "        \"body\": body,\n",
    "        \"message\": \"Review this email. You can approve, reject, or edit it.\"\n",
    "    })\n",
    "    \n",
    "    # å¤„ç†ä¸åŒçš„å“åº”ç±»å‹\n",
    "    if response[\"type\"] == \"approve\":\n",
    "        return f\"Email sent to {to} with subject '{subject}'\"\n",
    "\n",
    "    elif response[\"type\"] == \"reject\":\n",
    "        return \"Email cancelled\"\n",
    "\n",
    "    elif response[\"type\"] == \"edit\":\n",
    "        # æ›´æ–°ä¸ºç¼–è¾‘åçš„å€¼\n",
    "        to = response.get(\"to\", to)\n",
    "        subject = response.get(\"subject\", subject)\n",
    "        body = response.get(\"body\", body)\n",
    "        return f\"\"\"Email sent with edits:\n",
    "                To: {to}\n",
    "                Subject: {subject}\n",
    "                Body: {body}\"\"\"\n",
    "    \n",
    "    return \"Unknown response\"\n",
    "\n",
    "# åˆ›å»ºä½¿ç”¨å¢å¼ºå·¥å…·çš„æ–° Agent\n",
    "agent_v2 = create_agent(\n",
    "    model=model,\n",
    "    tools=[send_email_v2],\n",
    "    system_prompt=\"You are a helpful email assistant.\",\n",
    "    checkpointer=MemorySaver()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¿è¡Œå¹¶ç¼–è¾‘é‚®ä»¶\n",
    "config_3 = {\"configurable\": {\"thread_id\": uuid7()}}\n",
    "\n",
    "# è¿è¡Œç›´åˆ°ä¸­æ–­\n",
    "result = agent_v2.invoke(\n",
    "    {\n",
    "        \"messages\": [HumanMessage(content=\"Send an email to team@example.com about the meeting\")]\n",
    "    },\n",
    "    config=config_3\n",
    ")\n",
    "\n",
    "print(\"Paused for review... (æš‚åœç­‰å¾…å®¡æŸ¥)\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç°åœ¨ï¼Œè®©æˆ‘ä»¬ä¿®æ”¹é‚®ä»¶ä¸»é¢˜ï¼Œå°†å…¶æ ‡è®°ä¸º URGENT (ç´§æ€¥) ä¼šè®®ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¢å¤å¹¶å¸¦å…¥ç¼–è¾‘åçš„å†…å®¹\n",
    "result = agent_v2.invoke(\n",
    "    Command(resume={\n",
    "        \"type\": \"edit\",\n",
    "        \"subject\": \"URGENT: Meeting Today at 2pm\",  # æˆ‘ä»¬ä¿®æ”¹äº†é‚®ä»¶ä¸»é¢˜\n",
    "        \"body\": \"This is the edited email body with more details.\"\n",
    "    }),\n",
    "    config=config_3\n",
    ")\n",
    "\n",
    "print(\"Final response:\")\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç¬¬ 3 éƒ¨åˆ†: ä¸­é—´ä»¶ (Middleware) ç®€ä»‹\n",
    "\n",
    "**Middleware (ä¸­é—´ä»¶)** æä¾›äº†å¯¹ Agent å¾ªç¯ (Loop) çš„ç»†ç²’åº¦æ§åˆ¶ã€‚å®ƒå¯ä»¥è®©ä½ ï¼š\n",
    "- åœ¨æ¨¡å‹è°ƒç”¨å‰åæ£€æŸ¥çŠ¶æ€\n",
    "- åŠ¨æ€ä¿®æ”¹æ¨¡å‹è¯·æ±‚\n",
    "- åœ¨æ‰§è¡Œçš„å…³é”®ç‚¹æ·»åŠ è‡ªå®šä¹‰é€»è¾‘\n",
    "\n",
    "### Agent å¾ªç¯ (The Agent Loop)\n",
    "\n",
    "```\n",
    "Input --> [before_model] --> [wrap_model_call] --> Model --> [after_model] --> Tools --> ...\n",
    "```\n",
    "\n",
    "Middleware ä¼šæŒ‚è½½åˆ°è¿™ä¸ªå¾ªç¯ä¸­ï¼š\n",
    "- **`before_model`** - åœ¨æ¨¡å‹æ‰§è¡Œå‰è¿è¡Œï¼Œå¯ä»¥æ›´æ–°çŠ¶æ€\n",
    "- **`wrap_model_call`** - åŒ…è£…æ¨¡å‹è°ƒç”¨ï¼Œæ§åˆ¶æ¨¡å‹ä½•æ—¶/å¦‚ä½•è¢«è°ƒç”¨ï¼ˆä¾‹å¦‚é‡è¯•ã€ç¼“å­˜ï¼‰\n",
    "- **`after_model`** - åœ¨æ¨¡å‹æ‰§è¡Œåï¼Œæ‰§è¡Œå·¥å…·å‰è¿è¡Œ\n",
    "\n",
    "### ä¸¤ç§ Hook é£æ ¼\n",
    "\n",
    "**Node-style hooks (èŠ‚ç‚¹å¼é’©å­)** æŒ‰é¡ºåºè¿è¡Œï¼š\n",
    "- `before_agent`, `before_model`, `after_model`, `after_agent`\n",
    "- é€‚åˆç”¨äºæ—¥å¿—è®°å½•ã€éªŒè¯ã€çŠ¶æ€æ›´æ–°\n",
    "\n",
    "**Wrap-style hooks (åŒ…è£…å¼é’©å­)** æ‹¦æˆªæ‰§è¡Œï¼š\n",
    "- `wrap_model_call`, `wrap_tool_call`\n",
    "- å®Œå…¨æ§åˆ¶å¤„ç†ç¨‹åºçš„è°ƒç”¨\n",
    "- é€‚åˆç”¨äºé‡è¯•é€»è¾‘ã€ç¼“å­˜ã€æ•°æ®è½¬æ¢"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ç¤ºä¾‹ 1: åŠ¨æ€ç³»ç»Ÿæç¤ºè¯ (Dynamic System Prompt)\n",
    "\n",
    "è®©æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªä¸­é—´ä»¶ï¼Œæ ¹æ®ç”¨æˆ·çš„è§’è‰²åŠ¨æ€æ›´æ”¹ç³»ç»Ÿæç¤ºè¯ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.middleware import dynamic_prompt, ModelRequest\n",
    "from typing import TypedDict\n",
    "\n",
    "# å®šä¹‰ä¸Šä¸‹æ–‡ Schema\n",
    "class Context(TypedDict):\n",
    "    user_role: str\n",
    "\n",
    "# ä½¿ç”¨è£…é¥°å™¨åˆ›å»ºä¸­é—´ä»¶\n",
    "@dynamic_prompt\n",
    "def dynamic_prompt_middleware(request: ModelRequest) -> str:\n",
    "    \"\"\"æ ¹æ®ç”¨æˆ·è§’è‰²è°ƒæ•´ç³»ç»Ÿæç¤ºè¯ã€‚\"\"\"\n",
    "    \n",
    "    # ä»è¿è¡Œæ—¶ä¸Šä¸‹æ–‡ä¸­è·å– user_role\n",
    "    user_role = request.runtime.context.get(\"user_role\", \"general\")\n",
    "    \n",
    "    if user_role == \"expert\":\n",
    "        return \"You are an AI assistant for experts. Provide detailed technical responses with code examples.\"\n",
    "    elif user_role == \"beginner\":\n",
    "        return \"You are an AI assistant for beginners. Explain concepts simply, avoid jargon.\"\n",
    "    else:\n",
    "        return \"You are a helpful AI assistant.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def explain_concept(concept: str) -> str:\n",
    "    \"\"\"Explain a programming concept.\"\"\"\n",
    "    explanations = {\n",
    "        \"async\": \"Asynchronous programming allows code to run without blocking.\",\n",
    "        \"recursion\": \"Recursion is when a function calls itself.\"\n",
    "    }\n",
    "    return explanations.get(concept.lower(), \"Concept not found.\")\n",
    "\n",
    "# åˆ›å»ºå¸¦æœ‰ä¸­é—´ä»¶çš„ Agent\n",
    "agent_with_middleware = create_agent(\n",
    "    model=model,\n",
    "    tools=[explain_concept],\n",
    "    middleware=[dynamic_prompt_middleware],\n",
    "    context_schema=Context\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æµ‹è¯•ä¸åŒçš„ç”¨æˆ·è§’è‰²\n",
    "\n",
    "è®©æˆ‘ä»¬çœ‹çœ‹ Agent å¦‚ä½•æ ¹æ®ç”¨æˆ·è§’è‰²åšå‡ºä¸åŒçš„ååº”ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¸“å®¶ç”¨æˆ·\n",
    "print(\"=\" * 50)\n",
    "print(\"EXPERT USER (ä¸“å®¶ç”¨æˆ·)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "result = agent_with_middleware.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"Explain async programming\")]},\n",
    "    context={\"user_role\": \"expert\"}\n",
    ")\n",
    "print(result[\"messages\"][-1].content)\n",
    "print()\n",
    "\n",
    "# åˆå­¦è€…\n",
    "print(\"=\" * 50)\n",
    "print(\"BEGINNER USER (åˆå­¦è€…)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "result = agent_with_middleware.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"Explain async programming\")]},\n",
    "    context={\"user_role\": \"beginner\"}\n",
    ")\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ç¤ºä¾‹ 2: è‡ªå®šä¹‰ä¸­é—´ä»¶ - è¯·æ±‚æ—¥å¿—è®°å½•å™¨ (Request Logger)\n",
    "\n",
    "ä¸­é—´ä»¶å…è®¸ä½  hook è¿› Agent å¾ªç¯ï¼ŒæŸ¥çœ‹æ¯ä¸€æ­¥å‘ç”Ÿäº†ä»€ä¹ˆã€‚è¿™å¯¹äºè°ƒè¯•å’Œç†è§£ Agent çš„å·¥ä½œåŸç†éå¸¸æœ‰ç”¨ã€‚\n",
    "\n",
    "**Agent å¾ªç¯ï¼š**\n",
    "User Input --> [before_model] --> [wrap_model_call] --> Model --> [after_model] --> Tools --> ...\n",
    "\n",
    "**æˆ‘ä»¬å°†æ„å»ºä¸€ä¸ªæ—¥å¿—è®°å½•å™¨ï¼Œåœ¨ä»¥ä¸‹æ­¥éª¤æ‰“å°ä¿¡æ¯ï¼š**\n",
    "- **Before model** - å½“å‰å¯¹è¯ä¸­æœ‰å¤šå°‘æ¡æ¶ˆæ¯ï¼Ÿ\n",
    "- **Wrap model call** - æ­£åœ¨ä½¿ç”¨å“ªä¸ªæ¨¡å‹å’Œå·¥å…·ï¼Ÿ\n",
    "- **After model** - æ¨¡å‹æ˜¯è°ƒç”¨äº†å·¥å…·è¿˜æ˜¯ç»™å‡ºäº†æœ€ç»ˆç­”æ¡ˆï¼Ÿ\n",
    "\n",
    "è¿™å°±åƒæ˜¯æ·»åŠ äº†è°ƒè¯•ç”¨çš„ `print()` è¯­å¥ï¼Œä½†ä»¥ä¸€ç§å¹²å‡€ã€å¯é‡ç”¨çš„æ–¹å¼ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.middleware import AgentMiddleware, AgentState, ModelRequest, ModelResponse\n",
    "from typing import Any, Callable\n",
    "\n",
    "class RequestLoggerMiddleware(AgentMiddleware):\n",
    "    \"\"\"ç”¨äºè°ƒè¯•çš„æ¨¡å‹è¯·æ±‚æ—¥å¿—è®°å½•ä¸­é—´ä»¶ã€‚\"\"\"\n",
    "    \n",
    "    def before_model(self, state: AgentState, runtime) -> dict[str, Any] | None:\n",
    "        \"\"\"åœ¨æ¨¡å‹æ‰§è¡Œå‰è®°å½•æ—¥å¿—ã€‚\n",
    "        \n",
    "        Args:\n",
    "            state: å½“å‰ Agent çš„çŠ¶æ€ (åŒ…å«æ¶ˆæ¯å†å²ç­‰)\n",
    "            runtime: è¿è¡Œæ—¶ä¸Šä¸‹æ–‡\n",
    "        \"\"\"\n",
    "        message_count = len(state.get(\"messages\", []))\n",
    "        print(f\"[BEFORE MODEL] Processing {message_count} messages\")\n",
    "        return None  # ä¸ä¿®æ”¹çŠ¶æ€\n",
    "    \n",
    "    def wrap_model_call(\n",
    "        self, \n",
    "        request: ModelRequest,\n",
    "        handler: Callable[[ModelRequest], ModelResponse]\n",
    "    ) -> ModelResponse:\n",
    "        \"\"\"åŒ…è£…æ¨¡å‹è°ƒç”¨ï¼Œè®°å½•è¯·æ±‚è¯¦æƒ…ã€‚\n",
    "        \n",
    "        Args:\n",
    "           request: å³å°†å‘é€ç»™æ¨¡å‹çš„è¯·æ±‚å¯¹è±¡\n",
    "           handler: æ‰§è¡Œå®é™…æ¨¡å‹è°ƒç”¨çš„å‡½æ•°\n",
    "        \"\"\"\n",
    "        print(f\"  [MODEL REQUEST]\")\n",
    "        print(f\"   Model: {request.model if hasattr(request, 'model') else 'default'}\")\n",
    "        print(f\"   Tools available: {len(request.tools) if request.tools else 0}\")\n",
    "        \n",
    "        # è°ƒç”¨å®é™…çš„æ¨¡å‹å¤„ç†ç¨‹åº\n",
    "        return handler(request)\n",
    "    \n",
    "    def after_model(self, state: AgentState, runtime) -> dict[str, Any] | None:\n",
    "        \"\"\"åœ¨æ¨¡å‹æ‰§è¡Œåè®°å½•æ—¥å¿—ã€‚\"\"\"\n",
    "        last_message = state[\"messages\"][-1]\n",
    "        if hasattr(last_message, 'tool_calls') and last_message.tool_calls:\n",
    "            print(f\" [AFTER MODEL] Model requested {len(last_message.tool_calls)} tool call(s)\")\n",
    "        else:\n",
    "            print(f\" [AFTER MODEL] Model provided final response\")\n",
    "        return None  # ä¸ä¿®æ”¹çŠ¶æ€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ›å»ºå¸¦æœ‰æ—¥å¿—ä¸­é—´ä»¶çš„ Agent\n",
    "agent_with_logger = create_agent(\n",
    "    model=model,\n",
    "    tools=[explain_concept],\n",
    "    middleware=[RequestLoggerMiddleware()],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### é¢„æœŸç»“æœ\n",
    "\n",
    "å½“æˆ‘ä»¬è¿è¡Œå¸¦æ—¥å¿—è®°å½•å™¨çš„ Agent æ—¶ï¼Œä½ ä¼šå®æ—¶çœ‹åˆ°æ‰§è¡Œæµç¨‹ï¼š\n",
    "\n",
    "**ç¬¬ä¸€æ¬¡è¿­ä»£:**\n",
    "1. `[BEFORE MODEL]` - æ˜¾ç¤ºæˆ‘ä»¬å¼€å§‹æ—¶çš„æ¶ˆæ¯æ•°é‡\n",
    "2. `[MODEL REQUEST]` - æ˜¾ç¤ºå¯ç”¨æ¨¡å‹å’Œå·¥å…·\n",
    "3. `[AFTER MODEL]` - æ¨¡å‹å†³å®šè°ƒç”¨ `explain_concept` å·¥å…·\n",
    "\n",
    "**ç¬¬äºŒæ¬¡è¿­ä»£ (å·¥å…·æ‰§è¡Œå):**\n",
    "1. `[BEFORE MODEL]` - ç°åœ¨æ¶ˆæ¯æ›´å¤šäº†ï¼ˆåŒ…å«å·¥å…·ç»“æœï¼‰\n",
    "2. `[MODEL REQUEST]` -å†æ¬¡æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯\n",
    "3. `[AFTER MODEL]` - æ¨¡å‹ç»™å‡ºæœ€ç»ˆç­”æ¡ˆï¼ˆä¸å†éœ€è¦å·¥å…·ï¼‰\n",
    "\n",
    "è¿™è®©ä½ èƒ½å¤Ÿæ·±å…¥äº†è§£ Agent çš„å†³ç­–è¿‡ç¨‹ã€‚\n",
    "\n",
    "è®©æˆ‘ä»¬è¿è¡Œå®ƒï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¿è¡Œå¹¶è§‚å¯Ÿæ—¥å¿—\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"RUNNING AGENT WITH LOGGER\")\n",
    "print(\"=\" * 50 + \"\\n\")\n",
    "\n",
    "result = agent_with_logger.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Explain recursion\"}]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"FINAL RESPONSE\")\n",
    "print(\"=\" * 50)\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç¬¬ 4 éƒ¨åˆ†: ç»“åˆ Middleware å’Œ Human-in-the-loop\n",
    "\n",
    "è®©æˆ‘ä»¬ç»“åˆ Human-in-the-Loop å’Œ Middlewareï¼Œæ„å»ºä¸€ä¸ªç”Ÿäº§å°±ç»ªçš„ Agentï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# éœ€è¦æ‰¹å‡†çš„æ•æ„Ÿå·¥å…·\n",
    "@tool\n",
    "def delete_database(database_name: str) -> str:\n",
    "    \"\"\"Delete a database. THIS IS DANGEROUS!\"\"\"\n",
    "    \n",
    "    response = interrupt({\n",
    "        \"action\": \"delete_database\",\n",
    "        \"database_name\": database_name,\n",
    "        \"warning\": \"This will permanently delete the database!\",\n",
    "        \"message\": \"Are you absolutely sure?\"\n",
    "    })\n",
    "    \n",
    "    if response.get(\"confirmed\"):\n",
    "        return f\"Database '{database_name}' has been deleted (simulation)\"\n",
    "    else:\n",
    "        return \"Database deletion cancelled\"\n",
    "\n",
    "# ç”¨äºè·Ÿè¸ªå±é™©æ“ä½œçš„ä¸­é—´ä»¶\n",
    "class SafetyMiddleware(AgentMiddleware):\n",
    "    \"\"\"æ·»åŠ å®‰å…¨æ£€æŸ¥å’Œæ—¥å¿—è®°å½•çš„ä¸­é—´ä»¶ã€‚\"\"\"\n",
    "    \n",
    "    name = \"safety_checker\"\n",
    "    \n",
    "    def after_model(self, state: AgentState) -> dict[str, Any] | None:\n",
    "        \"\"\"æ£€æŸ¥å±é™©çš„å·¥å…·è°ƒç”¨ã€‚\"\"\"\n",
    "        last_message = state[\"messages\"][-1]\n",
    "        \n",
    "        if hasattr(last_message, 'tool_calls') and last_message.tool_calls:\n",
    "            for tool_call in last_message.tool_calls:\n",
    "                if \"delete\" in tool_call[\"name\"].lower():\n",
    "                    print(\"   [SAFETY] Dangerous operation detected!\")\n",
    "                    print(f\"   Tool: {tool_call['name']}\")\n",
    "                    print(f\"   Args: {tool_call['args']}\")\n",
    "        \n",
    "        return None\n",
    "\n",
    "# åˆ›å»ºç”Ÿäº§çº§ Agent\n",
    "production_agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[delete_database],\n",
    "    middleware=[SafetyMiddleware()],\n",
    "    checkpointer=MemorySaver()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### é¢„æœŸç»“æœï¼šå¤šå±‚å®‰å…¨æœºåˆ¶å®æˆ˜\n",
    "\n",
    "  å½“æˆ‘ä»¬å°è¯•ä¸€ä¸ªå±é™©æ“ä½œæ—¶ï¼Œä½ ä¼šçœ‹åˆ° **ä¸¤ç§** å®‰å…¨æœºåˆ¶è¢«æ¿€æ´»ï¼š\n",
    "\n",
    "  **ç¬¬ 1 å±‚ - Middleware æ£€æµ‹:**\n",
    "  - `[SAFETY] Dangerous operation detected!` - ä¸­é—´ä»¶å‘ç° delete æ“ä½œ\n",
    "  - è®°å½•å·¥å…·åç§°å’Œå‚æ•°ä»¥ç”¨äºå®¡è®¡è¿½è¸ª\n",
    "\n",
    "  **ç¬¬ 2 å±‚ - äººå·¥æ‰¹å‡† (Interrupt):**\n",
    "  - Agent æ‰§è¡Œåœ¨ `interrupt()` å¤„æš‚åœ\n",
    "  - å‘å®¡æ ¸äººå‘˜å±•ç¤ºè­¦å‘Šä¿¡æ¯\n",
    "  - é™¤éè·å¾—æ˜ç¡®æ‰¹å‡†ï¼Œå¦åˆ™æ‰§è¡Œä¸ä¼šç»§ç»­\n",
    "\n",
    "  **è¿™å°±æ˜¯çºµæ·±é˜²å¾¡ï¼š** Middleware ç›‘æ§æ‰€æœ‰æ“ä½œï¼Œè€Œ Interrupts å¼ºåˆ¶å¯¹å…³é”®è¡ŒåŠ¨è¿›è¡Œäººå·¥æ‰¹å‡†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æµ‹è¯•ç»„åˆæ¨¡å¼\n",
    "config_4 = {\"configurable\": {\"thread_id\": uuid7()}}\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"DANGEROUS OPERATION ATTEMPT (å±é™©æ“ä½œå°è¯•)\")\n",
    "print(\"=\" * 50 + \"\\n\")\n",
    "\n",
    "# è¿è¡Œç›´åˆ° interrupt\n",
    "result = production_agent.invoke(\n",
    "    {\n",
    "        \"messages\": [HumanMessage(content=\"Delete the production_db database\")]\n",
    "    },\n",
    "    config=config_4\n",
    ")\n",
    "\n",
    "if \"__interrupt__\" in result:\n",
    "    interrupt_info = result[\"__interrupt__\"][0]\n",
    "    print(\"\\n  Human approval required (éœ€è¦äººå·¥æ‰¹å‡†):\")\n",
    "    print(f\"   {interrupt_info.value['warning']}\")\n",
    "    print(f\"   Database: {interrupt_info.value['database_name']}\")\n",
    "\n",
    "print(\"\\n(In a real app, a human would review this before proceeding)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ ¸å¿ƒè¦ç‚¹\n",
    "\n",
    "### Human-in-the-Loop (Interrupts)\n",
    "- ä½¿ç”¨ `interrupt()` æš‚åœæ‰§è¡Œ\n",
    "- å¿…é¡»é…åˆ `checkpointer` å®ç°æŒä¹…åŒ–\n",
    "- ä½¿ç”¨ `Command(resume=value)` æ¢å¤æ‰§è¡Œ\n",
    "- éå¸¸é€‚åˆå®¡æ‰¹å·¥ä½œæµå’Œæ•æ„Ÿæ“ä½œ\n",
    "\n",
    "### Middleware\n",
    "- **Node-style hooks**: `before_model`, `after_model` - é¡ºåºé€»è¾‘ã€éªŒè¯ã€æ—¥å¿—\n",
    "- **Wrap-style hooks**: `wrap_model_call`, `wrap_tool_call` - å®Œå…¨æ§åˆ¶ã€é‡è¯•ã€è½¬æ¢\n",
    "- **Decorators**: `@dynamic_prompt`, `@before_model`, `@wrap_model_call` ç”¨äºå¿«é€Ÿå®šä¹‰ä¸­é—´ä»¶\n",
    "- **Classes**: ç»§æ‰¿ `AgentMiddleware` ä»¥æ„å»ºå¤æ‚ã€å¯é‡ç”¨çš„ç»„ä»¶\n",
    "\n",
    "### ä½•æ—¶ä½¿ç”¨ä»€ä¹ˆï¼Ÿ\n",
    "\n",
    "**ä½¿ç”¨ Interrupts å½“ï¼š**\n",
    "- åŠ¨ä½œéœ€è¦äººå·¥æ‰¹å‡†\n",
    "- ä½ æƒ³å®¡æŸ¥/ç¼–è¾‘å·¥å…·è°ƒç”¨\n",
    "- éœ€è¦éªŒè¯ç”¨æˆ·è¾“å…¥\n",
    "\n",
    "**ä½¿ç”¨ Middleware å½“ï¼š**\n",
    "- éœ€è¦åŠ¨æ€ä¿®æ”¹ Agent è¡Œä¸º\n",
    "- æƒ³è¦æ·»åŠ æ—¥å¿—/ç›‘æ§\n",
    "- éœ€è¦æ‰§è¡Œç­–ç•¥ï¼ˆToken é™åˆ¶ã€å®‰å…¨æ£€æŸ¥ï¼‰\n",
    "- æƒ³è¦æ ¹æ®ä¸Šä¸‹æ–‡ä¸ªæ€§åŒ–å“åº”\n",
    "\n",
    "**Node-style vs Wrap-style:**\n",
    "- Node-style ç”¨äºé¡ºåºæ“ä½œï¼ˆæ—¥å¿—ã€éªŒè¯ï¼‰\n",
    "- Wrap-style ç”¨äºæ§åˆ¶æµï¼ˆé‡è¯•ã€å›é€€ã€ç¼“å­˜ï¼‰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç»ƒä¹  (å¯é€‰)\n",
    "\n",
    "å°è¯•æ„å»ºä¸€ä¸ª Agentï¼š\n",
    "1. æ‹¥æœ‰ä¸€ä¸ªè¿›è¡Œè´­ä¹°æ“ä½œçš„å·¥å…·\n",
    "2. ä½¿ç”¨ä¸­é—´ä»¶æ£€æŸ¥è´­ä¹°é‡‘é¢æ˜¯å¦è¶…è¿‡ $1000\n",
    "3. å¦‚æœè¶…è¿‡ $1000ï¼Œä½¿ç”¨ interrupt è¦æ±‚æ‰¹å‡†\n",
    "4. å¦‚æœä½äº $1000ï¼Œè‡ªåŠ¨å¤„ç†\n",
    "\n",
    "æç¤ºï¼šç»“åˆ `before_model` ä¸­é—´ä»¶å’Œæ¡ä»¶æ€§çš„ `interrupt()` é€»è¾‘ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä½ çš„ä»£ç ï¼\n",
    "# æŒ‘æˆ˜ï¼šæ„å»ºè´­ä¹°å®¡æ‰¹ Agent\n",
    "\n",
    "# @tool\n",
    "# def make_purchase(item: str, amount: float) -> str:\n",
    "#     ...\n",
    "#\n",
    "# class PurchaseLimitMiddleware(AgentMiddleware):\n",
    "#     ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ä¸‹ä¸€æ­¥\n",
    "\n",
    "ä½ ç°åœ¨å·²ç»æ‹¥æœ‰äº†æ„å»ºç”Ÿäº§çº§ Agent çš„å¼ºå¤§å·¥å…·ï¼\n",
    "\n",
    "**ç»§ç»­ä½ çš„æ—…ç¨‹ï¼š**\n",
    "1.  æŸ¥çœ‹ `multi_agent.ipynb` äº†è§£å¤š Agent ç³»ç»Ÿ\n",
    "2.  æ¢ç´¢å†…ç½®ä¸­é—´ä»¶ï¼ˆæ‘˜è¦ Summarizationã€Anthropic Prompt Cachingï¼‰\n",
    "3.  ä¸ºä½ è‡ªå·±çš„ç”¨ä¾‹æ„å»ºè‡ªå®šä¹‰ä¸­é—´ä»¶\n",
    "4.  æ·»åŠ  LangSmith è¿›è¡Œè°ƒè¯•å’Œç›‘æ§\n",
    "\n",
    "**èµ„æºï¼š**\n",
    "- [Middleware æ–‡æ¡£](https://docs.langchain.com/oss/python/langchain/middleware)\n",
    "- [Human-in-the-Loop äº¤äº’æŒ‡å—](https://docs.langchain.com/oss/python/langchain/human-in-the-loop)\n",
    "- [LangGraph æ–‡æ¡£](https://langchain-ai.github.io/langgraph/)\n",
    "\n",
    "</br>\n",
    "</br>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}