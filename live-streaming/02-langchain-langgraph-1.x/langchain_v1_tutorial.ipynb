{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain 1.0 & LangGraph 1.0 å‡çº§æ•™ç¨‹\n",
    "\n",
    "**é¢å‘äººç¾¤**ï¼šå¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸­é«˜çº§å¼€å‘è€…  \n",
    "**å‡çº§è·¯å¾„**ï¼šLangChain 0.3.x â†’ 1.0 / LangGraph 0.6.x â†’ 1.0  \n",
    "**å‚è€ƒæ–‡æ¡£**ï¼š[LangChain å®˜æ–¹æ–‡æ¡£](https://docs.langchain.com)\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“‹ æ•™ç¨‹ç»“æ„\n",
    "\n",
    "1. **ç¯å¢ƒå‡†å¤‡** - å®‰è£…ä¸é…ç½®\n",
    "2. **æ ¸å¿ƒæ¦‚å¿µ** - æ¶æ„å¯¹æ¯”ä¸å˜æ›´\n",
    "3. **LangChain 1.0** - create_agentã€Middlewareã€Content Blocks\n",
    "4. **LangGraph 1.0** - StateGraphã€Checkpointer æŒä¹…åŒ–\n",
    "5. **å®Œæ•´æ¡ˆä¾‹** - ç«¯åˆ°ç«¯è¿ç§»ç¤ºä¾‹\n",
    "6. **æœ€ä½³å®è·µ** - è°ƒè¯•æŠ€å·§ä¸æ€§èƒ½ä¼˜åŒ–"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ç¬¬ 1 éƒ¨åˆ†ï¼šç¯å¢ƒå‡†å¤‡\n",
    "\n",
    "### 1.1 æ£€æŸ¥ Python ç‰ˆæœ¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "print(f\"Python ç‰ˆæœ¬: {sys.version}\")\n",
    "\n",
    "if sys.version_info < (3, 10):\n",
    "    print(\"âš ï¸ è­¦å‘Š: LangChain 1.0 éœ€è¦ Python 3.10+\")\n",
    "else:\n",
    "    print(\"âœ… Python ç‰ˆæœ¬ç¬¦åˆè¦æ±‚\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 å®‰è£…ä¾èµ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU langchain langgraph langchain-core langchain-openai langchain-anthropic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 éªŒè¯å®‰è£…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "import langgraph\n",
    "\n",
    "print(f\"LangChain: {langchain.__version__}\")\n",
    "print(f\"LangGraph: {langgraph.__version__}\")\n",
    "\n",
    "from langchain.agents import create_agent\n",
    "print(\"âœ… æ ¸å¿ƒæ¨¡å—å¯¼å…¥æˆåŠŸ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 é…ç½® API Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "# æ ¹æ®ä½¿ç”¨çš„æ¨¡å‹é…ç½® API Key\n",
    "# os.environ[\"OPENAI_API_KEY\"] = getpass(\"OpenAI API Key: \")\n",
    "# os.environ[\"ANTHROPIC_API_KEY\"] = getpass(\"Anthropic API Key: \")\n",
    "\n",
    "print(\"âœ… é…ç½®å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ç¬¬ 2 éƒ¨åˆ†ï¼šæ ¸å¿ƒæ¦‚å¿µå¯¹æ¯”\n",
    "\n",
    "### 2.1 æ¶æ„å…³ç³»\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  LangChain 1.0 (é«˜å±‚æ¡†æ¶)   â”‚\n",
    "â”‚  â€¢ create_agent            â”‚\n",
    "â”‚  â€¢ Middleware              â”‚\n",
    "â”‚  â€¢ Content Blocks          â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "           â”‚ è¿è¡Œåœ¨\n",
    "           â†“\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  LangGraph 1.0 (è¿è¡Œæ—¶)     â”‚\n",
    "â”‚  â€¢ StateGraph              â”‚\n",
    "â”‚  â€¢ Checkpointer            â”‚\n",
    "â”‚  â€¢ HITL & Streaming        â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 å…³é”®å˜æ›´é€ŸæŸ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "changes = pd.DataFrame({\n",
    "    \"åŠŸèƒ½\": [\n",
    "        \"æ™ºèƒ½ä½“åˆ›å»º\",\n",
    "        \"Prompt\",\n",
    "        \"Hooks\",\n",
    "        \"çŠ¶æ€ç±»å‹\",\n",
    "        \"Context\"\n",
    "    ],\n",
    "    \"v0.x\": [\n",
    "        \"create_react_agent\",\n",
    "        \"prompt=SystemMessage\",\n",
    "        \"state_modifier\",\n",
    "        \"TypedDict/Pydantic\",\n",
    "        \"config['configurable']\"\n",
    "    ],\n",
    "    \"v1.0\": [\n",
    "        \"create_agent\",\n",
    "        \"system_prompt=str\",\n",
    "        \"Middleware\",\n",
    "        \"ä»… TypedDict\",\n",
    "        \"context å‚æ•°\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "display(changes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ç¬¬ 3 éƒ¨åˆ†ï¼šLangChain 1.0 å®æˆ˜\n",
    "\n",
    "### 3.1 åˆ›å»ºåŸºç¡€æ™ºèƒ½ä½“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"è·å–åŸå¸‚å¤©æ°”\"\"\"\n",
    "    return f\"{city}: æ™´å¤© 20Â°C\"\n",
    "\n",
    "@tool\n",
    "def calculate(expr: str) -> str:\n",
    "    \"\"\"è®¡ç®—æ•°å­¦è¡¨è¾¾å¼\"\"\"\n",
    "    try:\n",
    "        return f\"ç»“æœ: {eval(expr)}\"\n",
    "    except:\n",
    "        return \"è®¡ç®—é”™è¯¯\"\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    tools=[get_weather, calculate],\n",
    "    system_prompt=\"ä½ æ˜¯ä¸€ä¸ªåŠ©æ‰‹\"\n",
    ")\n",
    "\n",
    "print(\"âœ… æ™ºèƒ½ä½“åˆ›å»ºæˆåŠŸ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è°ƒç”¨æ™ºèƒ½ä½“\n",
    "result = agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"åŒ—äº¬å¤©æ°”?\"}]\n",
    "})\n",
    "\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Middleware ç¤ºä¾‹\n",
    "\n",
    "#### å†…ç½® PII è„±æ•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.middleware import PIIMiddleware\n",
    "\n",
    "pii_agent = create_agent(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    tools=[get_weather],\n",
    "    middleware=[\n",
    "        PIIMiddleware(\"email\", strategy=\"redact\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "result = pii_agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"user@example.com\"}]\n",
    "})\n",
    "\n",
    "print(\"PII è„±æ•:\", result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### è‡ªå®šä¹‰ Middleware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.middleware import AgentMiddleware\n",
    "\n",
    "class LogMiddleware(AgentMiddleware):\n",
    "    def before_model(self, request):\n",
    "        print(f\"ğŸ“ è°ƒç”¨ LLM: {len(request.state['messages'])} æ¡æ¶ˆæ¯\")\n",
    "        return None\n",
    "    \n",
    "    def after_model(self, state, runtime):\n",
    "        print(f\"âœ… LLM å“åº”å®Œæˆ\")\n",
    "        return None\n",
    "\n",
    "log_agent = create_agent(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    tools=[get_weather],\n",
    "    middleware=[LogMiddleware()]\n",
    ")\n",
    "\n",
    "result = log_agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"å¤©æ°”?\"}]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Content Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"gpt-4o-mini\")\n",
    "response = model.invoke(\"ä»€ä¹ˆæ˜¯ AI?\")\n",
    "\n",
    "print(f\"Blocks æ•°é‡: {len(response.content_blocks)}\")\n",
    "for block in response.content_blocks:\n",
    "    if block[\"type\"] == \"text\":\n",
    "        print(f\"æ–‡æœ¬: {block['text'][:50]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 ç»“æ„åŒ–è¾“å‡º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.structured_output import ToolStrategy\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Weather(BaseModel):\n",
    "    city: str\n",
    "    temp: float\n",
    "    condition: str\n",
    "\n",
    "struct_agent = create_agent(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    tools=[get_weather],\n",
    "    response_format=ToolStrategy(Weather)\n",
    ")\n",
    "\n",
    "result = struct_agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"åŒ—äº¬å¤©æ°”\"}]\n",
    "})\n",
    "\n",
    "weather = result[\"structured_response\"]\n",
    "print(f\"åŸå¸‚: {weather.city}\")\n",
    "print(f\"æ¸©åº¦: {weather.temp}Â°C\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ç¬¬ 4 éƒ¨åˆ†ï¼šLangGraph 1.0 å®æˆ˜\n",
    "\n",
    "### 4.1 StateGraph åŸºç¡€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict\n",
    "\n",
    "class State(TypedDict):\n",
    "    count: int\n",
    "    messages: list\n",
    "\n",
    "def increment(state: State) -> State:\n",
    "    print(f\"ğŸ”µ Count: {state['count']}\")\n",
    "    return {\"count\": state[\"count\"] + 1}\n",
    "\n",
    "def router(state: State) -> str:\n",
    "    return \"end\" if state[\"count\"] >= 3 else \"continue\"\n",
    "\n",
    "graph = StateGraph(State)\n",
    "graph.add_node(\"inc\", increment)\n",
    "graph.add_conditional_edges(\"inc\", router, {\n",
    "    \"continue\": \"inc\",\n",
    "    \"end\": END\n",
    "})\n",
    "graph.set_entry_point(\"inc\")\n",
    "\n",
    "app = graph.compile()\n",
    "print(\"âœ… Graph æ„å»ºå®Œæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = app.invoke({\"count\": 0, \"messages\": []})\n",
    "print(f\"\\næœ€ç»ˆ count: {result['count']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Checkpointer æŒä¹…åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# ä½¿ç”¨å†…å­˜ Checkpointer\n",
    "memory = MemorySaver()\n",
    "app_with_memory = graph.compile(checkpointer=memory)\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"thread-1\"}}\n",
    "\n",
    "# ç¬¬ä¸€æ¬¡è°ƒç”¨\n",
    "r1 = app_with_memory.invoke(\n",
    "    {\"count\": 0, \"messages\": []}, \n",
    "    config\n",
    ")\n",
    "print(f\"ç¬¬ 1 æ¬¡: count = {r1['count']}\")\n",
    "\n",
    "# ç¬¬äºŒæ¬¡è°ƒç”¨ï¼ˆä»æ£€æŸ¥ç‚¹æ¢å¤ï¼‰\n",
    "r2 = app_with_memory.invoke(\n",
    "    {\"count\": 0, \"messages\": []},  # count ä»æ£€æŸ¥ç‚¹æ¢å¤\n",
    "    config\n",
    ")\n",
    "print(f\"ç¬¬ 2 æ¬¡: count = {r2['count']} (ä»æ£€æŸ¥ç‚¹ç»§ç»­)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 SQLite æŒä¹…åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n",
    "# SQLite æŒä¹…åŒ–\n",
    "sqlite = SqliteSaver.from_conn_string(\":memory:\")\n",
    "app_sqlite = graph.compile(checkpointer=sqlite)\n",
    "\n",
    "result = app_sqlite.invoke(\n",
    "    {\"count\": 0, \"messages\": []},\n",
    "    {\"configurable\": {\"thread_id\": \"sql-thread\"}}\n",
    ")\n",
    "\n",
    "print(f\"âœ… SQLite æŒä¹…åŒ–: count = {result['count']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ç¬¬ 5 éƒ¨åˆ†ï¼šå®Œæ•´è¿ç§»æ¡ˆä¾‹\n",
    "\n",
    "### 5.1 v0.x æ—§ä»£ç "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ—§ç‰ˆä»£ç ç¤ºä¾‹ï¼ˆå·²å¼ƒç”¨ï¼Œä»…ä½œæ¼”ç¤ºï¼‰\n",
    "OLD_CODE = \"\"\"\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain.messages import SystemMessage\n",
    "\n",
    "agent = create_react_agent(\n",
    "    model,\n",
    "    tools,\n",
    "    prompt=SystemMessage(content=\"You are helpful\"),\n",
    "    state_modifier=custom_modifier\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "print(\"âŒ æ—§ç‰ˆä»£ç  (v0.x):\")\n",
    "print(OLD_CODE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 v1.0 æ–°ä»£ç "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import AgentMiddleware\n",
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def search(query: str) -> str:\n",
    "    \"\"\"æœç´¢å·¥å…·\"\"\"\n",
    "    return f\"æœç´¢ç»“æœ: {query}\"\n",
    "\n",
    "class CustomModifier(AgentMiddleware):\n",
    "    def before_model(self, request):\n",
    "        # è‡ªå®šä¹‰é€»è¾‘\n",
    "        return None\n",
    "\n",
    "# âœ… æ–°ç‰ˆä»£ç  (v1.0)\n",
    "new_agent = create_agent(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    tools=[search],\n",
    "    system_prompt=\"You are helpful\",\n",
    "    middleware=[CustomModifier()]\n",
    ")\n",
    "\n",
    "print(\"âœ… æ–°ç‰ˆä»£ç å·²åˆ›å»º\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æµ‹è¯•æ–°ç‰ˆæ™ºèƒ½ä½“\n",
    "result = new_agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"æœç´¢ AI\"}]\n",
    "})\n",
    "\n",
    "print(\"ğŸ¤– å“åº”:\", result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ç¬¬ 6 éƒ¨åˆ†ï¼šæœ€ä½³å®è·µ\n",
    "\n",
    "### 6.1 è°ƒè¯•æŠ€å·§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯ç”¨è¯¦ç»†æ—¥å¿—\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# æµå¼è°ƒè¯•\n",
    "for event in agent.stream({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"æµ‹è¯•\"}]\n",
    "}):\n",
    "    node = list(event.keys())[0]\n",
    "    print(f\"[{node}] æ‰§è¡Œå®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 æ€§èƒ½ä¼˜åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.middleware import SummarizationMiddleware\n",
    "\n",
    "# å¯¹è¯å†å²è‡ªåŠ¨æ‘˜è¦\n",
    "optimized_agent = create_agent(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    tools=[search],\n",
    "    middleware=[\n",
    "        SummarizationMiddleware(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            trigger={\"tokens\": 1000}\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"âœ… ä¼˜åŒ–é…ç½®å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 è¿ç§»æ£€æŸ¥æ¸…å•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checklist = pd.DataFrame({\n",
    "    \"æ­¥éª¤\": [\n",
    "        \"1. Python >= 3.10\",\n",
    "        \"2. å‡çº§ä¾èµ–åŒ…\",\n",
    "        \"3. æ›´æ–°å¯¼å…¥è·¯å¾„\",\n",
    "        \"4. create_agent\",\n",
    "        \"5. è¿ç§» Middleware\",\n",
    "        \"6. TypedDict State\",\n",
    "        \"7. æµ‹è¯•éªŒè¯\"\n",
    "    ],\n",
    "    \"çŠ¶æ€\": [\"â˜\"] * 7\n",
    "})\n",
    "\n",
    "display(checklist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ“š å‚è€ƒèµ„æº\n",
    "\n",
    "### å®˜æ–¹æ–‡æ¡£\n",
    "\n",
    "- [LangChain 1.0 Release](https://docs.langchain.com/oss/python/releases/langchain-v1)\n",
    "- [LangGraph 1.0 Release](https://docs.langchain.com/oss/python/releases/langgraph-v1)\n",
    "- [Migration Guide](https://docs.langchain.com/oss/python/migrate/langchain-v1)\n",
    "- [API Reference](https://reference.langchain.com/python/)\n",
    "\n",
    "### ç¤¾åŒº\n",
    "\n",
    "- [GitHub Issues](https://github.com/langchain-ai/langchain/issues?q=label%3Av1)\n",
    "- [Discord](https://discord.gg/langchain)\n",
    "- [Forum](https://forum.langchain.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ¯ æ€»ç»“\n",
    "\n",
    "### æ ¸å¿ƒè¦ç‚¹\n",
    "\n",
    "1. **LangChain 1.0**ï¼šä»å·¥å…·åŒ…åˆ°ç”Ÿäº§çº§æ¡†æ¶\n",
    "   - âœ… ç»Ÿä¸€ `create_agent` æ¥å£\n",
    "   - âœ… å¯ç»„åˆ Middleware ç³»ç»Ÿ\n",
    "   - âœ… è·¨ä¾›åº”å•† Content Blocks\n",
    "\n",
    "2. **LangGraph 1.0**ï¼šç¨³å®šçš„è¿è¡Œæ—¶\n",
    "   - âœ… StateGraph API ä¸å˜\n",
    "   - âœ… ç”Ÿäº§çº§æŒä¹…åŒ–\n",
    "   - âœ… æ·±åº¦é›†æˆ LangChain\n",
    "\n",
    "3. **å‡çº§ç­–ç•¥**\n",
    "   - âœ… æ–°é¡¹ç›®ç›´æ¥ç”¨ v1.0\n",
    "   - âœ… ç°æœ‰é¡¹ç›®æ¸è¿›è¿ç§»\n",
    "   - âœ… ä½¿ç”¨ langchain-classic è¿‡æ¸¡\n",
    "\n",
    "### ä¸‹ä¸€æ­¥\n",
    "\n",
    "- ğŸ”¨ å®è·µï¼šåŸºäºæ¡ˆä¾‹ä¿®æ”¹è‡ªå·±çš„é¡¹ç›®\n",
    "- ğŸ“– æ·±å…¥ï¼šé˜…è¯»å®˜æ–¹æ–‡æ¡£è¿›é˜¶ç‰¹æ€§\n",
    "- ğŸ’¬ äº¤æµï¼šåŠ å…¥ç¤¾åŒºåˆ†äº«ç»éªŒ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (langchain1.x)",
   "language": "python",
   "name": "langchain1.x"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
