{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FlyAIBox/Agent_In_Action/blob/main/live-streaming/05-llm-inference/deepseek_vllm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPVYg0Z9SxCq"
      },
      "source": [
        "# åŸºäºŽvLLMéƒ¨ç½²DeepSeek-R1-Distill-Qwen-1.5B\n",
        "## ðŸ“– å…³äºŽ DeepSeek R1 è’¸é¦ç‰ˆ Qwen 1.5B æ¨¡åž‹\n",
        "\n",
        "### ðŸ§  æ¨¡åž‹ç‰¹ç‚¹\n",
        "- **æ¨¡åž‹åç§°**: `deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B`\n",
        "- **å‚æ•°è§„æ¨¡**: 15äº¿å‚æ•°ï¼Œé€‚åˆåœ¨æ˜¾å­˜æœ‰é™çš„GPUï¼ˆå¦‚Nvidia T4/4090ï¼‰ ä¸Šè¿è¡Œ\n",
        "- **æŽ¨ç†èƒ½åŠ›**: ç»§æ‰¿äº† DeepSeek R1 çš„å¼ºå¤§æŽ¨ç†èƒ½åŠ›\n",
        "- **è’¸é¦æŠ€æœ¯**: é€šè¿‡çŸ¥è¯†è’¸é¦èŽ·å¾—æ›´å°ä½†é«˜æ•ˆçš„æ¨¡åž‹\n",
        "\n",
        "### ðŸ” æ¨¡åž‹ä¼˜åŠ¿\n",
        "1. **è½»é‡åŒ–**: 15äº¿å‚æ•°ï¼Œå†…å­˜å ç”¨å°\n",
        "2. **é«˜æ•ˆæŽ¨ç†**: ä¼˜åŒ–çš„æŽ¨ç†é€Ÿåº¦\n",
        "3. **å¼ºå¤§èƒ½åŠ›**: ä¿æŒäº†å¤§æ¨¡åž‹çš„æŽ¨ç†èƒ½åŠ›\n",
        "4. **å…è´¹éƒ¨ç½²**: é€‚åˆåœ¨ Colabä¸Šå…è´¹çš„Nvidia T4 GPU ä¸Šè¿è¡Œ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ojg0UqLRnp1i",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "## ðŸŽ¯ å®žéªŒç›®æ ‡\n",
        "\n",
        "æœ¬å®žéªŒæ—¨åœ¨å¸®åŠ©å¤§æ¨¡åž‹æŠ€æœ¯åˆå­¦è€…ï¼š\n",
        "\n",
        "### ðŸ“š å­¦ä¹ å†…å®¹\n",
        "1. **çŽ¯å¢ƒå‡†å¤‡**: äº†è§£å¦‚ä½•æ£€æŸ¥å’Œé…ç½® Colab çŽ¯å¢ƒ\n",
        "2. **ä¾èµ–å®‰è£…**: å­¦ä¹ å®‰è£… VLLMç­‰å…³é”®åº“\n",
        "3. **æ¨¡åž‹éƒ¨ç½²**: æŽŒæ¡ä½¿ç”¨ VLLM éƒ¨ç½²å¤§è¯­è¨€æ¨¡åž‹çš„æ–¹æ³•\n",
        "\n",
        "\n",
        "### ðŸ’° æˆæœ¬ä¼˜åŠ¿\n",
        "- **å®Œå…¨å…è´¹**: ä½¿ç”¨ Google Colab å…è´¹ T4 GPU (15GB æ˜¾å­˜)\n",
        "- **é›¶é…ç½®**: æ— éœ€æœ¬åœ°çŽ¯å¢ƒé…ç½®ï¼Œæµè§ˆå™¨å³å¯è¿è¡Œ\n",
        "- **å³å¼€å³ç”¨**: ä¸€é”®å¯åŠ¨ï¼Œå¿«é€Ÿä½“éªŒå¤§æ¨¡åž‹éƒ¨ç½²\n",
        "\n",
        "### ðŸš€ æœŸæœ›æ”¶èŽ·\n",
        "é€šè¿‡æœ¬å®žéªŒï¼Œä½ å°†æŽŒæ¡ï¼š\n",
        "- å¤§è¯­è¨€æ¨¡åž‹çš„åŸºæœ¬éƒ¨ç½²æµç¨‹\n",
        "- VLLM æŽ¨ç†å¼•æ“Žçš„ä½¿ç”¨æ–¹æ³•"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LtZRZL_7jzo"
      },
      "source": [
        "## ðŸ”§ ç¬¬ä¸€æ­¥ï¼šçŽ¯å¢ƒä¿¡æ¯æ£€æŸ¥\n",
        "\n",
        "åœ¨å¼€å§‹éƒ¨ç½²æ¨¡åž‹ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦äº†è§£å½“å‰çš„è¿è¡ŒçŽ¯å¢ƒã€‚è¿™ä¸ªæ­¥éª¤éžå¸¸é‡è¦ï¼Œå› ä¸ºï¼š\n",
        "\n",
        "### ðŸŽ¯ æ£€æŸ¥ç›®çš„\n",
        "1. **ç¡¬ä»¶ç¡®è®¤**: ç¡®ä¿æœ‰è¶³å¤Ÿçš„ GPU æ˜¾å­˜è¿è¡Œæ¨¡åž‹\n",
        "2. **ç³»ç»Ÿå…¼å®¹**: éªŒè¯æ“ä½œç³»ç»Ÿå’Œ Python ç‰ˆæœ¬\n",
        "3. **èµ„æºè¯„ä¼°**: äº†è§£å¯ç”¨çš„ CPUã€å†…å­˜å’Œå­˜å‚¨ç©ºé—´\n",
        "4. **çŽ¯å¢ƒé…ç½®**: æ£€æŸ¥ CUDA ç‰ˆæœ¬å’Œç›¸å…³ä¾èµ–\n",
        "\n",
        "### ðŸ“Š æ£€æŸ¥å†…å®¹\n",
        "- **æ“ä½œç³»ç»Ÿ**: Linux å‘è¡Œç‰ˆå’Œç‰ˆæœ¬\n",
        "- **CPU ä¿¡æ¯**: å¤„ç†å™¨åž‹å·å’Œæ ¸å¿ƒæ•°\n",
        "- **å†…å­˜çŠ¶æ€**: æ€»å†…å­˜å’Œå¯ç”¨å†…å­˜\n",
        "- **GPU é…ç½®**: æ˜¾å¡åž‹å·å’Œæ˜¾å­˜å¤§å°\n",
        "- **CUDA ç‰ˆæœ¬**: æ·±åº¦å­¦ä¹ æ¡†æž¶æ”¯æŒ\n",
        "- **Python çŽ¯å¢ƒ**: è§£é‡Šå™¨ç‰ˆæœ¬\n",
        "- **ç£ç›˜ç©ºé—´**: å¯ç”¨å­˜å‚¨ç©ºé—´"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQMi5m-R7fLB",
        "outputId": "fb45d1b0-fe78-432f-bd53-0aa718084be7",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas==2.2.2 in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas==2.2.2) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas==2.2.2) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas==2.2.2) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas==2.2.2) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas==2.2.2) (1.17.0)\n",
            "### çŽ¯å¢ƒä¿¡æ¯\n",
            "| é¡¹ç›®         | ä¿¡æ¯                                                               |\n",
            "|:-------------|:-------------------------------------------------------------------|\n",
            "| æ“ä½œç³»ç»Ÿ     | Linux Ubuntu 22.04.4 LTS                                           |\n",
            "| CPU ä¿¡æ¯     | Intel(R) Xeon(R) CPU @ 2.20GHz (1 physical cores, 2 logical cores) |\n",
            "| å†…å­˜ä¿¡æ¯     | 12.67 GB (Available: 8.08 GB)                                      |\n",
            "| GPU ä¿¡æ¯     | Tesla T4 (15360 MiB)                                               |\n",
            "| CUDA ä¿¡æ¯    | 12.5                                                               |\n",
            "| Python ç‰ˆæœ¬  | 3.12.12                                                            |\n",
            "| Conda ç‰ˆæœ¬   | Conda not found                                                    |\n",
            "| ç‰©ç†ç£ç›˜ç©ºé—´ | Total: 112.64 GB, Used: 44.60 GB, Free: 68.02 GB                   |\n"
          ]
        }
      ],
      "source": [
        "# ðŸ” çŽ¯å¢ƒä¿¡æ¯æ£€æŸ¥è„šæœ¬\n",
        "#\n",
        "# æœ¬è„šæœ¬çš„ä½œç”¨ï¼š\n",
        "# 1. å®‰è£… pandas åº“ç”¨äºŽæ•°æ®è¡¨æ ¼å±•ç¤º\n",
        "# 2. æ£€æŸ¥ç³»ç»Ÿçš„å„é¡¹é…ç½®ä¿¡æ¯\n",
        "# 3. ç”Ÿæˆè¯¦ç»†çš„çŽ¯å¢ƒæŠ¥å‘Šè¡¨æ ¼\n",
        "#\n",
        "# å¯¹äºŽåˆå­¦è€…æ¥è¯´ï¼Œè¿™ä¸ªæ­¥éª¤å¸®åŠ©ä½ ï¼š\n",
        "# - äº†è§£å½“å‰è¿è¡ŒçŽ¯å¢ƒçš„ç¡¬ä»¶é…ç½®\n",
        "# - ç¡®è®¤æ˜¯å¦æ»¡è¶³æ¨¡åž‹è¿è¡Œçš„æœ€ä½Žè¦æ±‚\n",
        "# - å­¦ä¹ å¦‚ä½•é€šè¿‡ä»£ç èŽ·å–ç³»ç»Ÿä¿¡æ¯\n",
        "\n",
        "# å®‰è£… pandas åº“ - ç”¨äºŽåˆ›å»ºå’Œå±•ç¤ºæ•°æ®è¡¨æ ¼\n",
        "# pandas æ˜¯ Python ä¸­æœ€æµè¡Œçš„æ•°æ®å¤„ç†å’Œåˆ†æžåº“\n",
        "!pip install pandas==2.2.2\n",
        "\n",
        "import platform # å¯¼å…¥ platform æ¨¡å—ä»¥èŽ·å–ç³»ç»Ÿä¿¡æ¯\n",
        "import os # å¯¼å…¥ os æ¨¡å—ä»¥ä¸Žæ“ä½œç³»ç»Ÿäº¤äº’\n",
        "import subprocess # å¯¼å…¥ subprocess æ¨¡å—ä»¥è¿è¡Œå¤–éƒ¨å‘½ä»¤\n",
        "import pandas as pd # å¯¼å…¥ pandas æ¨¡å—ï¼Œé€šå¸¸ç”¨äºŽæ•°æ®å¤„ç†ï¼Œè¿™é‡Œç”¨äºŽåˆ›å»ºè¡¨æ ¼\n",
        "import shutil # å¯¼å…¥ shutil æ¨¡å—ä»¥èŽ·å–ç£ç›˜ç©ºé—´ä¿¡æ¯\n",
        "\n",
        "# èŽ·å– CPU ä¿¡æ¯çš„å‡½æ•°ï¼ŒåŒ…æ‹¬æ ¸å¿ƒæ•°é‡\n",
        "def get_cpu_info():\n",
        "    cpu_info = \"\" # åˆå§‹åŒ– CPU ä¿¡æ¯å­—ç¬¦ä¸²\n",
        "    physical_cores = \"N/A\"\n",
        "    logical_cores = \"N/A\"\n",
        "\n",
        "    if platform.system() == \"Windows\": # å¦‚æžœæ˜¯ Windows ç³»ç»Ÿ\n",
        "        cpu_info = platform.processor() # ä½¿ç”¨ platform.processor() èŽ·å– CPU ä¿¡æ¯\n",
        "        try:\n",
        "            # èŽ·å– Windows ä¸Šçš„æ ¸å¿ƒæ•°é‡ (éœ€è¦ WMI)\n",
        "            import wmi\n",
        "            c = wmi.WMI()\n",
        "            for proc in c.Win32_Processor():\n",
        "                physical_cores = proc.NumberOfCores\n",
        "                logical_cores = proc.NumberOfLogicalProcessors\n",
        "        except:\n",
        "            pass # å¦‚æžœ WMI ä¸å¯ç”¨ï¼Œå¿½ç•¥é”™è¯¯\n",
        "\n",
        "    elif platform.system() == \"Darwin\": # å¦‚æžœæ˜¯ macOS ç³»ç»Ÿ\n",
        "        # åœ¨ macOS ä¸Šä½¿ç”¨ sysctl å‘½ä»¤èŽ·å– CPU ä¿¡æ¯å’Œæ ¸å¿ƒæ•°é‡\n",
        "        os.environ['PATH'] = os.environ['PATH'] + os.pathsep + '/usr/sbin' # æ›´æ–° PATH çŽ¯å¢ƒå˜é‡\n",
        "        try:\n",
        "            process_brand = subprocess.Popen(['sysctl', \"machdep.cpu.brand_string\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "            stdout_brand, stderr_brand = process_brand.communicate()\n",
        "            cpu_info = stdout_brand.decode().split(': ')[1].strip() if stdout_brand else \"Could not retrieve CPU info\"\n",
        "\n",
        "            process_physical = subprocess.Popen(['sysctl', \"hw.physicalcpu\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "            stdout_physical, stderr_physical = process_physical.communicate()\n",
        "            physical_cores = stdout_physical.decode().split(': ')[1].strip() if stdout_physical else \"N/A\"\n",
        "\n",
        "            process_logical = subprocess.Popen(['sysctl', \"hw.logicalcpu\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "            stdout_logical, stderr_logical = process_logical.communicate()\n",
        "            logical_cores = stdout_logical.decode().split(': ')[1].strip() if stdout_logical else \"N/A\"\n",
        "\n",
        "        except:\n",
        "            cpu_info = \"Could not retrieve CPU info\"\n",
        "            physical_cores = \"N/A\"\n",
        "            logical_cores = \"N/A\"\n",
        "\n",
        "    else:  # Linux ç³»ç»Ÿ\n",
        "        try:\n",
        "            # åœ¨ Linux ä¸Šè¯»å– /proc/cpuinfo æ–‡ä»¶èŽ·å– CPU ä¿¡æ¯å’Œæ ¸å¿ƒæ•°é‡\n",
        "            with open('/proc/cpuinfo') as f:\n",
        "                physical_cores_count = 0\n",
        "                logical_cores_count = 0\n",
        "                cpu_info_lines = []\n",
        "                for line in f:\n",
        "                    if line.startswith('model name'): # æŸ¥æ‰¾ä»¥ 'model name'å¼€å¤´çš„è¡Œ\n",
        "                        if not cpu_info: # åªèŽ·å–ç¬¬ä¸€ä¸ª model name\n",
        "                            cpu_info = line.split(': ')[1].strip()\n",
        "                    elif line.startswith('cpu cores'): # æŸ¥æ‰¾ä»¥ 'cpu cores' å¼€å¤´çš„è¡Œ\n",
        "                        physical_cores_count = int(line.split(': ')[1].strip())\n",
        "                    elif line.startswith('processor'): # æŸ¥æ‰¾ä»¥ 'processor' å¼€å¤´çš„è¡Œ\n",
        "                        logical_cores_count += 1\n",
        "                physical_cores = str(physical_cores_count) if physical_cores_count > 0 else \"N/A\"\n",
        "                logical_cores = str(logical_cores_count) if logical_cores_count > 0 else \"N/A\"\n",
        "                if not cpu_info:\n",
        "                     cpu_info = \"Could not retrieve CPU info\"\n",
        "\n",
        "        except:\n",
        "            cpu_info = \"Could not retrieve CPU info\"\n",
        "            physical_cores = \"N/A\"\n",
        "            logical_cores = \"N/A\"\n",
        "\n",
        "    return f\"{cpu_info} ({physical_cores} physical cores, {logical_cores} logical cores)\" # è¿”å›ž CPU ä¿¡æ¯å’Œæ ¸å¿ƒæ•°é‡\n",
        "\n",
        "\n",
        "# èŽ·å–å†…å­˜ä¿¡æ¯çš„å‡½æ•°\n",
        "def get_memory_info():\n",
        "    mem_info = \"\" # åˆå§‹åŒ–å†…å­˜ä¿¡æ¯å­—ç¬¦ä¸²\n",
        "    if platform.system() == \"Windows\":\n",
        "        # åœ¨ Windows ä¸Šä¸å®¹æ˜“é€šè¿‡æ ‡å‡†åº“èŽ·å–ï¼Œéœ€è¦å¤–éƒ¨åº“æˆ– PowerShell\n",
        "        mem_info = \"Requires external tools on Windows\" # è®¾ç½®æç¤ºä¿¡æ¯\n",
        "    elif platform.system() == \"Darwin\": # å¦‚æžœæ˜¯ macOS ç³»ç»Ÿ\n",
        "        # åœ¨ macOS ä¸Šä½¿ç”¨ sysctl å‘½ä»¤èŽ·å–å†…å­˜å¤§å°\n",
        "        process = subprocess.Popen(['sysctl', \"hw.memsize\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE) # è¿è¡Œ sysctl å‘½ä»¤\n",
        "        stdout, stderr = process.communicate() # èŽ·å–æ ‡å‡†è¾“å‡ºå’Œæ ‡å‡†é”™è¯¯\n",
        "        mem_bytes = int(stdout.decode().split(': ')[1].strip()) # è§£æžè¾“å‡ºï¼ŒèŽ·å–å†…å­˜å¤§å°ï¼ˆå­—èŠ‚ï¼‰\n",
        "        mem_gb = mem_bytes / (1024**3) # è½¬æ¢ä¸º GB\n",
        "        mem_info = f\"{mem_gb:.2f} GB\" # æ ¼å¼åŒ–è¾“å‡º\n",
        "    else:  # Linux ç³»ç»Ÿ\n",
        "        try:\n",
        "            # åœ¨ Linux ä¸Šè¯»å– /proc/meminfo æ–‡ä»¶èŽ·å–å†…å­˜ä¿¡æ¯\n",
        "            with open('/proc/meminfo') as f:\n",
        "                total_mem_kb = 0\n",
        "                available_mem_kb = 0\n",
        "                for line in f:\n",
        "                    if line.startswith('MemTotal'): # æŸ¥æ‰¾ä»¥ 'MemTotal' å¼€å¤´çš„è¡Œ\n",
        "                        total_mem_kb = int(line.split(':')[1].strip().split()[0]) # è§£æžè¡Œï¼ŒèŽ·å–æ€»å†…å­˜ï¼ˆKBï¼‰\n",
        "                    elif line.startswith('MemAvailable'): # æŸ¥æ‰¾ä»¥ 'MemAvailable' å¼€å¤´çš„è¡Œ\n",
        "                         available_mem_kb = int(line.split(':')[1].strip().split()[0]) # è§£æžè¡Œï¼ŒèŽ·å–å¯ç”¨å†…å­˜ï¼ˆKBï¼‰\n",
        "\n",
        "                if total_mem_kb > 0:\n",
        "                    total_mem_gb = total_mem_kb / (1024**2) # è½¬æ¢ä¸º GB\n",
        "                    mem_info = f\"{total_mem_gb:.2f} GB\" # æ ¼å¼åŒ–è¾“å‡ºæ€»å†…å­˜\n",
        "                    if available_mem_kb > 0:\n",
        "                        available_mem_gb = available_mem_kb / (1024**2)\n",
        "                        mem_info += f\" (Available: {available_mem_gb:.2f} GB)\" # æ·»åŠ å¯ç”¨å†…å­˜ä¿¡æ¯\n",
        "                else:\n",
        "                     mem_info = \"Could not retrieve memory info\" # å¦‚æžœè¯»å–æ–‡ä»¶å‡ºé”™ï¼Œè®¾ç½®é”™è¯¯ä¿¡æ¯\n",
        "\n",
        "        except:\n",
        "            mem_info = \"Could not retrieve memory info\" # å¦‚æžœè¯»å–æ–‡ä»¶å‡ºé”™ï¼Œè®¾ç½®é”™è¯¯ä¿¡æ¯\n",
        "    return mem_info # è¿”å›žå†…å­˜ä¿¡æ¯\n",
        "\n",
        "# èŽ·å– GPU ä¿¡æ¯çš„å‡½æ•°ï¼ŒåŒ…æ‹¬æ˜¾å­˜\n",
        "def get_gpu_info():\n",
        "    try:\n",
        "        # å°è¯•ä½¿ç”¨ nvidia-smi èŽ·å– NVIDIA GPU ä¿¡æ¯å’Œæ˜¾å­˜\n",
        "        result = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total', '--format=csv,noheader'], capture_output=True, text=True)\n",
        "        if result.returncode == 0: # å¦‚æžœå‘½ä»¤æˆåŠŸæ‰§è¡Œ\n",
        "            gpu_lines = result.stdout.strip().split('\\n') # è§£æžè¾“å‡ºï¼ŒèŽ·å– GPU åç§°å’Œæ˜¾å­˜\n",
        "            gpu_info_list = []\n",
        "            for line in gpu_lines:\n",
        "                name, memory = line.split(', ')\n",
        "                gpu_info_list.append(f\"{name} ({memory})\") # æ ¼å¼åŒ– GPU ä¿¡æ¯\n",
        "            return \", \".join(gpu_info_list) if gpu_info_list else \"NVIDIA GPU found, but info not listed\" # è¿”å›ž GPU ä¿¡æ¯æˆ–æç¤ºä¿¡æ¯\n",
        "        else:\n",
        "             # å°è¯•ä½¿ç”¨ lshw èŽ·å–å…¶ä»– GPU ä¿¡æ¯ (éœ€è¦å®‰è£… lshw)\n",
        "            try:\n",
        "                result_lshw = subprocess.run(['lshw', '-C', 'display'], capture_output=True, text=True)\n",
        "                if result_lshw.returncode == 0: # å¦‚æžœå‘½ä»¤æˆåŠŸæ‰§è¡Œ\n",
        "                     # ç®€å•è§£æžè¾“å‡ºä¸­çš„ product åç§°å’Œæ˜¾å­˜\n",
        "                    gpu_info_lines = []\n",
        "                    current_gpu = {}\n",
        "                    for line in result_lshw.stdout.splitlines():\n",
        "                        if 'product:' in line:\n",
        "                             if current_gpu:\n",
        "                                 gpu_info_lines.append(f\"{current_gpu.get('product', 'GPU')} ({current_gpu.get('memory', 'N/A')})\")\n",
        "                             current_gpu = {'product': line.split('product:')[1].strip()}\n",
        "                        elif 'size:' in line and 'memory' in line:\n",
        "                             current_gpu['memory'] = line.split('size:')[1].strip()\n",
        "\n",
        "                    if current_gpu: # æ·»åŠ æœ€åŽä¸€ä¸ª GPU çš„ä¿¡æ¯\n",
        "                        gpu_info_lines.append(f\"{current_gpu.get('product', 'GPU')} ({current_gpu.get('memory', 'N/A')})\")\n",
        "\n",
        "                    return \", \".join(gpu_info_lines) if gpu_info_lines else \"GPU found (via lshw), but info not parsed\" # å¦‚æžœæ‰¾åˆ° GPU ä½†ä¿¡æ¯æ— æ³•è§£æžï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
        "                else:\n",
        "                    return \"No GPU found (checked nvidia-smi and lshw)\" # å¦‚æžœä¸¤ä¸ªå‘½ä»¤éƒ½æ‰¾ä¸åˆ° GPUï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
        "            except FileNotFoundError:\n",
        "                 return \"No GPU found (checked nvidia-smi, lshw not found)\" # å¦‚æžœæ‰¾ä¸åˆ° lshw å‘½ä»¤ï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
        "    except FileNotFoundError:\n",
        "        return \"No GPU found (nvidia-smi not found)\" # å¦‚æžœæ‰¾ä¸åˆ° nvidia-smi å‘½ä»¤ï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
        "\n",
        "\n",
        "# èŽ·å– CUDA ç‰ˆæœ¬çš„å‡½æ•°\n",
        "def get_cuda_version():\n",
        "    try:\n",
        "        # å°è¯•ä½¿ç”¨ nvcc --version èŽ·å– CUDA ç‰ˆæœ¬\n",
        "        result = subprocess.run(['nvcc', '--version'], capture_output=True, text=True)\n",
        "        if result.returncode == 0: # å¦‚æžœå‘½ä»¤æˆåŠŸæ‰§è¡Œ\n",
        "            for line in result.stdout.splitlines():\n",
        "                if 'release' in line: # æŸ¥æ‰¾åŒ…å« 'release' çš„è¡Œ\n",
        "                    return line.split('release ')[1].split(',')[0] # è§£æžè¡Œï¼Œæå–ç‰ˆæœ¬å·\n",
        "        return \"CUDA not found or version not parsed\" # å¦‚æžœæ‰¾ä¸åˆ° CUDA æˆ–ç‰ˆæœ¬æ— æ³•è§£æžï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
        "    except FileNotFoundError:\n",
        "        return \"CUDA not found\" # å¦‚æžœæ‰¾ä¸åˆ° nvcc å‘½ä»¤ï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
        "\n",
        "# èŽ·å– Python ç‰ˆæœ¬çš„å‡½æ•°\n",
        "def get_python_version():\n",
        "    return platform.python_version() # èŽ·å– Python ç‰ˆæœ¬\n",
        "\n",
        "# èŽ·å– Conda ç‰ˆæœ¬çš„å‡½æ•°\n",
        "def get_conda_version():\n",
        "    try:\n",
        "        # å°è¯•ä½¿ç”¨ conda --version èŽ·å– Conda ç‰ˆæœ¬\n",
        "        result = subprocess.run(['conda', '--version'], capture_output=True, text=True)\n",
        "        if result.returncode == 0: # å¦‚æžœå‘½ä»¤æˆåŠŸæ‰§è¡Œ\n",
        "            return result.stdout.strip() # è¿”å›ž Conda ç‰ˆæœ¬\n",
        "        return \"Conda not found or version not parsed\" # å¦‚æžœæ‰¾ä¸åˆ° Conda æˆ–ç‰ˆæœ¬æ— æ³•è§£æžï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
        "    except FileNotFoundError:\n",
        "        return \"Conda not found\" # å¦‚æžœæ‰¾ä¸åˆ° conda å‘½ä»¤ï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
        "\n",
        "# èŽ·å–ç‰©ç†ç£ç›˜ç©ºé—´ä¿¡æ¯çš„å‡½æ•°\n",
        "def get_disk_space():\n",
        "    try:\n",
        "        total, used, free = shutil.disk_usage(\"/\") # èŽ·å–æ ¹ç›®å½•çš„ç£ç›˜ä½¿ç”¨æƒ…å†µ\n",
        "        total_gb = total / (1024**3) # è½¬æ¢ä¸º GB\n",
        "        used_gb = used / (1024**3) # è½¬æ¢ä¸º GB\n",
        "        free_gb = free / (1024**3) # è½¬æ¢ä¸º GB\n",
        "        return f\"Total: {total_gb:.2f} GB, Used: {used_gb:.2f} GB, Free: {free_gb:.2f} GB\" # æ ¼å¼åŒ–è¾“å‡º\n",
        "    except Exception as e:\n",
        "        return f\"Could not retrieve disk info: {e}\" # å¦‚æžœèŽ·å–ä¿¡æ¯å‡ºé”™ï¼Œè®¾ç½®é”™è¯¯ä¿¡æ¯\n",
        "\n",
        "# èŽ·å–çŽ¯å¢ƒä¿¡æ¯\n",
        "os_name = platform.system() # èŽ·å–æ“ä½œç³»ç»Ÿåç§°\n",
        "os_version = platform.release() # èŽ·å–æ“ä½œç³»ç»Ÿç‰ˆæœ¬\n",
        "if os_name == \"Linux\":\n",
        "    try:\n",
        "        # åœ¨ Linux ä¸Šå°è¯•èŽ·å–å‘è¡Œç‰ˆå’Œç‰ˆæœ¬\n",
        "        lsb_info = subprocess.run(['lsb_release', '-a'], capture_output=True, text=True)\n",
        "        if lsb_info.returncode == 0: # å¦‚æžœå‘½ä»¤æˆåŠŸæ‰§è¡Œ\n",
        "            for line in lsb_info.stdout.splitlines():\n",
        "                if 'Description:' in line: # æŸ¥æ‰¾åŒ…å« 'Description:' çš„è¡Œ\n",
        "                    os_version = line.split('Description:')[1].strip() # æå–æè¿°ä¿¡æ¯ä½œä¸ºç‰ˆæœ¬\n",
        "                    break # æ‰¾åˆ°åŽé€€å‡ºå¾ªçŽ¯\n",
        "                elif 'Release:' in line: # æŸ¥æ‰¾åŒ…å« 'Release:' çš„è¡Œ\n",
        "                     os_version = line.split('Release:')[1].strip() # æå–ç‰ˆæœ¬å·\n",
        "                     # å°è¯•èŽ·å– codename\n",
        "                     try:\n",
        "                         codename_info = subprocess.run(['lsb_release', '-c'], capture_output=True, text=True)\n",
        "                         if codename_info.returncode == 0:\n",
        "                             os_version += f\" ({codename_info.stdout.split(':')[1].strip()})\" # å°† codename æ·»åŠ åˆ°ç‰ˆæœ¬ä¿¡æ¯ä¸­\n",
        "                     except:\n",
        "                         pass # å¦‚æžœèŽ·å– codename å¤±è´¥åˆ™å¿½ç•¥\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        pass # lsb_release å¯èƒ½æœªå®‰è£…ï¼Œå¿½ç•¥é”™è¯¯\n",
        "\n",
        "full_os_info = f\"{os_name} {os_version}\" # ç»„åˆå®Œæ•´çš„æ“ä½œç³»ç»Ÿä¿¡æ¯\n",
        "cpu_info = get_cpu_info() # è°ƒç”¨å‡½æ•°èŽ·å– CPU ä¿¡æ¯å’Œæ ¸å¿ƒæ•°é‡\n",
        "memory_info = get_memory_info() # è°ƒç”¨å‡½æ•°èŽ·å–å†…å­˜ä¿¡æ¯\n",
        "gpu_info = get_gpu_info() # è°ƒç”¨å‡½æ•°èŽ·å– GPU ä¿¡æ¯å’Œæ˜¾å­˜\n",
        "cuda_version = get_cuda_version() # è°ƒç”¨å‡½æ•°èŽ·å– CUDA ç‰ˆæœ¬\n",
        "python_version = get_python_version() # è°ƒç”¨å‡½æ•°èŽ·å– Python ç‰ˆæœ¬\n",
        "conda_version = get_conda_version() # è°ƒç”¨å‡½æ•°èŽ·å– Conda ç‰ˆæœ¬\n",
        "disk_info = get_disk_space() # è°ƒç”¨å‡½æ•°èŽ·å–ç‰©ç†ç£ç›˜ç©ºé—´ä¿¡æ¯\n",
        "\n",
        "\n",
        "# åˆ›å»ºç”¨äºŽå­˜å‚¨æ•°æ®çš„å­—å…¸\n",
        "env_data = {\n",
        "    \"é¡¹ç›®\": [ # é¡¹ç›®åç§°åˆ—è¡¨\n",
        "        \"æ“ä½œç³»ç»Ÿ\",\n",
        "        \"CPU ä¿¡æ¯\",\n",
        "        \"å†…å­˜ä¿¡æ¯\",\n",
        "        \"GPU ä¿¡æ¯\",\n",
        "        \"CUDA ä¿¡æ¯\",\n",
        "        \"Python ç‰ˆæœ¬\",\n",
        "        \"Conda ç‰ˆæœ¬\",\n",
        "        \"ç‰©ç†ç£ç›˜ç©ºé—´\" # æ·»åŠ ç‰©ç†ç£ç›˜ç©ºé—´\n",
        "    ],\n",
        "    \"ä¿¡æ¯\": [ # å¯¹åº”çš„ä¿¡æ¯åˆ—è¡¨\n",
        "        full_os_info,\n",
        "        cpu_info,\n",
        "        memory_info,\n",
        "        gpu_info,\n",
        "        cuda_version,\n",
        "        python_version,\n",
        "        conda_version,\n",
        "        disk_info # æ·»åŠ ç‰©ç†ç£ç›˜ç©ºé—´ä¿¡æ¯\n",
        "    ]\n",
        "}\n",
        "\n",
        "# åˆ›å»ºä¸€ä¸ª pandas DataFrame\n",
        "df = pd.DataFrame(env_data)\n",
        "\n",
        "# æ‰“å°è¡¨æ ¼\n",
        "print(\"### çŽ¯å¢ƒä¿¡æ¯\") # æ‰“å°æ ‡é¢˜\n",
        "print(df.to_markdown(index=False)) # å°† DataFrame è½¬æ¢ä¸º Markdown æ ¼å¼å¹¶æ‰“å°ï¼Œä¸åŒ…å«ç´¢å¼•"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bj_P8PUQjFFT"
      },
      "source": [
        "## ðŸ“¦ ç¬¬äºŒæ­¥ï¼šå®‰è£…ä¾èµ–åŒ…\n",
        "\n",
        "çŽ°åœ¨æˆ‘ä»¬éœ€è¦å®‰è£…è¿è¡Œæ¨¡åž‹æ‰€éœ€çš„å…³é”® Python åŒ…ï¼š\n",
        "\n",
        "### ðŸ”§ æ ¸å¿ƒä¾èµ–è¯´æ˜Ž\n",
        "\n",
        "#### 1. **FastAPI (0.116.0)**\n",
        "- **ä½œç”¨**: çŽ°ä»£åŒ–çš„ Python Web æ¡†æž¶\n",
        "- **ç”¨é€”**: åˆ›å»º RESTful API æŽ¥å£æœåŠ¡\n",
        "- **ç‰¹ç‚¹**: è‡ªåŠ¨ç”Ÿæˆ API æ–‡æ¡£ï¼Œæ”¯æŒå¼‚æ­¥å¤„ç†\n",
        "\n",
        "#### 2. **nest-asyncio (1.6.0)**\n",
        "- **ä½œç”¨**: å…è®¸åœ¨å·²æœ‰äº‹ä»¶å¾ªçŽ¯ä¸­è¿è¡Œå¼‚æ­¥ä»£ç \n",
        "- **ç”¨é€”**: è§£å†³ Jupyter çŽ¯å¢ƒä¸­çš„å¼‚æ­¥å…¼å®¹é—®é¢˜\n",
        "- **é‡è¦æ€§**: ç¡®ä¿ FastAPI åœ¨ Colab ä¸­æ­£å¸¸è¿è¡Œ\n",
        "\n",
        "#### 3. **pyngrok (7.2.12)**\n",
        "- **ä½œç”¨**: Python ç‰ˆæœ¬çš„ ngrok å®¢æˆ·ç«¯\n",
        "- **ç”¨é€”**: åˆ›å»ºå…¬ç½‘éš§é“ï¼Œè®©å¤–éƒ¨è®¿é—®æœ¬åœ°æœåŠ¡\n",
        "- **åœºæ™¯**: å°† Colab ä¸­çš„ API æœåŠ¡æš´éœ²ç»™å¤–éƒ¨\n",
        "\n",
        "#### 4. **uvicorn (0.35.0)**\n",
        "- **ä½œç”¨**: é«˜æ€§èƒ½çš„ ASGI æœåŠ¡å™¨\n",
        "- **ç”¨é€”**: è¿è¡Œ FastAPI åº”ç”¨ç¨‹åº\n",
        "- **ç‰¹ç‚¹**: æ”¯æŒå¼‚æ­¥å¤„ç†ï¼Œæ€§èƒ½ä¼˜å¼‚\n",
        "\n",
        "#### 5. **vllm (0.12.0)**\n",
        "- **ä½œç”¨**: é«˜æ€§èƒ½å¤§è¯­è¨€æ¨¡åž‹æŽ¨ç†å¼•æ“Ž\n",
        "- **ç”¨é€”**: åŠ è½½å’Œè¿è¡Œ DeepSeek æ¨¡åž‹\n",
        "- **ä¼˜åŠ¿**: å†…å­˜é«˜æ•ˆï¼ŒæŽ¨ç†é€Ÿåº¦å¿«\n",
        "\n",
        "### âš¡ å®‰è£…è¿‡ç¨‹\n",
        "ä¸‹é¢çš„å‘½ä»¤ä¼šå®‰è£…æ‰€æœ‰å¿…éœ€çš„ä¾èµ–åŒ…ï¼Œè¯·è€å¿ƒç­‰å¾…å®‰è£…å®Œæˆã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebACUjhXSwzJ",
        "outputId": "2022141d-f1b6-4b29-84b4-deaf8d3f3e6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: vllm==0.12.0 in /usr/local/lib/python3.12/dist-packages (0.12.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from vllm==0.12.0) (2025.11.3)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.12/dist-packages (from vllm==0.12.0) (6.2.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from vllm==0.12.0) (5.9.5)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from vllm==0.12.0) (0.2.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from vllm==0.12.0) (2.0.2)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from vllm==0.12.0) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from vllm==0.12.0) (4.67.1)\n",
            "Requirement already satisfied: blake3 in /usr/local/lib/python3.12/dist-packages (from vllm==0.12.0) (1.0.8)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.12/dist-packages (from vllm==0.12.0) (9.0.0)\n",
            "Requirement already satisfied: transformers<5,>=4.56.0 in /usr/local/lib/python3.12/dist-packages (from vllm==0.12.0) (4.57.6)\n",
            "Requirement already satisfied: tokenizers>=0.21.1 in /usr/local/lib/python3.12/dist-packages (from vllm==0.12.0) (0.22.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from vllm==0.12.0) (5.29.5)\n",
            "Requirement already satisfied: fastapi>=0.115.0 in /usr/local/lib/python3.12/dist-packages (from fastapi[standard]>=0.115.0->vllm==0.12.0) (0.124.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from vllm==0.12.0) (3.13.3)\n",
            "Requirement already satisfied: openai>=1.99.1 in /usr/local/lib/python3.12/dist-packages (from vllm==0.12.0) (2.15.0)\n",
            "Requirement already satisfied: pydantic>=2.12.0 in /usr/local/lib/python3.12/dist-packages (from vllm==0.12.0) (2.12.3)\n",
            "Requirement already satisfied: prometheus_client>=0.18.0 in /usr/local/lib/python3.12/dist-packages (from vllm==0.12.0) (0.24.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from vllm==0.12.0) (11.3.0)\n",
            "Requirement already satisfied: prometheus-fastapi-instrumentator>=7.0.0 in /usr/local/lib/python3.12/dist-packages (from vllm==0.12.0) (7.1.0)\n",
            "Requirement already satisfied: tiktoken>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from vllm==0.12.0) (0.12.0)\n",
            "Requirement already satisfied: lm-format-enforcer==0.11.3 in /usr/local/lib/python3.12/dist-packages (from vllm==0.12.0) (0.11.3)\n",
            "Requirement already satisfied: llguidance<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from vllm==0.12.0) (1.3.0)\n",
            "Requirement already satisfied: outlines_core==0.2.11 in /usr/local/lib/python3.12/dist-packages (from vllm==0.12.0) (0.2.11)\n",
            "Requirement already satisfied: diskcache==5.6.3 in /usr/local/lib/python3.12/dist-packages (from vllm==0.12.0) (5.6.3)\n",
            "Requirement already satisfied: lark==1.2.2 in /usr/local/lib/python3.12/dist-packages (from vllm==0.12.0) (1.2.2)\n",
            "Requirement already satisfied: xgrammar==0.1.27 in /usr/local/lib/python3.12/dist-packages (from vllm==0.12.0) (0.1.27)\n",
            "Requirement already satisfied: typing_extensions>=4.10 in /usr/local/lib/python3.12/dist-packages (from vllm==0.12.0) (4.15.0)\n",
            "Requirement already satisfied: filelock>=3.16.1 in /usr/local/lib/python3.12/dist-packages (from vllm==0.12.0) (3.20.3)\n",
            "Requirement already satisfied: partial-json-parser in /usr/local/lib/python3.12/dist-packages (from vllm==0.12.0) (0.2.1.1.post7)\n",
            "Requirement already satisfied: pyzmq>=25.0.0 in /usr/local/lib/python3.12/dist-packages (from vllm==0.12.0) (26.2.1)\n",
            "Requirement already satisfied: msgspec in /usr/local/lib/python3.12/dist-packages (from vllm==0.12.0) (0.20.0)\n",
            "Requirement already satisfied: gguf>=0.17.0 in /usr/local/lib/python3.12/dist-packages (from vllm==0.12.0) (0.17.1)\n",
            "Requirement already satisfied: mistral_common>=1.8.5 in /usr/local/lib/python3.12/dist-packages (from mistral_common[image]>=1.8.5->vllm==0.12.0) (1.8.8)\n",
            "Requirement already satisfied: opencv-python-headless>=4.11.0 in /usr/local/lib/python3.12/dist-packages (from vllm==0.12.0) (4.12.0.88)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from vllm==0.12.0) (6.0.3)\n",
            "Requirement already satisfied: six>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from vllm==0.12.0) (1.17.0)\n",
            "Requirement already satisfied: setuptools<81.0.0,>=77.0.3 in /usr/local/lib/python3.12/dist-packages (from vllm==0.12.0) (80.10.1)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from vllm==0.12.0) (0.8.1)\n",
            "Requirement already satisfied: compressed-tensors==0.12.2 in /usr/local/lib/python3.12/dist-packages (from vllm==0.12.0) (0.12.2)\n",
            "Requirement already satisfied: depyf==0.20.0 in /usr/local/lib/python3.12/dist-packages (from vllm==0.12.0) (0.20.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from vllm==0.12.0) (3.1.2)\n",
            "Requirement already satisfied: watchfiles in /usr/local/lib/python3.12/dist-packages (from vllm==0.12.0) (1.1.1)\n",
            "Requirement already satisfied: python-json-logger in /usr/local/lib/python3.12/dist-packages (from vllm==0.12.0) (4.0.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from vllm==0.12.0) (1.16.3)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.12/dist-packages (from vllm==0.12.0) (1.13.0)\n",
            "Requirement already satisfied: pybase64 in /usr/local/lib/python3.12/dist-packages (from vllm==0.12.0) (1.4.3)\n",
            "Requirement already satisfied: cbor2 in /usr/local/lib/python3.12/dist-packages (from vllm==0.12.0) (5.8.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.12/dist-packages (from vllm==0.12.0) (1.3.7)\n",
            "Requirement already satisfied: openai-harmony>=0.0.3 in /usr/local/lib/python3.12/dist-packages (from vllm==0.12.0) (0.0.8)\n",
            "Requirement already satisfied: anthropic==0.71.0 in /usr/local/lib/python3.12/dist-packages (from vllm==0.12.0) (0.71.0)\n",
            "Requirement already satisfied: model-hosting-container-standards<1.0.0,>=0.1.9 in /usr/local/lib/python3.12/dist-packages (from vllm==0.12.0) (0.1.13)\n",
            "Requirement already satisfied: numba==0.61.2 in /usr/local/lib/python3.12/dist-packages (from vllm==0.12.0) (0.61.2)\n",
            "Requirement already satisfied: ray>=2.48.0 in /usr/local/lib/python3.12/dist-packages (from ray[cgraph]>=2.48.0->vllm==0.12.0) (2.53.0)\n",
            "Requirement already satisfied: torch==2.9.0 in /usr/local/lib/python3.12/dist-packages (from vllm==0.12.0) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchaudio==2.9.0 in /usr/local/lib/python3.12/dist-packages (from vllm==0.12.0) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision==0.24.0 in /usr/local/lib/python3.12/dist-packages (from vllm==0.12.0) (0.24.0+cu126)\n",
            "Requirement already satisfied: flashinfer-python==0.5.3 in /usr/local/lib/python3.12/dist-packages (from vllm==0.12.0) (0.5.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from anthropic==0.71.0->vllm==0.12.0) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from anthropic==0.71.0->vllm==0.12.0) (1.9.0)\n",
            "Requirement already satisfied: docstring-parser<1,>=0.15 in /usr/local/lib/python3.12/dist-packages (from anthropic==0.71.0->vllm==0.12.0) (0.17.0)\n",
            "Requirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from anthropic==0.71.0->vllm==0.12.0) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from anthropic==0.71.0->vllm==0.12.0) (0.12.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from anthropic==0.71.0->vllm==0.12.0) (1.3.1)\n",
            "Requirement already satisfied: loguru in /usr/local/lib/python3.12/dist-packages (from compressed-tensors==0.12.2->vllm==0.12.0) (0.7.3)\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.12/dist-packages (from depyf==0.20.0->vllm==0.12.0) (0.8.1)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from depyf==0.20.0->vllm==0.12.0) (0.3.8)\n",
            "Requirement already satisfied: apache-tvm-ffi<0.2,>=0.1 in /usr/local/lib/python3.12/dist-packages (from flashinfer-python==0.5.3->vllm==0.12.0) (0.1.8.post2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from flashinfer-python==0.5.3->vllm==0.12.0) (8.3.1)\n",
            "Requirement already satisfied: nvidia-cudnn-frontend>=1.13.0 in /usr/local/lib/python3.12/dist-packages (from flashinfer-python==0.5.3->vllm==0.12.0) (1.17.0)\n",
            "Requirement already satisfied: nvidia-cutlass-dsl>=4.2.1 in /usr/local/lib/python3.12/dist-packages (from flashinfer-python==0.5.3->vllm==0.12.0) (4.3.5)\n",
            "Requirement already satisfied: nvidia-ml-py in /usr/local/lib/python3.12/dist-packages (from flashinfer-python==0.5.3->vllm==0.12.0) (13.590.44)\n",
            "Requirement already satisfied: packaging>=24.2 in /usr/local/lib/python3.12/dist-packages (from flashinfer-python==0.5.3->vllm==0.12.0) (25.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.12/dist-packages (from flashinfer-python==0.5.3->vllm==0.12.0) (0.9.0)\n",
            "Requirement already satisfied: interegular>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from lm-format-enforcer==0.11.3->vllm==0.12.0) (0.3.3)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba==0.61.2->vllm==0.12.0) (0.44.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->vllm==0.12.0) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->vllm==0.12.0) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->vllm==0.12.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->vllm==0.12.0) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->vllm==0.12.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->vllm==0.12.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->vllm==0.12.0) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->vllm==0.12.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->vllm==0.12.0) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->vllm==0.12.0) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->vllm==0.12.0) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->vllm==0.12.0) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->vllm==0.12.0) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->vllm==0.12.0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->vllm==0.12.0) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->vllm==0.12.0) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->vllm==0.12.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->vllm==0.12.0) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->vllm==0.12.0) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->vllm==0.12.0) (3.5.0)\n",
            "Requirement already satisfied: starlette<0.51.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm==0.12.0) (0.50.0)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm==0.12.0) (0.0.4)\n",
            "Requirement already satisfied: fastapi-cli>=0.0.8 in /usr/local/lib/python3.12/dist-packages (from fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.12.0) (0.0.20)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from fastapi[standard]>=0.115.0->vllm==0.12.0) (0.0.21)\n",
            "Requirement already satisfied: email-validator>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from fastapi[standard]>=0.115.0->vllm==0.12.0) (2.3.0)\n",
            "Requirement already satisfied: uvicorn>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.12.0) (0.38.0)\n",
            "Requirement already satisfied: jsonschema>=4.21.1 in /usr/local/lib/python3.12/dist-packages (from mistral_common>=1.8.5->mistral_common[image]>=1.8.5->vllm==0.12.0) (4.26.0)\n",
            "Requirement already satisfied: pydantic-extra-types>=2.10.5 in /usr/local/lib/python3.12/dist-packages (from pydantic-extra-types[pycountry]>=2.10.5->mistral_common>=1.8.5->mistral_common[image]>=1.8.5->vllm==0.12.0) (2.11.0)\n",
            "Requirement already satisfied: jmespath in /usr/local/lib/python3.12/dist-packages (from model-hosting-container-standards<1.0.0,>=0.1.9->vllm==0.12.0) (1.1.0)\n",
            "Requirement already satisfied: supervisor>=4.2.0 in /usr/local/lib/python3.12/dist-packages (from model-hosting-container-standards<1.0.0,>=0.1.9->vllm==0.12.0) (4.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.12.0->vllm==0.12.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.12.0->vllm==0.12.0) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.12.0->vllm==0.12.0) (0.4.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ray>=2.48.0->ray[cgraph]>=2.48.0->vllm==0.12.0) (1.1.2)\n",
            "Requirement already satisfied: cupy-cuda12x in /usr/local/lib/python3.12/dist-packages (from ray[cgraph]>=2.48.0->vllm==0.12.0) (13.6.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->vllm==0.12.0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->vllm==0.12.0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->vllm==0.12.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->vllm==0.12.0) (2026.1.4)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers>=0.21.1->vllm==0.12.0) (0.36.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5,>=4.56.0->vllm==0.12.0) (0.7.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm==0.12.0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm==0.12.0) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm==0.12.0) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm==0.12.0) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm==0.12.0) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm==0.12.0) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm==0.12.0) (1.22.0)\n",
            "Requirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from email-validator>=2.0.0->fastapi[standard]>=0.115.0->vllm==0.12.0) (2.8.0)\n",
            "Requirement already satisfied: typer>=0.15.1 in /usr/local/lib/python3.12/dist-packages (from fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.12.0) (0.21.1)\n",
            "Requirement already satisfied: rich-toolkit>=0.14.8 in /usr/local/lib/python3.12/dist-packages (from fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.12.0) (0.17.1)\n",
            "Requirement already satisfied: fastapi-cloud-cli>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.12.0) (0.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->anthropic==0.71.0->vllm==0.12.0) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic==0.71.0->vllm==0.12.0) (0.16.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.21.1->vllm==0.12.0) (1.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.9.0->vllm==0.12.0) (3.0.3)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.21.1->mistral_common>=1.8.5->mistral_common[image]>=1.8.5->vllm==0.12.0) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.21.1->mistral_common>=1.8.5->mistral_common[image]>=1.8.5->vllm==0.12.0) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.21.1->mistral_common>=1.8.5->mistral_common[image]>=1.8.5->vllm==0.12.0) (0.30.0)\n",
            "Requirement already satisfied: cuda-python>=12.8 in /usr/local/lib/python3.12/dist-packages (from nvidia-cutlass-dsl>=4.2.1->flashinfer-python==0.5.3->vllm==0.12.0) (12.9.5)\n",
            "Requirement already satisfied: pycountry>=23 in /usr/local/lib/python3.12/dist-packages (from pydantic-extra-types[pycountry]>=2.10.5->mistral_common>=1.8.5->mistral_common[image]>=1.8.5->vllm==0.12.0) (24.6.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch==2.9.0->vllm==0.12.0) (1.3.0)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.12.0) (0.7.1)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.12.0) (1.2.1)\n",
            "Requirement already satisfied: uvloop>=0.15.1 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.12.0) (0.22.1)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.12.0) (15.0.1)\n",
            "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.12/dist-packages (from cupy-cuda12x->ray[cgraph]>=2.48.0->vllm==0.12.0) (0.8.3)\n",
            "Requirement already satisfied: cuda-bindings~=12.9.5 in /usr/local/lib/python3.12/dist-packages (from cuda-python>=12.8->nvidia-cutlass-dsl>=4.2.1->flashinfer-python==0.5.3->vllm==0.12.0) (12.9.5)\n",
            "Requirement already satisfied: rignore>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.12.0) (0.7.6)\n",
            "Requirement already satisfied: sentry-sdk>=2.20.0 in /usr/local/lib/python3.12/dist-packages (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.12.0) (2.49.0)\n",
            "Requirement already satisfied: fastar>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.12.0) (0.8.0)\n",
            "Requirement already satisfied: rich>=13.7.1 in /usr/local/lib/python3.12/dist-packages (from rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.12.0) (13.9.4)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.15.1->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.12.0) (1.5.4)\n",
            "Requirement already satisfied: cuda-pathfinder~=1.1 in /usr/local/lib/python3.12/dist-packages (from cuda-bindings~=12.9.5->cuda-python>=12.8->nvidia-cutlass-dsl>=4.2.1->flashinfer-python==0.5.3->vllm==0.12.0) (1.3.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.12.0) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.12.0) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.12.0) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install \\\n",
        "    vllm==0.12.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFI6d95RjNzd"
      },
      "source": [
        "## ðŸš€ ç¬¬ä¸‰æ­¥ï¼šå¯åŠ¨ VLLM æ¨¡åž‹æœåŠ¡\n",
        "\n",
        "çŽ°åœ¨æˆ‘ä»¬å°†ä½¿ç”¨ VLLM åœ¨åŽå°å¯åŠ¨ DeepSeek R1 è’¸é¦ç‰ˆæ¨¡åž‹æœåŠ¡ã€‚\n",
        "\n",
        "### ðŸŽ¯ VLLM æœåŠ¡å¯åŠ¨è¯´æ˜Ž\n",
        "\n",
        "#### ðŸ” æ¨¡åž‹é€‰æ‹©\n",
        "- **æ¨¡åž‹æ¥æº**: [Hugging Face DeepSeek AI](https://huggingface.co/deepseek-ai/DeepSeek-R1#3-model-downloads)\n",
        "- **å½“å‰æ¨¡åž‹**: `deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B`\n",
        "- **å‚æ•°è§„æ¨¡**: 15äº¿å‚æ•°ï¼Œé€‚åˆ T4 GPU è¿è¡Œ\n",
        "- **æ›¿æ¢é€‰é¡¹**: å¯ä»¥æ›¿æ¢ä¸ºå…¶ä»– DeepSeek R1 ç³»åˆ—æ¨¡åž‹\n",
        "\n",
        "#### âš™ï¸ VLLM å‚æ•°è§£é‡Š\n",
        "- `serve`: VLLM çš„æœåŠ¡æ¨¡å¼å‘½ä»¤\n",
        "- `--trust-remote-code`: å…è®¸æ‰§è¡Œè¿œç¨‹ä»£ç ï¼ˆæ¨¡åž‹é…ç½®ï¼‰\n",
        "- `--dtype half`: ä½¿ç”¨åŠç²¾åº¦æµ®ç‚¹æ•°ï¼ŒèŠ‚çœæ˜¾å­˜\n",
        "- `--max-model-len 16384`: æœ€å¤§åºåˆ—é•¿åº¦ä¸º 16K tokens\n",
        "- `--tensor-parallel-size 1`: ä½¿ç”¨å•å¡æŽ¨ç†\n",
        "\n",
        "#### ðŸ”„ åŽå°è¿è¡Œ\n",
        "æ¨¡åž‹å°†åœ¨åŽå°å¯åŠ¨ï¼Œä¸ä¼šé˜»å¡žå½“å‰è¿›ç¨‹ï¼Œè¿™æ ·æˆ‘ä»¬å¯ä»¥ç»§ç»­æ‰§è¡Œå…¶ä»–ä»£ç ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4FjRHNbcFYl",
        "outputId": "dab0cda6-2588-4aa8-e235-67a98fe59dfe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸš€ æ­£åœ¨å¯åŠ¨ VLLM æœåŠ¡ï¼Œæ¨¡åž‹: deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\n",
            "â³ é¦–æ¬¡è¿è¡Œéœ€è¦ä¸‹è½½æ¨¡åž‹ï¼Œè¯·è€å¿ƒç­‰å¾…...\n",
            "âœ… VLLM æœåŠ¡å¯åŠ¨å‘½ä»¤å·²æ‰§è¡Œï¼Œæ­£åœ¨åŽå°åŠ è½½æ¨¡åž‹...\n",
            "ðŸ“¡ æœåŠ¡å°†åœ¨ http://localhost:8000 ä¸Šè¿è¡Œ\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import subprocess\n",
        "\n",
        "# ðŸ“ å¯é€‰ï¼šé…ç½® Hugging Face é•œåƒæº\n",
        "# å¦‚æžœåœ¨ä¸­å›½å¤§é™†è®¿é—® Hugging Face è¾ƒæ…¢ï¼Œå¯ä»¥å¯ç”¨ä¸‹é¢è¿™è¡Œ\n",
        "# os.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com\"\n",
        "\n",
        "# ðŸŽ¯ æ¨¡åž‹é…ç½®\n",
        "# æŒ‡å®šè¦ä½¿ç”¨çš„æ¨¡åž‹åç§°\n",
        "# è¿™é‡Œä½¿ç”¨çš„æ˜¯ DeepSeek R1 çš„è’¸é¦ç‰ˆæœ¬ï¼Œå‚æ•°é‡ä¸º 15äº¿\n",
        "model = 'deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B'\n",
        "\n",
        "# ðŸ”§ å¯åŠ¨ VLLM æœåŠ¡å™¨\n",
        "# ä½¿ç”¨ subprocess.Popen åœ¨åŽå°å¯åŠ¨æœåŠ¡ï¼Œè¿™æ ·ä¸ä¼šé˜»å¡žå½“å‰è¿›ç¨‹\n",
        "print(f\"ðŸš€ æ­£åœ¨å¯åŠ¨ VLLM æœåŠ¡ï¼Œæ¨¡åž‹: {model}\")\n",
        "print(\"â³ é¦–æ¬¡è¿è¡Œéœ€è¦ä¸‹è½½æ¨¡åž‹ï¼Œè¯·è€å¿ƒç­‰å¾…...\")\n",
        "\n",
        "vllm_process = subprocess.Popen([\n",
        "    'vllm',                      # VLLM å‘½ä»¤\n",
        "    'serve',                     # æœåŠ¡æ¨¡å¼\n",
        "    model,                       # æ¨¡åž‹åç§°\n",
        "    '--trust-remote-code',       # ä¿¡ä»»è¿œç¨‹ä»£ç \n",
        "    '--dtype', 'half',           # ä½¿ç”¨åŠç²¾åº¦æµ®ç‚¹æ•°\n",
        "    '--max-model-len', '4096',  # æœ€å¤§åºåˆ—é•¿åº¦\n",
        "    '--tensor-parallel-size', '1', # å•å¡æŽ¨ç†\n",
        "    '--gpu-memory-utilization', '0.72' # é™ä½Ž GPU å†…å­˜ä½¿ç”¨çŽ‡\n",
        "], stdout=subprocess.PIPE, stderr=subprocess.PIPE, start_new_session=True)\n",
        "\n",
        "print(\"âœ… VLLM æœåŠ¡å¯åŠ¨å‘½ä»¤å·²æ‰§è¡Œï¼Œæ­£åœ¨åŽå°åŠ è½½æ¨¡åž‹...\")\n",
        "print(\"ðŸ“¡ æœåŠ¡å°†åœ¨ http://localhost:8000 ä¸Šè¿è¡Œ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCR-O8i9lEbb"
      },
      "source": [
        "## ðŸ” ç¬¬å››æ­¥ï¼šç›‘æŽ§ vLLM æœåŠ¡çŠ¶æ€\n",
        "\n",
        "ç”±äºŽ vLLM åœ¨åŽå°è¿è¡Œï¼Œæˆ‘ä»¬éœ€è¦ç›‘æŽ§å…¶å¯åŠ¨çŠ¶æ€ã€‚\n",
        "\n",
        "### ðŸŽ¯ ç›‘æŽ§çš„é‡è¦æ€§\n",
        "\n",
        "#### ðŸ”„ ä¸ºä»€ä¹ˆéœ€è¦ç›‘æŽ§ï¼Ÿ\n",
        "- **å¼‚æ­¥å¯åŠ¨**: vLLM åœ¨åŽå°å¯åŠ¨ï¼Œéœ€è¦æ—¶é—´åŠ è½½æ¨¡åž‹\n",
        "- **çŠ¶æ€ç¡®è®¤**: ç¡®ä¿æœåŠ¡æ­£å¸¸è¿è¡ŒåŽå†è¿›è¡ŒåŽç»­æ“ä½œ\n",
        "- **é”™è¯¯è¯Šæ–­**: åŠæ—¶å‘çŽ°å’Œå¤„ç†å¯åŠ¨è¿‡ç¨‹ä¸­çš„é—®é¢˜\n",
        "- **èµ„æºç®¡ç†**: ç›‘æŽ§è¿›ç¨‹çŠ¶æ€ï¼Œé¿å…èµ„æºæ³„æ¼\n",
        "\n",
        "#### â±ï¸ å¯åŠ¨æ—¶é—´è¯´æ˜Ž\n",
        "- **é¦–æ¬¡è¿è¡Œ**: éœ€è¦ä¸‹è½½æ¨¡åž‹æ–‡ä»¶ï¼Œå¯èƒ½éœ€è¦ 5-10 åˆ†é’Ÿ\n",
        "- **åŽç»­è¿è¡Œ**: æ¨¡åž‹å·²ç¼“å­˜ï¼Œå¯åŠ¨æ—¶é—´çº¦ 1-2 åˆ†é’Ÿ\n",
        "- **æ£€æŸ¥é¢‘çŽ‡**: æ¯ 5 ç§’æ£€æŸ¥ä¸€æ¬¡æœåŠ¡çŠ¶æ€\n",
        "\n",
        "#### ðŸš¦ çŠ¶æ€æ£€æŸ¥æœºåˆ¶\n",
        "- **å¥åº·æ£€æŸ¥**: é€šè¿‡ HTTP è¯·æ±‚æ£€æŸ¥æœåŠ¡æ˜¯å¦å¯ç”¨\n",
        "- **è¿›ç¨‹ç›‘æŽ§**: ç›‘æŽ§ vLLM è¿›ç¨‹çš„è¿è¡ŒçŠ¶æ€\n",
        "- **æ—¥å¿—è¾“å‡º**: æ˜¾ç¤ºå¯åŠ¨è¿‡ç¨‹ä¸­çš„å…³é”®ä¿¡æ¯"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "bx5v9mXkvqPo"
      },
      "outputs": [],
      "source": [
        "# ðŸ” VLLM æœåŠ¡ç›‘æŽ§å‡½æ•°\n",
        "#\n",
        "# è¿™ä¸ªå•å…ƒæ ¼å®šä¹‰äº†ä¸¤ä¸ªé‡è¦çš„ç›‘æŽ§å‡½æ•°ï¼š\n",
        "# 1. check_vllm_status: æ£€æŸ¥ VLLM æœåŠ¡æ˜¯å¦å¯ç”¨\n",
        "# 2. monitor_vllm_process: æŒç»­ç›‘æŽ§ VLLM è¿›ç¨‹çŠ¶æ€\n",
        "\n",
        "import requests\n",
        "import time\n",
        "from typing import Tuple\n",
        "import sys\n",
        "\n",
        "def check_vllm_status(url: str = \"http://localhost:8000/health\") -> bool:\n",
        "    \"\"\"\n",
        "    ðŸ¥ æ£€æŸ¥ VLLM æœåŠ¡å™¨å¥åº·çŠ¶æ€\n",
        "\n",
        "    å‚æ•°:\n",
        "        url: å¥åº·æ£€æŸ¥çš„ URL åœ°å€\n",
        "\n",
        "    è¿”å›ž:\n",
        "        bool: True è¡¨ç¤ºæœåŠ¡æ­£å¸¸ï¼ŒFalse è¡¨ç¤ºæœåŠ¡ä¸å¯ç”¨\n",
        "\n",
        "    å·¥ä½œåŽŸç†:\n",
        "        å‘ VLLM çš„å¥åº·æ£€æŸ¥ç«¯ç‚¹å‘é€ GET è¯·æ±‚\n",
        "        å¦‚æžœè¿”å›ž 200 çŠ¶æ€ç ï¼Œè¯´æ˜ŽæœåŠ¡æ­£å¸¸è¿è¡Œ\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = requests.get(url, timeout=5)\n",
        "        return response.status_code == 200\n",
        "    except requests.exceptions.ConnectionError:\n",
        "        return False\n",
        "    except requests.exceptions.Timeout:\n",
        "        return False\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "def monitor_vllm_process(vllm_process: subprocess.Popen, check_interval: int = 5) -> Tuple[bool, str, str]:\n",
        "    \"\"\"\n",
        "    ðŸ“Š ç›‘æŽ§ VLLM è¿›ç¨‹çš„å¯åŠ¨çŠ¶æ€\n",
        "\n",
        "    å‚æ•°:\n",
        "        vllm_process: VLLM è¿›ç¨‹å¯¹è±¡\n",
        "        check_interval: æ£€æŸ¥é—´éš”æ—¶é—´ï¼ˆç§’ï¼‰\n",
        "\n",
        "    è¿”å›ž:\n",
        "        Tuple[bool, str, str]: (æ˜¯å¦æˆåŠŸ, æ ‡å‡†è¾“å‡º, æ ‡å‡†é”™è¯¯)\n",
        "\n",
        "    å·¥ä½œæµç¨‹:\n",
        "        1. å¾ªçŽ¯æ£€æŸ¥è¿›ç¨‹æ˜¯å¦è¿˜åœ¨è¿è¡Œ\n",
        "        2. å®šæœŸæ£€æŸ¥æœåŠ¡å¥åº·çŠ¶æ€\n",
        "        3. è¾“å‡ºè¿›ç¨‹çš„æ—¥å¿—ä¿¡æ¯\n",
        "        4. è¿”å›žæœ€ç»ˆçŠ¶æ€\n",
        "    \"\"\"\n",
        "    print(\"ðŸ” å¼€å§‹ VLLM æœåŠ¡å™¨ç›‘æŽ§...\")\n",
        "    print(\"â³ æ­£åœ¨ç­‰å¾…æœåŠ¡å¯åŠ¨ï¼Œè¯·è€å¿ƒç­‰å¾…...\")\n",
        "\n",
        "    while vllm_process.poll() is None:  # å½“è¿›ç¨‹ä»åœ¨è¿è¡Œæ—¶\n",
        "        # æ£€æŸ¥æœåŠ¡æ˜¯å¦å·²ç»å¯ç”¨\n",
        "        if check_vllm_status():\n",
        "            print(\"âœ… VLLM æœåŠ¡å™¨å·²å¯åŠ¨å¹¶è¿è¡Œï¼\")\n",
        "            print(\"ðŸŽ‰ æœåŠ¡åœ°å€: http://localhost:8000\")\n",
        "            return True, \"\", \"\"\n",
        "\n",
        "        print(\"â³ ç­‰å¾… VLLM æœåŠ¡å™¨å¯åŠ¨...\")\n",
        "        time.sleep(check_interval)\n",
        "\n",
        "        # æ£€æŸ¥å¹¶è¾“å‡ºè¿›ç¨‹æ—¥å¿—\n",
        "        if vllm_process.stdout and vllm_process.stdout.readable():\n",
        "            try:\n",
        "                stdout = vllm_process.stdout.read1(1024).decode('utf-8')\n",
        "                if stdout.strip():\n",
        "                    print(\"ðŸ“ æ ‡å‡†è¾“å‡º:\", stdout.strip())\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "        if vllm_process.stderr and vllm_process.stderr.readable():\n",
        "            try:\n",
        "                stderr = vllm_process.stderr.read1(1024).decode('utf-8')\n",
        "                if stderr.strip():\n",
        "                    print(\"âš ï¸ æ ‡å‡†é”™è¯¯:\", stderr.strip())\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "    # å¦‚æžœåˆ°è¾¾è¿™é‡Œï¼Œè¿›ç¨‹å·²ç»“æŸï¼ˆå¯èƒ½æ˜¯é”™è¯¯ï¼‰\n",
        "    print(\"âŒ VLLM è¿›ç¨‹å·²ç»“æŸ\")\n",
        "    try:\n",
        "        stdout, stderr = vllm_process.communicate(timeout=5)\n",
        "        return False, stdout.decode('utf-8'), stderr.decode('utf-8')\n",
        "    except Exception:\n",
        "        return False, \"\", \"è¿›ç¨‹é€šä¿¡è¶…æ—¶\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEbWUS2nvRJo",
        "outputId": "949efbe9-843e-4f60-ab08-06db953e210e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸŽ¯ å¼€å§‹ç›‘æŽ§ VLLM æœåŠ¡å¯åŠ¨çŠ¶æ€...\n",
            "ðŸ’¡ æç¤ºï¼šé¦–æ¬¡è¿è¡Œå¯èƒ½éœ€è¦ 5-10 åˆ†é’Ÿä¸‹è½½æ¨¡åž‹\n",
            "âŒ¨ï¸  æŒ‰ Ctrl+C å¯ä»¥ä¸­æ–­ç›‘æŽ§ï¼ˆä½†ä¸ä¼šåœæ­¢ VLLM æœåŠ¡ï¼‰\n",
            "ðŸ” å¼€å§‹ VLLM æœåŠ¡å™¨ç›‘æŽ§...\n",
            "â³ æ­£åœ¨ç­‰å¾…æœåŠ¡å¯åŠ¨ï¼Œè¯·è€å¿ƒç­‰å¾…...\n",
            "âœ… VLLM æœåŠ¡å™¨å·²å¯åŠ¨å¹¶è¿è¡Œï¼\n",
            "ðŸŽ‰ æœåŠ¡åœ°å€: http://localhost:8000\n",
            "\n",
            "ðŸŽ‰ VLLM æœåŠ¡å¯åŠ¨æˆåŠŸï¼\n",
            "ðŸ“¡ API æœåŠ¡åœ°å€: http://localhost:8000\n",
            "ðŸ“š API æ–‡æ¡£åœ°å€: http://localhost:8000/docs\n",
            "âœ… çŽ°åœ¨å¯ä»¥ç»§ç»­è¿è¡ŒåŽç»­å•å…ƒæ ¼\n"
          ]
        }
      ],
      "source": [
        "# ðŸš€ æ‰§è¡Œ VLLM æœåŠ¡ç›‘æŽ§\n",
        "#\n",
        "# è¿™ä¸ªå•å…ƒæ ¼çš„ä½œç”¨ï¼š\n",
        "# 1. è°ƒç”¨ç›‘æŽ§å‡½æ•°ï¼Œç­‰å¾… VLLM æœåŠ¡å¯åŠ¨\n",
        "# 2. å¤„ç†å¯åŠ¨æˆåŠŸå’Œå¤±è´¥çš„æƒ…å†µ\n",
        "# 3. æ”¯æŒç”¨æˆ·ä¸­æ–­æ“ä½œ\n",
        "\n",
        "print(\"ðŸŽ¯ å¼€å§‹ç›‘æŽ§ VLLM æœåŠ¡å¯åŠ¨çŠ¶æ€...\")\n",
        "print(\"ðŸ’¡ æç¤ºï¼šé¦–æ¬¡è¿è¡Œå¯èƒ½éœ€è¦ 5-10 åˆ†é’Ÿä¸‹è½½æ¨¡åž‹\")\n",
        "print(\"âŒ¨ï¸  æŒ‰ Ctrl+C å¯ä»¥ä¸­æ–­ç›‘æŽ§ï¼ˆä½†ä¸ä¼šåœæ­¢ VLLM æœåŠ¡ï¼‰\")\n",
        "\n",
        "try:\n",
        "    # è°ƒç”¨ç›‘æŽ§å‡½æ•°ï¼Œç­‰å¾…æœåŠ¡å¯åŠ¨\n",
        "    success, stdout, stderr = monitor_vllm_process(vllm_process)\n",
        "\n",
        "    if not success:\n",
        "        print(\"\\nâŒ VLLM æœåŠ¡å™¨å¯åŠ¨å¤±è´¥ï¼\")\n",
        "        print(\"\\nðŸ“‹ å®Œæ•´æ ‡å‡†è¾“å‡º:\")\n",
        "        print(stdout)\n",
        "        print(\"\\nðŸš¨ å®Œæ•´æ ‡å‡†é”™è¯¯:\")\n",
        "        print(stderr)\n",
        "        print(\"\\nðŸ”§ å¯èƒ½çš„è§£å†³æ–¹æ¡ˆ:\")\n",
        "        print(\"1. æ£€æŸ¥ GPU å†…å­˜æ˜¯å¦è¶³å¤Ÿ\")\n",
        "        print(\"2. ç¡®è®¤æ¨¡åž‹åç§°æ˜¯å¦æ­£ç¡®\")\n",
        "        print(\"3. é‡æ–°è¿è¡Œå®‰è£…ä¾èµ–åŒ…çš„å•å…ƒæ ¼\")\n",
        "        sys.exit(1)\n",
        "    else:\n",
        "        print(\"\\nðŸŽ‰ VLLM æœåŠ¡å¯åŠ¨æˆåŠŸï¼\")\n",
        "        print(\"ðŸ“¡ API æœåŠ¡åœ°å€: http://localhost:8000\")\n",
        "        print(\"ðŸ“š API æ–‡æ¡£åœ°å€: http://localhost:8000/docs\")\n",
        "        print(\"âœ… çŽ°åœ¨å¯ä»¥ç»§ç»­è¿è¡ŒåŽç»­å•å…ƒæ ¼\")\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    print(\"\\nâš ï¸ ç”¨æˆ·ä¸­æ–­ç›‘æŽ§\")\n",
        "    print(\"ðŸ’¡ æ³¨æ„ï¼šVLLM æœåŠ¡ä»åœ¨åŽå°è¿è¡Œ\")\n",
        "    print(\"ðŸ”„ å¦‚æžœéœ€è¦åœæ­¢ VLLM æœåŠ¡ï¼Œè¯·é‡å¯ Colab è¿è¡Œæ—¶\")\n",
        "\n",
        "    # å¯é€‰ï¼šå¼ºåˆ¶åœæ­¢ VLLM è¿›ç¨‹\n",
        "    # å–æ¶ˆä¸‹é¢çš„æ³¨é‡Šå¯ä»¥åœ¨ä¸­æ–­æ—¶åœæ­¢æœåŠ¡\n",
        "    # print(\"ðŸ›‘ æ­£åœ¨åœæ­¢ VLLM æœåŠ¡...\")\n",
        "    # vllm_process.terminate()\n",
        "    # try:\n",
        "    #     vllm_process.wait(timeout=5)\n",
        "    #     print(\"âœ… VLLM æœåŠ¡å·²åœæ­¢\")\n",
        "    # except subprocess.TimeoutExpired:\n",
        "    #     vllm_process.kill()\n",
        "    #     print(\"âš¡ å¼ºåˆ¶ç»ˆæ­¢ VLLM æœåŠ¡\")\n",
        "\n",
        "    # è¾“å‡ºæœ€ç»ˆæ—¥å¿—ä¿¡æ¯\n",
        "    try:\n",
        "        stdout, stderr = vllm_process.communicate(timeout=2)\n",
        "        if stdout:\n",
        "            print(\"\\nðŸ“ æœ€ç»ˆæ ‡å‡†è¾“å‡º:\")\n",
        "            print(stdout.decode('utf-8'))\n",
        "        if stderr:\n",
        "            print(\"\\nâš ï¸ æœ€ç»ˆæ ‡å‡†é”™è¯¯:\")\n",
        "            print(stderr.decode('utf-8'))\n",
        "    except:\n",
        "        print(\"ðŸ“ æ— æ³•èŽ·å–æœ€ç»ˆæ—¥å¿—\")\n",
        "\n",
        "    sys.exit(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ” ç¬¬äº”æ­¥ï¼šå¤§æ¨¡åž‹æŽ¨ç†æµ‹è¯•"
      ],
      "metadata": {
        "id": "qXKr58eBeBx3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Qb6UVM067WHp"
      },
      "outputs": [],
      "source": [
        "# ðŸ§ª æ¨¡åž‹æŽ¨ç†æµ‹è¯•å‡½æ•°\n",
        "#\n",
        "# è¿™ä¸ªå•å…ƒæ ¼å®šä¹‰äº†ä¸¤ä¸ªæ ¸å¿ƒå‡½æ•°ï¼š\n",
        "# 1. ask_model: å‘é€é—®é¢˜å¹¶èŽ·å–å®Œæ•´å›žç­”\n",
        "# 2. stream_llm_response: å®žçŽ°æµå¼å“åº”åŠŸèƒ½\n",
        "\n",
        "import requests\n",
        "import json\n",
        "from fastapi import FastAPI, HTTPException\n",
        "from pydantic import BaseModel\n",
        "from fastapi.responses import StreamingResponse\n",
        "\n",
        "# ðŸ“ å®šä¹‰è¯·æ±‚æ•°æ®æ¨¡åž‹\n",
        "class QuestionRequest(BaseModel):\n",
        "    \"\"\"\n",
        "    API è¯·æ±‚çš„æ•°æ®æ¨¡åž‹\n",
        "\n",
        "    å±žæ€§:\n",
        "        question (str): ç”¨æˆ·æå‡ºçš„é—®é¢˜\n",
        "\n",
        "    è¯´æ˜Ž:\n",
        "        ä½¿ç”¨ Pydantic æ¨¡åž‹ç¡®ä¿æ•°æ®ç±»åž‹å®‰å…¨\n",
        "        åŽç»­ FastAPI ä¼šè‡ªåŠ¨éªŒè¯è¯·æ±‚æ•°æ®\n",
        "    \"\"\"\n",
        "    question: str\n",
        "\n",
        "def ask_model(question: str):\n",
        "    \"\"\"\n",
        "    ðŸ¤– å‘ VLLM æ¨¡åž‹å‘é€é—®é¢˜å¹¶èŽ·å–å®Œæ•´å›žç­”\n",
        "\n",
        "    å‚æ•°:\n",
        "        question (str): ç”¨æˆ·æå‡ºçš„é—®é¢˜\n",
        "\n",
        "    è¿”å›ž:\n",
        "        dict: åŒ…å«æ¨¡åž‹å›žç­”çš„ JSON å“åº”\n",
        "\n",
        "    å·¥ä½œæµç¨‹:\n",
        "        1. æž„é€ ç¬¦åˆ OpenAI API æ ¼å¼çš„è¯·æ±‚\n",
        "        2. å‘é€ POST è¯·æ±‚åˆ° VLLM æœåŠ¡\n",
        "        3. å¤„ç†å“åº”å¹¶è¿”å›žç»“æžœ\n",
        "    \"\"\"\n",
        "    # VLLM çš„ OpenAI å…¼å®¹ API ç«¯ç‚¹\n",
        "    url = \"http://localhost:8000/v1/chat/completions\"\n",
        "\n",
        "    # è®¾ç½®è¯·æ±‚å¤´\n",
        "    headers = {\"Content-Type\": \"application/json\"}\n",
        "\n",
        "    # æž„é€ è¯·æ±‚æ•°æ®ï¼ˆOpenAI æ ¼å¼ï¼‰\n",
        "    data = {\n",
        "        \"model\": model,  # ä½¿ç”¨å…¨å±€æ¨¡åž‹å˜é‡\n",
        "        \"messages\": [\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": question\n",
        "            }\n",
        "        ],\n",
        "        \"max_tokens\": 2048,  # æœ€å¤§ç”Ÿæˆé•¿åº¦\n",
        "        \"temperature\": 0.7,  # ç”Ÿæˆçš„éšæœºæ€§\n",
        "        \"top_p\": 0.9         # æ ¸é‡‡æ ·å‚æ•°\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        # å‘é€è¯·æ±‚\n",
        "        response = requests.post(url, headers=headers, json=data, timeout=60)\n",
        "        response.raise_for_status()  # æ£€æŸ¥ HTTP é”™è¯¯\n",
        "        return response.json()\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"âŒ è¯·æ±‚å¤±è´¥: {e}\")\n",
        "        return None\n",
        "\n",
        "def stream_llm_response(question: str):\n",
        "    \"\"\"\n",
        "    ðŸŒŠ æµå¼å“åº”ç”Ÿæˆå™¨ - å®žæ—¶èŽ·å–æ¨¡åž‹è¾“å‡º\n",
        "\n",
        "    å‚æ•°:\n",
        "        question (str): ç”¨æˆ·æå‡ºçš„é—®é¢˜\n",
        "\n",
        "    ç”Ÿæˆ:\n",
        "        str: é€è¡Œè¿”å›žæ¨¡åž‹çš„ç”Ÿæˆå†…å®¹\n",
        "\n",
        "    ç‰¹ç‚¹:\n",
        "        - å®žæ—¶æ˜¾ç¤ºç”Ÿæˆè¿‡ç¨‹\n",
        "        - é™ä½Žç­‰å¾…æ—¶é—´\n",
        "        - æä¾›æ›´å¥½çš„ç”¨æˆ·ä½“éªŒ\n",
        "    \"\"\"\n",
        "    url = \"http://localhost:8000/v1/chat/completions\"\n",
        "    headers = {\"Content-Type\": \"application/json\"}\n",
        "\n",
        "    # å¯ç”¨æµå¼ä¼ è¾“\n",
        "    data = {\n",
        "        \"model\": model,\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": question}],\n",
        "        \"stream\": True,      # ðŸ”¥ å…³é”®ï¼šå¯ç”¨æµå¼ä¼ è¾“\n",
        "        \"max_tokens\": 2048,\n",
        "        \"temperature\": 0.7\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        with requests.post(url, headers=headers, json=data, stream=True, timeout=60) as response:\n",
        "            response.raise_for_status()\n",
        "\n",
        "            for line in response.iter_lines():\n",
        "                if line:\n",
        "                    # OpenAI é£Žæ ¼çš„æµå¼å“åº”ä»¥ \"data: \" ä¸ºå‰ç¼€\n",
        "                    decoded_line = line.decode(\"utf-8\")\n",
        "                    if decoded_line.startswith(\"data: \"):\n",
        "                        decoded_line = decoded_line[6:]  # ç§»é™¤ \"data: \" å‰ç¼€\n",
        "                    yield decoded_line + \"\\n\"\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        yield f\"âŒ æµå¼è¯·æ±‚å¤±è´¥: {e}\\n\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸ§ª æµ‹è¯•åŸºç¡€æŽ¨ç†åŠŸèƒ½\n",
        "print(\"ðŸ§ª æµ‹è¯•æ¨¡åž‹æŽ¨ç†åŠŸèƒ½...\")\n",
        "print(\"ðŸ“ å‘é€æµ‹è¯•é—®é¢˜: æˆ‘æ˜¯ä¸€åJavaåŽç«¯å·¥ç¨‹å¸ˆï¼Œæœ‰5å¹´å·¥ä½œç»åŽ†ï¼Œå¸®æˆ‘åˆ¶å®šä¸€ä»½Agentic AIå­¦ä¹ è®¡åˆ’\")\n",
        "\n",
        "try:\n",
        "    result = ask_model(\"æˆ‘æ˜¯ä¸€åJavaåŽç«¯å·¥ç¨‹å¸ˆï¼Œæœ‰5å¹´å·¥ä½œç»åŽ†ï¼Œå¸®æˆ‘åˆ¶å®šä¸€ä»½Agentic AIå­¦ä¹ è®¡åˆ’\")\n",
        "    if result:\n",
        "        print(\"\\nâœ… æ¨¡åž‹æŽ¨ç†æˆåŠŸï¼\")\n",
        "        print(\"ðŸ“‹ å®Œæ•´å“åº”:\")\n",
        "        print(json.dumps(result, indent=2, ensure_ascii=False))\n",
        "\n",
        "        # æå–å¹¶æ˜¾ç¤ºæ¨¡åž‹å›žç­”\n",
        "        if \"choices\" in result and len(result[\"choices\"]) > 0:\n",
        "            answer = result[\"choices\"][0][\"message\"][\"content\"]\n",
        "            print(f\"\\nðŸ¤– æ¨¡åž‹å›žç­”: {answer}\")\n",
        "    else:\n",
        "        print(\"âŒ æ¨¡åž‹æŽ¨ç†å¤±è´¥\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºçŽ°é”™è¯¯: {e}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"âœ… æŽ¨ç†å‡½æ•°å®šä¹‰å®Œæˆï¼Œå¯ä»¥ç»§ç»­ä¸‹ä¸€æ­¥ï¼\")"
      ],
      "metadata": {
        "id": "aCiksCeV8pvo",
        "outputId": "78ce0973-81d1-4efb-b00f-edbc6b61962f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ§ª æµ‹è¯•æ¨¡åž‹æŽ¨ç†åŠŸèƒ½...\n",
            "ðŸ“ å‘é€æµ‹è¯•é—®é¢˜: æˆ‘æ˜¯ä¸€åJavaåŽç«¯å·¥ç¨‹å¸ˆï¼Œæœ‰5å¹´å·¥ä½œç»åŽ†ï¼Œå¸®æˆ‘åˆ¶å®šä¸€ä»½Agentic AIå­¦ä¹ è®¡åˆ’\n",
            "\n",
            "âœ… æ¨¡åž‹æŽ¨ç†æˆåŠŸï¼\n",
            "ðŸ“‹ å®Œæ•´å“åº”:\n",
            "{\n",
            "  \"id\": \"chatcmpl-9d0d3353ef9e8087\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"created\": 1769156771,\n",
            "  \"model\": \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"index\": 0,\n",
            "      \"message\": {\n",
            "        \"role\": \"assistant\",\n",
            "        \"content\": \"å¥½ï¼Œæˆ‘çŽ°åœ¨éœ€è¦å¸®è¿™ä½JavaåŽç«¯å·¥ç¨‹å¸ˆåˆ¶å®šä¸€ä»½Agentic AIå­¦ä¹ è®¡åˆ’ã€‚é¦–å…ˆï¼Œæˆ‘å¾—äº†è§£Agentic AIæ˜¯ä»€ä¹ˆï¼Œå®ƒä¸»è¦æ¶‰åŠå“ªäº›é¢†åŸŸï¼Œæ¯”å¦‚æ·±åº¦å­¦ä¹ ã€å¼ºåŒ–å­¦ä¹ ã€NLPç­‰ç­‰ã€‚ç„¶åŽï¼Œè€ƒè™‘åˆ°è¿™ä½å·¥ç¨‹å¸ˆæœ‰5å¹´çš„JavaåŽç«¯ç»éªŒï¼Œå¯èƒ½å¯¹å‰ç«¯æœ‰ä¸€å®šçš„äº†è§£ï¼Œä½†å¯èƒ½éœ€è¦æ›´æ·±å…¥çš„å­¦ä¹ ã€‚\\n\\næŽ¥ä¸‹æ¥ï¼Œæˆ‘åº”è¯¥åˆ†é˜¶æ®µæ¥è§„åˆ’å­¦ä¹ å†…å®¹ã€‚ç¬¬ä¸€é˜¶æ®µå¯èƒ½éœ€è¦åŸºç¡€çš„Pythonå’ŒJavaï¼Œè¿™æ ·åŽé¢çš„å­¦ä¹ æ‰èƒ½è·Ÿä¸Šã€‚ç¬¬äºŒé˜¶æ®µå¯ä»¥æ·±å…¥å­¦ä¹ æœºå™¨å­¦ä¹ ï¼ŒåŒ…æ‹¬æ·±åº¦å­¦ä¹ å’Œå¼ºåŒ–å­¦ä¹ ï¼Œç¬¬ä¸‰é˜¶æ®µæ˜¯NLPå’Œè®¡ç®—æœºè§†è§‰ï¼Œç¬¬å››é˜¶æ®µæ˜¯åº”ç”¨ï¼Œæ¯”å¦‚TensorFlowå’ŒPyTorchçš„ä½¿ç”¨ï¼Œç¬¬äº”é˜¶æ®µæ˜¯é¡¹ç›®å®žæˆ˜ï¼Œæœ€åŽæ˜¯æŒç»­å­¦ä¹ å’Œå®žè·µã€‚\\n\\nå¯èƒ½ç”¨æˆ·å¯¹Agentic AIçš„å…·ä½“é¢†åŸŸä¸å¤ªäº†è§£ï¼Œæ‰€ä»¥éœ€è¦æ˜Žç¡®ä»–ä»¬éœ€è¦å­¦ä¹ çš„é‡ç‚¹ã€‚æ¯”å¦‚ï¼Œå¦‚æžœä»–ä»¬æƒ³åšNLPï¼Œé‚£ä¹ˆè¯æ±‡è¡¨ã€é¢„å¤„ç†ã€æ¨¡åž‹è®­ç»ƒç­‰éƒ½æ˜¯é‡ç‚¹ï¼›å¦‚æžœæ˜¯è®¡ç®—æœºè§†è§‰ï¼Œå¯èƒ½éœ€è¦å›¾åƒå¤„ç†ã€æ•°æ®å¢žå¼ºã€æ¨¡åž‹ä¼˜åŒ–ç­‰ã€‚\\n\\nå¦å¤–ï¼Œè€ƒè™‘åˆ°ä»–ä»¬åœ¨JavaåŽç«¯ï¼Œå¯èƒ½éœ€è¦åœ¨é¡¹ç›®ä¸­ä½¿ç”¨Javaï¼Œä½†Agentic AIæ›´å¤šæ˜¯åŸºäºŽPythonçš„ï¼Œæ‰€ä»¥å¯èƒ½éœ€è¦æŽ¨èä»–ä»¬å­¦ä¹ Pythonçš„å·¥å…·å’Œåº“ï¼Œæ¯”å¦‚TensorFlowã€PyTorchã€NumPyç­‰ã€‚\\n\\næœ€åŽï¼Œå­¦ä¹ è®¡åˆ’éœ€è¦æœ‰æ—¶é—´å®‰æŽ’ï¼Œåˆ†é˜¶æ®µå­¦ä¹ ï¼Œæ¯å‘¨å­¦ä¹ å¤šå°‘å†…å®¹ï¼Œè¿˜æœ‰å®žè·µé¡¹ç›®çš„æ—¶é—´ï¼Œç¡®ä¿ä»–ä»¬æœ‰è¶³å¤Ÿçš„å®žè·µæ¥å·©å›ºçŸ¥è¯†ã€‚åŒæ—¶ï¼Œå¯èƒ½è¿˜éœ€è¦æŽ¨èä¸€äº›èµ„æºï¼Œæ¯”å¦‚ä¹¦ç±ã€åœ¨çº¿è¯¾ç¨‹ã€æ–‡æ¡£å’Œç¤¾åŒºæ”¯æŒï¼Œè¿™æ ·ä»–ä»¬èƒ½æ›´å¥½åœ°å­¦ä¹ å’Œè§£å†³é—®é¢˜ã€‚\\n\\næ€»çš„æ¥è¯´ï¼Œæˆ‘éœ€è¦å…ˆåˆ—å‡ºAgentic AIçš„æ ¸å¿ƒé¢†åŸŸï¼Œæ ¹æ®ç”¨æˆ·çš„å…·ä½“éœ€æ±‚è°ƒæ•´é˜¶æ®µå’Œå†…å®¹ï¼Œç¡®ä¿å­¦ä¹ è®¡åˆ’å…¨é¢ä¸”æœ‰æ¡ç†ï¼ŒåŒæ—¶è€ƒè™‘ä»–ä»¬çš„JavaèƒŒæ™¯ï¼Œè®©ä»–ä»¬èƒ½å¤Ÿé¡ºåˆ©è¿‡æ¸¡åˆ°ä½¿ç”¨Agentic AIçš„æŠ€æœ¯æ ˆã€‚\\n</think>\\n\\n### Agentic AIå­¦ä¹ è®¡åˆ’\\n\\n#### ç¬¬ä¸€é˜¶æ®µï¼šåŸºç¡€Pythonå’ŒJavaå­¦ä¹ \\n**ç›®æ ‡ï¼š** ç¡®ä¿ä½ æŽŒæ¡Pythonå’ŒJavaçš„åŸºç¡€çŸ¥è¯†ï¼Œä¸ºåŽç»­å­¦ä¹ Agentic AIæ‰“ä¸‹åšå®žåŸºç¡€ã€‚\\n\\n**è¯¾ç¨‹æŽ¨èï¼š**\\n1. **PythonåŸºç¡€ï¼š**  \\n   - \\\"Pythonç¼–ç¨‹åŸºç¡€\\\"ï¼šæŽŒæ¡Pythonçš„åŸºæœ¬è¯­æ³•ã€æ•°æ®ç»“æž„ã€å‡½æ•°å’Œå¾ªçŽ¯ã€‚\\n   - \\\"Pythonè¿›é˜¶\\\"ï¼šæ·±å…¥å­¦ä¹ Pythonçš„é«˜çº§åŠŸèƒ½ã€ç±»ã€æ–‡ä»¶æ“ä½œå’Œæ•°æ®æµã€‚\\n\\n2. **JavaåŸºç¡€ï¼š**  \\n   - \\\"Javaç¼–ç¨‹åŸºç¡€\\\"ï¼šç†Ÿæ‚‰Javaçš„ç±»ã€å¯¹è±¡ã€äº‹ä»¶å¾ªçŽ¯å’ŒåŸºæœ¬ç»“æž„ã€‚\\n   - \\\"Javaé«˜çº§ç¼–ç¨‹\\\"ï¼šå­¦ä¹ Javaé¢å‘å¯¹è±¡ç¼–ç¨‹å’Œé¢å‘åè®®è®¾è®¡ã€‚\\n\\n**å­¦ä¹ æ—¶é—´ï¼š** 2å‘¨\\n\\n**å­¦ä¹ å†…å®¹ï¼š**\\n- åŸºæœ¬çš„Pythonè¯­æ³•å’Œæ•°æ®ç»“æž„ã€‚\\n- Javaä¸­çš„ç±»å’Œå¯¹è±¡è®¾è®¡ã€‚\\n- åŸºæœ¬çš„æ–‡ä»¶æ“ä½œå’Œè¾“å…¥è¾“å‡ºã€‚\\n\\n#### ç¬¬äºŒé˜¶æ®µï¼šæœºå™¨å­¦ä¹ åŸºç¡€ä¸Žæ·±åº¦å­¦ä¹ \\n**ç›®æ ‡ï¼š** äº†è§£æœºå™¨å­¦ä¹ çš„åŸºæœ¬æ¦‚å¿µå’Œæ·±åº¦å­¦ä¹ çš„åŸºæœ¬åŽŸç†ï¼Œä¸ºåŽç»­å­¦ä¹ Agentic AIåšå‡†å¤‡ã€‚\\n\\n**è¯¾ç¨‹æŽ¨èï¼š**\\n1. **æœºå™¨å­¦ä¹ åŸºç¡€ï¼š**  \\n   - \\\"æœºå™¨å­¦ä¹ åŸºç¡€\\\"ï¼šæ¶µç›–çº¿æ€§å›žå½’ã€é€»è¾‘å›žå½’ã€å†³ç­–æ ‘å’Œèšç±»åˆ†æžã€‚\\n   - \\\"æœºå™¨å­¦ä¹ é«˜çº§\\\"ï¼šæ·±å…¥å­¦ä¹ ç¥žç»ç½‘ç»œã€æ”¯æŒå‘é‡æœºã€å¼ºåŒ–å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ ã€‚\\n\\n2. **æ·±åº¦å­¦ä¹ ï¼š**  \\n   - \\\"æ·±åº¦å­¦ä¹ å…¥é—¨\\\"ï¼šå­¦ä¹ åŸºæœ¬çš„æ·±åº¦å­¦ä¹ æ¡†æž¶å¦‚TensorFlowå’ŒKerasã€‚\\n   - \\\"æ·±åº¦å­¦ä¹ è¿›é˜¶\\\"ï¼šæŽŒæ¡å¤æ‚çš„ç¥žç»ç½‘ç»œæž¶æž„ï¼Œå¦‚CNNå’ŒRNNã€‚\\n\\n**å­¦ä¹ æ—¶é—´ï¼š** 3å‘¨\\n\\n**å­¦ä¹ å†…å®¹ï¼š**\\n- æœºå™¨å­¦ä¹ çš„åŸºæœ¬ç®—æ³•å’Œåº”ç”¨åœºæ™¯ã€‚\\n- æ·±åº¦å­¦ä¹ çš„åŸºç¡€çŸ¥è¯†å’Œå…·ä½“æ¨¡åž‹ã€‚\\n\\n#### ç¬¬ä¸‰é˜¶æ®µï¼šå¼ºåŒ–å­¦ä¹ ä¸ŽNLPåŸºç¡€\\n**ç›®æ ‡ï¼š** å­¦ä¹ å¼ºåŒ–å­¦ä¹ å’ŒNLPçš„åŸºç¡€çŸ¥è¯†ï¼Œä¸ºåŽç»­çš„Agentic AIé¡¹ç›®æ‰“ä¸‹åŸºç¡€ã€‚\\n\\n**è¯¾ç¨‹æŽ¨èï¼š**\\n1. **å¼ºåŒ–å­¦ä¹ ï¼š**  \\n   - \\\"å¼ºåŒ–å­¦ä¹ å…¥é—¨\\\"ï¼šäº†è§£å¼ºåŒ–å­¦ä¹ çš„åŸºæœ¬æ¦‚å¿µå’Œç®—æ³•ã€‚\\n   - \\\"å¼ºåŒ–å­¦ä¹ è¿›é˜¶\\\"ï¼šå­¦ä¹ å¤æ‚çš„å¼ºåŒ–å­¦ä¹ ç®—æ³•å’Œåº”ç”¨ã€‚\\n\\n2. **NLPåŸºç¡€ï¼š**  \\n   - \\\"è‡ªç„¶è¯­è¨€å¤„ç†åŸºç¡€\\\"ï¼šå­¦ä¹ æ–‡æœ¬å¤„ç†ã€è¯è¢‹æ¨¡åž‹ã€TF-IDFå’Œæ–‡æœ¬åˆ†ç±»ã€‚\\n   - \\\"NLPè¿›é˜¶\\\"ï¼šæ·±å…¥å­¦ä¹ æœºå™¨å­¦ä¹ æ¨¡åž‹ï¼Œå¦‚LSTMå’ŒBERTã€‚\\n\\n**å­¦ä¹ æ—¶é—´ï¼š** 3å‘¨\\n\\n**å­¦ä¹ å†…å®¹ï¼š**\\n- å¼ºåŒ–å­¦ä¹ çš„æ ¸å¿ƒæ¦‚å¿µå’Œç®—æ³•ã€‚\\n- NLPä¸­çš„æ–‡æœ¬å¤„ç†å’Œå»ºæ¨¡ã€‚\\n\\n#### ç¬¬å››é˜¶æ®µï¼šè®¡ç®—æœºè§†è§‰ä¸Žå›¾åƒå¤„ç†\\n**ç›®æ ‡ï¼š** å­¦ä¹ è®¡ç®—æœºè§†è§‰çš„åŸºæœ¬æŠ€æœ¯ï¼ŒåŒ…æ‹¬å›¾åƒå¤„ç†å’Œæ¨¡åž‹è®­ç»ƒï¼Œä¸ºåŽç»­çš„Agentic AIé¡¹ç›®è®¾è®¡æä¾›åŸºç¡€ã€‚\\n\\n**è¯¾ç¨‹æŽ¨èï¼š**\\n1. **è®¡ç®—æœºè§†è§‰ï¼š**  \\n   - \\\"è®¡ç®—æœºè§†è§‰å…¥é—¨\\\"ï¼šäº†è§£å›¾åƒå¤„ç†çš„åŸºæœ¬æ¦‚å¿µå’Œå¸¸ç”¨ç®—æ³•ã€‚\\n   - \\\"è®¡ç®—æœºè§†è§‰é«˜çº§\\\"ï¼šå­¦ä¹ æ·±åº¦å­¦ä¹ åœ¨è®¡ç®—æœºè§†è§‰ä¸­çš„åº”ç”¨ï¼Œå¦‚YOLOå’ŒFaster R-CNNã€‚\\n\\n2. **å›¾åƒå¤„ç†ï¼š**  \\n   - \\\"å›¾åƒå¤„ç†åŸºç¡€\\\"ï¼šå­¦ä¹ å›¾åƒçš„è‰²å½©ç©ºé—´ã€æ»¤æ³¢å’Œé”åŒ–ã€‚\\n   - \\\"å›¾åƒå¤„ç†é«˜çº§\\\"ï¼šæ·±å…¥å­¦ä¹ å›¾åƒå¢žå¼ºå’Œæ–‡ä»¶æ“ä½œã€‚\\n\\n**å­¦ä¹ æ—¶é—´ï¼š** 2å‘¨\\n\\n**å­¦ä¹ å†…å®¹ï¼š**\\n- å›¾åƒå¤„ç†çš„åŸºæœ¬æ“ä½œå’Œç®—æ³•ã€‚\\n- æ·±åº¦å­¦ä¹ åœ¨å›¾åƒå¤„ç†ä¸­çš„åº”ç”¨ã€‚\\n\\n#### ç¬¬äº”é˜¶æ®µï¼šAgentic AIé¡¹ç›®å®žæˆ˜\\n**ç›®æ ‡ï¼š** å°†å­¦ä¹ åˆ°çš„Agentic AIæŠ€æœ¯åº”ç”¨åˆ°å®žé™…é¡¹ç›®ä¸­ï¼Œæå‡å®žé™…æ“ä½œèƒ½åŠ›å’Œé¡¹ç›®ç®¡ç†èƒ½åŠ›ã€‚\\n\\n**è¯¾ç¨‹æŽ¨èï¼š**\\n1. **Agentic AIé¡¹ç›®å®žæˆ˜ï¼š**  \\n   - \\\"Agentic AIé¡¹ç›®å®žæˆ˜\\\"ï¼šé€šè¿‡é¡¹ç›®è®¾è®¡å’Œå®žçŽ°ï¼Œå­¦ä¹ Agentic AIçš„æ ¸å¿ƒæŠ€æœ¯ã€‚\\n   - \\\"Agentic AIå®žæˆ˜è¯¾ç¨‹\\\"ï¼šæ·±å…¥å­¦ä¹ é¡¹ç›®å®žæˆ˜ï¼Œè§£å†³å®žé™…é—®é¢˜ã€‚\\n\\n2. **é¡¹ç›®ç®¡ç†å’Œå·¥å…·ä½¿ç”¨ï¼š**  \\n   - \\\"Agentic AIé¡¹ç›®ç®¡ç†\\\"ï¼šå­¦ä¹ é¡¹ç›®ç®¡ç†å·¥å…·å’Œæµç¨‹ã€‚\\n   - \\\"Agentic AIå·¥å…·ä½¿ç”¨\\\"ï¼šç†Ÿæ‚‰TensorFlowã€PyTorchç­‰å·¥å…·ã€‚\\n\\n**å­¦ä¹ æ—¶é—´ï¼š** 3å‘¨\\n\\n**å­¦ä¹ å†…å®¹ï¼š**\\n- å®žè·µé¡¹ç›®çš„è®¾è®¡ä¸Žå®žçŽ°ã€‚\\n- é¡¹ç›®ç®¡ç†å·¥å…·å’Œæµç¨‹çš„ä½¿ç”¨ã€‚\\n- æ·±åº¦å­¦ä¹ å’Œå¼ºåŒ–å­¦ä¹ çš„é¡¹ç›®åº”ç”¨ã€‚\\n\\n#### ç¬¬å…­é˜¶æ®µï¼šæŒç»­å­¦ä¹ ä¸Žå®žè·µ\\n**ç›®æ ‡ï¼š** ç¡®ä¿é•¿æœŸå­¦ä¹ å’Œå®žè·µï¼Œæå‡å¯¹Agentic AIæŠ€æœ¯çš„æŽŒæ¡å’Œåº”ç”¨èƒ½åŠ›ã€‚\\n\\n**æŽ¨èèµ„æºï¼š**\\n- **ä¹¦ç±ï¼š**  \\n  - \\\"Deep Learning\\\" by Ian Goodfellowã€Yoshua Bengioã€Yosha Bengio\\n  - \\\"Python Machine Learning\\\" by Kevin N. cave\\n  - \\\"Hands-On Machine Learning\\\" by AurÃ©lien GÃ©ron\\n- **åœ¨çº¿è¯¾ç¨‹ï¼š**  \\n  - TensorFlow for Machine Learning Specialization on TensorBoard\\n  - PyTorch for Deep Learning Specialization on Coursera\\n  - Agentic AI Specialization on Udemy\\n- **ç¤¾åŒºæ”¯æŒï¼š**  \\n  - åŠ å…¥Agentic AIçš„ç¤¾åŒºï¼ˆä¾‹å¦‚GitHubã€Redditã€Stack Overflowï¼‰\\n  - å‚ä¸ŽAgentic AIçš„è®¨è®ºå’Œè®ºå›\\n\\n**å­¦ä¹ æ—¶é—´ï¼š** 1å‘¨\\n\\n**å­¦ä¹ å†…å®¹ï¼š**\\n- æŒç»­å­¦ä¹ å’Œå®žè·µï¼Œç¡®ä¿æŠ€æœ¯ç†Ÿç»ƒåº¦å’Œé¡¹ç›®ç»éªŒçš„æå‡ã€‚\\n\\n---\\n\\n### æ€»ç»“\\nè¿™ä¸ªè®¡åˆ’åˆ†ä¸ºå…­ä¸ªé˜¶æ®µï¼Œæ¯ä¸ªé˜¶æ®µçš„å­¦ä¹ å†…å®¹å’Œæ—¶é—´å®‰æŽ’å‡åŸºäºŽAgentic AIçš„æ ¸å¿ƒæŠ€æœ¯ï¼Œç»“åˆJavaåŽç«¯çš„ç»éªŒï¼Œå¸®åŠ©ä½ é€æ­¥æŽŒæ¡Agentic AIçš„å„ä¸ªæ–¹é¢ã€‚é€šè¿‡ç³»ç»Ÿçš„è¯¾ç¨‹å­¦ä¹ å’Œé¡¹ç›®å®žæˆ˜ï¼Œä½ å°†èƒ½å¤Ÿç†Ÿç»ƒæŽŒæ¡Agentic AIçš„æŠ€æœ¯ï¼Œå¹¶å°†å…¶åº”ç”¨äºŽå®žé™…é¡¹ç›®ä¸­ã€‚\",\n",
            "        \"refusal\": null,\n",
            "        \"annotations\": null,\n",
            "        \"audio\": null,\n",
            "        \"function_call\": null,\n",
            "        \"tool_calls\": [],\n",
            "        \"reasoning\": null,\n",
            "        \"reasoning_content\": null\n",
            "      },\n",
            "      \"logprobs\": null,\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"stop_reason\": null,\n",
            "      \"token_ids\": null\n",
            "    }\n",
            "  ],\n",
            "  \"service_tier\": null,\n",
            "  \"system_fingerprint\": null,\n",
            "  \"usage\": {\n",
            "    \"prompt_tokens\": 26,\n",
            "    \"total_tokens\": 1589,\n",
            "    \"completion_tokens\": 1563,\n",
            "    \"prompt_tokens_details\": null\n",
            "  },\n",
            "  \"prompt_logprobs\": null,\n",
            "  \"prompt_token_ids\": null,\n",
            "  \"kv_transfer_params\": null\n",
            "}\n",
            "\n",
            "ðŸ¤– æ¨¡åž‹å›žç­”: å¥½ï¼Œæˆ‘çŽ°åœ¨éœ€è¦å¸®è¿™ä½JavaåŽç«¯å·¥ç¨‹å¸ˆåˆ¶å®šä¸€ä»½Agentic AIå­¦ä¹ è®¡åˆ’ã€‚é¦–å…ˆï¼Œæˆ‘å¾—äº†è§£Agentic AIæ˜¯ä»€ä¹ˆï¼Œå®ƒä¸»è¦æ¶‰åŠå“ªäº›é¢†åŸŸï¼Œæ¯”å¦‚æ·±åº¦å­¦ä¹ ã€å¼ºåŒ–å­¦ä¹ ã€NLPç­‰ç­‰ã€‚ç„¶åŽï¼Œè€ƒè™‘åˆ°è¿™ä½å·¥ç¨‹å¸ˆæœ‰5å¹´çš„JavaåŽç«¯ç»éªŒï¼Œå¯èƒ½å¯¹å‰ç«¯æœ‰ä¸€å®šçš„äº†è§£ï¼Œä½†å¯èƒ½éœ€è¦æ›´æ·±å…¥çš„å­¦ä¹ ã€‚\n",
            "\n",
            "æŽ¥ä¸‹æ¥ï¼Œæˆ‘åº”è¯¥åˆ†é˜¶æ®µæ¥è§„åˆ’å­¦ä¹ å†…å®¹ã€‚ç¬¬ä¸€é˜¶æ®µå¯èƒ½éœ€è¦åŸºç¡€çš„Pythonå’ŒJavaï¼Œè¿™æ ·åŽé¢çš„å­¦ä¹ æ‰èƒ½è·Ÿä¸Šã€‚ç¬¬äºŒé˜¶æ®µå¯ä»¥æ·±å…¥å­¦ä¹ æœºå™¨å­¦ä¹ ï¼ŒåŒ…æ‹¬æ·±åº¦å­¦ä¹ å’Œå¼ºåŒ–å­¦ä¹ ï¼Œç¬¬ä¸‰é˜¶æ®µæ˜¯NLPå’Œè®¡ç®—æœºè§†è§‰ï¼Œç¬¬å››é˜¶æ®µæ˜¯åº”ç”¨ï¼Œæ¯”å¦‚TensorFlowå’ŒPyTorchçš„ä½¿ç”¨ï¼Œç¬¬äº”é˜¶æ®µæ˜¯é¡¹ç›®å®žæˆ˜ï¼Œæœ€åŽæ˜¯æŒç»­å­¦ä¹ å’Œå®žè·µã€‚\n",
            "\n",
            "å¯èƒ½ç”¨æˆ·å¯¹Agentic AIçš„å…·ä½“é¢†åŸŸä¸å¤ªäº†è§£ï¼Œæ‰€ä»¥éœ€è¦æ˜Žç¡®ä»–ä»¬éœ€è¦å­¦ä¹ çš„é‡ç‚¹ã€‚æ¯”å¦‚ï¼Œå¦‚æžœä»–ä»¬æƒ³åšNLPï¼Œé‚£ä¹ˆè¯æ±‡è¡¨ã€é¢„å¤„ç†ã€æ¨¡åž‹è®­ç»ƒç­‰éƒ½æ˜¯é‡ç‚¹ï¼›å¦‚æžœæ˜¯è®¡ç®—æœºè§†è§‰ï¼Œå¯èƒ½éœ€è¦å›¾åƒå¤„ç†ã€æ•°æ®å¢žå¼ºã€æ¨¡åž‹ä¼˜åŒ–ç­‰ã€‚\n",
            "\n",
            "å¦å¤–ï¼Œè€ƒè™‘åˆ°ä»–ä»¬åœ¨JavaåŽç«¯ï¼Œå¯èƒ½éœ€è¦åœ¨é¡¹ç›®ä¸­ä½¿ç”¨Javaï¼Œä½†Agentic AIæ›´å¤šæ˜¯åŸºäºŽPythonçš„ï¼Œæ‰€ä»¥å¯èƒ½éœ€è¦æŽ¨èä»–ä»¬å­¦ä¹ Pythonçš„å·¥å…·å’Œåº“ï¼Œæ¯”å¦‚TensorFlowã€PyTorchã€NumPyç­‰ã€‚\n",
            "\n",
            "æœ€åŽï¼Œå­¦ä¹ è®¡åˆ’éœ€è¦æœ‰æ—¶é—´å®‰æŽ’ï¼Œåˆ†é˜¶æ®µå­¦ä¹ ï¼Œæ¯å‘¨å­¦ä¹ å¤šå°‘å†…å®¹ï¼Œè¿˜æœ‰å®žè·µé¡¹ç›®çš„æ—¶é—´ï¼Œç¡®ä¿ä»–ä»¬æœ‰è¶³å¤Ÿçš„å®žè·µæ¥å·©å›ºçŸ¥è¯†ã€‚åŒæ—¶ï¼Œå¯èƒ½è¿˜éœ€è¦æŽ¨èä¸€äº›èµ„æºï¼Œæ¯”å¦‚ä¹¦ç±ã€åœ¨çº¿è¯¾ç¨‹ã€æ–‡æ¡£å’Œç¤¾åŒºæ”¯æŒï¼Œè¿™æ ·ä»–ä»¬èƒ½æ›´å¥½åœ°å­¦ä¹ å’Œè§£å†³é—®é¢˜ã€‚\n",
            "\n",
            "æ€»çš„æ¥è¯´ï¼Œæˆ‘éœ€è¦å…ˆåˆ—å‡ºAgentic AIçš„æ ¸å¿ƒé¢†åŸŸï¼Œæ ¹æ®ç”¨æˆ·çš„å…·ä½“éœ€æ±‚è°ƒæ•´é˜¶æ®µå’Œå†…å®¹ï¼Œç¡®ä¿å­¦ä¹ è®¡åˆ’å…¨é¢ä¸”æœ‰æ¡ç†ï¼ŒåŒæ—¶è€ƒè™‘ä»–ä»¬çš„JavaèƒŒæ™¯ï¼Œè®©ä»–ä»¬èƒ½å¤Ÿé¡ºåˆ©è¿‡æ¸¡åˆ°ä½¿ç”¨Agentic AIçš„æŠ€æœ¯æ ˆã€‚\n",
            "</think>\n",
            "\n",
            "### Agentic AIå­¦ä¹ è®¡åˆ’\n",
            "\n",
            "#### ç¬¬ä¸€é˜¶æ®µï¼šåŸºç¡€Pythonå’ŒJavaå­¦ä¹ \n",
            "**ç›®æ ‡ï¼š** ç¡®ä¿ä½ æŽŒæ¡Pythonå’ŒJavaçš„åŸºç¡€çŸ¥è¯†ï¼Œä¸ºåŽç»­å­¦ä¹ Agentic AIæ‰“ä¸‹åšå®žåŸºç¡€ã€‚\n",
            "\n",
            "**è¯¾ç¨‹æŽ¨èï¼š**\n",
            "1. **PythonåŸºç¡€ï¼š**  \n",
            "   - \"Pythonç¼–ç¨‹åŸºç¡€\"ï¼šæŽŒæ¡Pythonçš„åŸºæœ¬è¯­æ³•ã€æ•°æ®ç»“æž„ã€å‡½æ•°å’Œå¾ªçŽ¯ã€‚\n",
            "   - \"Pythonè¿›é˜¶\"ï¼šæ·±å…¥å­¦ä¹ Pythonçš„é«˜çº§åŠŸèƒ½ã€ç±»ã€æ–‡ä»¶æ“ä½œå’Œæ•°æ®æµã€‚\n",
            "\n",
            "2. **JavaåŸºç¡€ï¼š**  \n",
            "   - \"Javaç¼–ç¨‹åŸºç¡€\"ï¼šç†Ÿæ‚‰Javaçš„ç±»ã€å¯¹è±¡ã€äº‹ä»¶å¾ªçŽ¯å’ŒåŸºæœ¬ç»“æž„ã€‚\n",
            "   - \"Javaé«˜çº§ç¼–ç¨‹\"ï¼šå­¦ä¹ Javaé¢å‘å¯¹è±¡ç¼–ç¨‹å’Œé¢å‘åè®®è®¾è®¡ã€‚\n",
            "\n",
            "**å­¦ä¹ æ—¶é—´ï¼š** 2å‘¨\n",
            "\n",
            "**å­¦ä¹ å†…å®¹ï¼š**\n",
            "- åŸºæœ¬çš„Pythonè¯­æ³•å’Œæ•°æ®ç»“æž„ã€‚\n",
            "- Javaä¸­çš„ç±»å’Œå¯¹è±¡è®¾è®¡ã€‚\n",
            "- åŸºæœ¬çš„æ–‡ä»¶æ“ä½œå’Œè¾“å…¥è¾“å‡ºã€‚\n",
            "\n",
            "#### ç¬¬äºŒé˜¶æ®µï¼šæœºå™¨å­¦ä¹ åŸºç¡€ä¸Žæ·±åº¦å­¦ä¹ \n",
            "**ç›®æ ‡ï¼š** äº†è§£æœºå™¨å­¦ä¹ çš„åŸºæœ¬æ¦‚å¿µå’Œæ·±åº¦å­¦ä¹ çš„åŸºæœ¬åŽŸç†ï¼Œä¸ºåŽç»­å­¦ä¹ Agentic AIåšå‡†å¤‡ã€‚\n",
            "\n",
            "**è¯¾ç¨‹æŽ¨èï¼š**\n",
            "1. **æœºå™¨å­¦ä¹ åŸºç¡€ï¼š**  \n",
            "   - \"æœºå™¨å­¦ä¹ åŸºç¡€\"ï¼šæ¶µç›–çº¿æ€§å›žå½’ã€é€»è¾‘å›žå½’ã€å†³ç­–æ ‘å’Œèšç±»åˆ†æžã€‚\n",
            "   - \"æœºå™¨å­¦ä¹ é«˜çº§\"ï¼šæ·±å…¥å­¦ä¹ ç¥žç»ç½‘ç»œã€æ”¯æŒå‘é‡æœºã€å¼ºåŒ–å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ ã€‚\n",
            "\n",
            "2. **æ·±åº¦å­¦ä¹ ï¼š**  \n",
            "   - \"æ·±åº¦å­¦ä¹ å…¥é—¨\"ï¼šå­¦ä¹ åŸºæœ¬çš„æ·±åº¦å­¦ä¹ æ¡†æž¶å¦‚TensorFlowå’ŒKerasã€‚\n",
            "   - \"æ·±åº¦å­¦ä¹ è¿›é˜¶\"ï¼šæŽŒæ¡å¤æ‚çš„ç¥žç»ç½‘ç»œæž¶æž„ï¼Œå¦‚CNNå’ŒRNNã€‚\n",
            "\n",
            "**å­¦ä¹ æ—¶é—´ï¼š** 3å‘¨\n",
            "\n",
            "**å­¦ä¹ å†…å®¹ï¼š**\n",
            "- æœºå™¨å­¦ä¹ çš„åŸºæœ¬ç®—æ³•å’Œåº”ç”¨åœºæ™¯ã€‚\n",
            "- æ·±åº¦å­¦ä¹ çš„åŸºç¡€çŸ¥è¯†å’Œå…·ä½“æ¨¡åž‹ã€‚\n",
            "\n",
            "#### ç¬¬ä¸‰é˜¶æ®µï¼šå¼ºåŒ–å­¦ä¹ ä¸ŽNLPåŸºç¡€\n",
            "**ç›®æ ‡ï¼š** å­¦ä¹ å¼ºåŒ–å­¦ä¹ å’ŒNLPçš„åŸºç¡€çŸ¥è¯†ï¼Œä¸ºåŽç»­çš„Agentic AIé¡¹ç›®æ‰“ä¸‹åŸºç¡€ã€‚\n",
            "\n",
            "**è¯¾ç¨‹æŽ¨èï¼š**\n",
            "1. **å¼ºåŒ–å­¦ä¹ ï¼š**  \n",
            "   - \"å¼ºåŒ–å­¦ä¹ å…¥é—¨\"ï¼šäº†è§£å¼ºåŒ–å­¦ä¹ çš„åŸºæœ¬æ¦‚å¿µå’Œç®—æ³•ã€‚\n",
            "   - \"å¼ºåŒ–å­¦ä¹ è¿›é˜¶\"ï¼šå­¦ä¹ å¤æ‚çš„å¼ºåŒ–å­¦ä¹ ç®—æ³•å’Œåº”ç”¨ã€‚\n",
            "\n",
            "2. **NLPåŸºç¡€ï¼š**  \n",
            "   - \"è‡ªç„¶è¯­è¨€å¤„ç†åŸºç¡€\"ï¼šå­¦ä¹ æ–‡æœ¬å¤„ç†ã€è¯è¢‹æ¨¡åž‹ã€TF-IDFå’Œæ–‡æœ¬åˆ†ç±»ã€‚\n",
            "   - \"NLPè¿›é˜¶\"ï¼šæ·±å…¥å­¦ä¹ æœºå™¨å­¦ä¹ æ¨¡åž‹ï¼Œå¦‚LSTMå’ŒBERTã€‚\n",
            "\n",
            "**å­¦ä¹ æ—¶é—´ï¼š** 3å‘¨\n",
            "\n",
            "**å­¦ä¹ å†…å®¹ï¼š**\n",
            "- å¼ºåŒ–å­¦ä¹ çš„æ ¸å¿ƒæ¦‚å¿µå’Œç®—æ³•ã€‚\n",
            "- NLPä¸­çš„æ–‡æœ¬å¤„ç†å’Œå»ºæ¨¡ã€‚\n",
            "\n",
            "#### ç¬¬å››é˜¶æ®µï¼šè®¡ç®—æœºè§†è§‰ä¸Žå›¾åƒå¤„ç†\n",
            "**ç›®æ ‡ï¼š** å­¦ä¹ è®¡ç®—æœºè§†è§‰çš„åŸºæœ¬æŠ€æœ¯ï¼ŒåŒ…æ‹¬å›¾åƒå¤„ç†å’Œæ¨¡åž‹è®­ç»ƒï¼Œä¸ºåŽç»­çš„Agentic AIé¡¹ç›®è®¾è®¡æä¾›åŸºç¡€ã€‚\n",
            "\n",
            "**è¯¾ç¨‹æŽ¨èï¼š**\n",
            "1. **è®¡ç®—æœºè§†è§‰ï¼š**  \n",
            "   - \"è®¡ç®—æœºè§†è§‰å…¥é—¨\"ï¼šäº†è§£å›¾åƒå¤„ç†çš„åŸºæœ¬æ¦‚å¿µå’Œå¸¸ç”¨ç®—æ³•ã€‚\n",
            "   - \"è®¡ç®—æœºè§†è§‰é«˜çº§\"ï¼šå­¦ä¹ æ·±åº¦å­¦ä¹ åœ¨è®¡ç®—æœºè§†è§‰ä¸­çš„åº”ç”¨ï¼Œå¦‚YOLOå’ŒFaster R-CNNã€‚\n",
            "\n",
            "2. **å›¾åƒå¤„ç†ï¼š**  \n",
            "   - \"å›¾åƒå¤„ç†åŸºç¡€\"ï¼šå­¦ä¹ å›¾åƒçš„è‰²å½©ç©ºé—´ã€æ»¤æ³¢å’Œé”åŒ–ã€‚\n",
            "   - \"å›¾åƒå¤„ç†é«˜çº§\"ï¼šæ·±å…¥å­¦ä¹ å›¾åƒå¢žå¼ºå’Œæ–‡ä»¶æ“ä½œã€‚\n",
            "\n",
            "**å­¦ä¹ æ—¶é—´ï¼š** 2å‘¨\n",
            "\n",
            "**å­¦ä¹ å†…å®¹ï¼š**\n",
            "- å›¾åƒå¤„ç†çš„åŸºæœ¬æ“ä½œå’Œç®—æ³•ã€‚\n",
            "- æ·±åº¦å­¦ä¹ åœ¨å›¾åƒå¤„ç†ä¸­çš„åº”ç”¨ã€‚\n",
            "\n",
            "#### ç¬¬äº”é˜¶æ®µï¼šAgentic AIé¡¹ç›®å®žæˆ˜\n",
            "**ç›®æ ‡ï¼š** å°†å­¦ä¹ åˆ°çš„Agentic AIæŠ€æœ¯åº”ç”¨åˆ°å®žé™…é¡¹ç›®ä¸­ï¼Œæå‡å®žé™…æ“ä½œèƒ½åŠ›å’Œé¡¹ç›®ç®¡ç†èƒ½åŠ›ã€‚\n",
            "\n",
            "**è¯¾ç¨‹æŽ¨èï¼š**\n",
            "1. **Agentic AIé¡¹ç›®å®žæˆ˜ï¼š**  \n",
            "   - \"Agentic AIé¡¹ç›®å®žæˆ˜\"ï¼šé€šè¿‡é¡¹ç›®è®¾è®¡å’Œå®žçŽ°ï¼Œå­¦ä¹ Agentic AIçš„æ ¸å¿ƒæŠ€æœ¯ã€‚\n",
            "   - \"Agentic AIå®žæˆ˜è¯¾ç¨‹\"ï¼šæ·±å…¥å­¦ä¹ é¡¹ç›®å®žæˆ˜ï¼Œè§£å†³å®žé™…é—®é¢˜ã€‚\n",
            "\n",
            "2. **é¡¹ç›®ç®¡ç†å’Œå·¥å…·ä½¿ç”¨ï¼š**  \n",
            "   - \"Agentic AIé¡¹ç›®ç®¡ç†\"ï¼šå­¦ä¹ é¡¹ç›®ç®¡ç†å·¥å…·å’Œæµç¨‹ã€‚\n",
            "   - \"Agentic AIå·¥å…·ä½¿ç”¨\"ï¼šç†Ÿæ‚‰TensorFlowã€PyTorchç­‰å·¥å…·ã€‚\n",
            "\n",
            "**å­¦ä¹ æ—¶é—´ï¼š** 3å‘¨\n",
            "\n",
            "**å­¦ä¹ å†…å®¹ï¼š**\n",
            "- å®žè·µé¡¹ç›®çš„è®¾è®¡ä¸Žå®žçŽ°ã€‚\n",
            "- é¡¹ç›®ç®¡ç†å·¥å…·å’Œæµç¨‹çš„ä½¿ç”¨ã€‚\n",
            "- æ·±åº¦å­¦ä¹ å’Œå¼ºåŒ–å­¦ä¹ çš„é¡¹ç›®åº”ç”¨ã€‚\n",
            "\n",
            "#### ç¬¬å…­é˜¶æ®µï¼šæŒç»­å­¦ä¹ ä¸Žå®žè·µ\n",
            "**ç›®æ ‡ï¼š** ç¡®ä¿é•¿æœŸå­¦ä¹ å’Œå®žè·µï¼Œæå‡å¯¹Agentic AIæŠ€æœ¯çš„æŽŒæ¡å’Œåº”ç”¨èƒ½åŠ›ã€‚\n",
            "\n",
            "**æŽ¨èèµ„æºï¼š**\n",
            "- **ä¹¦ç±ï¼š**  \n",
            "  - \"Deep Learning\" by Ian Goodfellowã€Yoshua Bengioã€Yosha Bengio\n",
            "  - \"Python Machine Learning\" by Kevin N. cave\n",
            "  - \"Hands-On Machine Learning\" by AurÃ©lien GÃ©ron\n",
            "- **åœ¨çº¿è¯¾ç¨‹ï¼š**  \n",
            "  - TensorFlow for Machine Learning Specialization on TensorBoard\n",
            "  - PyTorch for Deep Learning Specialization on Coursera\n",
            "  - Agentic AI Specialization on Udemy\n",
            "- **ç¤¾åŒºæ”¯æŒï¼š**  \n",
            "  - åŠ å…¥Agentic AIçš„ç¤¾åŒºï¼ˆä¾‹å¦‚GitHubã€Redditã€Stack Overflowï¼‰\n",
            "  - å‚ä¸ŽAgentic AIçš„è®¨è®ºå’Œè®ºå›\n",
            "\n",
            "**å­¦ä¹ æ—¶é—´ï¼š** 1å‘¨\n",
            "\n",
            "**å­¦ä¹ å†…å®¹ï¼š**\n",
            "- æŒç»­å­¦ä¹ å’Œå®žè·µï¼Œç¡®ä¿æŠ€æœ¯ç†Ÿç»ƒåº¦å’Œé¡¹ç›®ç»éªŒçš„æå‡ã€‚\n",
            "\n",
            "---\n",
            "\n",
            "### æ€»ç»“\n",
            "è¿™ä¸ªè®¡åˆ’åˆ†ä¸ºå…­ä¸ªé˜¶æ®µï¼Œæ¯ä¸ªé˜¶æ®µçš„å­¦ä¹ å†…å®¹å’Œæ—¶é—´å®‰æŽ’å‡åŸºäºŽAgentic AIçš„æ ¸å¿ƒæŠ€æœ¯ï¼Œç»“åˆJavaåŽç«¯çš„ç»éªŒï¼Œå¸®åŠ©ä½ é€æ­¥æŽŒæ¡Agentic AIçš„å„ä¸ªæ–¹é¢ã€‚é€šè¿‡ç³»ç»Ÿçš„è¯¾ç¨‹å­¦ä¹ å’Œé¡¹ç›®å®žæˆ˜ï¼Œä½ å°†èƒ½å¤Ÿç†Ÿç»ƒæŽŒæ¡Agentic AIçš„æŠ€æœ¯ï¼Œå¹¶å°†å…¶åº”ç”¨äºŽå®žé™…é¡¹ç›®ä¸­ã€‚\n",
            "\n",
            "==================================================\n",
            "âœ… æŽ¨ç†å‡½æ•°å®šä¹‰å®Œæˆï¼Œå¯ä»¥ç»§ç»­ä¸‹ä¸€æ­¥ï¼\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸ§ª æµ‹è¯•åŸºç¡€æŽ¨ç†åŠŸèƒ½\n",
        "print(\"ðŸ§ª æµ‹è¯•æ¨¡åž‹æŽ¨ç†åŠŸèƒ½...\")\n",
        "print(\"ðŸ“ å‘é€æµ‹è¯•é—®é¢˜: æˆ‘æ˜¯ä¸€åJavaåŽç«¯å·¥ç¨‹å¸ˆï¼Œæœ‰5å¹´å·¥ä½œç»åŽ†ï¼Œå¸®æˆ‘åˆ¶å®šä¸€ä»½Agentic AIå­¦ä¹ è®¡åˆ’\")\n",
        "\n",
        "try:\n",
        "    result = stream_llm_response(\"æˆ‘æ˜¯ä¸€åJavaåŽç«¯å·¥ç¨‹å¸ˆï¼Œæœ‰5å¹´å·¥ä½œç»åŽ†ï¼Œå¸®æˆ‘åˆ¶å®šä¸€ä»½Agentic AIå­¦ä¹ è®¡åˆ’\")\n",
        "    if result:\n",
        "        print(\"\\nâœ… æ¨¡åž‹æŽ¨ç†æˆåŠŸï¼\")\n",
        "        print(\"ðŸ“‹ å®Œæ•´å“åº”:\")\n",
        "        print(json.dumps(result, indent=2, ensure_ascii=False))\n",
        "\n",
        "        # æå–å¹¶æ˜¾ç¤ºæ¨¡åž‹å›žç­”\n",
        "        if \"choices\" in result and len(result[\"choices\"]) > 0:\n",
        "            answer = result[\"choices\"][0][\"message\"][\"content\"]\n",
        "            print(f\"\\nðŸ¤– æ¨¡åž‹å›žç­”: {answer}\")\n",
        "    else:\n",
        "        print(\"âŒ æ¨¡åž‹æŽ¨ç†å¤±è´¥\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºçŽ°é”™è¯¯: {e}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"âœ… æŽ¨ç†å‡½æ•°å®šä¹‰å®Œæˆï¼Œå¯ä»¥ç»§ç»­ä¸‹ä¸€æ­¥ï¼\")"
      ],
      "metadata": {
        "id": "ValdCWQS-BB5",
        "outputId": "8b2a7efc-e879-4485-910d-cc7caf08bf5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ§ª æµ‹è¯•æ¨¡åž‹æŽ¨ç†åŠŸèƒ½...\n",
            "ðŸ“ å‘é€æµ‹è¯•é—®é¢˜: æˆ‘æ˜¯ä¸€åJavaåŽç«¯å·¥ç¨‹å¸ˆï¼Œæœ‰5å¹´å·¥ä½œç»åŽ†ï¼Œå¸®æˆ‘åˆ¶å®šä¸€ä»½Agentic AIå­¦ä¹ è®¡åˆ’\n",
            "\n",
            "âœ… æ¨¡åž‹æŽ¨ç†æˆåŠŸï¼\n",
            "ðŸ“‹ å®Œæ•´å“åº”:\n",
            "âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºçŽ°é”™è¯¯: Object of type generator is not JSON serializable\n",
            "\n",
            "==================================================\n",
            "âœ… æŽ¨ç†å‡½æ•°å®šä¹‰å®Œæˆï¼Œå¯ä»¥ç»§ç»­ä¸‹ä¸€æ­¥ï¼\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYXWde1knE2T"
      },
      "source": [
        "### ðŸ“‹ API å“åº”ç¤ºä¾‹\n",
        "\n",
        "### ðŸ¤– å®Œæ•´å“åº”æ ¼å¼\n",
        "\n",
        "å½“ä½ è°ƒç”¨ `/api/v1/generate-response` ç«¯ç‚¹æ—¶ï¼Œä¼šæ”¶åˆ°å¦‚ä¸‹æ ¼å¼çš„ JSON å“åº”ï¼š\n",
        "\n",
        "```\n",
        "{\n",
        "  \"response\": {\n",
        "    \"id\": \"chatcmpl-13e29c35212b486ead18d91aa0668886\",\n",
        "    \"object\": \"chat.completion\",\n",
        "    \"created\": 1752386782,\n",
        "    \"model\": \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\n",
        "    \"choices\": [\n",
        "      {\n",
        "        \"index\": 0,\n",
        "        \"message\": {\n",
        "          \"role\": \"assistant\",\n",
        "          \"reasoning_content\": null,\n",
        "          \"content\": \"å¥½ï¼Œç”¨æˆ·å‘æ¥â€œå‘¦å‘¦é¹¿é¸£â€è¿™ä¸ªè¯ï¼Œçœ‹èµ·æ¥åƒæ˜¯åœ¨çŽ©æ‰‹æœºçš„è¯­éŸ³åˆæˆåŠŸèƒ½ã€‚æˆ‘åº”è¯¥å›žå¤ç”¨æˆ·ä¸€ä¸ªå‹å¥½åˆæœ‰è¶£çš„å›žåº”ï¼Œæ¯”å¦‚â€œå—¯ï¼Œçœ‹åˆ°ä½ è¿™ä¹ˆè¯´ï¼Œæˆ‘å¥½åƒä¹Ÿå¬åˆ°äº†ï¼Œé¹¿é¸£çš„å£°éŸ³å¾ˆæ¸©æŸ”å•Šï¼â€è¿™æ ·æ—¢å›žåº”äº†ä»–ä»¬çš„æé—®ï¼Œåˆè®©è¯­æ°”æ›´ç”ŸåŠ¨ã€‚å¦å¤–ï¼Œå¯ä»¥ç”¨ä¸€äº›è½»æ¾çš„è¯­æ°”ï¼Œè®©ç”¨æˆ·è§‰å¾—æœ‰è¶£åˆä¸è§‰å¾—åŽ‹åŠ›ã€‚å¯èƒ½ç”¨æˆ·æƒ³äº†è§£è¿™å¥è¯çš„å«ä¹‰ï¼Œæˆ–è€…åªæ˜¯æƒ³åœ¨èŠå¤©ã€‚æ‰€ä»¥ï¼Œæˆ‘éœ€è¦ä¿æŒè‡ªç„¶ï¼Œä¸æ˜¾å¾—å¤ªç”Ÿç¡¬ã€‚å¦å¤–ï¼Œå¯èƒ½ç”¨æˆ·æ˜¯æƒ³æµ‹è¯•ä¸€ä¸‹è¯­éŸ³åˆæˆçš„åŠŸèƒ½ï¼Œæˆ–è€…æ˜¯æƒ³äº†è§£ä¸€äº›æœ‰è¶£çš„è¯é¢˜ã€‚ä¸ç®¡æ€Žæ ·ï¼Œå›žåº”è¦å‹å¥½ï¼ŒåŒæ—¶å¸¦ç‚¹è¶£å‘³ï¼Œè®©ç”¨æˆ·æ„Ÿåˆ°æ„‰å¿«ã€‚\\n</think>\\n\\nå—¯ï¼Œçœ‹åˆ°ä½ è¿™ä¹ˆè¯´ï¼Œæˆ‘å¥½åƒä¹Ÿå¬åˆ°äº†ï¼Œé¹¿é¸£çš„å£°éŸ³å¾ˆæ¸©æŸ”å•Šï¼\",\n",
        "          \"tool_calls\": []\n",
        "        },\n",
        "        \"logprobs\": null,\n",
        "        \"finish_reason\": \"stop\",\n",
        "        \"stop_reason\": null\n",
        "      }\n",
        "    ],\n",
        "    \"usage\": {\n",
        "      \"prompt_tokens\": 9,\n",
        "      \"total_tokens\": 176,\n",
        "      \"completion_tokens\": 167,\n",
        "      \"prompt_tokens_details\": null\n",
        "    },\n",
        "    \"prompt_logprobs\": null,\n",
        "    \"kv_transfer_params\": null\n",
        "  }\n",
        "}\n",
        "```\n",
        "\n",
        "#### ðŸ“Š å“åº”ç»“æž„è¯´æ˜Ž\n",
        "- **id**: è¯·æ±‚çš„å”¯ä¸€æ ‡è¯†ç¬¦\n",
        "- **object**: å“åº”å¯¹è±¡ç±»åž‹\n",
        "- **created**: å“åº”åˆ›å»ºæ—¶é—´æˆ³\n",
        "- **model**: ä½¿ç”¨çš„æ¨¡åž‹åç§°\n",
        "- **choices**: æ¨¡åž‹ç”Ÿæˆçš„é€‰æ‹©åˆ—è¡¨\n",
        "  - **index**: é€‰æ‹©çš„ç´¢å¼•\n",
        "  - **message**: æ¶ˆæ¯å†…å®¹\n",
        "    - **role**: è§’è‰²ï¼ˆassistantï¼‰\n",
        "    - **content**: æ¨¡åž‹ç”Ÿæˆçš„å›žç­”\n",
        "  - **finish_reason**: å®ŒæˆåŽŸå› ï¼ˆstop è¡¨ç¤ºæ­£å¸¸ç»“æŸï¼‰\n",
        "- **usage**: ä»¤ç‰Œä½¿ç”¨ç»Ÿè®¡\n",
        "  - **prompt_tokens**: è¾“å…¥ä»¤ç‰Œæ•°\n",
        "  - **completion_tokens**: ç”Ÿæˆä»¤ç‰Œæ•°\n",
        "  - **total_tokens**: æ€»ä»¤ç‰Œæ•°"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRer8bosm041"
      },
      "source": [
        "### ðŸŒŠ æµå¼å“åº”æ ¼å¼\n",
        "\n",
        "å½“ä½ è°ƒç”¨ `/api/v1/generate-response-stream` ç«¯ç‚¹æ—¶ï¼Œä¼šæ”¶åˆ°ä¸€ç³»åˆ— JSON å¯¹è±¡ï¼Œæ¯ä¸ªå¯¹è±¡ä»£è¡¨ç”Ÿæˆè¿‡ç¨‹ä¸­çš„ä¸€ä¸ªæ­¥éª¤ï¼š\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "{\"id\":\"chatcmpl-72594106be2541269cc68e8b37123051\",\"object\":\"chat.completion.chunk\",\"created\":1752386825,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-72594106be2541269cc68e8b37123051\",\"object\":\"chat.completion.chunk\",\"created\":1752386825,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"å—¯\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-72594106be2541269cc68e8b37123051\",\"object\":\"chat.completion.chunk\",\"created\":1752386825,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"ï¼Œ\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-72594106be2541269cc68e8b37123051\",\"object\":\"chat.completion.chunk\",\"created\":1752386825,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"æˆ‘çŽ°åœ¨\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-72594106be2541269cc68e8b37123051\",\"object\":\"chat.completion.chunk\",\"created\":1752386825,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"åœ¨\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-72594106be2541269cc68e8b37123051\",\"object\":\"chat.completion.chunk\",\"created\":1752386825,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"å­¦ä¹ \"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-72594106be2541269cc68e8b37123051\",\"object\":\"chat.completion.chunk\",\"created\":1752386825,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"å¤§\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-72594106be2541269cc68e8b37123051\",\"object\":\"chat.completion.chunk\",\"created\":1752386825,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"æ¨¡åž‹\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-72594106be2541269cc68e8b37123051\",\"object\":\"chat.completion.chunk\",\"created\":1752386825,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"ï¼Œ\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "{\"id\":\"chatcmpl-72594106be2541269cc68e8b37123051\",\"object\":\"chat.completion.chunk\",\"created\":1752386825,\"model\":\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\",\"choices\":[{\"index\":0,\"delta\":{\"content\":\"æ¯”å¦‚\"},\"logprobs\":null,\"finish_reason\":null}]}\n",
        "...\n",
        "[DONE]\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "#### ðŸ“¡ æµå¼å“åº”ç‰¹ç‚¹\n",
        "- **å®žæ—¶æ€§**: é€æ­¥è¿”å›žç”Ÿæˆå†…å®¹ï¼Œæ— éœ€ç­‰å¾…å®Œæ•´å›žç­”\n",
        "- **ä½Žå»¶è¿Ÿ**: ç”¨æˆ·å¯ä»¥ç«‹å³çœ‹åˆ°æ¨¡åž‹å¼€å§‹ç”Ÿæˆ\n",
        "- **æ›´å¥½ä½“éªŒ**: é€‚åˆé•¿æ–‡æœ¬ç”Ÿæˆå’Œå®žæ—¶å¯¹è¯\n",
        "\n",
        "#### ðŸ”„ æµå¼æ•°æ®æ ¼å¼\n",
        "æ¯è¡Œæ•°æ®éƒ½æ˜¯ä¸€ä¸ªç‹¬ç«‹çš„ JSON å¯¹è±¡ï¼ŒåŒ…å«ï¼š\n",
        "- **id**: è¯·æ±‚æ ‡è¯†ç¬¦ï¼ˆæ•´ä¸ªæµä¸­ä¿æŒä¸€è‡´ï¼‰\n",
        "- **object**: \"chat.completion.chunk\"\n",
        "- **created**: æ—¶é—´æˆ³\n",
        "- **model**: æ¨¡åž‹åç§°\n",
        "- **choices**: å½“å‰ç”Ÿæˆçš„å†…å®¹å—\n",
        "  - **index**: é€‰æ‹©ç´¢å¼•\n",
        "  - **delta**: å¢žé‡å†…å®¹\n",
        "    - **content**: æ–°ç”Ÿæˆçš„æ–‡æœ¬ç‰‡æ®µ\n",
        "  - **finish_reason**: ç»“æŸåŽŸå› ï¼ˆnull è¡¨ç¤ºç»§ç»­ï¼Œ\"stop\" è¡¨ç¤ºç»“æŸï¼‰\n",
        "\n",
        "#### ðŸ’¡ ä½¿ç”¨å»ºè®®\n",
        "- é€‚åˆéœ€è¦å®žæ—¶åé¦ˆçš„åº”ç”¨åœºæ™¯\n",
        "- å¯ä»¥å®žçŽ°æ‰“å­—æœºæ•ˆæžœçš„ç”¨æˆ·ç•Œé¢\n",
        "- å¯¹äºŽé•¿æ–‡æœ¬ç”Ÿæˆç‰¹åˆ«æœ‰ç”¨"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbY6mDWCmTsf"
      },
      "source": [
        "## ðŸ” ç¬¬å…­æ­¥ï¼š ç»ˆæ­¢ vLLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "MQbgsTX83j8i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a6a9f10-1610-4e4f-a57f-620d42105210"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-15"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# å¦‚æžœè¦ç»ˆæ­¢vLLMï¼Œå¯ä»¥æ‰§è¡Œå¦‚ä¸‹ä»£ç \n",
        "vllm_process.terminate()\n",
        "vllm_process.wait()  # Wait for process to terminate"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}