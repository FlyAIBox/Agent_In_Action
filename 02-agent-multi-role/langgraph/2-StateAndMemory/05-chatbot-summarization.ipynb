{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "env_config_overview",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### üîß ÁéØÂ¢ÉÈÖçÁΩÆÂíåÊ£ÄÊü•\n",
    "\n",
    "#### Ê¶ÇËø∞\n",
    "\n",
    "Êú¨ÊïôÁ®ãÈúÄË¶ÅÁâπÂÆöÁöÑÁéØÂ¢ÉÈÖçÁΩÆ‰ª•Á°Æ‰øùÊúÄ‰Ω≥Â≠¶‰π†‰ΩìÈ™å„ÄÇ‰ª•‰∏ãÈÖçÁΩÆÂ∞ÜÂ∏ÆÂä©‰Ω†Ôºö\n",
    "\n",
    "- ‰ΩøÁî®Áªü‰∏ÄÁöÑcondaÁéØÂ¢ÉÔºöÊøÄÊ¥ªÁªü‰∏ÄÁöÑÂ≠¶‰π†ÁéØÂ¢É\n",
    "- ÈÄöËøáÂõΩÂÜÖÈïúÂÉèÊ∫êÂø´ÈÄüÂÆâË£Ö‰æùËµñÔºöÈÖçÁΩÆpip‰ΩøÁî®Ê∏ÖÂçéÈïúÂÉèÊ∫ê\n",
    "- Âä†ÈÄüÊ®°Âûã‰∏ãËΩΩÔºöËÆæÁΩÆHuggingFaceÈïúÂÉè‰ª£ÁêÜ\n",
    "- Ê£ÄÊü•Á≥ªÁªüÈÖçÁΩÆÔºöÊ£ÄÊü•Á°¨‰ª∂ÂíåËΩØ‰ª∂ÈÖçÁΩÆ\n",
    "\n",
    "#### ÈÖçÁΩÆ\n",
    "\n",
    "- **ÊâÄÈúÄÁéØÂ¢ÉÂèäÂÖ∂‰æùËµñÂ∑≤ÁªèÈÉ®ÁΩ≤Â•Ω**\n",
    "- Âú®`Notebook`Âè≥‰∏äËßíÈÄâÊã©`jupyterÂÜÖÊ†∏`‰∏∫`python(agent101)`ÔºåÂç≥ÂèØÊâßË°å‰∏ãÊñπ‰ª£Á†Å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "env_conda_activate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================\n",
      "== Conda ÁéØÂ¢ÉÊ£ÄÊü•Êä•Âëä (‰ªÖÈíàÂØπÂΩìÂâç Bash Â≠êËøõÔøΩÔøΩ) ==\n",
      "=========================================\n",
      "‚úÖ ÂΩìÂâçÂçïÂÖÉÊ†ºÂ∑≤ÊàêÂäüÊøÄÊ¥ªÂà∞ agent101 ÁéØÂ¢É„ÄÇ\n",
      "‚úÖ Ê≠£Âú®‰ΩøÁî®ÁöÑÁéØÂ¢ÉË∑ØÂæÑ: /root/miniconda3/envs/agent101\n",
      "\n",
      "üí° ÊèêÁ§∫: ÂêéÁª≠ÁöÑPythonÂçïÂÖÉÊ†ºÂ∞Ü‰ΩøÁî®NotebookÂΩìÂâçÈÄâÊã©ÁöÑJupyterÔøΩÔøΩÊ†∏„ÄÇ\n",
      "   Â¶ÇÊûúÈúÄË¶ÅÂêéÁª≠ÂçïÂÖÉÊ†º‰πü‰ΩøÁî®Ê≠§ÁéØÂ¢ÉÔºåËØ∑ÊâßË°å‰ª•‰∏ãÊìç‰Ωú:\n",
      "   1. Ê£ÄÊü• Notebook Âè≥‰∏äËßíÊòØÂê¶Â∑≤ÈÄâÊã© 'python(agent101)'„ÄÇ\n",
      "=========================================\n"
     ]
    }
   ],
   "source": [
    "%%script bash\n",
    "\n",
    "# 1. ÊøÄÊ¥ª conda ÁéØÂ¢É (‰ªÖÂØπÂΩìÂâçÂçïÂÖÉÊ†ºÊúâÊïà)\n",
    "eval \"$(conda shell.bash hook)\"\n",
    "conda activate agent101\n",
    "\n",
    "echo \"=========================================\"\n",
    "echo \"== Conda ÁéØÂ¢ÉÊ£ÄÊü•Êä•Âëä (‰ªÖÈíàÂØπÂΩìÂâç Bash Â≠êËøõÁ®ã) ==\"\n",
    "echo \"=========================================\"\n",
    "\n",
    "# 2. Ê£ÄÊü•ÂΩìÂâçÊøÄÊ¥ªÁöÑÁéØÂ¢É\n",
    "CURRENT_ENV_NAME=$(basename $CONDA_PREFIX)\n",
    "\n",
    "if [ \"$CURRENT_ENV_NAME\" = \"agent101\" ]; then\n",
    "    echo \"‚úÖ ÂΩìÂâçÂçïÂÖÉÊ†ºÂ∑≤ÊàêÂäüÊøÄÊ¥ªÂà∞ agent101 ÁéØÂ¢É„ÄÇ\"\n",
    "    echo \"‚úÖ Ê≠£Âú®‰ΩøÁî®ÁöÑÁéØÂ¢ÉË∑ØÂæÑ: $CONDA_PREFIX\"\n",
    "    echo \"\"\n",
    "    echo \"üí° ÊèêÁ§∫: ÂêéÁª≠ÁöÑPythonÂçïÂÖÉÊ†ºÂ∞Ü‰ΩøÁî®NotebookÂΩìÂâçÈÄâÊã©ÁöÑJupyterÂÜÖÊ†∏„ÄÇ\"\n",
    "    echo \"   Â¶ÇÊûúÈúÄË¶ÅÂêéÁª≠ÂçïÂÖÉÊ†º‰πü‰ΩøÁî®Ê≠§ÁéØÂ¢ÉÔºåËØ∑ÊâßË°å‰ª•‰∏ãÊìç‰Ωú:\"\n",
    "    echo \"   1. Ê£ÄÊü• Notebook Âè≥‰∏äËßíÊòØÂê¶Â∑≤ÈÄâÊã© 'python(agent101)'„ÄÇ\"\n",
    "else\n",
    "    echo \"‚ùå ÊøÄÊ¥ªÂ§±Ë¥•ÊàñÁéØÂ¢ÉÂêçÁß∞‰∏çÂåπÈÖç„ÄÇÂΩìÂâçÁéØÂ¢É: $CURRENT_ENV_NAME\"\n",
    "    echo \"\"\n",
    "    echo \"‚ö†Ô∏è ‰∏•ÈáçÊèêÁ§∫: Âª∫ËÆÆÂ∞Ü Notebook ÁöÑ Jupyter **ÂÜÖÊ†∏ (Kernel)** ÂàáÊç¢‰∏∫ 'python(agent101)'„ÄÇ\"\n",
    "    echo \"   (ÈÄöÂ∏∏‰Ωç‰∫é Notebook Âè≥‰∏äËßíÊàñ 'ÂÜÖÊ†∏' ËèúÂçï‰∏≠)\"\n",
    "    echo \"\"\n",
    "    echo \"üìö Â§áÁî®ÊñπÊ≥ï (‰∏çÊé®Ëçê): Â¶ÇÊûúÊó†Ê≥ïÂàáÊç¢ÂÜÖÊ†∏ÔºåÂàôÂøÖÈ°ªÂú®**ÊØè‰∏™**‰ª£Á†ÅÂçïÂÖÉÊ†ºÁöÑÂ§¥ÈÉ®ÈáçÂ§ç‰ª•‰∏ãÂëΩ‰ª§:\"\n",
    "    echo \"\"\n",
    "    echo \"%%script bash\"\n",
    "    echo \"# ÂøÖÈ°ªÂú®ÊØè‰∏™ÂçïÂÖÉÊ†ºÈÉΩÊâßË°å\"\n",
    "    echo \"eval \\\"\\$(conda shell.bash hook)\\\"\"\n",
    "    echo \"conda activate agent101\"\n",
    "fi\n",
    "\n",
    "echo \"=========================================\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "env_pip_config",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For variant 'global', will try loading '/etc/xdg/pip/pip.conf'\n",
      "For variant 'global', will try loading '/etc/pip.conf'\n",
      "For variant 'user', will try loading '/root/.pip/pip.conf'\n",
      "For variant 'user', will try loading '/root/.config/pip/pip.conf'\n",
      "For variant 'site', will try loading '/root/miniconda3/envs/agent101/pip.conf'\n",
      "\u001b[31mERROR: Got unexpected number of arguments, expected 0. (example: \"/root/miniconda3/envs/agent101/bin/python -m pip config list\")\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "For variant 'global', will try loading '/etc/xdg/pip/pip.conf'\n",
      "For variant 'global', will try loading '/etc/pip.conf'\n",
      "For variant 'user', will try loading '/root/.pip/pip.conf'\n",
      "For variant 'user', will try loading '/root/.config/pip/pip.conf'\n",
      "For variant 'site', will try loading '/root/miniconda3/envs/agent101/pip.conf'\n",
      "\u001b[31mERROR: Got unexpected number of arguments, expected 0. (example: \"/root/miniconda3/envs/agent101/bin/python -m pip config list\")\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# 2. ËÆæÁΩÆpip ‰∏∫Ê∏ÖÂçéÊ∫ê\n",
    "%pip config list -v set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "%pip config list -v list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "env_hf_proxy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: HF_ENDPOINT=https://hf-mirror.com\n",
      "https://hf-mirror.com\n"
     ]
    }
   ],
   "source": [
    "# 3. ËÆæÁΩÆHuggingFace‰ª£ÁêÜ\n",
    "%env HF_ENDPOINT=https://hf-mirror.com\n",
    "# È™åËØÅÔºö‰ΩøÁî®shellÂëΩ‰ª§Ê£ÄÊü•\n",
    "!echo $HF_ENDPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "env_system_check",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas==2.2.2 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (2.2.2)\n",
      "Requirement already satisfied: tabulate==0.9.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from pandas==2.2.2) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from pandas==2.2.2) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from pandas==2.2.2) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from pandas==2.2.2) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas==2.2.2) (1.17.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "### ÁéØÂ¢É‰ø°ÊÅØ\n",
      "| È°πÁõÆ         | ‰ø°ÊÅØ                                                                               |\n",
      "|:-------------|:-----------------------------------------------------------------------------------|\n",
      "| Êìç‰ΩúÁ≥ªÁªü     | Linux Ubuntu 22.04.4 LTS                                                           |\n",
      "| CPU ‰ø°ÊÅØ     | 11th Gen Intel(R) Core(TM) i5-1135G7 @ 2.40GHz (1 physical cores, 4 logical cores) |\n",
      "| ÂÜÖÂ≠ò‰ø°ÊÅØ     | 5.75 GB (Available: 2.38 GB)                                                       |\n",
      "| GPU ‰ø°ÊÅØ     | No GPU found (nvidia-smi not found)                                                |\n",
      "| CUDA ‰ø°ÊÅØ    | CUDA not found                                                                     |\n",
      "| Python ÁâàÊú¨  | 3.10.18                                                                            |\n",
      "| Conda ÁâàÊú¨   | conda 24.4.0                                                                       |\n",
      "| Áâ©ÁêÜÁ£ÅÁõòÁ©∫Èó¥ | Total: 145.49 GB, Used: 20.19 GB, Free: 119.07 GB                                  |\n"
     ]
    }
   ],
   "source": [
    "# üîç ÁéØÂ¢É‰ø°ÊÅØÊ£ÄÊü•ËÑöÊú¨\n",
    "#\n",
    "# Êú¨ËÑöÊú¨ÁöÑ‰ΩúÁî®Ôºö\n",
    "# 1. ÂÆâË£Ö pandas Â∫ìÁî®‰∫éÊï∞ÊçÆË°®Ê†ºÂ±ïÁ§∫\n",
    "# 2. Ê£ÄÊü•Á≥ªÁªüÁöÑÂêÑÈ°πÈÖçÁΩÆ‰ø°ÊÅØ\n",
    "# 3. ÁîüÊàêËØ¶ÁªÜÁöÑÁéØÂ¢ÉÊä•ÂëäË°®Ê†º\n",
    "#\n",
    "# ÂØπ‰∫éÂàùÂ≠¶ËÄÖÊù•ËØ¥ÔºåËøô‰∏™Ê≠•È™§Â∏ÆÂä©‰Ω†Ôºö\n",
    "# - ‰∫ÜËß£ÂΩìÂâçËøêË°åÁéØÂ¢ÉÁöÑÁ°¨‰ª∂ÈÖçÁΩÆ\n",
    "# - Á°ÆËÆ§ÊòØÂê¶Êª°Ë∂≥Ê®°ÂûãËøêË°åÁöÑÊúÄ‰ΩéË¶ÅÊ±Ç\n",
    "# - Â≠¶‰π†Â¶Ç‰ΩïÈÄöËøá‰ª£Á†ÅËé∑ÂèñÁ≥ªÁªü‰ø°ÊÅØ\n",
    "\n",
    "# ÂÆâË£Ö pandas Â∫ì - Áî®‰∫éÂàõÂª∫ÂíåÂ±ïÁ§∫Êï∞ÊçÆË°®Ê†º\n",
    "# pandas ÊòØ Python ‰∏≠ÊúÄÊµÅË°åÁöÑÊï∞ÊçÆÂ§ÑÁêÜÂíåÂàÜÊûêÂ∫ì\n",
    "%pip install pandas==2.2.2 tabulate==0.9.0\n",
    "\n",
    "import platform # ÂØºÂÖ• platform Ê®°Âùó‰ª•Ëé∑ÂèñÁ≥ªÁªü‰ø°ÊÅØ\n",
    "import os # ÂØºÂÖ• os Ê®°Âùó‰ª•‰∏éÊìç‰ΩúÁ≥ªÁªü‰∫§‰∫í\n",
    "import subprocess # ÂØºÂÖ• subprocess Ê®°Âùó‰ª•ËøêË°åÂ§ñÈÉ®ÂëΩ‰ª§\n",
    "import pandas as pd # ÂØºÂÖ• pandas Ê®°ÂùóÔºåÈÄöÂ∏∏Áî®‰∫éÊï∞ÊçÆÂ§ÑÁêÜÔºåËøôÈáåÁî®‰∫éÂàõÂª∫Ë°®Ê†º\n",
    "import shutil # ÂØºÂÖ• shutil Ê®°Âùó‰ª•Ëé∑ÂèñÁ£ÅÁõòÁ©∫Èó¥‰ø°ÊÅØ\n",
    "\n",
    "# Ëé∑Âèñ CPU ‰ø°ÊÅØÁöÑÂáΩÊï∞ÔºåÂåÖÊã¨Ê†∏ÂøÉÊï∞Èáè\n",
    "def get_cpu_info():\n",
    "    cpu_info = \"\" # ÂàùÂßãÂåñ CPU ‰ø°ÊÅØÂ≠óÁ¨¶‰∏≤\n",
    "    physical_cores = \"N/A\"\n",
    "    logical_cores = \"N/A\"\n",
    "\n",
    "    if platform.system() == \"Windows\": # Â¶ÇÊûúÊòØ Windows Á≥ªÁªü\n",
    "        cpu_info = platform.processor() # ‰ΩøÁî® platform.processor() Ëé∑Âèñ CPU ‰ø°ÊÅØ\n",
    "        try:\n",
    "            # Ëé∑Âèñ Windows ‰∏äÁöÑÊ†∏ÂøÉÊï∞Èáè (ÈúÄË¶Å WMI)\n",
    "            import wmi\n",
    "            c = wmi.WMI()\n",
    "            for proc in c.Win32_Processor():\n",
    "                physical_cores = proc.NumberOfCores\n",
    "                logical_cores = proc.NumberOfLogicalProcessors\n",
    "        except:\n",
    "            pass # Â¶ÇÊûú WMI ‰∏çÂèØÁî®ÔºåÂøΩÁï•ÈîôËØØ\n",
    "\n",
    "    elif platform.system() == \"Darwin\": # Â¶ÇÊûúÊòØ macOS Á≥ªÁªü\n",
    "        # Âú® macOS ‰∏ä‰ΩøÁî® sysctl ÂëΩ‰ª§Ëé∑Âèñ CPU ‰ø°ÊÅØÂíåÊ†∏ÂøÉÊï∞Èáè\n",
    "        os.environ['PATH'] = os.environ['PATH'] + os.pathsep + '/usr/sbin' # Êõ¥Êñ∞ PATH ÁéØÂ¢ÉÂèòÈáè\n",
    "        try:\n",
    "            process_brand = subprocess.Popen(['sysctl', \"machdep.cpu.brand_string\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            stdout_brand, stderr_brand = process_brand.communicate()\n",
    "            cpu_info = stdout_brand.decode().split(': ')[1].strip() if stdout_brand else \"Could not retrieve CPU info\"\n",
    "\n",
    "            process_physical = subprocess.Popen(['sysctl', \"hw.physicalcpu\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            stdout_physical, stderr_physical = process_physical.communicate()\n",
    "            physical_cores = stdout_physical.decode().split(': ')[1].strip() if stdout_physical else \"N/A\"\n",
    "\n",
    "            process_logical = subprocess.Popen(['sysctl', \"hw.logicalcpu\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            stdout_logical, stderr_logical = process_logical.communicate()\n",
    "            logical_cores = stdout_logical.decode().split(': ')[1].strip() if stdout_logical else \"N/A\"\n",
    "\n",
    "        except:\n",
    "            cpu_info = \"Could not retrieve CPU info\"\n",
    "            physical_cores = \"N/A\"\n",
    "            logical_cores = \"N/A\"\n",
    "\n",
    "    else:  # Linux Á≥ªÁªü\n",
    "        try:\n",
    "            # Âú® Linux ‰∏äËØªÂèñ /proc/cpuinfo Êñá‰ª∂Ëé∑Âèñ CPU ‰ø°ÊÅØÂíåÊ†∏ÂøÉÊï∞Èáè\n",
    "            with open('/proc/cpuinfo') as f:\n",
    "                physical_cores_count = 0\n",
    "                logical_cores_count = 0\n",
    "                cpu_info_lines = []\n",
    "                for line in f:\n",
    "                    if line.startswith('model name'): # Êü•Êâæ‰ª• 'model name'ÂºÄÂ§¥ÁöÑË°å\n",
    "                        if not cpu_info: # Âè™Ëé∑ÂèñÁ¨¨‰∏Ä‰∏™ model name\n",
    "                            cpu_info = line.split(': ')[1].strip()\n",
    "                    elif line.startswith('cpu cores'): # Êü•Êâæ‰ª• 'cpu cores' ÂºÄÂ§¥ÁöÑË°å\n",
    "                        physical_cores_count = int(line.split(': ')[1].strip())\n",
    "                    elif line.startswith('processor'): # Êü•Êâæ‰ª• 'processor' ÂºÄÂ§¥ÁöÑË°å\n",
    "                        logical_cores_count += 1\n",
    "                physical_cores = str(physical_cores_count) if physical_cores_count > 0 else \"N/A\"\n",
    "                logical_cores = str(logical_cores_count) if logical_cores_count > 0 else \"N/A\"\n",
    "                if not cpu_info:\n",
    "                     cpu_info = \"Could not retrieve CPU info\"\n",
    "\n",
    "        except:\n",
    "            cpu_info = \"Could not retrieve CPU info\"\n",
    "            physical_cores = \"N/A\"\n",
    "            logical_cores = \"N/A\"\n",
    "\n",
    "    return f\"{cpu_info} ({physical_cores} physical cores, {logical_cores} logical cores)\" # ËøîÂõû CPU ‰ø°ÊÅØÂíåÊ†∏ÂøÉÊï∞Èáè\n",
    "\n",
    "\n",
    "# Ëé∑ÂèñÂÜÖÂ≠ò‰ø°ÊÅØÁöÑÂáΩÊï∞\n",
    "def get_memory_info():\n",
    "    mem_info = \"\" # ÂàùÂßãÂåñÂÜÖÂ≠ò‰ø°ÊÅØÂ≠óÁ¨¶‰∏≤\n",
    "    if platform.system() == \"Windows\":\n",
    "        # Âú® Windows ‰∏ä‰∏çÂÆπÊòìÈÄöËøáÊ†áÂáÜÂ∫ìËé∑ÂèñÔºåÈúÄË¶ÅÂ§ñÈÉ®Â∫ìÊàñ PowerShell\n",
    "        mem_info = \"Requires external tools on Windows\" # ËÆæÁΩÆÊèêÁ§∫‰ø°ÊÅØ\n",
    "    elif platform.system() == \"Darwin\": # Â¶ÇÊûúÊòØ macOS Á≥ªÁªü\n",
    "        # Âú® macOS ‰∏ä‰ΩøÁî® sysctl ÂëΩ‰ª§Ëé∑ÂèñÂÜÖÂ≠òÂ§ßÂ∞è\n",
    "        process = subprocess.Popen(['sysctl', \"hw.memsize\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE) # ËøêË°å sysctl ÂëΩ‰ª§\n",
    "        stdout, stderr = process.communicate() # Ëé∑ÂèñÊ†áÂáÜËæìÂá∫ÂíåÊ†áÂáÜÈîôËØØ\n",
    "        mem_bytes = int(stdout.decode().split(': ')[1].strip()) # Ëß£ÊûêËæìÂá∫ÔºåËé∑ÂèñÂÜÖÂ≠òÂ§ßÂ∞èÔºàÂ≠óËäÇÔºâ\n",
    "        mem_gb = mem_bytes / (1024**3) # ËΩ¨Êç¢‰∏∫ GB\n",
    "        mem_info = f\"{mem_gb:.2f} GB\" # Ê†ºÂºèÂåñËæìÂá∫\n",
    "    else:  # Linux Á≥ªÁªü\n",
    "        try:\n",
    "            # Âú® Linux ‰∏äËØªÂèñ /proc/meminfo Êñá‰ª∂Ëé∑ÂèñÂÜÖÂ≠ò‰ø°ÊÅØ\n",
    "            with open('/proc/meminfo') as f:\n",
    "                total_mem_kb = 0\n",
    "                available_mem_kb = 0\n",
    "                for line in f:\n",
    "                    if line.startswith('MemTotal'): # Êü•Êâæ‰ª• 'MemTotal' ÂºÄÂ§¥ÁöÑË°å\n",
    "                        total_mem_kb = int(line.split(':')[1].strip().split()[0]) # Ëß£ÊûêË°åÔºåËé∑ÂèñÊÄªÂÜÖÂ≠òÔºàKBÔºâ\n",
    "                    elif line.startswith('MemAvailable'): # Êü•Êâæ‰ª• 'MemAvailable' ÂºÄÂ§¥ÁöÑË°å\n",
    "                         available_mem_kb = int(line.split(':')[1].strip().split()[0]) # Ëß£ÊûêË°åÔºåËé∑ÂèñÂèØÁî®ÂÜÖÂ≠òÔºàKBÔºâ\n",
    "\n",
    "                if total_mem_kb > 0:\n",
    "                    total_mem_gb = total_mem_kb / (1024**2) # ËΩ¨Êç¢‰∏∫ GB\n",
    "                    mem_info = f\"{total_mem_gb:.2f} GB\" # Ê†ºÂºèÂåñËæìÂá∫ÊÄªÂÜÖÂ≠ò\n",
    "                    if available_mem_kb > 0:\n",
    "                        available_mem_gb = available_mem_kb / (1024**2)\n",
    "                        mem_info += f\" (Available: {available_mem_gb:.2f} GB)\" # Ê∑ªÂä†ÂèØÁî®ÂÜÖÂ≠ò‰ø°ÊÅØ\n",
    "                else:\n",
    "                     mem_info = \"Could not retrieve memory info\" # Â¶ÇÊûúËØªÂèñÊñá‰ª∂Âá∫ÈîôÔºåËÆæÁΩÆÈîôËØØ‰ø°ÊÅØ\n",
    "\n",
    "        except:\n",
    "            mem_info = \"Could not retrieve memory info\" # Â¶ÇÊûúËØªÂèñÊñá‰ª∂Âá∫ÈîôÔºåËÆæÁΩÆÈîôËØØ‰ø°ÊÅØ\n",
    "    return mem_info # ËøîÂõûÂÜÖÂ≠ò‰ø°ÊÅØ\n",
    "\n",
    "# Ëé∑Âèñ GPU ‰ø°ÊÅØÁöÑÂáΩÊï∞ÔºåÂåÖÊã¨ÊòæÂ≠ò\n",
    "def get_gpu_info():\n",
    "    try:\n",
    "        # Â∞ùËØï‰ΩøÁî® nvidia-smi Ëé∑Âèñ NVIDIA GPU ‰ø°ÊÅØÂíåÊòæÂ≠ò\n",
    "        result = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total', '--format=csv,noheader'], capture_output=True, text=True)\n",
    "        if result.returncode == 0: # Â¶ÇÊûúÂëΩ‰ª§ÊàêÂäüÊâßË°å\n",
    "            gpu_lines = result.stdout.strip().split('\\n') # Ëß£ÊûêËæìÂá∫ÔºåËé∑Âèñ GPU ÂêçÁß∞ÂíåÊòæÂ≠ò\n",
    "            gpu_info_list = []\n",
    "            for line in gpu_lines:\n",
    "                name, memory = line.split(', ')\n",
    "                gpu_info_list.append(f\"{name} ({memory})\") # Ê†ºÂºèÂåñ GPU ‰ø°ÊÅØ\n",
    "            return \", \".join(gpu_info_list) if gpu_info_list else \"NVIDIA GPU found, but info not listed\" # ËøîÂõû GPU ‰ø°ÊÅØÊàñÊèêÁ§∫‰ø°ÊÅØ\n",
    "        else:\n",
    "             # Â∞ùËØï‰ΩøÁî® lshw Ëé∑ÂèñÂÖ∂‰ªñ GPU ‰ø°ÊÅØ (ÈúÄË¶ÅÂÆâË£Ö lshw)\n",
    "            try:\n",
    "                result_lshw = subprocess.run(['lshw', '-C', 'display'], capture_output=True, text=True)\n",
    "                if result_lshw.returncode == 0: # Â¶ÇÊûúÂëΩ‰ª§ÊàêÂäüÊâßË°å\n",
    "                     # ÁÆÄÂçïËß£ÊûêËæìÂá∫‰∏≠ÁöÑ product ÂêçÁß∞ÂíåÊòæÂ≠ò\n",
    "                    gpu_info_lines = []\n",
    "                    current_gpu = {}\n",
    "                    for line in result_lshw.stdout.splitlines():\n",
    "                        if 'product:' in line:\n",
    "                             if current_gpu:\n",
    "                                 gpu_info_lines.append(f\"{current_gpu.get('product', 'GPU')} ({current_gpu.get('memory', 'N/A')})\")\n",
    "                             current_gpu = {'product': line.split('product:')[1].strip()}\n",
    "                        elif 'size:' in line and 'memory' in line:\n",
    "                             current_gpu['memory'] = line.split('size:')[1].strip()\n",
    "\n",
    "                    if current_gpu: # Ê∑ªÂä†ÊúÄÂêé‰∏Ä‰∏™ GPU ÁöÑ‰ø°ÊÅØ\n",
    "                        gpu_info_lines.append(f\"{current_gpu.get('product', 'GPU')} ({current_gpu.get('memory', 'N/A')})\")\n",
    "\n",
    "                    return \", \".join(gpu_info_lines) if gpu_info_lines else \"GPU found (via lshw), but info not parsed\" # Â¶ÇÊûúÊâæÂà∞ GPU ‰ΩÜ‰ø°ÊÅØÊó†Ê≥ïËß£ÊûêÔºåËÆæÁΩÆÊèêÁ§∫‰ø°ÊÅØ\n",
    "                else:\n",
    "                    return \"No GPU found (checked nvidia-smi and lshw)\" # Â¶ÇÊûú‰∏§‰∏™ÂëΩ‰ª§ÈÉΩÊâæ‰∏çÂà∞ GPUÔºåËÆæÁΩÆÊèêÁ§∫‰ø°ÊÅØ\n",
    "            except FileNotFoundError:\n",
    "                 return \"No GPU found (checked nvidia-smi, lshw not found)\" # Â¶ÇÊûúÊâæ‰∏çÂà∞ lshw ÂëΩ‰ª§ÔºåËÆæÁΩÆÊèêÁ§∫‰ø°ÊÅØ\n",
    "    except FileNotFoundError:\n",
    "        return \"No GPU found (nvidia-smi not found)\" # Â¶ÇÊûúÊâæ‰∏çÂà∞ nvidia-smi ÂëΩ‰ª§ÔºåËÆæÁΩÆÊèêÁ§∫‰ø°ÊÅØ\n",
    "\n",
    "\n",
    "# Ëé∑Âèñ CUDA ÁâàÊú¨ÁöÑÂáΩÊï∞\n",
    "def get_cuda_version():\n",
    "    try:\n",
    "        # Â∞ùËØï‰ΩøÁî® nvcc --version Ëé∑Âèñ CUDA ÁâàÊú¨\n",
    "        result = subprocess.run(['nvcc', '--version'], capture_output=True, text=True)\n",
    "        if result.returncode == 0: # Â¶ÇÊûúÂëΩ‰ª§ÊàêÂäüÊâßË°å\n",
    "            for line in result.stdout.splitlines():\n",
    "                if 'release' in line: # Êü•ÊâæÂåÖÂê´ 'release' ÁöÑË°å\n",
    "                    return line.split('release ')[1].split(',')[0] # Ëß£ÊûêË°åÔºåÊèêÂèñÁâàÊú¨Âè∑\n",
    "        return \"CUDA not found or version not parsed\" # Â¶ÇÊûúÊâæ‰∏çÂà∞ CUDA ÊàñÁâàÊú¨Êó†Ê≥ïËß£ÊûêÔºåËÆæÁΩÆÊèêÁ§∫‰ø°ÊÅØ\n",
    "    except FileNotFoundError:\n",
    "        return \"CUDA not found\" # Â¶ÇÊûúÊâæ‰∏çÂà∞ nvcc ÂëΩ‰ª§ÔºåËÆæÁΩÆÊèêÁ§∫‰ø°ÊÅØ\n",
    "\n",
    "# Ëé∑Âèñ Python ÁâàÊú¨ÁöÑÂáΩÊï∞\n",
    "def get_python_version():\n",
    "    return platform.python_version() # Ëé∑Âèñ Python ÁâàÊú¨\n",
    "\n",
    "# Ëé∑Âèñ Conda ÁâàÊú¨ÁöÑÂáΩÊï∞\n",
    "def get_conda_version():\n",
    "    try:\n",
    "        # Â∞ùËØï‰ΩøÁî® conda --version Ëé∑Âèñ Conda ÁâàÊú¨\n",
    "        result = subprocess.run(['conda', '--version'], capture_output=True, text=True)\n",
    "        if result.returncode == 0: # Â¶ÇÊûúÂëΩ‰ª§ÊàêÂäüÊâßË°å\n",
    "            return result.stdout.strip() # ËøîÂõû Conda ÁâàÊú¨\n",
    "        return \"Conda not found or version not parsed\" # Â¶ÇÊûúÊâæ‰∏çÂà∞ Conda ÊàñÁâàÊú¨Êó†Ê≥ïËß£ÊûêÔºåËÆæÁΩÆÊèêÁ§∫‰ø°ÊÅØ\n",
    "    except FileNotFoundError:\n",
    "        return \"Conda not found\" # Â¶ÇÊûúÊâæ‰∏çÂà∞ conda ÂëΩ‰ª§ÔºåËÆæÁΩÆÊèêÁ§∫‰ø°ÊÅØ\n",
    "\n",
    "# Ëé∑ÂèñÁâ©ÁêÜÁ£ÅÁõòÁ©∫Èó¥‰ø°ÊÅØÁöÑÂáΩÊï∞\n",
    "def get_disk_space():\n",
    "    try:\n",
    "        total, used, free = shutil.disk_usage(\"/\") # Ëé∑ÂèñÊ†πÁõÆÂΩïÁöÑÁ£ÅÁõò‰ΩøÁî®ÊÉÖÂÜµ\n",
    "        total_gb = total / (1024**3) # ËΩ¨Êç¢‰∏∫ GB\n",
    "        used_gb = used / (1024**3) # ËΩ¨Êç¢‰∏∫ GB\n",
    "        free_gb = free / (1024**3) # ËΩ¨Êç¢‰∏∫ GB\n",
    "        return f\"Total: {total_gb:.2f} GB, Used: {used_gb:.2f} GB, Free: {free_gb:.2f} GB\" # Ê†ºÂºèÂåñËæìÂá∫\n",
    "    except Exception as e:\n",
    "        return f\"Could not retrieve disk info: {e}\" # Â¶ÇÊûúËé∑Âèñ‰ø°ÊÅØÂá∫ÈîôÔºåËÆæÁΩÆÈîôËØØ‰ø°ÊÅØ\n",
    "\n",
    "# Ëé∑ÂèñÁéØÂ¢É‰ø°ÊÅØ\n",
    "os_name = platform.system() # Ëé∑ÂèñÊìç‰ΩúÁ≥ªÁªüÂêçÁß∞\n",
    "os_version = platform.release() # Ëé∑ÂèñÊìç‰ΩúÁ≥ªÁªüÁâàÊú¨\n",
    "if os_name == \"Linux\":\n",
    "    try:\n",
    "        # Âú® Linux ‰∏äÂ∞ùËØïËé∑ÂèñÂèëË°åÁâàÂíåÁâàÊú¨\n",
    "        lsb_info = subprocess.run(['lsb_release', '-a'], capture_output=True, text=True)\n",
    "        if lsb_info.returncode == 0: # Â¶ÇÊûúÂëΩ‰ª§ÊàêÂäüÊâßË°å\n",
    "            for line in lsb_info.stdout.splitlines():\n",
    "                if 'Description:' in line: # Êü•ÊâæÂåÖÂê´ 'Description:' ÁöÑË°å\n",
    "                    os_version = line.split('Description:')[1].strip() # ÊèêÂèñÊèèËø∞‰ø°ÊÅØ‰Ωú‰∏∫ÁâàÊú¨\n",
    "                    break # ÊâæÂà∞ÂêéÈÄÄÂá∫Âæ™ÁéØ\n",
    "                elif 'Release:' in line: # Êü•ÊâæÂåÖÂê´ 'Release:' ÁöÑË°å\n",
    "                     os_version = line.split('Release:')[1].strip() # ÊèêÂèñÁâàÊú¨Âè∑\n",
    "                     # Â∞ùËØïËé∑Âèñ codename\n",
    "                     try:\n",
    "                         codename_info = subprocess.run(['lsb_release', '-c'], capture_output=True, text=True)\n",
    "                         if codename_info.returncode == 0:\n",
    "                             os_version += f\" ({codename_info.stdout.split(':')[1].strip()})\" # Â∞Ü codename Ê∑ªÂä†Âà∞ÁâàÊú¨‰ø°ÊÅØ‰∏≠\n",
    "                     except:\n",
    "                         pass # Â¶ÇÊûúËé∑Âèñ codename Â§±Ë¥•ÂàôÂøΩÁï•\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        pass # lsb_release ÂèØËÉΩÊú™ÂÆâË£ÖÔºåÂøΩÁï•ÈîôËØØ\n",
    "\n",
    "full_os_info = f\"{os_name} {os_version}\" # ÁªÑÂêàÂÆåÊï¥ÁöÑÊìç‰ΩúÁ≥ªÁªü‰ø°ÊÅØ\n",
    "cpu_info = get_cpu_info() # Ë∞ÉÁî®ÂáΩÊï∞Ëé∑Âèñ CPU ‰ø°ÊÅØÂíåÊ†∏ÂøÉÊï∞Èáè\n",
    "memory_info = get_memory_info() # Ë∞ÉÁî®ÂáΩÊï∞Ëé∑ÂèñÂÜÖÂ≠ò‰ø°ÊÅØ\n",
    "gpu_info = get_gpu_info() # Ë∞ÉÁî®ÂáΩÊï∞Ëé∑Âèñ GPU ‰ø°ÊÅØÂíåÊòæÂ≠ò\n",
    "cuda_version = get_cuda_version() # Ë∞ÉÁî®ÂáΩÊï∞Ëé∑Âèñ CUDA ÁâàÊú¨\n",
    "python_version = get_python_version() # Ë∞ÉÁî®ÂáΩÊï∞Ëé∑Âèñ Python ÁâàÊú¨\n",
    "conda_version = get_conda_version() # Ë∞ÉÁî®ÂáΩÊï∞Ëé∑Âèñ Conda ÁâàÊú¨\n",
    "disk_info = get_disk_space() # Ë∞ÉÁî®ÂáΩÊï∞Ëé∑ÂèñÁâ©ÁêÜÁ£ÅÁõòÁ©∫Èó¥‰ø°ÊÅØ\n",
    "\n",
    "\n",
    "# ÂàõÂª∫Áî®‰∫éÂ≠òÂÇ®Êï∞ÊçÆÁöÑÂ≠óÂÖ∏\n",
    "env_data = {\n",
    "    \"È°πÁõÆ\": [ # È°πÁõÆÂêçÁß∞ÂàóË°®\n",
    "        \"Êìç‰ΩúÁ≥ªÁªü\",\n",
    "        \"CPU ‰ø°ÊÅØ\",\n",
    "        \"ÂÜÖÂ≠ò‰ø°ÊÅØ\",\n",
    "        \"GPU ‰ø°ÊÅØ\",\n",
    "        \"CUDA ‰ø°ÊÅØ\",\n",
    "        \"Python ÁâàÊú¨\",\n",
    "        \"Conda ÁâàÊú¨\",\n",
    "        \"Áâ©ÁêÜÁ£ÅÁõòÁ©∫Èó¥\" # Ê∑ªÂä†Áâ©ÁêÜÁ£ÅÁõòÁ©∫Èó¥\n",
    "    ],\n",
    "    \"‰ø°ÊÅØ\": [ # ÂØπÂ∫îÁöÑ‰ø°ÊÅØÂàóË°®\n",
    "        full_os_info,\n",
    "        cpu_info,\n",
    "        memory_info,\n",
    "        gpu_info,\n",
    "        cuda_version,\n",
    "        python_version,\n",
    "        conda_version,\n",
    "        disk_info # Ê∑ªÂä†Áâ©ÁêÜÁ£ÅÁõòÁ©∫Èó¥‰ø°ÊÅØ\n",
    "    ]\n",
    "}\n",
    "\n",
    "# ÂàõÂª∫‰∏Ä‰∏™ pandas DataFrame\n",
    "df = pd.DataFrame(env_data)\n",
    "\n",
    "# ÊâìÂç∞Ë°®Ê†º\n",
    "print(\"### ÁéØÂ¢É‰ø°ÊÅØ\") # ÊâìÂç∞Ê†áÈ¢ò\n",
    "print(df.to_markdown(index=False)) # Â∞Ü DataFrame ËΩ¨Êç¢‰∏∫ Markdown Ê†ºÂºèÂπ∂ÊâìÂç∞Ôºå‰∏çÂåÖÂê´Á¥¢Âºï\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b651ead9-5504-45ee-938d-f91ac78dddd1",
   "metadata": {
    "id": "b651ead9-5504-45ee-938d-f91ac78dddd1"
   },
   "source": [
    "# Â∏¶Ê∂àÊÅØÊëòË¶ÅÂäüËÉΩÁöÑËÅäÂ§©Êú∫Âô®‰∫∫\n",
    "\n",
    "## ÂõûÈ°æ\n",
    "\n",
    "Êàë‰ª¨Â∑≤ÁªèÂ≠¶‰π†‰∫ÜÂ¶Ç‰ΩïËá™ÂÆö‰πâÂõæÁä∂ÊÄÅÊ®°ÂºèÔºàgraph state schemaÔºâÂíåÁä∂ÊÄÅÂΩíÁ∫¶Âô®ÔºàreducerÔºâ„ÄÇ\n",
    "\n",
    "Êàë‰ª¨‰πüÂ±ïÁ§∫‰∫ÜÂ§öÁßçÂú®ÂõæÁä∂ÊÄÅ‰∏≠‰øÆÂâ™ÊàñËøáÊª§Ê∂àÊÅØÁöÑÊñπÊ≥ï„ÄÇ\n",
    "\n",
    "## ÁõÆÊ†á\n",
    "\n",
    "Áé∞Âú®ÔºåËÆ©Êàë‰ª¨Êõ¥Ëøõ‰∏ÄÊ≠•ÔºÅ\n",
    "\n",
    "‰∏ç‰ªÖ‰ªÖÊòØ‰øÆÂâ™ÊàñËøáÊª§Ê∂àÊÅØÔºåÊàë‰ª¨Â∞ÜÂ±ïÁ§∫**Â¶Ç‰Ωï‰ΩøÁî®Â§ßËØ≠Ë®ÄÊ®°ÂûãÔºàLLMÔºâÊù•ÁîüÊàêÂØπËØùÁöÑÊåÅÁª≠ÊëòË¶Å**„ÄÇ\n",
    "\n",
    "Ëøô‰ΩøÊàë‰ª¨ËÉΩÂ§ü‰øùÁïôÂÆåÊï¥ÂØπËØùÁöÑÂéãÁº©Ë°®Á§∫ÔºåËÄå‰∏çÊòØÁÆÄÂçïÂú∞ÈÄöËøá‰øÆÂâ™ÊàñËøáÊª§Êù•Âà†Èô§ÂÆÉ‰ª¨„ÄÇ\n",
    "\n",
    "Êàë‰ª¨Â∞ÜÊääËøôÁßçÊëòË¶ÅÂäüËÉΩÊï¥ÂêàÂà∞‰∏Ä‰∏™ÁÆÄÂçïÁöÑËÅäÂ§©Êú∫Âô®‰∫∫‰∏≠„ÄÇ\n",
    "\n",
    "Âπ∂‰∏îÊàë‰ª¨Â∞Ü‰∏∫Ëøô‰∏™ËÅäÂ§©Êú∫Âô®‰∫∫ÈÖçÂ§áËÆ∞ÂøÜÂäüËÉΩÔºåÊîØÊåÅÈïøÊó∂Èó¥ËøêË°åÁöÑÂØπËØùÔºåËÄå‰∏ç‰ºö‰∫ßÁîüÈ´òÊòÇÁöÑtokenÊàêÊú¨ÊàñÂª∂Ëøü„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "000a6daa-92ad-4e57-a060-d1c81176eb0d",
   "metadata": {
    "id": "000a6daa-92ad-4e57-a060-d1c81176eb0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# ÂÆâË£ÖÂøÖË¶ÅÁöÑ‰æùËµñÂåÖ\n",
    "# ‰ΩøÁî® %%capture Êù•ÈöêËóèÂÆâË£ÖËøáÁ®ãÁöÑËæìÂá∫‰ø°ÊÅØ\n",
    "# %%capture --no-stderr\n",
    "# %pip install --quiet -U langchain_core langgraph langchain_openai\n",
    "%pip install --quiet langchain_openai==0.3.32 langchain_core==0.3.75 langgraph==0.6.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09201a62",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "09201a62",
    "outputId": "181fdbf3-2fa5-42a5-d4de-ec9ab8e0a9ee"
   },
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    \"\"\"\n",
    "    ËÆæÁΩÆÁéØÂ¢ÉÂèòÈáèÁöÑËæÖÂä©ÂáΩÊï∞\n",
    "    Â¶ÇÊûúÁéØÂ¢ÉÂèòÈáè‰∏çÂ≠òÂú®ÔºåÂàôÊèêÁ§∫Áî®Êà∑ËæìÂÖ•\n",
    "    \"\"\"\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "# ËÆæÁΩÆ OpenAI API ÂØÜÈí•\n",
    "# ËøôÊòØ‰ΩøÁî® OpenAI Ê®°ÂûãÊâÄÂøÖÈúÄÁöÑ\n",
    "_set_env(\"OPENAI_API_KEY\")\n",
    "# ËÆæÁΩÆ OpenAI API‰ª£ÁêÜÂú∞ÂùÄ (‰æãÂ¶ÇÔºöhttps://api.apiyi.com/v1Ôºâ\n",
    "_set_env(\"OPENAI_BASE_URL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfddfce9-3a9b-4b35-a76d-28265515aabd",
   "metadata": {
    "id": "dfddfce9-3a9b-4b35-a76d-28265515aabd"
   },
   "source": [
    "Êàë‰ª¨Â∞Ü‰ΩøÁî® [LangSmith](https://docs.smith.langchain.com/) ËøõË°å[ËøΩË∏™](https://docs.smith.langchain.com/concepts/tracing)„ÄÇ\n",
    "\n",
    "LangSmith ÊòØ LangChain Êèê‰æõÁöÑË∞ÉËØïÂíåÁõëÊéßÂ∑•ÂÖ∑ÔºåÂèØ‰ª•Â∏ÆÂä©Êàë‰ª¨Ôºö\n",
    "- ËøΩË∏™ LLM Ë∞ÉÁî®Èìæ\n",
    "- ÁõëÊéßÊÄßËÉΩÂíåÊàêÊú¨\n",
    "- Ë∞ÉËØïÂØπËØùÊµÅÁ®ã\n",
    "- ÂàÜÊûêÊ®°ÂûãË°å‰∏∫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "464856d4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "464856d4",
    "outputId": "02083c1b-58d2-4ecf-9bfd-d176c5ed864a"
   },
   "outputs": [],
   "source": [
    "# ËÆæÁΩÆ LangSmith Áõ∏ÂÖ≥ÁéØÂ¢ÉÂèòÈáè\n",
    "# LangSmith Áî®‰∫éËøΩË∏™ÂíåË∞ÉËØï LangChain Â∫îÁî®\n",
    "_set_env(\"LANGSMITH_API_KEY\")  # LangSmith API ÂØÜÈí•\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"  # ÂêØÁî®ËøΩË∏™ÂäüËÉΩ\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"FlyAIBox\"  # ËÆæÁΩÆÈ°πÁõÆÂêçÁß∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "537ade30-6a0e-4b6b-8bcd-ce90790b6392",
   "metadata": {
    "id": "537ade30-6a0e-4b6b-8bcd-ce90790b6392"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ÂàùÂßãÂåñ OpenAI ËÅäÂ§©Ê®°Âûã\n",
    "# gpt-4o: ‰ΩøÁî® GPT-4 Omni Ê®°ÂûãÔºåËøôÊòØ OpenAI ÊúÄÊñ∞ÁöÑÂ§öÊ®°ÊÄÅÊ®°Âûã\n",
    "# temperature=0: ËÆæÁΩÆÊ∏©Â∫¶‰∏∫ 0Ôºå‰ΩøÊ®°ÂûãËæìÂá∫Êõ¥Âä†Á°ÆÂÆöÊÄßÂíå‰∏ÄËá¥\n",
    "model = ChatOpenAI(model=\"gpt-4o\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3afac3-8b7a-45db-a3c1-7e4125c1bc8b",
   "metadata": {
    "id": "db3afac3-8b7a-45db-a3c1-7e4125c1bc8b"
   },
   "source": [
    "Êàë‰ª¨Â∞Ü‰ΩøÁî® `MessagesState`ÔºåÂ∞±ÂÉè‰πãÂâç‰∏ÄÊ†∑„ÄÇ\n",
    "\n",
    "Èô§‰∫ÜÂÜÖÁΩÆÁöÑ `messages` ÈîÆ‰πãÂ§ñÔºåÊàë‰ª¨Áé∞Âú®ËøòÂ∞ÜÂåÖÂê´‰∏Ä‰∏™Ëá™ÂÆö‰πâÈîÆÔºà`summary`Ôºâ„ÄÇ\n",
    "\n",
    "**Áä∂ÊÄÅËÆæËÆ°ËØ¥ÊòéÔºö**\n",
    "- `messages`: Â≠òÂÇ®ÂØπËØùÂéÜÂè≤Ê∂àÊÅØÂàóË°®\n",
    "- `summary`: Â≠òÂÇ®ÂØπËØùÁöÑÊëòË¶Å‰ø°ÊÅØÔºåÁî®‰∫éÂéãÁº©ÈïøÂØπËØùÂéÜÂè≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "948e60f0-5c76-4235-b40e-cf523205d40e",
   "metadata": {
    "id": "948e60f0-5c76-4235-b40e-cf523205d40e"
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState\n",
    "\n",
    "class State(MessagesState):\n",
    "    \"\"\"\n",
    "    Ëá™ÂÆö‰πâÁä∂ÊÄÅÁ±ªÔºåÁªßÊâøËá™ MessagesState\n",
    "\n",
    "    ÁªßÊâøÁöÑÂäüËÉΩÔºö\n",
    "    - messages: Ê∂àÊÅØÂàóË°®ÔºåÁî®‰∫éÂ≠òÂÇ®ÂØπËØùÂéÜÂè≤\n",
    "\n",
    "    Êñ∞Â¢ûÂäüËÉΩÔºö\n",
    "    - summary: Â≠óÁ¨¶‰∏≤Á±ªÂûãÔºåÁî®‰∫éÂ≠òÂÇ®ÂØπËØùÊëòË¶Å\n",
    "    \"\"\"\n",
    "    summary: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6855ea31-5cc1-4277-a189-0b72459f67ec",
   "metadata": {
    "id": "6855ea31-5cc1-4277-a189-0b72459f67ec"
   },
   "source": [
    "Êàë‰ª¨Â∞ÜÂÆö‰πâ‰∏Ä‰∏™ËäÇÁÇπÊù•Ë∞ÉÁî®Êàë‰ª¨ÁöÑ LLMÔºåÂ¶ÇÊûúÂ≠òÂú®ÊëòË¶ÅÔºåÂàôÂ∞ÜÂÖ∂ËûçÂÖ•Âà∞ÊèêÁ§∫‰∏≠„ÄÇ\n",
    "\n",
    "**ËäÇÁÇπÂäüËÉΩËØ¥ÊòéÔºö**\n",
    "- Ê£ÄÊü•Áä∂ÊÄÅ‰∏≠ÊòØÂê¶Â≠òÂú®ÊëòË¶Å\n",
    "- Â¶ÇÊûúÂ≠òÂú®ÊëòË¶ÅÔºåÂ∞ÜÂÖ∂‰Ωú‰∏∫Á≥ªÁªüÊ∂àÊÅØÊ∑ªÂä†Âà∞ÂØπËØù‰∏≠\n",
    "- Ë∞ÉÁî® LLM ÁîüÊàêÂõûÂ§ç\n",
    "- ËøîÂõû AI ÁöÑÂõûÂ§çÊ∂àÊÅØ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3f7d19b-afe0-4381-9b1a-0a832b162e7b",
   "metadata": {
    "id": "c3f7d19b-afe0-4381-9b1a-0a832b162e7b"
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage, RemoveMessage\n",
    "\n",
    "def call_model(state: State):\n",
    "    \"\"\"\n",
    "    Ë∞ÉÁî® LLM Ê®°ÂûãÁîüÊàêÂõûÂ§çÁöÑËäÇÁÇπÂáΩÊï∞\n",
    "\n",
    "    ÂèÇÊï∞:\n",
    "        state (State): ÂΩìÂâçÂõæÁä∂ÊÄÅÔºåÂåÖÂê´Ê∂àÊÅØÂíåÊëòË¶Å‰ø°ÊÅØ\n",
    "\n",
    "    ËøîÂõû:\n",
    "        dict: ÂåÖÂê´ AI ÂõûÂ§çÊ∂àÊÅØÁöÑÂ≠óÂÖ∏\n",
    "\n",
    "    ÂäüËÉΩËØ¥Êòé:\n",
    "        1. Ê£ÄÊü•Áä∂ÊÄÅ‰∏≠ÊòØÂê¶Â≠òÂú®ÂØπËØùÊëòË¶Å\n",
    "        2. Â¶ÇÊûúÂ≠òÂú®ÊëòË¶ÅÔºåÂ∞ÜÂÖ∂‰Ωú‰∏∫Á≥ªÁªüÊ∂àÊÅØÊ∑ªÂä†Âà∞ÂØπËØù‰∏ä‰∏ãÊñá‰∏≠\n",
    "        3. Ë∞ÉÁî® LLM Ê®°ÂûãÁîüÊàêÂõûÂ§ç\n",
    "        4. ËøîÂõûÂåÖÂê´ AI ÂõûÂ§çÁöÑÁä∂ÊÄÅÊõ¥Êñ∞\n",
    "    \"\"\"\n",
    "\n",
    "    # Ëé∑ÂèñÊëòË¶Å‰ø°ÊÅØÔºåÂ¶ÇÊûú‰∏çÂ≠òÂú®ÂàôËøîÂõûÁ©∫Â≠óÁ¨¶‰∏≤\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    # Â¶ÇÊûúÂ≠òÂú®ÊëòË¶ÅÔºåÂ∞ÜÂÖ∂ËûçÂÖ•Âà∞ÊèêÁ§∫‰∏≠\n",
    "    if summary:\n",
    "        # ÂàõÂª∫ÂåÖÂê´ÊëòË¶ÅÁöÑÁ≥ªÁªüÊ∂àÊÅØ\n",
    "        # ËøôÊúâÂä©‰∫é LLM ÁêÜËß£‰πãÂâçÁöÑÂØπËØù‰∏ä‰∏ãÊñá\n",
    "        # system_message = f\"Summary of conversation earlier: {summary}\"\n",
    "        system_message = f\"Ê≠§ÂâçÂØπËØùÁöÑÊëòË¶ÅÔºö{summary}\"\n",
    "\n",
    "        # Â∞ÜÁ≥ªÁªüÊ∂àÊÅØÊ∑ªÂä†Âà∞Ê∂àÊÅØÂàóË°®ÁöÑÂºÄÂ§¥\n",
    "        # Á≥ªÁªüÊ∂àÊÅØÈÄöÂ∏∏Áî®‰∫éÊèê‰æõ‰∏ä‰∏ãÊñáÂíåÊåá‰ª§\n",
    "        messages = [SystemMessage(content=system_message)] + state[\"messages\"]\n",
    "\n",
    "    else:\n",
    "        # Â¶ÇÊûúÊ≤°ÊúâÊëòË¶ÅÔºåÁõ¥Êé•‰ΩøÁî®ÂéüÂßãÊ∂àÊÅØ\n",
    "        messages = state[\"messages\"]\n",
    "\n",
    "    # Ë∞ÉÁî® LLM Ê®°ÂûãÁîüÊàêÂõûÂ§ç\n",
    "    response = model.invoke(messages)\n",
    "\n",
    "    # ËøîÂõûÂåÖÂê´Êñ∞Ê∂àÊÅØÁöÑÁä∂ÊÄÅÊõ¥Êñ∞\n",
    "    return {\"messages\": response}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6882042c-b42d-4d52-a6a7-6ec8efa72450",
   "metadata": {
    "id": "6882042c-b42d-4d52-a6a7-6ec8efa72450"
   },
   "source": [
    "Êàë‰ª¨Â∞ÜÂÆö‰πâ‰∏Ä‰∏™ËäÇÁÇπÊù•ÁîüÊàêÊëòË¶Å„ÄÇ\n",
    "\n",
    "**ÊëòË¶ÅËäÇÁÇπÂäüËÉΩÔºö**\n",
    "- ÂàÜÊûêÂΩìÂâçÂØπËØùÂéÜÂè≤\n",
    "- ‰ΩøÁî® LLM ÁîüÊàêÂØπËØùÊëòË¶Å\n",
    "- Ê∏ÖÁêÜÊóßÊ∂àÊÅØÔºåÂè™‰øùÁïôÊúÄËøëÁöÑÂá†Êù°Ê∂àÊÅØ\n",
    "- Êõ¥Êñ∞Áä∂ÊÄÅ‰∏≠ÁöÑÊëòË¶Å‰ø°ÊÅØ\n",
    "\n",
    "**Ê≥®ÊÑèÔºö** ËøôÈáåÊàë‰ª¨Â∞Ü‰ΩøÁî® `RemoveMessage` Âú®ÁîüÊàêÊëòË¶ÅÂêéËøáÊª§Êàë‰ª¨ÁöÑÁä∂ÊÄÅÔºåËøôÊ†∑ÂèØ‰ª•Ôºö\n",
    "- ÂáèÂ∞ëÂÜÖÂ≠òÂç†Áî®\n",
    "- Èôç‰ΩéÂêéÁª≠Ë∞ÉÁî®ÁöÑ token ÊàêÊú¨\n",
    "- ‰øùÊåÅÂØπËØùÁöÑËøûÁª≠ÊÄß"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78c7aa59-3760-4e76-93f1-bc713e3ec39e",
   "metadata": {
    "id": "78c7aa59-3760-4e76-93f1-bc713e3ec39e"
   },
   "outputs": [],
   "source": [
    "def summarize_conversation(state: State):\n",
    "    \"\"\"\n",
    "    ÁîüÊàêÂØπËØùÊëòË¶ÅÁöÑËäÇÁÇπÂáΩÊï∞\n",
    "\n",
    "    ÂèÇÊï∞:\n",
    "        state (State): ÂΩìÂâçÂõæÁä∂ÊÄÅÔºåÂåÖÂê´Ê∂àÊÅØÂíåÊëòË¶Å‰ø°ÊÅØ\n",
    "\n",
    "    ËøîÂõû:\n",
    "        dict: ÂåÖÂê´Êñ∞ÊëòË¶ÅÂíåÊ∂àÊÅØÂà†Èô§Êåá‰ª§ÁöÑÂ≠óÂÖ∏\n",
    "\n",
    "    ÂäüËÉΩËØ¥Êòé:\n",
    "        1. Ê£ÄÊü•ÊòØÂê¶Â∑≤Â≠òÂú®ÊëòË¶Å\n",
    "        2. Ê†πÊçÆÊÉÖÂÜµÂàõÂª∫‰∏çÂêåÁöÑÊëòË¶ÅÊèêÁ§∫\n",
    "        3. Ë∞ÉÁî® LLM ÁîüÊàêÊàñÊõ¥Êñ∞ÊëòË¶Å\n",
    "        4. Âà†Èô§ÊóßÊ∂àÊÅØÔºåÂè™‰øùÁïôÊúÄËøëÁöÑ 2 Êù°Ê∂àÊÅØ\n",
    "        5. Êõ¥Êñ∞Áä∂ÊÄÅ‰∏≠ÁöÑÊëòË¶Å‰ø°ÊÅØ\n",
    "    \"\"\"\n",
    "\n",
    "    # È¶ñÂÖàËé∑Âèñ‰ªª‰ΩïÁé∞ÊúâÁöÑÊëòË¶Å\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    if summary:\n",
    "      # Â¶ÇÊûúÊëòË¶ÅÂ∑≤Â≠òÂú®ÔºåÂàôÊâ©Â±ïÁé∞ÊúâÊëòË¶Å\n",
    "      summary_message = (\n",
    "          f\"ÁõÆÂâç‰∏∫Ê≠¢ÁöÑÂØπËØùÊëòË¶ÅÔºö{summary}\\n\\n\"\n",
    "          \"ËØ∑ÁªìÂêà‰∏äÊñπÁöÑÊñ∞Ê∂àÊÅØÔºåÊâ©Â±ïÁé∞ÊúâÊëòË¶ÅÔºö\"\n",
    "      )\n",
    "\n",
    "    else:\n",
    "        # Â¶ÇÊûúÊ≤°ÊúâÁé∞ÊúâÊëòË¶ÅÔºåÂàôÂàõÂª∫Êñ∞ÊëòË¶Å\n",
    "        summary_message = \"ËØ∑ÂØπ‰∏äÊñπÁöÑÂØπËØùÂàõÂª∫ÊëòË¶ÅÔºö\"\n",
    "\n",
    "    # Â∞ÜÊëòË¶ÅÊèêÁ§∫Ê∑ªÂä†Âà∞Ê∂àÊÅØÂéÜÂè≤‰∏≠\n",
    "    # ËøôÊ†∑ LLM ÂèØ‰ª•Âü∫‰∫éÂÆåÊï¥ÁöÑÂØπËØùÂéÜÂè≤ÁîüÊàêÊëòË¶Å\n",
    "    messages = state[\"messages\"] + [HumanMessage(content=summary_message)]\n",
    "\n",
    "    # Ë∞ÉÁî® LLM ÁîüÊàêÊëòË¶Å\n",
    "    response = model.invoke(messages)\n",
    "\n",
    "    # Âà†Èô§Èô§ÊúÄËøë 2 Êù°Ê∂àÊÅØÂ§ñÁöÑÊâÄÊúâÊ∂àÊÅØ\n",
    "    # ËøôÊ†∑ÂèØ‰ª•ÂáèÂ∞ëÂÜÖÂ≠òÂç†Áî®Âíå token ÊàêÊú¨\n",
    "    # RemoveMessage Áî®‰∫éÊ†áËÆ∞Ê∂àÊÅØ‰∏∫Âà†Èô§Áä∂ÊÄÅ\n",
    "    delete_messages = [RemoveMessage(id=m.id) for m in state[\"messages\"][:-2]]\n",
    "\n",
    "    # ËøîÂõûÊñ∞ÁöÑÊëòË¶ÅÂíåÊ∂àÊÅØÂà†Èô§Êåá‰ª§\n",
    "    return {\"summary\": response.content, \"messages\": delete_messages}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f982993e-f4be-4ff7-9a38-886f75398b3d",
   "metadata": {
    "id": "f982993e-f4be-4ff7-9a38-886f75398b3d"
   },
   "source": [
    "Êàë‰ª¨Â∞ÜÊ∑ªÂä†‰∏Ä‰∏™Êù°‰ª∂ËæπÊù•ÂÜ≥ÂÆöÊòØÂê¶Âü∫‰∫éÂØπËØùÈïøÂ∫¶ÁîüÊàêÊëòË¶Å„ÄÇ\n",
    "\n",
    "**Êù°‰ª∂ËæπÁöÑ‰ΩúÁî®Ôºö**\n",
    "- ÁõëÊéßÂØπËØù‰∏≠ÁöÑÊ∂àÊÅØÊï∞Èáè\n",
    "- ÂΩìÊ∂àÊÅØÊï∞ÈáèË∂ÖËøáÈòàÂÄºÊó∂ÔºåËß¶ÂèëÊëòË¶ÅÁîüÊàê\n",
    "- Âê¶ÂàôÁõ¥Êé•ÁªìÊùüÂØπËØù\n",
    "- ËøôÊ†∑ÂèØ‰ª•Âπ≥Ë°°ÂØπËØùË¥®ÈáèÂíåÊÄßËÉΩ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b507665d-7f5d-442a-b498-218c94c5dd8b",
   "metadata": {
    "id": "b507665d-7f5d-442a-b498-218c94c5dd8b"
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import END\n",
    "from typing_extensions import Literal\n",
    "\n",
    "def should_continue(state: State) -> Literal[\"summarize_conversation\", END]:\n",
    "    \"\"\"\n",
    "    ÂÜ≥ÂÆöÊòØÂê¶ÁªßÁª≠ÂØπËØùÊàñÁîüÊàêÊëòË¶ÅÁöÑÊù°‰ª∂ÂáΩÊï∞\n",
    "\n",
    "    ÂèÇÊï∞:\n",
    "        state (State): ÂΩìÂâçÂõæÁä∂ÊÄÅ\n",
    "\n",
    "    ËøîÂõû:\n",
    "        Literal: ‰∏ã‰∏Ä‰∏™Ë¶ÅÊâßË°åÁöÑËäÇÁÇπÂêçÁß∞Êàñ END\n",
    "\n",
    "    ÂäüËÉΩËØ¥Êòé:\n",
    "        Ê†πÊçÆÂØπËØù‰∏≠ÁöÑÊ∂àÊÅØÊï∞ÈáèÂÜ≥ÂÆö‰∏ã‰∏ÄÊ≠•Êìç‰ΩúÔºö\n",
    "        - Â¶ÇÊûúÊ∂àÊÅØÊï∞Èáè > 6ÔºåÂàôÁîüÊàêÊëòË¶Å\n",
    "        - Âê¶ÂàôÁõ¥Êé•ÁªìÊùüÂØπËØù\n",
    "\n",
    "    ËÆæËÆ°ÁêÜÂøµ:\n",
    "        Ëøô‰∏™ÈòàÂÄºÂèØ‰ª•Ê†πÊçÆÂÆûÈôÖÈúÄÊ±ÇË∞ÉÊï¥Ôºö\n",
    "        - ËæÉÂ∞èÁöÑÈòàÂÄºÔºöÊõ¥È¢ëÁπÅÁöÑÊëòË¶ÅÔºå‰ΩÜÂèØËÉΩ‰∏¢Â§±ÁªÜËäÇ\n",
    "        - ËæÉÂ§ßÁöÑÈòàÂÄºÔºö‰øùÁïôÊõ¥Â§ö‰∏ä‰∏ãÊñáÔºå‰ΩÜÂèØËÉΩÂ¢ûÂä†ÊàêÊú¨\n",
    "    \"\"\"\n",
    "\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    # Â¶ÇÊûúÊ∂àÊÅØÊï∞ÈáèË∂ÖËøá 6 Êù°ÔºåÂàôÁîüÊàêÂØπËØùÊëòË¶Å\n",
    "    # Ëøô‰∏™ÈòàÂÄºÂèØ‰ª•Ê†πÊçÆÂÆûÈôÖÈúÄÊ±ÇË∞ÉÊï¥\n",
    "    if len(messages) > 6:\n",
    "        return \"summarize_conversation\"\n",
    "\n",
    "    # Âê¶ÂàôÁõ¥Êé•ÁªìÊùüÂØπËØù\n",
    "    return END"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a838f4c-7067-4f7f-a4c4-6654e11214cd",
   "metadata": {
    "id": "5a838f4c-7067-4f7f-a4c4-6654e11214cd"
   },
   "source": [
    "## Ê∑ªÂä†ËÆ∞ÂøÜÂäüËÉΩ\n",
    "\n",
    "ÂõûÈ°æ‰∏Ä‰∏ãÔºå[Áä∂ÊÄÅÂú®ÂçïÊ¨°ÂõæÊâßË°å‰∏≠ÊòØÁû¨ÊÄÅÁöÑ](https://github.com/langchain-ai/langgraph/discussions/352#discussioncomment-9291220)„ÄÇ\n",
    "\n",
    "ËøôÈôêÂà∂‰∫ÜÊàë‰ª¨Âú®‰∏≠Êñ≠ÊÉÖÂÜµ‰∏ãËøõË°åÂ§öËΩÆÂØπËØùÁöÑËÉΩÂäõ„ÄÇ\n",
    "\n",
    "Ê≠£Â¶ÇÂú®Ê®°Âùó 1 Êú´Â∞æ‰ªãÁªçÁöÑÈÇ£Ê†∑ÔºåÊàë‰ª¨ÂèØ‰ª•‰ΩøÁî®[ÊåÅ‰πÖÂåñ](https://langchain-ai.github.io/langgraph/how-tos/persistence/)Êù•Ëß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÔºÅ\n",
    "\n",
    "**LangGraph ÊåÅ‰πÖÂåñÊú∫Âà∂Ôºö**\n",
    "- LangGraph ÂèØ‰ª•‰ΩøÁî®Ê£ÄÊü•ÁÇπÂô®ÔºàcheckpointerÔºâÂú®ÊØè‰∏ÄÊ≠•ÂêéËá™Âä®‰øùÂ≠òÂõæÁä∂ÊÄÅ\n",
    "- Ëøô‰∏™ÂÜÖÁΩÆÁöÑÊåÅ‰πÖÂåñÂ±Ç‰∏∫Êàë‰ª¨Êèê‰æõ‰∫ÜËÆ∞ÂøÜÂäüËÉΩ\n",
    "- ÂÖÅËÆ∏ LangGraph ‰ªéÊúÄÂêé‰∏ÄÊ¨°Áä∂ÊÄÅÊõ¥Êñ∞Â§ÑÁªßÁª≠ÊâßË°å\n",
    "\n",
    "**MemorySaver ‰ªãÁªçÔºö**\n",
    "- Êàë‰ª¨‰πãÂâçÂ±ïÁ§∫ÁöÑÊúÄÂÆπÊòì‰ΩøÁî®ÁöÑÊ£ÄÊü•ÁÇπÂô®‰πã‰∏ÄÊòØ `MemorySaver`\n",
    "- ÂÆÉÊòØ‰∏Ä‰∏™Áî®‰∫éÂõæÁä∂ÊÄÅÁöÑÂÜÖÂ≠òÈîÆÂÄºÂ≠òÂÇ®\n",
    "- Êàë‰ª¨Âè™ÈúÄË¶ÅÂú®ÁºñËØëÂõæÊó∂Ê∑ªÂä†Ê£ÄÊü•ÁÇπÂô®ÔºåÂõæÂ∞±ÂÖ∑Êúâ‰∫ÜËÆ∞ÂøÜÂäüËÉΩÔºÅ\n",
    "\n",
    "**ËÆ∞ÂøÜÂäüËÉΩÁöÑÂ•ΩÂ§ÑÔºö**\n",
    "- ÊîØÊåÅÈïøÊó∂Èó¥ËøêË°åÁöÑÂØπËØù\n",
    "- ÂèØ‰ª•Âú®‰∏≠Êñ≠ÂêéÊÅ¢Â§çÂØπËØù\n",
    "- ‰øùÊåÅÂØπËØùÁöÑËøûÁª≠ÊÄßÂíå‰∏ä‰∏ãÊñá"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d57516d-f9f1-4d3c-a84a-7277b5ce6df6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "1d57516d-f9f1-4d3c-a84a-7277b5ce6df6",
    "outputId": "47e6692c-8686-4f20-939d-ad595e76a491"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START\n",
    "\n",
    "# ÂÆö‰πâ‰∏Ä‰∏™Êñ∞ÁöÑÂõæÂ∑•‰ΩúÊµÅ\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "# Ê∑ªÂä†ËäÇÁÇπ\n",
    "# conversation: Â§ÑÁêÜÁî®Êà∑ËæìÂÖ•Âπ∂ÁîüÊàêÂõûÂ§çÁöÑËäÇÁÇπ\n",
    "workflow.add_node(\"conversation\", call_model)\n",
    "# summarize_conversation: ÁîüÊàêÂØπËØùÊëòË¶ÅÁöÑËäÇÁÇπ\n",
    "workflow.add_node(summarize_conversation)\n",
    "\n",
    "# ËÆæÁΩÆÂõæÁöÑËøûÊé•ÂÖ≥Á≥ª\n",
    "# ËÆæÁΩÆÂÖ•Âè£ÁÇπ‰∏∫ conversation ËäÇÁÇπ\n",
    "workflow.add_edge(START, \"conversation\")\n",
    "# Ê∑ªÂä†Êù°‰ª∂ËæπÔºöÊ†πÊçÆÊ∂àÊÅØÊï∞ÈáèÂÜ≥ÂÆöÊòØÂê¶ÁîüÊàêÊëòË¶Å\n",
    "workflow.add_conditional_edges(\"conversation\", should_continue)\n",
    "# ÊëòË¶ÅÁîüÊàêÂÆåÊàêÂêéÁõ¥Êé•ÁªìÊùü\n",
    "workflow.add_edge(\"summarize_conversation\", END)\n",
    "\n",
    "# ÁºñËØëÂõæÂπ∂Ê∑ªÂä†ËÆ∞ÂøÜÂäüËÉΩ\n",
    "memory = MemorySaver()  # ÂàõÂª∫ÂÜÖÂ≠òÊ£ÄÊü•ÁÇπÂô®\n",
    "graph = workflow.compile(checkpointer=memory)  # ÁºñËØëÂõæÂπ∂ÂêØÁî®ÊåÅ‰πÖÂåñ\n",
    "\n",
    "# ÊòæÁ§∫ÂõæÁöÑÊµÅÁ®ãÂõæ\n",
    "# ËøôÊúâÂä©‰∫éÁêÜËß£Êï¥‰∏™ÂØπËØùÊµÅÁ®ã\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bd5d23-ac3b-4496-a049-9a9f97d2feb9",
   "metadata": {
    "id": "d0bd5d23-ac3b-4496-a049-9a9f97d2feb9"
   },
   "source": [
    "## Á∫øÁ®ãÔºàThreadsÔºâ\n",
    "\n",
    "Ê£ÄÊü•ÁÇπÂô®Âú®ÊØè‰∏ÄÊ≠•ÈÉΩÂ∞ÜÁä∂ÊÄÅ‰øùÂ≠ò‰∏∫Ê£ÄÊü•ÁÇπ„ÄÇ\n",
    "\n",
    "Ëøô‰∫õ‰øùÂ≠òÁöÑÊ£ÄÊü•ÁÇπÂèØ‰ª•ÂàÜÁªÑÂà∞‰∏Ä‰∏™ÂØπËØùÁöÑ`Á∫øÁ®ã`‰∏≠„ÄÇ\n",
    "\n",
    "**Á∫øÁ®ãÊ¶ÇÂøµÁ±ªÊØîÔºö**\n",
    "- ÊÉ≥Ë±° Slack ‰Ωú‰∏∫Á±ªÊØîÔºö‰∏çÂêåÁöÑÈ¢ëÈÅìÊâøËΩΩ‰∏çÂêåÁöÑÂØπËØù\n",
    "- Á∫øÁ®ãÂ∞±ÂÉè Slack È¢ëÈÅìÔºåÊçïËé∑ÂàÜÁªÑÁöÑÁä∂ÊÄÅÈõÜÂêàÔºà‰æãÂ¶ÇÂØπËØùÔºâ\n",
    "\n",
    "**Á∫øÁ®ãÁöÑ‰ΩúÁî®Ôºö**\n",
    "- ÈöîÁ¶ª‰∏çÂêåÁöÑÂØπËØù‰ºöËØù\n",
    "- ÂÖÅËÆ∏ÂêåÊó∂ËøõË°åÂ§ö‰∏™Áã¨Á´ãÁöÑÂØπËØù\n",
    "- ÊØè‰∏™Á∫øÁ®ãÁª¥Êä§Ëá™Â∑±ÁöÑÁä∂ÊÄÅÂíåËÆ∞ÂøÜ\n",
    "\n",
    "**ÈÖçÁΩÆÁ∫øÁ®ãÔºö**\n",
    "- ‰ΩøÁî® `configurable` ÂèÇÊï∞ËÆæÁΩÆÁ∫øÁ®ã ID\n",
    "- ‰∏çÂêåÁöÑÁ∫øÁ®ã ID ÂØπÂ∫î‰∏çÂêåÁöÑÂØπËØù‰ºöËØù\n",
    "- ËøôÊ†∑ÂèØ‰ª•Âú®Âêå‰∏Ä‰∏™Âõæ‰∏≠ÁÆ°ÁêÜÂ§ö‰∏™Áã¨Á´ãÁöÑÂØπËØù\n",
    "\n",
    "![Áä∂ÊÄÅÂõæ](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbadf3b379c2ee621adfd1_chatbot-summarization1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2566c93b-13e6-4a53-bc0f-b00fff691d30",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2566c93b-13e6-4a53-bc0f-b00fff691d30",
    "outputId": "184c1386-bed2-453e-a56a-0a82841e1200"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Á¨¨‰∏ÄËΩÆÂØπËØù ===\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "‰Ω†Â•ΩÔºåLanceÔºÅÂæàÈ´òÂÖ¥ËÆ§ËØÜ‰Ω†ÔºÅÊúâ‰ªÄ‰πàÊàëÂèØ‰ª•Â∏ÆÂøôÁöÑÂêóÔºü\n",
      "\n",
      "=== Á¨¨‰∫åËΩÆÂØπËØù ===\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "‰Ω†ÂàöÂàöÂëäËØâÊàë‰Ω†ÁöÑÂêçÂ≠óÊòØ LanceÔºÅüòä\n",
      "\n",
      "=== Á¨¨‰∏âËΩÆÂØπËØù ===\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "ÂìáÔºåYo-Yo MaÁöÑÂè§ÂÖ∏Èü≥‰πêÁ°ÆÂÆûÈùûÂ∏∏Ëø∑‰∫∫ÔºÅ‰ªñÁöÑÂ§ßÊèêÁê¥ÊºîÂ•èÂÖÖÊª°ÊÉÖÊÑüÂíåÊ∑±Â∫¶ÔºåÂ∞§ÂÖ∂ÊòØÂ∑¥Ëµ´ÁöÑ„ÄäÊó†‰º¥Â•èÂ§ßÊèêÁê¥ÁªÑÊõ≤„ÄãÔºåÁÆÄÁõ¥ÊòØÁªèÂÖ∏‰∏≠ÁöÑÁªèÂÖ∏„ÄÇ‰Ω†ÊúâÁâπÂà´ÂñúÊ¨¢ÁöÑÊõ≤ÁõÆÂêóÔºüÊàñËÄÖ‰Ω†ÂñúÊ¨¢‰ªñÂíåÂÖ∂‰ªñËâ∫ÊúØÂÆ∂ÁöÑÂêà‰Ωú‰ΩúÂìÅÔºü\n"
     ]
    }
   ],
   "source": [
    "# ÂàõÂª∫‰∏Ä‰∏™ÂØπËØùÁ∫øÁ®ã\n",
    "# Á∫øÁ®ã ID Áî®‰∫éÂå∫ÂàÜ‰∏çÂêåÁöÑÂØπËØù‰ºöËØù\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# ÂºÄÂßãÂØπËØù - Á¨¨‰∏ÄËΩÆ\n",
    "print(\"=== Á¨¨‰∏ÄËΩÆÂØπËØù ===\")\n",
    "input_message = HumanMessage(content=\"‰Ω†Â•ΩÔºÅÊàëÊòØLance\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config)\n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()\n",
    "\n",
    "# ÁªßÁª≠ÂØπËØù - Á¨¨‰∫åËΩÆ\n",
    "print(\"\\n=== Á¨¨‰∫åËΩÆÂØπËØù ===\")\n",
    "input_message = HumanMessage(content=\"ÊàëÂè´‰ªÄ‰πàÂêçÂ≠óÔºü\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config)\n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()\n",
    "\n",
    "# ÁªßÁª≠ÂØπËØù - Á¨¨‰∏âËΩÆ\n",
    "print(\"\\n=== Á¨¨‰∏âËΩÆÂØπËØù ===\")\n",
    "input_message = HumanMessage(content=\"ÊàëÂñúÊ¨¢YoYoMAÁöÑÂè§ÂÖ∏Èü≥‰πê\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config)\n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()\n",
    "\n",
    "# Ê≥®ÊÑèÔºöÁî±‰∫éÊàë‰ª¨‰ΩøÁî®‰∫ÜÁõ∏ÂêåÁöÑ configÔºàÁõ∏ÂêåÁöÑÁ∫øÁ®ã IDÔºâÔºå\n",
    "# ËÅäÂ§©Êú∫Âô®‰∫∫ÂèØ‰ª•ËÆ∞‰Ωè‰πãÂâçÁöÑÂØπËØùÂÜÖÂÆπ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531e5b63-5e8b-486e-baa0-a45521e2fbc2",
   "metadata": {
    "id": "531e5b63-5e8b-486e-baa0-a45521e2fbc2"
   },
   "source": [
    "Áé∞Âú®ÔºåÊàë‰ª¨ËøòÊ≤°ÊúâÁîüÊàêÁä∂ÊÄÅÊëòË¶ÅÔºåÂõ†‰∏∫Êàë‰ª¨‰ªçÁÑ∂Êúâ ‚â§ 6 Êù°Ê∂àÊÅØ„ÄÇ\n",
    "\n",
    "ËøôÊòØÂú® `should_continue` ÂáΩÊï∞‰∏≠ËÆæÁΩÆÁöÑ„ÄÇ\n",
    "\n",
    "```python\n",
    "# Â¶ÇÊûúÊ∂àÊÅØÊï∞ÈáèË∂ÖËøá 6 Êù°ÔºåÂàôÁîüÊàêÂØπËØùÊëòË¶Å\n",
    "if len(messages) > 6:\n",
    "    return \"summarize_conversation\"\n",
    "```\n",
    "\n",
    "**ÂΩìÂâçÁä∂ÊÄÅÂàÜÊûêÔºö**\n",
    "- ÁõÆÂâçÊúâ 6 Êù°Ê∂àÊÅØÔºà3 ËΩÆÂØπËØùÔºåÊØèËΩÆ 2 Êù°Ê∂àÊÅØÔºâ\n",
    "- ËøòÊ≤°ÊúâËææÂà∞Ëß¶ÂèëÊëòË¶ÅÁöÑÈòàÂÄºÔºà> 6Ôºâ\n",
    "- Âõ†Ê≠§ÂØπËØùÁõ¥Êé•ÁªìÊùüÔºåÊ≤°ÊúâÁîüÊàêÊëòË¶Å\n",
    "\n",
    "**Á∫øÁ®ãÁöÑ‰ΩúÁî®Ôºö**\n",
    "- Áî±‰∫éÊàë‰ª¨‰ΩøÁî®‰∫ÜÁ∫øÁ®ãÔºåÂèØ‰ª•ÁªßÁª≠ÂØπËØù\n",
    "- ÊØèÊ¨°Ë∞ÉÁî®ÈÉΩ‰ºö‰ªé‰∏äÊ¨°ÁöÑÁä∂ÊÄÅÁªßÁª≠\n",
    "- ËøôÂ±ïÁ§∫‰∫ÜËÆ∞ÂøÜÂäüËÉΩÁöÑÈáçË¶ÅÊÄß"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91b82aaa-17f9-49e2-9528-f4b22e23ebcb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "91b82aaa-17f9-49e2-9528-f4b22e23ebcb",
    "outputId": "138d7ee8-9f26-4e81-d71d-ff29296ac79d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÂΩìÂâçÊëòË¶Å: ''\n",
      "ËØ¥Êòé: Áî±‰∫éÊ∂àÊÅØÊï∞Èáè ‚â§ 6ÔºåËøòÊ≤°ÊúâÁîüÊàêÊëòË¶Å\n"
     ]
    }
   ],
   "source": [
    "# Ê£ÄÊü•ÂΩìÂâçÁ∫øÁ®ãÁöÑÁä∂ÊÄÅÊëòË¶Å\n",
    "# Áî±‰∫éÊ∂àÊÅØÊï∞ÈáèËøòÊ≤°ÊúâË∂ÖËøáÈòàÂÄºÔºåÊëòË¶ÅÂ∫îËØ•‰∏∫Á©∫\n",
    "current_summary = graph.get_state(config).values.get(\"summary\", \"\")\n",
    "print(f\"ÂΩìÂâçÊëòË¶Å: '{current_summary}'\")\n",
    "print(\"ËØ¥Êòé: Áî±‰∫éÊ∂àÊÅØÊï∞Èáè ‚â§ 6ÔºåËøòÊ≤°ÊúâÁîüÊàêÊëòË¶Å\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068a93e9-f716-4980-8edf-94115017d865",
   "metadata": {
    "id": "068a93e9-f716-4980-8edf-94115017d865"
   },
   "source": [
    "Â∏¶ÊúâÁ∫øÁ®ã ID ÁöÑ `config` ÂÖÅËÆ∏Êàë‰ª¨‰ªé‰πãÂâçËÆ∞ÂΩïÁöÑÁä∂ÊÄÅÁªßÁª≠ÔºÅ\n",
    "\n",
    "**Á∫øÁ®ãËÆ∞ÂøÜÂäüËÉΩÊºîÁ§∫Ôºö**\n",
    "- ÊØèÊ¨°Ë∞ÉÁî® `graph.invoke()` Êó∂ÈÉΩ‰ΩøÁî®Áõ∏ÂêåÁöÑ `config`\n",
    "- ËøôÁ°Æ‰øù‰∫ÜÂØπËØùÁöÑËøûÁª≠ÊÄßÂíå‰∏ä‰∏ãÊñá‰øùÊåÅ\n",
    "- ËÅäÂ§©Êú∫Âô®‰∫∫ËÉΩÂ§üËÆ∞‰Ωè‰πãÂâçÁöÑÊâÄÊúâÂØπËØùÂÜÖÂÆπ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24b34f0f-62ef-4008-8e96-480cbe92ea3e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "24b34f0f-62ef-4008-8e96-480cbe92ea3e",
    "outputId": "d48baf28-45b8-491a-8dc4-458982a5f08a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Á¨¨ÂõõËΩÆÂØπËØùÔºàËß¶ÂèëÊëòË¶ÅÔºâ ===\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "ÊòØÁöÑÔºåÂ≠ôÈ¢ñËééÊòØ‰∏Ä‰ΩçÈùûÂ∏∏‰ºòÁßÄÁöÑ‰πí‰πìÁêÉËøêÂä®ÂëòÔºÅÂ•πÊäÄÊúØÂÖ®Èù¢„ÄÅÈÄüÂ∫¶Âø´„ÄÅÂøÉÁêÜÁ¥†Ë¥®‰πüÈùûÂ∏∏Âº∫ÔºåËøëÂπ¥Êù•Âú®ÂõΩÈôÖÊØîËµõ‰∏≠Ë°®Áé∞ÈùûÂ∏∏Âá∫Ëâ≤„ÄÇËôΩÁÑ∂‰πí‰πìÁêÉÊéíÂêç‰ºöÊ†πÊçÆÊØîËµõÊàêÁª©Âä®ÊÄÅÂèòÂåñÔºå‰ΩÜÂ•πÁ°ÆÂÆûÊòØ‰∏ñÁïå‰πíÂùõÁöÑÈ°∂Â∞ñÈÄâÊâã‰πã‰∏Ä„ÄÇ‰Ω†ÂñúÊ¨¢ÁúãÂ•πÁöÑÊØîËµõÂêóÔºüÂ•πÁöÑÊØîËµõÊÄªÊòØÂÖÖÊª°ÊøÄÊÉÖÂíåÁ≤æÂΩ©Áû¨Èó¥ÔºÅ\n"
     ]
    }
   ],
   "source": [
    "# ÁªßÁª≠ÂØπËØù - Á¨¨ÂõõËΩÆÔºàËøôÂ∞ÜËß¶ÂèëÊëòË¶ÅÁîüÊàêÔºâ\n",
    "print(\"=== Á¨¨ÂõõËΩÆÂØπËØùÔºàËß¶ÂèëÊëòË¶ÅÔºâ ===\")\n",
    "input_message = (HumanMessage(content=\"ÊàëÂñúÊ¨¢Â≠ôÈ¢ñËééÔºåÂ•π‰∏çÊòØ‰πí‰πìÁêÉÂ•≥Âçï‰∏ñÁïåÁ¨¨‰∏ÄÂêóÔºü\"))\n",
    "output = graph.invoke({\"messages\": [input_message]}, config)\n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()\n",
    "\n",
    "# Ê≥®ÊÑèÔºöËøô‰∏ÄËΩÆÂØπËØùÂêéÔºåÊ∂àÊÅØÊï∞ÈáèÂ∞ÜË∂ÖËøá 6 Êù°\n",
    "# Á≥ªÁªü‰ºöËá™Âä®ÁîüÊàêÂØπËØùÊëòË¶Å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22f1b35f-e4bb-47f6-87b1-d84d8aed9aa9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "22f1b35f-e4bb-47f6-87b1-d84d8aed9aa9",
    "outputId": "851714ce-7f06-468b-e438-0c6a86ddb51a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ÁîüÊàêÁöÑÂØπËØùÊëòË¶Å ===\n",
      "ÊëòË¶ÅÂÜÖÂÆπ: Áî®Êà∑Ëá™Êàë‰ªãÁªç‰∏∫LanceÔºåË°®Á§∫ÂñúÊ¨¢Yo-Yo MaÁöÑÂè§ÂÖ∏Èü≥‰πê‰ª•Âèä‰πí‰πìÁêÉËøêÂä®ÂëòÂ≠ôÈ¢ñËééÔºåÂπ∂ÊèêÂà∞Â≠ôÈ¢ñËééÊòØ‰πí‰πìÁêÉÂ•≥Âçï‰∏ñÁïåÈ°∂Â∞ñÈÄâÊâã‰πã‰∏Ä„ÄÇÂä©ÊâãÂõûÂ∫î‰∫ÜÁî®Êà∑ÁöÑÂÖ¥Ë∂£ÔºåË°®Ëææ‰∫ÜÂØπYo-Yo MaÈü≥‰πêÂíåÂ≠ôÈ¢ñËéé‰πí‰πìÁêÉÊäÄËâ∫ÁöÑËµûËµèÔºåÂπ∂‰∏éÁî®Êà∑‰∫íÂä®ËÆ®ËÆ∫Áõ∏ÂÖ≥ËØùÈ¢ò„ÄÇ\n",
      "\n",
      "=== ÊëòË¶ÅÂäüËÉΩËØ¥Êòé ===\n",
      "1. Á≥ªÁªüËá™Âä®ÂàÜÊûê‰∫ÜÊï¥‰∏™ÂØπËØùÂéÜÂè≤\n",
      "2. ÁîüÊàê‰∫ÜÂåÖÂê´ÂÖ≥ÈîÆ‰ø°ÊÅØÁöÑÊëòË¶Å\n",
      "3. ÊóßÊ∂àÊÅØË¢´Ê∏ÖÁêÜÔºåÂè™‰øùÁïôÊúÄËøëÁöÑ 2 Êù°\n",
      "4. ÊëòË¶ÅÂ∞ÜÂú®ÂêéÁª≠ÂØπËØù‰∏≠Êèê‰æõ‰∏ä‰∏ãÊñá\n"
     ]
    }
   ],
   "source": [
    "# Ê£ÄÊü•ÊëòË¶ÅÁîüÊàêÂêéÁöÑÁä∂ÊÄÅ\n",
    "# Áé∞Âú®Â∫îËØ•Êúâ‰∫ÜÂØπËØùÊëòË¶Å\n",
    "final_summary = graph.get_state(config).values.get(\"summary\", \"\")\n",
    "print(\"=== ÁîüÊàêÁöÑÂØπËØùÊëòË¶Å ===\")\n",
    "print(f\"ÊëòË¶ÅÂÜÖÂÆπ: {final_summary}\")\n",
    "print(\"\\n=== ÊëòË¶ÅÂäüËÉΩËØ¥Êòé ===\")\n",
    "print(\"1. Á≥ªÁªüËá™Âä®ÂàÜÊûê‰∫ÜÊï¥‰∏™ÂØπËØùÂéÜÂè≤\")\n",
    "print(\"2. ÁîüÊàê‰∫ÜÂåÖÂê´ÂÖ≥ÈîÆ‰ø°ÊÅØÁöÑÊëòË¶Å\")\n",
    "print(\"3. ÊóßÊ∂àÊÅØË¢´Ê∏ÖÁêÜÔºåÂè™‰øùÁïôÊúÄËøëÁöÑ 2 Êù°\")\n",
    "print(\"4. ÊëòË¶ÅÂ∞ÜÂú®ÂêéÁª≠ÂØπËØù‰∏≠Êèê‰æõ‰∏ä‰∏ãÊñá\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7cc0ab-905a-4037-b7cb-69db5b89591e",
   "metadata": {
    "id": "ad7cc0ab-905a-4037-b7cb-69db5b89591e"
   },
   "source": [
    "## LangSmith ËøΩË∏™\n",
    "\n",
    "ËÆ©Êàë‰ª¨Êü•ÁúãËøΩË∏™‰ø°ÊÅØÔºÅ\n",
    "\n",
    "**LangSmith ËøΩË∏™ÂäüËÉΩÔºö**\n",
    "- ÂèØ‰ª•Êü•ÁúãÂÆåÊï¥ÁöÑÂØπËØùÊµÅÁ®ã\n",
    "- ÁõëÊéßÊØè‰∏™ËäÇÁÇπÁöÑÊâßË°åÊÉÖÂÜµ\n",
    "- ÂàÜÊûê LLM Ë∞ÉÁî®ÁöÑÊÄßËÉΩÂíåÊàêÊú¨\n",
    "- Ë∞ÉËØïÂØπËØùÈÄªËæëÂíåÁä∂ÊÄÅÂèòÂåñ\n",
    "\n",
    "**Â¶Ç‰ΩïÊü•ÁúãËøΩË∏™Ôºö**\n",
    "1. ËÆøÈóÆ LangSmith ÁΩëÁ´ô\n",
    "2. ÁôªÂΩï‰Ω†ÁöÑË¥¶Êà∑\n",
    "3. Êü•Áúã \"FlyAIBox\" È°πÁõÆ\n",
    "4. ÊâæÂà∞ÊúÄÊñ∞ÁöÑËøΩË∏™ËÆ∞ÂΩï\n",
    "5. ÂàÜÊûêÂØπËØùÊµÅÁ®ãÂíåÊÄßËÉΩÊåáÊ†á"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62e1501",
   "metadata": {
    "id": "c62e1501"
   },
   "source": [
    "## Á≥ªÁªüÊû∂ÊûÑÊÄªÁªì\n",
    "\n",
    "### Ê†∏ÂøÉÁªÑ‰ª∂\n",
    "\n",
    "1. **Áä∂ÊÄÅÁÆ°ÁêÜ (State)**\n",
    "   - `MessagesState`: Âü∫Á°ÄÊ∂àÊÅØÁä∂ÊÄÅ\n",
    "   - `summary`: Ëá™ÂÆö‰πâÊëòË¶ÅÂ≠óÊÆµ\n",
    "   - ÊîØÊåÅÊ∂àÊÅØÁöÑÂ¢ûÂà†ÊîπÊü•\n",
    "\n",
    "2. **ËäÇÁÇπÂäüËÉΩ (Nodes)**\n",
    "   - `call_model`: Ë∞ÉÁî® LLM ÁîüÊàêÂõûÂ§ç\n",
    "   - `summarize_conversation`: ÁîüÊàêÂØπËØùÊëòË¶Å\n",
    "   - `should_continue`: Êù°‰ª∂Âà§Êñ≠ÈÄªËæë\n",
    "\n",
    "3. **ËÆ∞ÂøÜÁ≥ªÁªü (Memory)**\n",
    "   - `MemorySaver`: ÂÜÖÂ≠òÊ£ÄÊü•ÁÇπÂô®\n",
    "   - Á∫øÁ®ãÈöîÁ¶ª: ÊîØÊåÅÂ§öÂØπËØùÂπ∂Ë°å\n",
    "   - Áä∂ÊÄÅÊåÅ‰πÖÂåñ: ÊîØÊåÅ‰∏≠Êñ≠ÊÅ¢Â§ç\n",
    "\n",
    "### Â∑•‰ΩúÊµÅÁ®ã\n",
    "\n",
    "```\n",
    "Áî®Êà∑ËæìÂÖ• ‚Üí call_model ‚Üí should_continue ‚Üí\n",
    "    ‚Üì                    ‚Üì\n",
    "   ÁªìÊùü               summarize_conversation ‚Üí ÁªìÊùü\n",
    "```\n",
    "\n",
    "### ÂÖ≥ÈîÆÁâπÊÄß\n",
    "\n",
    "- **Êô∫ËÉΩÊëòË¶Å**: Ëá™Âä®ÂéãÁº©ÈïøÂØπËØùÂéÜÂè≤\n",
    "- **ËÆ∞ÂøÜ‰øùÊåÅ**: ÊîØÊåÅÈïøÊó∂Èó¥ÂØπËØù\n",
    "- **ÊàêÊú¨‰ºòÂåñ**: ÂáèÂ∞ë token ‰ΩøÁî®Èáè\n",
    "- **Áä∂ÊÄÅÁÆ°ÁêÜ**: ÁÅµÊ¥ªÁöÑÁä∂ÊÄÅÊõ¥Êñ∞Êú∫Âà∂\n",
    "\n",
    "### ÈÄÇÁî®Âú∫ÊôØ\n",
    "\n",
    "- ÂÆ¢ÊúçËÅäÂ§©Êú∫Âô®‰∫∫\n",
    "- ‰∏™‰∫∫Âä©ÊâãÂ∫îÁî®\n",
    "- ÊïôËÇ≤ÂØπËØùÁ≥ªÁªü\n",
    "- ÊäÄÊúØÊîØÊåÅÂ∑•ÂÖ∑\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39bd23a4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "39bd23a4",
    "outputId": "9e47ee8e-577a-4569-d5c6-24ef80e9a9b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ÂàõÂª∫Êñ∞ÂØπËØùÁ∫øÁ®ãÊºîÁ§∫ ===\n",
      "Êñ∞Á∫øÁ®ã‰∏≠ÁöÑÂØπËØùÔºö\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "‰Ω†Â•ΩÔºÅÊ¨¢Ëøé‰Ω†‰ΩøÁî®ÊàëÁöÑÊúçÂä°ÔºÅÊàëÊòØ‰∏Ä‰∏™Êô∫ËÉΩÂä©ÊâãÔºåÂèØ‰ª•Â∏ÆÂä©‰Ω†Ëß£Á≠îÈóÆÈ¢ò„ÄÅÊèê‰æõ‰ø°ÊÅØÊàñÂçèÂä©ÂÆåÊàê‰ªªÂä°„ÄÇÂ¶ÇÊûúÊúâ‰ªª‰ΩïÈúÄË¶ÅÔºåÈöèÊó∂ÂëäËØâÊàëÂì¶ÔºÅüòä\n",
      "\n",
      "=== Á∫øÁ®ãÈöîÁ¶ªËØ¥Êòé ===\n",
      "1. Á∫øÁ®ã 1 ÂíåÁ∫øÁ®ã 2 ÊòØÂÆåÂÖ®Áã¨Á´ãÁöÑÂØπËØù\n",
      "2. ÊØè‰∏™Á∫øÁ®ãÁª¥Êä§Ëá™Â∑±ÁöÑÁä∂ÊÄÅÂíåËÆ∞ÂøÜ\n",
      "3. ÂèØ‰ª•Âú®Âêå‰∏Ä‰∏™Âõæ‰∏≠ÂêåÊó∂ÁÆ°ÁêÜÂ§ö‰∏™ÂØπËØù\n",
      "4. ËøôÁ±ª‰ºº‰∫é Slack ‰∏≠ÁöÑ‰∏çÂêåÈ¢ëÈÅì\n"
     ]
    }
   ],
   "source": [
    "# ÊºîÁ§∫Â¶Ç‰ΩïÂàõÂª∫Êñ∞ÁöÑÂØπËØùÁ∫øÁ®ã\n",
    "print(\"=== ÂàõÂª∫Êñ∞ÂØπËØùÁ∫øÁ®ãÊºîÁ§∫ ===\")\n",
    "\n",
    "# ÂàõÂª∫Êñ∞ÁöÑÁ∫øÁ®ãÈÖçÁΩÆ\n",
    "new_config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Âú®Êñ∞Á∫øÁ®ã‰∏≠ÂºÄÂßãÂØπËØù\n",
    "print(\"Êñ∞Á∫øÁ®ã‰∏≠ÁöÑÂØπËØùÔºö\")\n",
    "input_message = HumanMessage(content=\"‰Ω†Â•ΩÔºåÊàëÊòØÊñ∞Áî®Êà∑\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, new_config)\n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()\n",
    "\n",
    "print(\"\\n=== Á∫øÁ®ãÈöîÁ¶ªËØ¥Êòé ===\")\n",
    "print(\"1. Á∫øÁ®ã 1 ÂíåÁ∫øÁ®ã 2 ÊòØÂÆåÂÖ®Áã¨Á´ãÁöÑÂØπËØù\")\n",
    "print(\"2. ÊØè‰∏™Á∫øÁ®ãÁª¥Êä§Ëá™Â∑±ÁöÑÁä∂ÊÄÅÂíåËÆ∞ÂøÜ\")\n",
    "print(\"3. ÂèØ‰ª•Âú®Âêå‰∏Ä‰∏™Âõæ‰∏≠ÂêåÊó∂ÁÆ°ÁêÜÂ§ö‰∏™ÂØπËØù\")\n",
    "print(\"4. ËøôÁ±ª‰ºº‰∫é Slack ‰∏≠ÁöÑ‰∏çÂêåÈ¢ëÈÅì\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (agent101)",
   "language": "python",
   "name": "agent101"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
