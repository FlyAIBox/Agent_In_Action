{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "env_config_overview",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 🔧 环境配置和检查\n",
    "\n",
    "#### 概述\n",
    "\n",
    "本教程需要特定的环境配置以确保最佳学习体验。以下配置将帮助你：\n",
    "\n",
    "- 使用统一的conda环境：激活统一的学习环境\n",
    "- 通过国内镜像源快速安装依赖：配置pip使用清华镜像源\n",
    "- 加速模型下载：设置HuggingFace镜像代理\n",
    "- 检查系统配置：检查硬件和软件配置\n",
    "\n",
    "#### 配置\n",
    "\n",
    "- **所需环境及其依赖已经部署好**\n",
    "- 在`Notebook`右上角选择`jupyter内核`为`python(agent101)`，即可执行下方代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "env_conda_activate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================\n",
      "== Conda 环境检查报告 (仅针对当前 Bash 子进程) ==\n",
      "=========================================\n",
      "✅ 当前单元格已成功激活到 agent101 环境。\n",
      "✅ 正在使用的环境路径: /root/miniconda3/envs/agent101\n",
      "\n",
      "💡 提示: 后续的Python单元格将使用Notebook当前选择的Jupyter��核。\n",
      "   如果需要后续单元格也使用此环境，请执行以下操作:\n",
      "   1. 检查 Notebook 右上角是否已选择 'python(agent101)'。\n",
      "=========================================\n"
     ]
    }
   ],
   "source": [
    "%%script bash\n",
    "\n",
    "# 1. 激活 conda 环境 (仅对当前单元格有效)\n",
    "eval \"$(conda shell.bash hook)\"\n",
    "conda activate agent101\n",
    "\n",
    "echo \"=========================================\"\n",
    "echo \"== Conda 环境检查报告 (仅针对当前 Bash 子进程) ==\"\n",
    "echo \"=========================================\"\n",
    "\n",
    "# 2. 检查当前激活的环境\n",
    "CURRENT_ENV_NAME=$(basename $CONDA_PREFIX)\n",
    "\n",
    "if [ \"$CURRENT_ENV_NAME\" = \"agent101\" ]; then\n",
    "    echo \"✅ 当前单元格已成功激活到 agent101 环境。\"\n",
    "    echo \"✅ 正在使用的环境路径: $CONDA_PREFIX\"\n",
    "    echo \"\"\n",
    "    echo \"💡 提示: 后续的Python单元格将使用Notebook当前选择的Jupyter内核。\"\n",
    "    echo \"   如果需要后续单元格也使用此环境，请执行以下操作:\"\n",
    "    echo \"   1. 检查 Notebook 右上角是否已选择 'python(agent101)'。\"\n",
    "else\n",
    "    echo \"❌ 激活失败或环境名称不匹配。当前环境: $CURRENT_ENV_NAME\"\n",
    "    echo \"\"\n",
    "    echo \"⚠️ 严重提示: 建议将 Notebook 的 Jupyter **内核 (Kernel)** 切换为 'python(agent101)'。\"\n",
    "    echo \"   (通常位于 Notebook 右上角或 '内核' 菜单中)\"\n",
    "    echo \"\"\n",
    "    echo \"📚 备用方法 (不推荐): 如果无法切换内核，则必须在**每个**代码单元格的头部重复以下命令:\"\n",
    "    echo \"\"\n",
    "    echo \"%%script bash\"\n",
    "    echo \"# 必须在每个单元格都执行\"\n",
    "    echo \"eval \\\"\\$(conda shell.bash hook)\\\"\"\n",
    "    echo \"conda activate agent101\"\n",
    "fi\n",
    "\n",
    "echo \"=========================================\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "env_pip_config",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For variant 'global', will try loading '/etc/xdg/pip/pip.conf'\n",
      "For variant 'global', will try loading '/etc/pip.conf'\n",
      "For variant 'user', will try loading '/root/.pip/pip.conf'\n",
      "For variant 'user', will try loading '/root/.config/pip/pip.conf'\n",
      "For variant 'site', will try loading '/root/miniconda3/envs/agent101/pip.conf'\n",
      "\u001b[31mERROR: Got unexpected number of arguments, expected 0. (example: \"/root/miniconda3/envs/agent101/bin/python -m pip config list\")\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "For variant 'global', will try loading '/etc/xdg/pip/pip.conf'\n",
      "For variant 'global', will try loading '/etc/pip.conf'\n",
      "For variant 'user', will try loading '/root/.pip/pip.conf'\n",
      "For variant 'user', will try loading '/root/.config/pip/pip.conf'\n",
      "For variant 'site', will try loading '/root/miniconda3/envs/agent101/pip.conf'\n",
      "\u001b[31mERROR: Got unexpected number of arguments, expected 0. (example: \"/root/miniconda3/envs/agent101/bin/python -m pip config list\")\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# 2. 设置pip 为清华源\n",
    "%pip config list -v set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "%pip config list -v list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "env_hf_proxy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: HF_ENDPOINT=https://hf-mirror.com\n",
      "https://hf-mirror.com\n"
     ]
    }
   ],
   "source": [
    "# 3. 设置HuggingFace代理\n",
    "%env HF_ENDPOINT=https://hf-mirror.com\n",
    "# 验证：使用shell命令检查\n",
    "!echo $HF_ENDPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "env_system_check",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas==2.2.2 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (2.2.2)\n",
      "Requirement already satisfied: tabulate==0.9.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from pandas==2.2.2) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from pandas==2.2.2) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from pandas==2.2.2) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from pandas==2.2.2) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas==2.2.2) (1.17.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "### 环境信息\n",
      "| 项目         | 信息                                                                               |\n",
      "|:-------------|:-----------------------------------------------------------------------------------|\n",
      "| 操作系统     | Linux Ubuntu 22.04.4 LTS                                                           |\n",
      "| CPU 信息     | 11th Gen Intel(R) Core(TM) i5-1135G7 @ 2.40GHz (1 physical cores, 4 logical cores) |\n",
      "| 内存信息     | 5.75 GB (Available: 1.76 GB)                                                       |\n",
      "| GPU 信息     | No GPU found (nvidia-smi not found)                                                |\n",
      "| CUDA 信息    | CUDA not found                                                                     |\n",
      "| Python 版本  | 3.10.18                                                                            |\n",
      "| Conda 版本   | conda 24.4.0                                                                       |\n",
      "| 物理磁盘空间 | Total: 145.49 GB, Used: 20.20 GB, Free: 119.07 GB                                  |\n"
     ]
    }
   ],
   "source": [
    "# 🔍 环境信息检查脚本\n",
    "#\n",
    "# 本脚本的作用：\n",
    "# 1. 安装 pandas 库用于数据表格展示\n",
    "# 2. 检查系统的各项配置信息\n",
    "# 3. 生成详细的环境报告表格\n",
    "#\n",
    "# 对于初学者来说，这个步骤帮助你：\n",
    "# - 了解当前运行环境的硬件配置\n",
    "# - 确认是否满足模型运行的最低要求\n",
    "# - 学习如何通过代码获取系统信息\n",
    "\n",
    "# 安装 pandas 库 - 用于创建和展示数据表格\n",
    "# pandas 是 Python 中最流行的数据处理和分析库\n",
    "%pip install pandas==2.2.2 tabulate==0.9.0\n",
    "\n",
    "import platform # 导入 platform 模块以获取系统信息\n",
    "import os # 导入 os 模块以与操作系统交互\n",
    "import subprocess # 导入 subprocess 模块以运行外部命令\n",
    "import pandas as pd # 导入 pandas 模块，通常用于数据处理，这里用于创建表格\n",
    "import shutil # 导入 shutil 模块以获取磁盘空间信息\n",
    "\n",
    "# 获取 CPU 信息的函数，包括核心数量\n",
    "def get_cpu_info():\n",
    "    cpu_info = \"\" # 初始化 CPU 信息字符串\n",
    "    physical_cores = \"N/A\"\n",
    "    logical_cores = \"N/A\"\n",
    "\n",
    "    if platform.system() == \"Windows\": # 如果是 Windows 系统\n",
    "        cpu_info = platform.processor() # 使用 platform.processor() 获取 CPU 信息\n",
    "        try:\n",
    "            # 获取 Windows 上的核心数量 (需要 WMI)\n",
    "            import wmi\n",
    "            c = wmi.WMI()\n",
    "            for proc in c.Win32_Processor():\n",
    "                physical_cores = proc.NumberOfCores\n",
    "                logical_cores = proc.NumberOfLogicalProcessors\n",
    "        except:\n",
    "            pass # 如果 WMI 不可用，忽略错误\n",
    "\n",
    "    elif platform.system() == \"Darwin\": # 如果是 macOS 系统\n",
    "        # 在 macOS 上使用 sysctl 命令获取 CPU 信息和核心数量\n",
    "        os.environ['PATH'] = os.environ['PATH'] + os.pathsep + '/usr/sbin' # 更新 PATH 环境变量\n",
    "        try:\n",
    "            process_brand = subprocess.Popen(['sysctl', \"machdep.cpu.brand_string\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            stdout_brand, stderr_brand = process_brand.communicate()\n",
    "            cpu_info = stdout_brand.decode().split(': ')[1].strip() if stdout_brand else \"Could not retrieve CPU info\"\n",
    "\n",
    "            process_physical = subprocess.Popen(['sysctl', \"hw.physicalcpu\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            stdout_physical, stderr_physical = process_physical.communicate()\n",
    "            physical_cores = stdout_physical.decode().split(': ')[1].strip() if stdout_physical else \"N/A\"\n",
    "\n",
    "            process_logical = subprocess.Popen(['sysctl', \"hw.logicalcpu\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            stdout_logical, stderr_logical = process_logical.communicate()\n",
    "            logical_cores = stdout_logical.decode().split(': ')[1].strip() if stdout_logical else \"N/A\"\n",
    "\n",
    "        except:\n",
    "            cpu_info = \"Could not retrieve CPU info\"\n",
    "            physical_cores = \"N/A\"\n",
    "            logical_cores = \"N/A\"\n",
    "\n",
    "    else:  # Linux 系统\n",
    "        try:\n",
    "            # 在 Linux 上读取 /proc/cpuinfo 文件获取 CPU 信息和核心数量\n",
    "            with open('/proc/cpuinfo') as f:\n",
    "                physical_cores_count = 0\n",
    "                logical_cores_count = 0\n",
    "                cpu_info_lines = []\n",
    "                for line in f:\n",
    "                    if line.startswith('model name'): # 查找以 'model name'开头的行\n",
    "                        if not cpu_info: # 只获取第一个 model name\n",
    "                            cpu_info = line.split(': ')[1].strip()\n",
    "                    elif line.startswith('cpu cores'): # 查找以 'cpu cores' 开头的行\n",
    "                        physical_cores_count = int(line.split(': ')[1].strip())\n",
    "                    elif line.startswith('processor'): # 查找以 'processor' 开头的行\n",
    "                        logical_cores_count += 1\n",
    "                physical_cores = str(physical_cores_count) if physical_cores_count > 0 else \"N/A\"\n",
    "                logical_cores = str(logical_cores_count) if logical_cores_count > 0 else \"N/A\"\n",
    "                if not cpu_info:\n",
    "                     cpu_info = \"Could not retrieve CPU info\"\n",
    "\n",
    "        except:\n",
    "            cpu_info = \"Could not retrieve CPU info\"\n",
    "            physical_cores = \"N/A\"\n",
    "            logical_cores = \"N/A\"\n",
    "\n",
    "    return f\"{cpu_info} ({physical_cores} physical cores, {logical_cores} logical cores)\" # 返回 CPU 信息和核心数量\n",
    "\n",
    "\n",
    "# 获取内存信息的函数\n",
    "def get_memory_info():\n",
    "    mem_info = \"\" # 初始化内存信息字符串\n",
    "    if platform.system() == \"Windows\":\n",
    "        # 在 Windows 上不容易通过标准库获取，需要外部库或 PowerShell\n",
    "        mem_info = \"Requires external tools on Windows\" # 设置提示信息\n",
    "    elif platform.system() == \"Darwin\": # 如果是 macOS 系统\n",
    "        # 在 macOS 上使用 sysctl 命令获取内存大小\n",
    "        process = subprocess.Popen(['sysctl', \"hw.memsize\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE) # 运行 sysctl 命令\n",
    "        stdout, stderr = process.communicate() # 获取标准输出和标准错误\n",
    "        mem_bytes = int(stdout.decode().split(': ')[1].strip()) # 解析输出，获取内存大小（字节）\n",
    "        mem_gb = mem_bytes / (1024**3) # 转换为 GB\n",
    "        mem_info = f\"{mem_gb:.2f} GB\" # 格式化输出\n",
    "    else:  # Linux 系统\n",
    "        try:\n",
    "            # 在 Linux 上读取 /proc/meminfo 文件获取内存信息\n",
    "            with open('/proc/meminfo') as f:\n",
    "                total_mem_kb = 0\n",
    "                available_mem_kb = 0\n",
    "                for line in f:\n",
    "                    if line.startswith('MemTotal'): # 查找以 'MemTotal' 开头的行\n",
    "                        total_mem_kb = int(line.split(':')[1].strip().split()[0]) # 解析行，获取总内存（KB）\n",
    "                    elif line.startswith('MemAvailable'): # 查找以 'MemAvailable' 开头的行\n",
    "                         available_mem_kb = int(line.split(':')[1].strip().split()[0]) # 解析行，获取可用内存（KB）\n",
    "\n",
    "                if total_mem_kb > 0:\n",
    "                    total_mem_gb = total_mem_kb / (1024**2) # 转换为 GB\n",
    "                    mem_info = f\"{total_mem_gb:.2f} GB\" # 格式化输出总内存\n",
    "                    if available_mem_kb > 0:\n",
    "                        available_mem_gb = available_mem_kb / (1024**2)\n",
    "                        mem_info += f\" (Available: {available_mem_gb:.2f} GB)\" # 添加可用内存信息\n",
    "                else:\n",
    "                     mem_info = \"Could not retrieve memory info\" # 如果读取文件出错，设置错误信息\n",
    "\n",
    "        except:\n",
    "            mem_info = \"Could not retrieve memory info\" # 如果读取文件出错，设置错误信息\n",
    "    return mem_info # 返回内存信息\n",
    "\n",
    "# 获取 GPU 信息的函数，包括显存\n",
    "def get_gpu_info():\n",
    "    try:\n",
    "        # 尝试使用 nvidia-smi 获取 NVIDIA GPU 信息和显存\n",
    "        result = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total', '--format=csv,noheader'], capture_output=True, text=True)\n",
    "        if result.returncode == 0: # 如果命令成功执行\n",
    "            gpu_lines = result.stdout.strip().split('\\n') # 解析输出，获取 GPU 名称和显存\n",
    "            gpu_info_list = []\n",
    "            for line in gpu_lines:\n",
    "                name, memory = line.split(', ')\n",
    "                gpu_info_list.append(f\"{name} ({memory})\") # 格式化 GPU 信息\n",
    "            return \", \".join(gpu_info_list) if gpu_info_list else \"NVIDIA GPU found, but info not listed\" # 返回 GPU 信息或提示信息\n",
    "        else:\n",
    "             # 尝试使用 lshw 获取其他 GPU 信息 (需要安装 lshw)\n",
    "            try:\n",
    "                result_lshw = subprocess.run(['lshw', '-C', 'display'], capture_output=True, text=True)\n",
    "                if result_lshw.returncode == 0: # 如果命令成功执行\n",
    "                     # 简单解析输出中的 product 名称和显存\n",
    "                    gpu_info_lines = []\n",
    "                    current_gpu = {}\n",
    "                    for line in result_lshw.stdout.splitlines():\n",
    "                        if 'product:' in line:\n",
    "                             if current_gpu:\n",
    "                                 gpu_info_lines.append(f\"{current_gpu.get('product', 'GPU')} ({current_gpu.get('memory', 'N/A')})\")\n",
    "                             current_gpu = {'product': line.split('product:')[1].strip()}\n",
    "                        elif 'size:' in line and 'memory' in line:\n",
    "                             current_gpu['memory'] = line.split('size:')[1].strip()\n",
    "\n",
    "                    if current_gpu: # 添加最后一个 GPU 的信息\n",
    "                        gpu_info_lines.append(f\"{current_gpu.get('product', 'GPU')} ({current_gpu.get('memory', 'N/A')})\")\n",
    "\n",
    "                    return \", \".join(gpu_info_lines) if gpu_info_lines else \"GPU found (via lshw), but info not parsed\" # 如果找到 GPU 但信息无法解析，设置提示信息\n",
    "                else:\n",
    "                    return \"No GPU found (checked nvidia-smi and lshw)\" # 如果两个命令都找不到 GPU，设置提示信息\n",
    "            except FileNotFoundError:\n",
    "                 return \"No GPU found (checked nvidia-smi, lshw not found)\" # 如果找不到 lshw 命令，设置提示信息\n",
    "    except FileNotFoundError:\n",
    "        return \"No GPU found (nvidia-smi not found)\" # 如果找不到 nvidia-smi 命令，设置提示信息\n",
    "\n",
    "\n",
    "# 获取 CUDA 版本的函数\n",
    "def get_cuda_version():\n",
    "    try:\n",
    "        # 尝试使用 nvcc --version 获取 CUDA 版本\n",
    "        result = subprocess.run(['nvcc', '--version'], capture_output=True, text=True)\n",
    "        if result.returncode == 0: # 如果命令成功执行\n",
    "            for line in result.stdout.splitlines():\n",
    "                if 'release' in line: # 查找包含 'release' 的行\n",
    "                    return line.split('release ')[1].split(',')[0] # 解析行，提取版本号\n",
    "        return \"CUDA not found or version not parsed\" # 如果找不到 CUDA 或版本无法解析，设置提示信息\n",
    "    except FileNotFoundError:\n",
    "        return \"CUDA not found\" # 如果找不到 nvcc 命令，设置提示信息\n",
    "\n",
    "# 获取 Python 版本的函数\n",
    "def get_python_version():\n",
    "    return platform.python_version() # 获取 Python 版本\n",
    "\n",
    "# 获取 Conda 版本的函数\n",
    "def get_conda_version():\n",
    "    try:\n",
    "        # 尝试使用 conda --version 获取 Conda 版本\n",
    "        result = subprocess.run(['conda', '--version'], capture_output=True, text=True)\n",
    "        if result.returncode == 0: # 如果命令成功执行\n",
    "            return result.stdout.strip() # 返回 Conda 版本\n",
    "        return \"Conda not found or version not parsed\" # 如果找不到 Conda 或版本无法解析，设置提示信息\n",
    "    except FileNotFoundError:\n",
    "        return \"Conda not found\" # 如果找不到 conda 命令，设置提示信息\n",
    "\n",
    "# 获取物理磁盘空间信息的函数\n",
    "def get_disk_space():\n",
    "    try:\n",
    "        total, used, free = shutil.disk_usage(\"/\") # 获取根目录的磁盘使用情况\n",
    "        total_gb = total / (1024**3) # 转换为 GB\n",
    "        used_gb = used / (1024**3) # 转换为 GB\n",
    "        free_gb = free / (1024**3) # 转换为 GB\n",
    "        return f\"Total: {total_gb:.2f} GB, Used: {used_gb:.2f} GB, Free: {free_gb:.2f} GB\" # 格式化输出\n",
    "    except Exception as e:\n",
    "        return f\"Could not retrieve disk info: {e}\" # 如果获取信息出错，设置错误信息\n",
    "\n",
    "# 获取环境信息\n",
    "os_name = platform.system() # 获取操作系统名称\n",
    "os_version = platform.release() # 获取操作系统版本\n",
    "if os_name == \"Linux\":\n",
    "    try:\n",
    "        # 在 Linux 上尝试获取发行版和版本\n",
    "        lsb_info = subprocess.run(['lsb_release', '-a'], capture_output=True, text=True)\n",
    "        if lsb_info.returncode == 0: # 如果命令成功执行\n",
    "            for line in lsb_info.stdout.splitlines():\n",
    "                if 'Description:' in line: # 查找包含 'Description:' 的行\n",
    "                    os_version = line.split('Description:')[1].strip() # 提取描述信息作为版本\n",
    "                    break # 找到后退出循环\n",
    "                elif 'Release:' in line: # 查找包含 'Release:' 的行\n",
    "                     os_version = line.split('Release:')[1].strip() # 提取版本号\n",
    "                     # 尝试获取 codename\n",
    "                     try:\n",
    "                         codename_info = subprocess.run(['lsb_release', '-c'], capture_output=True, text=True)\n",
    "                         if codename_info.returncode == 0:\n",
    "                             os_version += f\" ({codename_info.stdout.split(':')[1].strip()})\" # 将 codename 添加到版本信息中\n",
    "                     except:\n",
    "                         pass # 如果获取 codename 失败则忽略\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        pass # lsb_release 可能未安装，忽略错误\n",
    "\n",
    "full_os_info = f\"{os_name} {os_version}\" # 组合完整的操作系统信息\n",
    "cpu_info = get_cpu_info() # 调用函数获取 CPU 信息和核心数量\n",
    "memory_info = get_memory_info() # 调用函数获取内存信息\n",
    "gpu_info = get_gpu_info() # 调用函数获取 GPU 信息和显存\n",
    "cuda_version = get_cuda_version() # 调用函数获取 CUDA 版本\n",
    "python_version = get_python_version() # 调用函数获取 Python 版本\n",
    "conda_version = get_conda_version() # 调用函数获取 Conda 版本\n",
    "disk_info = get_disk_space() # 调用函数获取物理磁盘空间信息\n",
    "\n",
    "\n",
    "# 创建用于存储数据的字典\n",
    "env_data = {\n",
    "    \"项目\": [ # 项目名称列表\n",
    "        \"操作系统\",\n",
    "        \"CPU 信息\",\n",
    "        \"内存信息\",\n",
    "        \"GPU 信息\",\n",
    "        \"CUDA 信息\",\n",
    "        \"Python 版本\",\n",
    "        \"Conda 版本\",\n",
    "        \"物理磁盘空间\" # 添加物理磁盘空间\n",
    "    ],\n",
    "    \"信息\": [ # 对应的信息列表\n",
    "        full_os_info,\n",
    "        cpu_info,\n",
    "        memory_info,\n",
    "        gpu_info,\n",
    "        cuda_version,\n",
    "        python_version,\n",
    "        conda_version,\n",
    "        disk_info # 添加物理磁盘空间信息\n",
    "    ]\n",
    "}\n",
    "\n",
    "# 创建一个 pandas DataFrame\n",
    "df = pd.DataFrame(env_data)\n",
    "\n",
    "# 打印表格\n",
    "print(\"### 环境信息\") # 打印标题\n",
    "print(df.to_markdown(index=False)) # 将 DataFrame 转换为 Markdown 格式并打印，不包含索引\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147e576c",
   "metadata": {
    "id": "147e576c"
   },
   "source": [
    "# 图状态编辑与人工反馈\n",
    "\n",
    "\n",
    "## 本教程简介\n",
    "\n",
    "本教程将向你展示如何在LangGraph中编辑图状态并集成人工反馈。这是构建人机协作AI系统的关键技术，让人类可以在AI执行过程中进行干预和指导。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2f2448-21c3-4196-9e61-0b47e7d0048b",
   "metadata": {
    "id": "3b2f2448-21c3-4196-9e61-0b47e7d0048b"
   },
   "source": [
    "# 编辑图状态\n",
    "\n",
    "## 回顾\n",
    "\n",
    "我们之前讨论了人机协作（human-in-the-loop）的动机：\n",
    "\n",
    "**(1) 审批（Approval）** - 我们可以中断智能体，向用户展示状态，并允许用户接受某个操作\n",
    "\n",
    "**(2) 调试（Debugging）** - 我们可以回滚图来重现或避免问题\n",
    "\n",
    "**(3) 编辑（Editing）** - 你可以修改状态\n",
    "\n",
    "我们展示了断点如何支持用户审批，但还不知道如何在图被中断后修改图状态！\n",
    "\n",
    "## 学习目标\n",
    "\n",
    "现在，让我们展示如何直接编辑图状态并插入人工反馈。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95d26b8c-d958-4d21-9ca4-4636d3dfe45c",
   "metadata": {
    "id": "95d26b8c-d958-4d21-9ca4-4636d3dfe45c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# 安装必要的依赖包\n",
    "# 这些包是构建LangGraph应用的核心组件\n",
    "%pip install --quiet langgraph==0.6.7 langchain_openai==0.3.32 langgraph_sdk==0.2.6 langgraph-prebuilt==0.6.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5948594",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d5948594",
    "outputId": "90174103-6cdd-4be5-a4c9-7c84d2b01331"
   },
   "outputs": [],
   "source": [
    "# 设置环境变量\n",
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    \"\"\"安全地设置环境变量，如果不存在则提示用户输入\"\"\"\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "# 设置OpenAI API密钥，这是使用OpenAI模型所必需的\n",
    "_set_env(\"OPENAI_API_KEY\")\n",
    "# 设置 OpenAI API代理地址 (例如：https://api.apiyi.com/v1）\n",
    "_set_env(\"OPENAI_BASE_URL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a8df1f-a76a-4803-a532-ea9802106ac8",
   "metadata": {
    "id": "65a8df1f-a76a-4803-a532-ea9802106ac8"
   },
   "source": [
    "## 编辑状态\n",
    "\n",
    "之前，我们介绍了断点（breakpoints）。\n",
    "\n",
    "我们使用断点来中断图，并在执行下一个节点之前等待用户审批。\n",
    "\n",
    "但**断点也是[修改图状态的机会](https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/edit-graph-state/)。**\n",
    "\n",
    "让我们在`assistant`节点之前设置一个断点来构建我们的智能体。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcf24f05-ac2b-455e-846c-0c50ac86e1f4",
   "metadata": {
    "id": "bcf24f05-ac2b-455e-846c-0c50ac86e1f4"
   },
   "outputs": [],
   "source": [
    "# 导入必要的库\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 定义数学运算工具函数\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"乘法运算：计算两个整数的乘积\n",
    "\n",
    "    Args:\n",
    "        a: 第一个整数\n",
    "        b: 第二个整数\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"加法运算：计算两个整数的和\n",
    "\n",
    "    Args:\n",
    "        a: 第一个整数\n",
    "        b: 第二个整数\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "def divide(a: int, b: int) -> float:\n",
    "    \"\"\"除法运算：计算两个整数的商\n",
    "\n",
    "    Args:\n",
    "        a: 被除数\n",
    "        b: 除数\n",
    "    \"\"\"\n",
    "    return a / b\n",
    "\n",
    "# 将工具函数组合成工具列表\n",
    "tools = [add, multiply, divide]\n",
    "\n",
    "# 初始化OpenAI聊天模型\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "# 将工具绑定到语言模型，使模型能够调用这些工具\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5dfe84af-5c62-4c3f-8ed7-96b5261f0b7b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 308
    },
    "id": "5dfe84af-5c62-4c3f-8ed7-96b5261f0b7b",
    "outputId": "b0a5516f-31c0-495d-d439-caf0e80e825b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "图可视化：\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 图渲染成功！\n"
     ]
    }
   ],
   "source": [
    "# 导入必要的库\n",
    "from IPython.display import Image, display\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import MessagesState\n",
    "from langgraph.graph import START, StateGraph\n",
    "from langgraph.prebuilt import tools_condition, ToolNode\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# 定义系统消息，指导AI助手的行为\n",
    "sys_msg = SystemMessage(content=\"You are a helpful assistant tasked with performing arithmetic on a set of inputs.\")\n",
    "\n",
    "# 定义助手节点函数\n",
    "def assistant(state: MessagesState):\n",
    "    \"\"\"助手节点：使用语言模型处理消息并可能调用工具\n",
    "\n",
    "    Args:\n",
    "        state: 包含消息列表的图状态\n",
    "\n",
    "    Returns:\n",
    "        包含AI响应的新状态更新\n",
    "    \"\"\"\n",
    "    return {\"messages\": [llm_with_tools.invoke([sys_msg] + state[\"messages\"])]}\n",
    "\n",
    "# 创建状态图构建器\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "# 定义节点：这些节点执行具体的工作\n",
    "builder.add_node(\"assistant\", assistant)  # AI助手节点\n",
    "builder.add_node(\"tools\", ToolNode(tools))  # 工具执行节点\n",
    "\n",
    "# 定义边：这些边决定控制流程\n",
    "builder.add_edge(START, \"assistant\")  # 从开始到助手\n",
    "builder.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    # 如果助手的最新消息是工具调用 -> tools_condition 路由到工具节点\n",
    "    # 如果助手的最新消息不是工具调用 -> tools_condition 路由到结束\n",
    "    tools_condition,\n",
    ")\n",
    "builder.add_edge(\"tools\", \"assistant\")  # 从工具回到助手\n",
    "\n",
    "# 创建内存检查点保存器，用于保存图状态\n",
    "memory = MemorySaver()\n",
    "\n",
    "# 编译图，在assistant节点之前设置中断点\n",
    "graph = builder.compile(interrupt_before=[\"assistant\"], checkpointer=memory)\n",
    "\n",
    "# 展示图结构\n",
    "# 图可视化\n",
    "print(\"图可视化：\")\n",
    "\n",
    "# 方案1：尝试使用 Pyppeteer 本地渲染（推荐）\n",
    "try:\n",
    "    # 可视化：通过 Mermaid 渲染图结构\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "    print(\"✅ 图渲染成功！\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Pyppeteer 渲染失败: {e}\")\n",
    "    \n",
    "    # 方案2：显示 Mermaid 文本格式\n",
    "    print(\"\\n📝 图结构（Mermaid 文本格式）：\")\n",
    "    print(\"=\" * 50)\n",
    "    mermaid_text = graph.get_graph().draw_mermaid()\n",
    "    print(mermaid_text)\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # 方案3：显示图的节点和边信息\n",
    "    print(\"\\n🔗 图结构信息：\")\n",
    "    print(\"节点:\", list(graph.get_graph().nodes.keys()))\n",
    "    print(\"边:\", list(graph.get_graph().edges))\n",
    "    \n",
    "    # 方案4：提供手动渲染说明\n",
    "    print(\"\\n💡 手动渲染说明：\")\n",
    "    print(\"1. 复制上面的 Mermaid 文本\")\n",
    "    print(\"2. 访问 https://mermaid.live/\")\n",
    "    print(\"3. 粘贴文本到编辑器中查看图形\")\n",
    "    print(\"4. 或者使用支持 Mermaid 的 Markdown 编辑器\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a47fd5-1f60-41dc-9206-698ed8ece530",
   "metadata": {
    "id": "92a47fd5-1f60-41dc-9206-698ed8ece530"
   },
   "source": [
    "让我们运行图！\n",
    "\n",
    "我们可以看到图在聊天模型响应之前被中断了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2ce488d-00e4-492e-a62c-dd98702c313f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a2ce488d-00e4-492e-a62c-dd98702c313f",
    "outputId": "7736c7bb-0693-433a-99c8-9a04c1458e72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Multiply 2 and 3\n"
     ]
    }
   ],
   "source": [
    "# 定义初始输入：用户要求进行数学运算\n",
    "initial_input = {\"messages\": \"Multiply 2 and 3\"}\n",
    "\n",
    "# 创建线程配置，用于跟踪对话状态\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# 运行图直到第一个中断点\n",
    "# 由于设置了interrupt_before=[\"assistant\"]，图会在assistant节点执行前停止\n",
    "for event in graph.stream(initial_input, thread, stream_mode=\"values\"):\n",
    "    event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4be478ef-bd60-4d32-8a05-5f56c93a8396",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4be478ef-bd60-4d32-8a05-5f56c93a8396",
    "outputId": "d898817a-3556-4785-c4e3-2fc1cc4a1229"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content='Multiply 2 and 3', additional_kwargs={}, response_metadata={}, id='9e69316f-22d0-42ac-9e77-3e3e58a51e0c')]}, next=('assistant',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0ab3e5-b9e4-6258-8000-5e26474f0c03'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2025-10-17T09:47:56.190270+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0ab3e5-b97f-687c-bfff-c54209c6fa69'}}, tasks=(PregelTask(id='6249a2f1-962f-90e5-e09e-189f761a209d', name='assistant', path=('__pregel_pull', 'assistant'), error=None, interrupts=(), state=None, result=None),), interrupts=())"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 获取当前图状态，查看中断时的状态信息\n",
    "state = graph.get_state(thread)\n",
    "state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ef63a1-2ab8-416d-babf-d35054e294f0",
   "metadata": {
    "id": "36ef63a1-2ab8-416d-babf-d35054e294f0"
   },
   "source": [
    "现在，我们可以直接应用状态更新。\n",
    "\n",
    "记住，对`messages`键的更新将使用`add_messages`归约器：\n",
    "\n",
    "* 如果我们想要覆盖现有消息，可以提供消息的`id`。\n",
    "* 如果我们只是想要追加到消息列表中，那么可以传递一个没有指定`id`的消息，如下所示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9179cff1-e529-473a-9ce2-e23b932c2063",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9179cff1-e529-473a-9ce2-e23b932c2063",
    "outputId": "1ea55096-4c34-41bd-8f31-6795d6cef635"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '1',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1f0ab3e5-bae2-65f3-8001-d7fd62c17a5e'}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 更新图状态：添加新的人类消息\n",
    "# 这里我们添加一条新消息来修改用户的原始请求\n",
    "graph.update_state(\n",
    "    thread,\n",
    "    {\"messages\": [HumanMessage(content=\"No, actually multiply 3 and 3!\")]},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77b8d6a-8c7b-4f7a-b723-121af25ac829",
   "metadata": {
    "id": "d77b8d6a-8c7b-4f7a-b723-121af25ac829"
   },
   "source": [
    "让我们看一下结果。\n",
    "\n",
    "我们使用新消息调用了`update_state`。\n",
    "\n",
    "`add_messages`归约器将其追加到我们的状态键`messages`中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "141b6aab-ec6d-44f3-beb1-6c22ac5f2158",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "141b6aab-ec6d-44f3-beb1-6c22ac5f2158",
    "outputId": "29f6863a-e7ed-492a-8754-ad65919747d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Multiply 2 and 3\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "No, actually multiply 3 and 3!\n"
     ]
    }
   ],
   "source": [
    "# 获取更新后的状态并显示所有消息\n",
    "new_state = graph.get_state(thread).values\n",
    "for m in new_state['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4041959-cc3a-4168-8cf7-06d1711921d8",
   "metadata": {
    "id": "e4041959-cc3a-4168-8cf7-06d1711921d8"
   },
   "source": [
    "现在，让我们继续执行我们的智能体，只需传递`None`并允许它从当前状态继续。\n",
    "\n",
    "我们发出当前状态，然后继续执行剩余的节点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f166bed2-87c9-41ec-b235-0305721c2d6b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f166bed2-87c9-41ec-b235-0305721c2d6b",
    "outputId": "ee0bd980-4ec0-49d3-e382-a65aa66b03d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "No, actually multiply 3 and 3!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (call_f7Xx8j8fDZaYKLh6754OGYqT)\n",
      " Call ID: call_f7Xx8j8fDZaYKLh6754OGYqT\n",
      "  Args:\n",
      "    a: 3\n",
      "    b: 3\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# 继续执行图，从当前中断点开始\n",
    "# 传递None表示从当前状态继续，而不是重新开始\n",
    "for event in graph.stream(None, thread, stream_mode=\"values\"):\n",
    "    event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18dc1ca",
   "metadata": {
    "id": "b18dc1ca"
   },
   "source": [
    "现在，我们又回到了`assistant`节点，它设置了我们的`breakpoint`。\n",
    "\n",
    "我们可以再次传递`None`来继续执行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5952731-0170-4589-a399-ee787df35400",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f5952731-0170-4589-a399-ee787df35400",
    "outputId": "2f880747-c7b3-41d7-f6e1-165ab9ca18f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "9\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The result of multiplying 3 and 3 is 9.\n"
     ]
    }
   ],
   "source": [
    "# 继续执行图，完成剩余的计算\n",
    "for event in graph.stream(None, thread, stream_mode=\"values\"):\n",
    "    event['messages'][-1].pretty_print()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (agent101)",
   "language": "python",
   "name": "agent101"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
