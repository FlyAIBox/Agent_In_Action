{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🔧 环境配置和检查\n",
    "\n",
    "#### 概述\n",
    "\n",
    "本教程需要特定的环境配置以确保最佳学习体验。以下配置将帮助你：\n",
    "\n",
    "- 使用统一的conda环境：激活统一的学习环境\n",
    "- 通过国内镜像源快速安装依赖：配置pip使用清华镜像源\n",
    "- 加速模型下载：设置HuggingFace镜像代理\n",
    "- 检查系统配置：检查硬件和软件配置\n",
    "\n",
    "#### 配置\n",
    "\n",
    "- **所需环境及其依赖已经部署好**\n",
    "- 在`Notebook`右上角选择`jupyter内核`为`python(agent101)`，即可执行下方代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================\n",
      "== Conda 环境检查报告 (仅针对当前 Bash 子进��) ==\n",
      "=========================================\n",
      "✅ 当前单元格已成功激活到 agent101 环境。\n",
      "✅ 正在使用的环境路径: /root/miniconda3/envs/agent101\n",
      "\n",
      "💡 提示: 后续的Python单元格将使用Notebook当前选择的Jupyter��核。\n",
      "   如果需要后续单元格也使用此环境，请执行以下操作:\n",
      "   1. 检查 Notebook 右上角是否已选择 'python(agent101)'。\n",
      "=========================================\n"
     ]
    }
   ],
   "source": [
    "%%script bash\n",
    "\n",
    "# 1. 激活 conda 环境 (仅对当前单元格有效)\n",
    "eval \"$(conda shell.bash hook)\"\n",
    "conda activate agent101\n",
    "\n",
    "echo \"=========================================\"\n",
    "echo \"== Conda 环境检查报告 (仅针对当前 Bash 子进程) ==\"\n",
    "echo \"=========================================\"\n",
    "\n",
    "# 2. 检查当前激活的环境\n",
    "CURRENT_ENV_NAME=$(basename $CONDA_PREFIX)\n",
    "\n",
    "if [ \"$CURRENT_ENV_NAME\" = \"agent101\" ]; then\n",
    "    echo \"✅ 当前单元格已成功激活到 agent101 环境。\"\n",
    "    echo \"✅ 正在使用的环境路径: $CONDA_PREFIX\"\n",
    "    echo \"\"\n",
    "    echo \"💡 提示: 后续的Python单元格将使用Notebook当前选择的Jupyter内核。\"\n",
    "    echo \"   如果需要后续单元格也使用此环境，请执行以下操作:\"\n",
    "    echo \"   1. 检查 Notebook 右上角是否已选择 'python(agent101)'。\"\n",
    "else\n",
    "    echo \"❌ 激活失败或环境名称不匹配。当前环境: $CURRENT_ENV_NAME\"\n",
    "    echo \"\"\n",
    "    echo \"⚠️ 严重提示: 建议将 Notebook 的 Jupyter **内核 (Kernel)** 切换为 'python(agent101)'。\"\n",
    "    echo \"   (通常位于 Notebook 右上角或 '内核' 菜单中)\"\n",
    "    echo \"\"\n",
    "    echo \"📚 备用方法 (不推荐): 如果无法切换内核，则必须在**每个**代码单元格的头部重复以下命令:\"\n",
    "    echo \"\"\n",
    "    echo \"%%script bash\"\n",
    "    echo \"# 必须在每个单元格都执行\"\n",
    "    echo \"eval \\\"\\$(conda shell.bash hook)\\\"\"\n",
    "    echo \"conda activate agent101\"\n",
    "fi\n",
    "\n",
    "echo \"=========================================\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For variant 'global', will try loading '/etc/xdg/pip/pip.conf'\n",
      "For variant 'global', will try loading '/etc/pip.conf'\n",
      "For variant 'user', will try loading '/root/.pip/pip.conf'\n",
      "For variant 'user', will try loading '/root/.config/pip/pip.conf'\n",
      "For variant 'site', will try loading '/root/miniconda3/envs/agent101/pip.conf'\n",
      "\u001b[31mERROR: Got unexpected number of arguments, expected 0. (example: \"/root/miniconda3/envs/agent101/bin/python -m pip config list\")\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "For variant 'global', will try loading '/etc/xdg/pip/pip.conf'\n",
      "For variant 'global', will try loading '/etc/pip.conf'\n",
      "For variant 'user', will try loading '/root/.pip/pip.conf'\n",
      "For variant 'user', will try loading '/root/.config/pip/pip.conf'\n",
      "For variant 'site', will try loading '/root/miniconda3/envs/agent101/pip.conf'\n",
      "\u001b[31mERROR: Got unexpected number of arguments, expected 0. (example: \"/root/miniconda3/envs/agent101/bin/python -m pip config list\")\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# 2. 设置pip 为清华源\n",
    "%pip config list -v set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "%pip config list -v list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: HF_ENDPOINT=https://hf-mirror.com\n",
      "https://hf-mirror.com\n"
     ]
    }
   ],
   "source": [
    "# 3. 设置HuggingFace代理\n",
    "%env HF_ENDPOINT=https://hf-mirror.com\n",
    "# 验证：使用shell命令检查\n",
    "!echo $HF_ENDPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas==2.2.2 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (2.2.2)\n",
      "Requirement already satisfied: tabulate==0.9.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from pandas==2.2.2) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from pandas==2.2.2) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from pandas==2.2.2) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from pandas==2.2.2) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas==2.2.2) (1.17.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "### 环境信息\n",
      "| 项目         | 信息                                                                               |\n",
      "|:-------------|:-----------------------------------------------------------------------------------|\n",
      "| 操作系统     | Linux Ubuntu 22.04.4 LTS                                                           |\n",
      "| CPU 信息     | 11th Gen Intel(R) Core(TM) i5-1135G7 @ 2.40GHz (1 physical cores, 4 logical cores) |\n",
      "| 内存信息     | 5.75 GB (Available: 3.60 GB)                                                       |\n",
      "| GPU 信息     | No GPU found (nvidia-smi not found)                                                |\n",
      "| CUDA 信息    | CUDA not found                                                                     |\n",
      "| Python 版本  | 3.10.18                                                                            |\n",
      "| Conda 版本   | conda 24.4.0                                                                       |\n",
      "| 物理磁盘空间 | Total: 145.49 GB, Used: 20.26 GB, Free: 119.00 GB                                  |\n"
     ]
    }
   ],
   "source": [
    "# 🔍 环境信息检查脚本\n",
    "#\n",
    "# 本脚本的作用：\n",
    "# 1. 安装 pandas 库用于数据表格展示\n",
    "# 2. 检查系统的各项配置信息\n",
    "# 3. 生成详细的环境报告表格\n",
    "#\n",
    "# 对于初学者来说，这个步骤帮助你：\n",
    "# - 了解当前运行环境的硬件配置\n",
    "# - 确认是否满足模型运行的最低要求\n",
    "# - 学习如何通过代码获取系统信息\n",
    "\n",
    "# 安装 pandas 库 - 用于创建和展示数据表格\n",
    "# pandas 是 Python 中最流行的数据处理和分析库\n",
    "%pip install pandas==2.2.2 tabulate==0.9.0\n",
    "\n",
    "import platform # 导入 platform 模块以获取系统信息\n",
    "import os # 导入 os 模块以与操作系统交互\n",
    "import subprocess # 导入 subprocess 模块以运行外部命令\n",
    "import pandas as pd # 导入 pandas 模块，通常用于数据处理，这里用于创建表格\n",
    "import shutil # 导入 shutil 模块以获取磁盘空间信息\n",
    "\n",
    "# 获取 CPU 信息的函数，包括核心数量\n",
    "def get_cpu_info():\n",
    "    cpu_info = \"\" # 初始化 CPU 信息字符串\n",
    "    physical_cores = \"N/A\"\n",
    "    logical_cores = \"N/A\"\n",
    "\n",
    "    if platform.system() == \"Windows\": # 如果是 Windows 系统\n",
    "        cpu_info = platform.processor() # 使用 platform.processor() 获取 CPU 信息\n",
    "        try:\n",
    "            # 获取 Windows 上的核心数量 (需要 WMI)\n",
    "            import wmi\n",
    "            c = wmi.WMI()\n",
    "            for proc in c.Win32_Processor():\n",
    "                physical_cores = proc.NumberOfCores\n",
    "                logical_cores = proc.NumberOfLogicalProcessors\n",
    "        except:\n",
    "            pass # 如果 WMI 不可用，忽略错误\n",
    "\n",
    "    elif platform.system() == \"Darwin\": # 如果是 macOS 系统\n",
    "        # 在 macOS 上使用 sysctl 命令获取 CPU 信息和核心数量\n",
    "        os.environ['PATH'] = os.environ['PATH'] + os.pathsep + '/usr/sbin' # 更新 PATH 环境变量\n",
    "        try:\n",
    "            process_brand = subprocess.Popen(['sysctl', \"machdep.cpu.brand_string\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            stdout_brand, stderr_brand = process_brand.communicate()\n",
    "            cpu_info = stdout_brand.decode().split(': ')[1].strip() if stdout_brand else \"Could not retrieve CPU info\"\n",
    "\n",
    "            process_physical = subprocess.Popen(['sysctl', \"hw.physicalcpu\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            stdout_physical, stderr_physical = process_physical.communicate()\n",
    "            physical_cores = stdout_physical.decode().split(': ')[1].strip() if stdout_physical else \"N/A\"\n",
    "\n",
    "            process_logical = subprocess.Popen(['sysctl', \"hw.logicalcpu\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            stdout_logical, stderr_logical = process_logical.communicate()\n",
    "            logical_cores = stdout_logical.decode().split(': ')[1].strip() if stdout_logical else \"N/A\"\n",
    "\n",
    "        except:\n",
    "            cpu_info = \"Could not retrieve CPU info\"\n",
    "            physical_cores = \"N/A\"\n",
    "            logical_cores = \"N/A\"\n",
    "\n",
    "    else:  # Linux 系统\n",
    "        try:\n",
    "            # 在 Linux 上读取 /proc/cpuinfo 文件获取 CPU 信息和核心数量\n",
    "            with open('/proc/cpuinfo') as f:\n",
    "                physical_cores_count = 0\n",
    "                logical_cores_count = 0\n",
    "                cpu_info_lines = []\n",
    "                for line in f:\n",
    "                    if line.startswith('model name'): # 查找以 'model name'开头的行\n",
    "                        if not cpu_info: # 只获取第一个 model name\n",
    "                            cpu_info = line.split(': ')[1].strip()\n",
    "                    elif line.startswith('cpu cores'): # 查找以 'cpu cores' 开头的行\n",
    "                        physical_cores_count = int(line.split(': ')[1].strip())\n",
    "                    elif line.startswith('processor'): # 查找以 'processor' 开头的行\n",
    "                        logical_cores_count += 1\n",
    "                physical_cores = str(physical_cores_count) if physical_cores_count > 0 else \"N/A\"\n",
    "                logical_cores = str(logical_cores_count) if logical_cores_count > 0 else \"N/A\"\n",
    "                if not cpu_info:\n",
    "                     cpu_info = \"Could not retrieve CPU info\"\n",
    "\n",
    "        except:\n",
    "            cpu_info = \"Could not retrieve CPU info\"\n",
    "            physical_cores = \"N/A\"\n",
    "            logical_cores = \"N/A\"\n",
    "\n",
    "    return f\"{cpu_info} ({physical_cores} physical cores, {logical_cores} logical cores)\" # 返回 CPU 信息和核心数量\n",
    "\n",
    "\n",
    "# 获取内存信息的函数\n",
    "def get_memory_info():\n",
    "    mem_info = \"\" # 初始化内存信息字符串\n",
    "    if platform.system() == \"Windows\":\n",
    "        # 在 Windows 上不容易通过标准库获取，需要外部库或 PowerShell\n",
    "        mem_info = \"Requires external tools on Windows\" # 设置提示信息\n",
    "    elif platform.system() == \"Darwin\": # 如果是 macOS 系统\n",
    "        # 在 macOS 上使用 sysctl 命令获取内存大小\n",
    "        process = subprocess.Popen(['sysctl', \"hw.memsize\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE) # 运行 sysctl 命令\n",
    "        stdout, stderr = process.communicate() # 获取标准输出和标准错误\n",
    "        mem_bytes = int(stdout.decode().split(': ')[1].strip()) # 解析输出，获取内存大小（字节）\n",
    "        mem_gb = mem_bytes / (1024**3) # 转换为 GB\n",
    "        mem_info = f\"{mem_gb:.2f} GB\" # 格式化输出\n",
    "    else:  # Linux 系统\n",
    "        try:\n",
    "            # 在 Linux 上读取 /proc/meminfo 文件获取内存信息\n",
    "            with open('/proc/meminfo') as f:\n",
    "                total_mem_kb = 0\n",
    "                available_mem_kb = 0\n",
    "                for line in f:\n",
    "                    if line.startswith('MemTotal'): # 查找以 'MemTotal' 开头的行\n",
    "                        total_mem_kb = int(line.split(':')[1].strip().split()[0]) # 解析行，获取总内存（KB）\n",
    "                    elif line.startswith('MemAvailable'): # 查找以 'MemAvailable' 开头的行\n",
    "                         available_mem_kb = int(line.split(':')[1].strip().split()[0]) # 解析行，获取可用内存（KB）\n",
    "\n",
    "                if total_mem_kb > 0:\n",
    "                    total_mem_gb = total_mem_kb / (1024**2) # 转换为 GB\n",
    "                    mem_info = f\"{total_mem_gb:.2f} GB\" # 格式化输出总内存\n",
    "                    if available_mem_kb > 0:\n",
    "                        available_mem_gb = available_mem_kb / (1024**2)\n",
    "                        mem_info += f\" (Available: {available_mem_gb:.2f} GB)\" # 添加可用内存信息\n",
    "                else:\n",
    "                     mem_info = \"Could not retrieve memory info\" # 如果读取文件出错，设置错误信息\n",
    "\n",
    "        except:\n",
    "            mem_info = \"Could not retrieve memory info\" # 如果读取文件出错，设置错误信息\n",
    "    return mem_info # 返回内存信息\n",
    "\n",
    "# 获取 GPU 信息的函数，包括显存\n",
    "def get_gpu_info():\n",
    "    try:\n",
    "        # 尝试使用 nvidia-smi 获取 NVIDIA GPU 信息和显存\n",
    "        result = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total', '--format=csv,noheader'], capture_output=True, text=True)\n",
    "        if result.returncode == 0: # 如果命令成功执行\n",
    "            gpu_lines = result.stdout.strip().split('\\n') # 解析输出，获取 GPU 名称和显存\n",
    "            gpu_info_list = []\n",
    "            for line in gpu_lines:\n",
    "                name, memory = line.split(', ')\n",
    "                gpu_info_list.append(f\"{name} ({memory})\") # 格式化 GPU 信息\n",
    "            return \", \".join(gpu_info_list) if gpu_info_list else \"NVIDIA GPU found, but info not listed\" # 返回 GPU 信息或提示信息\n",
    "        else:\n",
    "             # 尝试使用 lshw 获取其他 GPU 信息 (需要安装 lshw)\n",
    "            try:\n",
    "                result_lshw = subprocess.run(['lshw', '-C', 'display'], capture_output=True, text=True)\n",
    "                if result_lshw.returncode == 0: # 如果命令成功执行\n",
    "                     # 简单解析输出中的 product 名称和显存\n",
    "                    gpu_info_lines = []\n",
    "                    current_gpu = {}\n",
    "                    for line in result_lshw.stdout.splitlines():\n",
    "                        if 'product:' in line:\n",
    "                             if current_gpu:\n",
    "                                 gpu_info_lines.append(f\"{current_gpu.get('product', 'GPU')} ({current_gpu.get('memory', 'N/A')})\")\n",
    "                             current_gpu = {'product': line.split('product:')[1].strip()}\n",
    "                        elif 'size:' in line and 'memory' in line:\n",
    "                             current_gpu['memory'] = line.split('size:')[1].strip()\n",
    "\n",
    "                    if current_gpu: # 添加最后一个 GPU 的信息\n",
    "                        gpu_info_lines.append(f\"{current_gpu.get('product', 'GPU')} ({current_gpu.get('memory', 'N/A')})\")\n",
    "\n",
    "                    return \", \".join(gpu_info_lines) if gpu_info_lines else \"GPU found (via lshw), but info not parsed\" # 如果找到 GPU 但信息无法解析，设置提示信息\n",
    "                else:\n",
    "                    return \"No GPU found (checked nvidia-smi and lshw)\" # 如果两个命令都找不到 GPU，设置提示信息\n",
    "            except FileNotFoundError:\n",
    "                 return \"No GPU found (checked nvidia-smi, lshw not found)\" # 如果找不到 lshw 命令，设置提示信息\n",
    "    except FileNotFoundError:\n",
    "        return \"No GPU found (nvidia-smi not found)\" # 如果找不到 nvidia-smi 命令，设置提示信息\n",
    "\n",
    "\n",
    "# 获取 CUDA 版本的函数\n",
    "def get_cuda_version():\n",
    "    try:\n",
    "        # 尝试使用 nvcc --version 获取 CUDA 版本\n",
    "        result = subprocess.run(['nvcc', '--version'], capture_output=True, text=True)\n",
    "        if result.returncode == 0: # 如果命令成功执行\n",
    "            for line in result.stdout.splitlines():\n",
    "                if 'release' in line: # 查找包含 'release' 的行\n",
    "                    return line.split('release ')[1].split(',')[0] # 解析行，提取版本号\n",
    "        return \"CUDA not found or version not parsed\" # 如果找不到 CUDA 或版本无法解析，设置提示信息\n",
    "    except FileNotFoundError:\n",
    "        return \"CUDA not found\" # 如果找不到 nvcc 命令，设置提示信息\n",
    "\n",
    "# 获取 Python 版本的函数\n",
    "def get_python_version():\n",
    "    return platform.python_version() # 获取 Python 版本\n",
    "\n",
    "# 获取 Conda 版本的函数\n",
    "def get_conda_version():\n",
    "    try:\n",
    "        # 尝试使用 conda --version 获取 Conda 版本\n",
    "        result = subprocess.run(['conda', '--version'], capture_output=True, text=True)\n",
    "        if result.returncode == 0: # 如果命令成功执行\n",
    "            return result.stdout.strip() # 返回 Conda 版本\n",
    "        return \"Conda not found or version not parsed\" # 如果找不到 Conda 或版本无法解析，设置提示信息\n",
    "    except FileNotFoundError:\n",
    "        return \"Conda not found\" # 如果找不到 conda 命令，设置提示信息\n",
    "\n",
    "# 获取物理磁盘空间信息的函数\n",
    "def get_disk_space():\n",
    "    try:\n",
    "        total, used, free = shutil.disk_usage(\"/\") # 获取根目录的磁盘使用情况\n",
    "        total_gb = total / (1024**3) # 转换为 GB\n",
    "        used_gb = used / (1024**3) # 转换为 GB\n",
    "        free_gb = free / (1024**3) # 转换为 GB\n",
    "        return f\"Total: {total_gb:.2f} GB, Used: {used_gb:.2f} GB, Free: {free_gb:.2f} GB\" # 格式化输出\n",
    "    except Exception as e:\n",
    "        return f\"Could not retrieve disk info: {e}\" # 如果获取信息出错，设置错误信息\n",
    "\n",
    "# 获取环境信息\n",
    "os_name = platform.system() # 获取操作系统名称\n",
    "os_version = platform.release() # 获取操作系统版本\n",
    "if os_name == \"Linux\":\n",
    "    try:\n",
    "        # 在 Linux 上尝试获取发行版和版本\n",
    "        lsb_info = subprocess.run(['lsb_release', '-a'], capture_output=True, text=True)\n",
    "        if lsb_info.returncode == 0: # 如果命令成功执行\n",
    "            for line in lsb_info.stdout.splitlines():\n",
    "                if 'Description:' in line: # 查找包含 'Description:' 的行\n",
    "                    os_version = line.split('Description:')[1].strip() # 提取描述信息作为版本\n",
    "                    break # 找到后退出循环\n",
    "                elif 'Release:' in line: # 查找包含 'Release:' 的行\n",
    "                     os_version = line.split('Release:')[1].strip() # 提取版本号\n",
    "                     # 尝试获取 codename\n",
    "                     try:\n",
    "                         codename_info = subprocess.run(['lsb_release', '-c'], capture_output=True, text=True)\n",
    "                         if codename_info.returncode == 0:\n",
    "                             os_version += f\" ({codename_info.stdout.split(':')[1].strip()})\" # 将 codename 添加到版本信息中\n",
    "                     except:\n",
    "                         pass # 如果获取 codename 失败则忽略\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        pass # lsb_release 可能未安装，忽略错误\n",
    "\n",
    "full_os_info = f\"{os_name} {os_version}\" # 组合完整的操作系统信息\n",
    "cpu_info = get_cpu_info() # 调用函数获取 CPU 信息和核心数量\n",
    "memory_info = get_memory_info() # 调用函数获取内存信息\n",
    "gpu_info = get_gpu_info() # 调用函数获取 GPU 信息和显存\n",
    "cuda_version = get_cuda_version() # 调用函数获取 CUDA 版本\n",
    "python_version = get_python_version() # 调用函数获取 Python 版本\n",
    "conda_version = get_conda_version() # 调用函数获取 Conda 版本\n",
    "disk_info = get_disk_space() # 调用函数获取物理磁盘空间信息\n",
    "\n",
    "\n",
    "# 创建用于存储数据的字典\n",
    "env_data = {\n",
    "    \"项目\": [ # 项目名称列表\n",
    "        \"操作系统\",\n",
    "        \"CPU 信息\",\n",
    "        \"内存信息\",\n",
    "        \"GPU 信息\",\n",
    "        \"CUDA 信息\",\n",
    "        \"Python 版本\",\n",
    "        \"Conda 版本\",\n",
    "        \"物理磁盘空间\" # 添加物理磁盘空间\n",
    "    ],\n",
    "    \"信息\": [ # 对应的信息列表\n",
    "        full_os_info,\n",
    "        cpu_info,\n",
    "        memory_info,\n",
    "        gpu_info,\n",
    "        cuda_version,\n",
    "        python_version,\n",
    "        conda_version,\n",
    "        disk_info # 添加物理磁盘空间信息\n",
    "    ]\n",
    "}\n",
    "\n",
    "# 创建一个 pandas DataFrame\n",
    "df = pd.DataFrame(env_data)\n",
    "\n",
    "# 打印表格\n",
    "print(\"### 环境信息\") # 打印标题\n",
    "print(df.to_markdown(index=False)) # 将 DataFrame 转换为 Markdown 格式并打印，不包含索引\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/FlyAIBox/AIAgent101/blob/main/06-agent-evaluation/langfuse/01_04_integration_langgraph.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YlCI9KeX4Zn4"
   },
   "source": [
    "## 什么是 LangGraph？\n",
    "\n",
    "[LangGraph](https://langchain-ai.github.io/langgraph/) 是由 LangChain 团队开源的框架，用于基于大语言模型（LLM）构建复杂、有状态的多智能体应用。LangGraph 内置了持久化能力，可保存与恢复状态，从而支持错误恢复与包含“人机交互”（Human-in-the-loop, HITL）的工作流。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3o8L1qPcaZeC"
   },
   "source": [
    "## 本实践手册的目标\n",
    "\n",
    "本手册演示如何借助 [Langfuse](https://langfuse.com/docs)，通过其与 [LangChain 的集成](https://langfuse.com/integrations/frameworks/langchain)，对你的 LangGraph 应用进行调试、分析与迭代优化。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gPTaMtxH4eHV"
   },
   "source": [
    "**完成本手册后，你将能够：**\n",
    "\n",
    "- 自动通过 Langfuse 集成对 LangGraph 应用进行追踪（tracing）\n",
    "- 监控复杂的多智能体（multi-agent）方案\n",
    "- 添加评分（例如用户反馈）\n",
    "- 使用 Langfuse 管理 LangGraph 中使用的提示词（prompt）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0sSIS88y9Ewm"
   },
   "source": [
    "## 初始化 Langfuse\n",
    "\n",
    "在 Langfuse 控制台项目设置页获取你的 [API 密钥](https://langfuse.com/faq/all/where-are-langfuse-api-keys)，并将其加入到运行环境变量中以初始化 Langfuse 客户端。\n",
    "\n",
    "<!-- CALLOUT_START type: \"info\" emoji: \"⚠️\" -->\n",
    "_**注意：** 本笔记使用 Langfuse Python SDK v3。_\n",
    "<!-- CALLOUT_END -->\n",
    "\n",
    "<!-- CALLOUT_START type: \"info\" emoji: \"ℹ️\" -->\n",
    "_**注意：** 需要至少 Python 3.11（参见 [GitHub Issue](https://github.com/langfuse/langfuse/issues/1926)）。_\n",
    "<!-- CALLOUT_END -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C85BK1vJ5yD3",
    "outputId": "806323f8-3c9c-4bd1-d558-e474a2078baf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langfuse==3.3.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (3.3.0)\n",
      "Requirement already satisfied: langchain==0.3.27 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (0.3.27)\n",
      "Requirement already satisfied: langchain-openai==0.3.31 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (0.3.31)\n",
      "Requirement already satisfied: langchain_community==0.3.27 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (0.3.27)\n",
      "Requirement already satisfied: langgraph==0.6.7 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (0.6.7)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langfuse==3.3.0) (2.2.1)\n",
      "Requirement already satisfied: httpx<1.0,>=0.15.4 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langfuse==3.3.0) (0.28.1)\n",
      "Requirement already satisfied: opentelemetry-api<2.0.0,>=1.33.1 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langfuse==3.3.0) (1.38.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langfuse==3.3.0) (1.38.0)\n",
      "Requirement already satisfied: opentelemetry-sdk<2.0.0,>=1.33.1 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langfuse==3.3.0) (1.38.0)\n",
      "Requirement already satisfied: packaging<26.0,>=23.2 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langfuse==3.3.0) (25.0)\n",
      "Requirement already satisfied: pydantic<3.0,>=1.10.7 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langfuse==3.3.0) (2.11.9)\n",
      "Requirement already satisfied: requests<3,>=2 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langfuse==3.3.0) (2.32.5)\n",
      "Requirement already satisfied: wrapt<2.0,>=1.14 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langfuse==3.3.0) (1.17.3)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langchain==0.3.27) (0.3.75)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langchain==0.3.27) (0.3.9)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langchain==0.3.27) (0.4.34)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langchain==0.3.27) (2.0.44)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langchain==0.3.27) (6.0.3)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langchain==0.3.27) (4.0.3)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.99.9 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langchain-openai==0.3.31) (1.107.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langchain-openai==0.3.31) (0.11.0)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langchain_community==0.3.27) (3.13.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langchain_community==0.3.27) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langchain_community==0.3.27) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langchain_community==0.3.27) (2.11.0)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langchain_community==0.3.27) (0.4.2)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langchain_community==0.3.27) (2.2.6)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.1.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langgraph==0.6.7) (2.1.2)\n",
      "Requirement already satisfied: langgraph-prebuilt<0.7.0,>=0.6.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langgraph==0.6.7) (0.6.4)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langgraph==0.6.7) (0.2.6)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langgraph==0.6.7) (3.6.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.27) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.27) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.27) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.27) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.27) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.27) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community==0.3.27) (1.22.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community==0.3.27) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community==0.3.27) (0.9.0)\n",
      "Requirement already satisfied: anyio in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from httpx<1.0,>=0.15.4->langfuse==3.3.0) (4.11.0)\n",
      "Requirement already satisfied: certifi in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from httpx<1.0,>=0.15.4->langfuse==3.3.0) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from httpx<1.0,>=0.15.4->langfuse==3.3.0) (1.0.9)\n",
      "Requirement already satisfied: idna in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from httpx<1.0,>=0.15.4->langfuse==3.3.0) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from httpcore==1.*->httpx<1.0,>=0.15.4->langfuse==3.3.0) (0.16.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain==0.3.27) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain==0.3.27) (4.14.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain==0.3.27) (3.0.0)\n",
      "Requirement already satisfied: ormsgpack>=1.10.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph==0.6.7) (1.11.0)\n",
      "Requirement already satisfied: orjson>=3.10.1 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph==0.6.7) (3.11.3)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from openai<2.0.0,>=1.99.9->langchain-openai==0.3.31) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from openai<2.0.0,>=1.99.9->langchain-openai==0.3.31) (0.11.0)\n",
      "Requirement already satisfied: sniffio in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from openai<2.0.0,>=1.99.9->langchain-openai==0.3.31) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from openai<2.0.0,>=1.99.9->langchain-openai==0.3.31) (4.67.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from anyio->httpx<1.0,>=0.15.4->langfuse==3.3.0) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from opentelemetry-api<2.0.0,>=1.33.1->langfuse==3.3.0) (8.7.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api<2.0.0,>=1.33.1->langfuse==3.3.0) (3.23.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse==3.3.0) (1.70.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.38.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse==3.3.0) (1.38.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.38.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse==3.3.0) (1.38.0)\n",
      "Requirement already satisfied: protobuf<7.0,>=5.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from opentelemetry-proto==1.38.0->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.33.1->langfuse==3.3.0) (5.29.5)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.59b0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from opentelemetry-sdk<2.0.0,>=1.33.1->langfuse==3.3.0) (0.59b0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from pydantic<3.0,>=1.10.7->langfuse==3.3.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from pydantic<3.0,>=1.10.7->langfuse==3.3.0) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from pydantic<3.0,>=1.10.7->langfuse==3.3.0) (0.4.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community==0.3.27) (1.1.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from requests<3,>=2->langfuse==3.3.0) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from requests<3,>=2->langfuse==3.3.0) (2.5.0)\n",
      "Requirement already satisfied: greenlet>=1 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain==0.3.27) (3.2.4)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from tiktoken<1,>=0.7->langchain-openai==0.3.31) (2025.9.18)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community==0.3.27) (1.1.0)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langsmith>=0.1.17->langchain==0.3.27) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /root/miniconda3/envs/agent101/lib/python3.10/site-packages (from langsmith>=0.1.17->langchain==0.3.27) (0.25.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langfuse==3.3.0 langchain==0.3.27 langchain-openai==0.3.31 langchain_community==0.3.27 langgraph==0.6.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sUbRmJ-Kh0rq"
   },
   "source": [
    "在 Langfuse 控制台的项目设置页获取 API Key，初始化 Langfuse 客户端，并将其设置到环境变量中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vku6l5CLhwdC",
    "outputId": "604ff78f-65af-4fc1-8d81-a1a998a4c345"
   },
   "outputs": [],
   "source": [
    "# 🔐 环境变量配置 - 安全存储敏感信息\n",
    "# 环境变量是存储API密钥等敏感信息的最佳实践\n",
    "# 避免在代码中硬编码密钥，防止泄露\n",
    "\n",
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    \"\"\"\n",
    "    安全地设置环境变量\n",
    "    如果环境变量不存在，会提示用户输入\n",
    "    使用getpass模块隐藏输入内容，防止密码泄露\n",
    "    \"\"\"\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "# 🤖 OpenAI API 配置\n",
    "# OpenAI API密钥：从 https://platform.openai.com/api-keys 获取\n",
    "# 这是调用GPT模型必需的认证信息\n",
    "_set_env(\"OPENAI_API_KEY\")\n",
    "\n",
    "# API代理地址：如果你使用第三方代理服务（如国内代理）\n",
    "# 示例：https://api.apiyi.com/v1\n",
    "# 如果直接使用OpenAI官方API，可以留空\n",
    "_set_env(\"OPENAI_BASE_URL\")\n",
    "\n",
    "# 🌐 Langfuse 配置\n",
    "# Langfuse是一个可观测性平台，需要注册账户获取密钥\n",
    "# 注册地址：https://cloud.langfuse.com\n",
    "\n",
    "# 公开密钥：用于标识你的项目\n",
    "_set_env(\"LANGFUSE_PUBLIC_KEY\")\n",
    "\n",
    "# 秘密密钥：用于认证，请妥善保管\n",
    "_set_env(\"LANGFUSE_SECRET_KEY\")\n",
    "\n",
    "# 服务器地址：选择离你最近的区域\n",
    "# 🇪🇺 欧盟区域(推荐) https://cloud.langfuse.com\n",
    "# 🇺🇸 美国区域（不推荐） https://us.cloud.langfuse.com\n",
    "_set_env(\"LANGFUSE_HOST\")\n",
    "\n",
    "# 💡 初学者提示：\n",
    "# 1. 环境变量存储在操作系统中，重启后需要重新设置\n",
    "# 2. 生产环境中建议使用.env文件或云服务配置\n",
    "# 3. 永远不要在代码中硬编码API密钥！\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Agy0r3Byg-Aw"
   },
   "source": [
    "在环境变量设置完成后，我们即可初始化 Langfuse 客户端。`get_client()` 会使用环境变量中提供的凭据来初始化 Langfuse 客户端。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3LVLs2A8g-Ax",
    "outputId": "44ce9dd7-1ada-4a05-bb0b-ca3281833dde"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Langfuse 客户端已通过身份验证，准备就绪！\n",
      "🔧 现在可以开始使用追踪功能了\n"
     ]
    }
   ],
   "source": [
    "from langfuse import get_client\n",
    "\n",
    "# 🚀 初始化 Langfuse 客户端\n",
    "# get_client() 会自动读取环境变量中的配置信息\n",
    "langfuse = get_client()\n",
    "\n",
    "# 🔍 验证客户端连接状态\n",
    "# 这个步骤非常重要，确保后续的追踪功能能够正常工作\n",
    "if langfuse.auth_check():\n",
    "    print(\"✅ Langfuse 客户端已通过身份验证，准备就绪！\")\n",
    "    print(\"🔧 现在可以开始使用追踪功能了\")\n",
    "else:\n",
    "    print(\"❌ 身份验证失败！\")\n",
    "    print(\"🔍 请检查以下配置项：\")\n",
    "    print(\"   - LANGFUSE_PUBLIC_KEY 是否正确\")\n",
    "    print(\"   - LANGFUSE_SECRET_KEY 是否正确\")\n",
    "    print(\"   - LANGFUSE_HOST 是否可访问\")\n",
    "    print(\"   - 网络连接是否正常\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kqYMmi6n9Nh1"
   },
   "source": [
    "## 示例 1：使用 LangGraph 构建简单聊天应用\n",
    "\n",
    "**本节将完成：**\n",
    "\n",
    "- 在 LangGraph 中构建一个可回答常见问题的客服聊天机器人\n",
    "- 使用 Langfuse 对机器人的输入与输出进行追踪（tracing）\n",
    "\n",
    "我们先从一个基础机器人入手，随后在下一节扩展为更高级的多智能体（multi-agent）设置，并在过程中介绍关键的 LangGraph 概念。\n",
    "\n",
    "### 创建智能体（Agent）\n",
    "\n",
    "首先创建一个 `StateGraph`。`StateGraph` 定义了聊天机器人的状态机结构。我们会添加节点来表示 LLM 以及机器人可调用的函数，并通过边（edge）定义机器人在这些函数之间的状态流转。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "aGIxgPww6VX6"
   },
   "outputs": [],
   "source": [
    "# 🔧 导入 LangGraph 构建智能体所需的核心模块\n",
    "from typing import Annotated\n",
    "from langchain_openai import ChatOpenAI  # OpenAI 聊天模型\n",
    "from langchain_core.messages import HumanMessage  # 人类消息类型\n",
    "from typing_extensions import TypedDict  # 类型化字典\n",
    "from langgraph.graph import StateGraph  # LangGraph 状态图\n",
    "from langgraph.graph.message import add_messages  # 消息添加函数\n",
    "\n",
    "# 📋 定义智能体的状态结构\n",
    "# State 是一个类型化字典，定义了智能体在执行过程中需要维护的状态信息\n",
    "class State(TypedDict):\n",
    "    # 💬 消息列表：存储对话历史\n",
    "    # Annotated[list, add_messages] 的含义：\n",
    "    # - list: 消息的数据类型是列表\n",
    "    # - add_messages: 指定状态更新策略，新消息会追加到列表末尾而不是覆盖整个列表\n",
    "    # 这种设计确保了对话历史的完整保存\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# 🏗️ 创建状态图构建器\n",
    "# StateGraph 是 LangGraph 的核心组件，用于定义智能体的工作流程\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "# 🤖 初始化语言模型\n",
    "# 选择 GPT-4o 模型，temperature=0.2 确保输出相对稳定但仍有一定创造性\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.2)\n",
    "\n",
    "# 🔄 定义聊天机器人节点函数\n",
    "# 这是 LangGraph 节点函数的基本模式：接收当前状态，返回更新后的状态\n",
    "def chatbot(state: State):\n",
    "    \"\"\"\n",
    "    聊天机器人节点的核心逻辑\n",
    "\n",
    "    参数:\n",
    "        state (State): 当前的智能体状态，包含消息历史\n",
    "\n",
    "    返回:\n",
    "        dict: 包含新生成消息的状态更新\n",
    "\n",
    "    工作流程:\n",
    "    1. 获取当前的消息历史\n",
    "    2. 将消息历史发送给语言模型\n",
    "    3. 接收模型生成的回复\n",
    "    4. 将回复包装成状态更新返回\n",
    "    \"\"\"\n",
    "    # 调用语言模型处理当前对话历史，生成回复\n",
    "    response = llm.invoke(state[\"messages\"])\n",
    "\n",
    "    # 返回状态更新：将模型的回复添加到消息列表中\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# 🔗 向图中添加\"chatbot\"节点\n",
    "# 节点代表工作单元，通常是普通的 Python 函数\n",
    "# 每个节点负责特定的处理逻辑，如调用 LLM、处理工具、数据转换等\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "# 🚀 设置图的入口点\n",
    "# 告诉图每次运行时从哪个节点开始执行\n",
    "# 在这个简单示例中，我们直接从 chatbot 节点开始\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "\n",
    "# 🏁 设置图的结束点\n",
    "# 指示图\"当这个节点运行完成后，可以退出执行\"\n",
    "# 对于简单的单轮对话，chatbot 节点执行完就可以结束\n",
    "graph_builder.set_finish_point(\"chatbot\")\n",
    "\n",
    "# ⚙️ 编译图形为可执行对象\n",
    "# compile() 方法将图构建器转换为 CompiledGraph\n",
    "# CompiledGraph 是可以实际运行的图形对象，支持 invoke、stream 等方法\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "# 💡 理解 LangGraph 的核心概念：\n",
    "# 🏗️ StateGraph: 定义智能体的状态和工作流程\n",
    "# 🔄 Node: 执行具体任务的函数，如调用 LLM、使用工具等\n",
    "# 🔗 Edge: 连接节点，定义执行顺序和条件跳转\n",
    "# 📊 State: 智能体运行过程中维护的数据结构\n",
    "# ⚙️ CompiledGraph: 编译后的可执行图形对象"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IW2SJcRgh7Xo"
   },
   "source": [
    "### 在调用时添加 Langfuse 回调\n",
    "\n",
    "现在，为了追踪应用执行过程，我们将添加 [面向 LangChain 的 Langfuse 回调处理器](https://langfuse.com/integrations/frameworks/langchain)：`config={\"callbacks\": [langfuse_handler]}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8PxEc455-KYM",
    "outputId": "f7564588-e640-49a9-d36c-bbd3955eef94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 智能体开始运行，正在处理问题……\n",
      "❓ 用户提问：什么是 Langfuse？\n",
      "📋 执行过程:\n",
      "📤 节点执行结果：{'chatbot': {'messages': [AIMessage(content='Langfuse 是一种专门用于监控和调试生成式 AI 应用程序的开源工具。它旨在帮助开发者和团队更高效地追踪、分析和优化基于大语言模型（LLM）或其他生成式 AI 技术的应用程序。Langfuse 提供了全面的可视化和数据分析功能，使开发者能够深入了解应用程序的运行状况、性能瓶颈以及用户交互的具体细节。\\n\\n### Langfuse 的主要功能\\n1. **请求跟踪和监控**：\\n   Langfuse 可以记录和跟踪生成式 AI 应用程序的每个请求，包括输入、输出以及相关的元数据。这使开发者能够清楚地了解每次调用的具体情况。\\n\\n2. **链路可视化**：\\n   Langfuse 支持对复杂的调用链进行可视化展示。例如，在一个多步骤的 AI 应用中，Langfuse 可以显示每个步骤的输入、输出和处理时间，帮助开发者识别问题所在。\\n\\n3. **性能分析**：\\n   Langfuse 提供了详细的性能指标，包括响应时间、错误率等。开发者可以通过这些数据优化模型调用和应用程序的整体性能。\\n\\n4. **调试和错误排查**：\\n   Langfuse 能够记录错误信息和异常情况，帮助开发者快速定位问题并进行修复。\\n\\n5. **用户交互分析**：\\n   Langfuse 可以记录用户与生成式 AI 应用的交互数据，帮助开发者了解用户行为并优化用户体验。\\n\\n6. **集成支持**：\\n   Langfuse 可以与多种生成式 AI框架和工具集成，例如 OpenAI 的 API、LangChain 等，使其能够无缝融入现有的开发流程。\\n\\n7. **数据存储和查询**：\\n   Langfuse 提供了强大的数据存储和查询功能，开发者可以轻松检索历史数据以进行深入分析。\\n\\n### 典型应用场景\\n1. **生成式 AI 应用的开发和调试**：\\n   在开发基于大语言模型的应用时，Langfuse 可以帮助开发者实时监控模型的输入输出，快速发现和解决问题。\\n\\n2. **复杂对话系统的优化**：\\n   对于多轮对话系统，Langfuse 能够记录每轮对话的详细信息，帮助开发者分析对话逻辑并优化用户体验。\\n\\n3. **性能监控和优化**：\\n   Langfuse 可以帮助团队监控生成式 AI 应用的性能指标，识别瓶颈并优化模型调用效率。\\n\\n4. **用户行为分析**：\\n   Langfuse 能够记录用户与 AI 应用的交互数据，帮助产品团队了解用户需求并改进产品设计。\\n\\n5. **错误排查和问题解决**：\\n   在生成式 AI 应用中，错误和异常可能会影响用户体验。Langfuse 提供详细的错误日志，帮助开发者快速定位问题。\\n\\n6. **团队协作和数据共享**：\\n   Langfuse 的可视化功能和数据存储能力使团队成员能够轻松共享信息，从而提高协作效率。\\n\\n### 总结\\nLangfuse 是一个强大的工具，专注于生成式 AI 应用的监控、调试和优化。它的主要功能包括请求跟踪、性能分析、错误排查和用户行为分析，适用于各种生成式 AI 应用场景。通过使用 Langfuse，开发者可以显著提升应用的性能和用户体验，同时加速开发和迭代过程。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 785, 'prompt_tokens': 26, 'total_tokens': 811, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_b54fe76834', 'id': 'chatcmpl-CU2S0K4zeVWoBjw5wopU0mVKVMKf1', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--f26a6e48-f512-4a3a-bf05-31498a9d10d1-0', usage_metadata={'input_tokens': 26, 'output_tokens': 785, 'total_tokens': 811, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
      "✅ 智能体执行完成！\n",
      "🔍 请前往 Langfuse 控制台查看完整的追踪记录。\n"
     ]
    }
   ],
   "source": [
    "from langfuse.langchain import CallbackHandler\n",
    "\n",
    "# 🛎️ 初始化 Langfuse 回调处理器\n",
    "# 该处理器会自动捕获 LangChain/LangGraph 的执行细节，用于：\n",
    "# - 🕒 记录每个节点的耗时与延迟\n",
    "# - 📝 保存输入、输出及中间状态\n",
    "# - 💰 统计 token 消耗和 API 调用成本\n",
    "# - 🐞 收集异常信息，便于排错\n",
    "# - 📈 在 Langfuse 中生成可视化调用链\n",
    "langfuse_handler = CallbackHandler()\n",
    "\n",
    "# 🚀 运行智能体并启用 Langfuse 追踪\n",
    "print(\"🤖 智能体开始运行，正在处理问题……\")\n",
    "print(\"❓ 用户提问：什么是 Langfuse？\")\n",
    "print(\"📋 执行过程:\")\n",
    "\n",
    "# 使用 stream 方法可以实时查看智能体的执行步骤：\n",
    "# - graph.stream(...) 会在每个节点完成后产生一次增量输出（生成器）\n",
    "# - config={\"callbacks\": [langfuse_handler]} 确保每一步都写入 Langfuse\n",
    "# - 适合本地调试/教学演示，清晰观察逐步推理过程与耗时\n",
    "for step_result in graph.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"什么是 Langfuse？请详细介绍其主要功能和典型应用场景。\")]},\n",
    "    config={\"callbacks\": [langfuse_handler]}\n",
    "):\n",
    "    # 提示：step_result 的结构类似 {\"chatbot\": {\"messages\": [...]}}，\n",
    "    # 你可以在此对中间结果执行断言/日志上报，构建更稳健的测试与可观测性\n",
    "    print(f\"📤 节点执行结果：{step_result}\")\n",
    "\n",
    "# 结束提示：在 Langfuse 控制台可查看完整调用链、耗时、token 成本等\n",
    "print(\"✅ 智能体执行完成！\")\n",
    "print(\"🔍 请前往 Langfuse 控制台查看完整的追踪记录。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fdf3ZRnWGZ0N"
   },
   "source": [
    "### 在 Langfuse 中查看追踪结果\n",
    "\n",
    "示例追踪：https://cloud.langfuse.com/project/cmequpe0j00euad07w6wrvkzg/traces?peek=cbc8503a9a111fc5eadb5e914be3fa7a&timestamp=2025-09-22T03%3A48%3A16.647Z&observation=47245ec86916a5d1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "17Aq7u6_LBR6"
   },
   "source": [
    "![在 Langfuse 中查看聊天应用的追踪](https://cdn.jsdelivr.net/gh/Fly0905/note-picture@main/imag/202509221150147.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v3yyVtGKhMPU"
   },
   "source": [
    "### 可视化聊天应用\n",
    "\n",
    "你可以使用 `get_graph` 方法配合相应的 “draw” 方法对图进行可视化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 251
    },
    "id": "MKkM6mw47kIy",
    "outputId": "66a35e42-b0bd-4163-eeaa-9946473ff849"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "# 可视化当前图（graph）：有助于直观理解节点与执行顺序\n",
    "# 若图较大，可改用 draw_mermaid_file() 输出到文件或 draw_mermaid_svg() 生成矢量图\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yY0HW5xISntw"
   },
   "source": [
    "```mermaid\n",
    "graph TD;\n",
    "\t__start__([__start__]):::first\n",
    "\tchatbot(chatbot)\n",
    "\t__end__([__end__]):::last\n",
    "\t__start__ --> chatbot;\n",
    "\tchatbot --> __end__;\n",
    "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
    "\tclassDef first fill-opacity:0\n",
    "\tclassDef last fill:#bfb6fc\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9F4Tt_E4g-A0"
   },
   "source": [
    "### 在 LangGraph Server 中使用 Langfuse\n",
    "\n",
    "#### 🖥️ LangGraph Server 简介\n",
    "\n",
    "[LangGraph Server](https://langchain-ai.github.io/langgraph/concepts/langgraph_server/) 是 LangGraph 提供的服务器部署方案，用于将本地构建的图工作流发布为可扩展的在线服务，具备以下能力：\n",
    "\n",
    "- 🌐 **HTTP API 接口**：将 LangGraph 智能体封装为 REST API，便于与业务系统集成\n",
    "- 🚀 **生产级运行**：支持高并发、负载均衡与容器化交付\n",
    "- 🔧 **运维友好**：自动处理请求路由、状态恢复与错误重试\n",
    "- 📊 **监控集成**：兼容主流监控与追踪体系，便于观测运行状况\n",
    "- 🔒 **安全管控**：内置身份认证与授权机制，满足企业安全需求\n",
    "\n",
    "#### 💡 为什么要在 Server 环境接入 Langfuse？\n",
    "\n",
    "- 🏭 **生产可观测性**：实时查看线上请求的调用链与状态\n",
    "- 🐛 **远程调试**：无需复现场景即可还原问题细节\n",
    "- 📈 **性能洞察**：量化每个节点的耗时与成本\n",
    "- 💰 **费用治理**：准确统计第三方 API 的调用量与费用\n",
    "- 👥 **团队协作**：共享追踪记录，支持跨职能协同排查\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DTW_X4rFg-A0"
   },
   "source": [
    "#### 🔧 配置方法说明\n",
    "\n",
    "使用 LangGraph Server 时，智能体图的调用由服务器自动处理，用户无法在每次请求时手动指定回调处理器。\n",
    "\n",
    "**关键差异：**\n",
    "- 🏠 **本地开发**：可以在每次调用时添加 `config={\"callbacks\": [langfuse_handler]}`\n",
    "- 🖥️ **服务器部署**：需要在图编译时预先配置回调处理器\n",
    "\n",
    "**解决方案：**\n",
    "在声明和编译图时就添加 Langfuse 回调，这样服务器上的所有请求都会自动启用追踪功能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "J5UKXzbUg-A0"
   },
   "outputs": [],
   "source": [
    "# 🔧 导入服务器部署所需的模块\n",
    "# 初学者须知：本节示例面向“部署到 LangGraph Server（或任何持久化服务端）”场景，\n",
    "# 重点在于将追踪回调“静态注入”到图对象中，确保线上每个请求都被自动追踪。\n",
    "from typing import Annotated\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langfuse.langchain import CallbackHandler\n",
    "\n",
    "# 📋 定义与前文一致的智能体状态结构\n",
    "# - State 是图的“共享黑板”，所有节点通过它传递数据\n",
    "# - messages 字段使用 add_messages 策略：新消息在运行中会被“追加”，而不是覆盖\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# 🏗️ 构建图形结构\n",
    "# 小贴士：将最小可用功能先装成一张图，有利于后续扩展、观测与运维\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "# 🤖 初始化语言模型\n",
    "# 说明：temperature 控制随机性。生产环境若追求稳定复现，可适当降低至 0~0.2。\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.2)\n",
    "\n",
    "# 🔄 定义聊天机器人节点\n",
    "# 约定：节点函数签名 (state) -> partial_state\n",
    "# 返回值是“增量状态”（partial update），LangGraph 会据此合并到全局状态\n",
    "\n",
    "def chatbot(state: State):\n",
    "    \"\"\"处理用户消息并生成回复。\"\"\"\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"]) ]}\n",
    "\n",
    "# 🔗 组装图形结构\n",
    "# entry_point / finish_point 分别指定起点与终点，便于 Server 判定一次执行的生命周期\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "graph_builder.set_finish_point(\"chatbot\")\n",
    "\n",
    "# 🔄 初始化 Langfuse 回调处理器（服务器模式）\n",
    "# 注意：在 Server 场景无法逐次在调用处传入 callbacks，需在图对象层面预配置\n",
    "langfuse_handler = CallbackHandler()\n",
    "\n",
    "# ⚙️ 编译图形并预配置回调处理器\n",
    "# 🎯 核心方法：with_config()\n",
    "# - compile()：编译图形，生成可执行的 CompiledGraph\n",
    "# - with_config()：为编译后的图形设置默认配置（如回调处理器）\n",
    "#\n",
    "# 💡 工作流程：\n",
    "# 1. 编译图形得到 CompiledGraph 对象\n",
    "# 2. 调用 with_config() 注入 Langfuse 回调\n",
    "# 3. 得到一个“默认启用追踪”的图对象，Server 直接引用即可\n",
    "#\n",
    "# ✅ 常见误区：\n",
    "# - 在 API Handler 内再临时创建 CallbackHandler → 会导致追踪分散、不易聚合\n",
    "# - 只在本地调试时传 callbacks，忘记在 Server 端注入 → 线上无追踪\n",
    "#\n",
    "# 🚀 优势：\n",
    "# - 无需在每次请求时手动添加回调配置\n",
    "# - 所有 API 请求都会自动写入 Langfuse 追踪\n",
    "# - 简化生产环境的部署与运维\n",
    "graph = graph_builder.compile().with_config({\"callbacks\": [langfuse_handler]})\n",
    "\n",
    "# 💡 部署提示：\n",
    "# - 在 LangGraph Server 中直接引用此 graph，即可立即获得完整的追踪数据\n",
    "# - 如需区分环境（dev/staging/prod），可在环境变量中切换 Langfuse Host/Key；\n",
    "#   但“图对象注入回调”的做法保持一致。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PvKULkc6g-BE"
   },
   "source": [
    "## 多个 LangGraph 智能体的协同\n",
    "\n",
    "在某些架构中，一个 LangGraph 智能体会调用一个或多个其他 LangGraph 智能体。若想让整套执行链在 Langfuse 中聚合为同一条追踪，可显式传入自定义的 `trace_id`。\n",
    "\n",
    "首先生成一个共享的 `trace_id`，供主智能体与子智能体共用，以便在 Langfuse 中合并为同一条记录。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "TS8hQBHVg-BE"
   },
   "outputs": [],
   "source": [
    "from langfuse import get_client, Langfuse\n",
    "from langfuse.langchain import CallbackHandler\n",
    "\n",
    "# ✅ 初学者要点：\n",
    "# - get_client() 会自动读取环境变量（LANGFUSE_PUBLIC_KEY/SECRET_KEY/HOST）进行认证\n",
    "# - Langfuse.create_trace_id() 生成可跨服务复用的 trace_id，用于将多段执行“串成一条”\n",
    "langfuse = get_client()\n",
    "\n",
    "# 🔐 生成一个稳定的 trace_id（也可由上游网关/业务系统传入，实现全链路同一 Trace）\n",
    "predefined_trace_id = Langfuse.create_trace_id()\n",
    "\n",
    "# 📡 初始化 Langfuse 回调处理器，用于采集 LangChain/LangGraph 的执行数据\n",
    "# 小贴士：该 handler 可复用，避免在每个请求内重复创建，减少开销\n",
    "langfuse_handler = CallbackHandler()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "73necyiUg-BE"
   },
   "source": [
    "接下来，构建子智能体的逻辑。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "LWS82VWsg-BE"
   },
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "# 子智能体（Sub Agent）的最小实现：仅负责根据 messages 生成一次回复\n",
    "# 这样可把“研究/检索”等专项逻辑与主流程解耦，便于复用与独立观测\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "# 说明：与主智能体可使用相同或不同模型；按需求选择\n",
    "llm = ChatOpenAI(model = \"gpt-4o\", temperature = 0.2)\n",
    "\n",
    "def chatbot(state: State):\n",
    "    # LangGraph 约定：返回增量状态（只包含需要更新的键）\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "\n",
    "# 仅单节点的直通图，适合封装为工具被主流程调用\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "graph_builder.set_finish_point(\"chatbot\")\n",
    "sub_agent = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oIcpIMEPg-BF"
   },
   "source": [
    "随后，将该子智能体封装成工具，供主流程调用并复用。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "R0KC8Gvzg-BF"
   },
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def langgraph_research(question):\n",
    "  \"\"\"Conducts research for various topics.\"\"\"\n",
    "\n",
    "  # 关键思路：\n",
    "  # - 使用 start_as_current_span 创建一个子跨度（span），并注入共享 trace_id，\n",
    "  #   确保该工具内的执行与主流程聚合到同一条追踪\n",
    "  with langfuse.start_as_current_span(\n",
    "      name=\"🤖-sub-research-agent\",\n",
    "      trace_context={\"trace_id\": predefined_trace_id}\n",
    "  ) as span:\n",
    "      # 在进入子智能体前，将用户问题写入 trace，便于还原现场\n",
    "      span.update_trace(input=question)\n",
    "\n",
    "      # 调用子智能体；通过 callbacks 将 LangChain 级别的细节采集到 Langfuse\n",
    "      response = sub_agent.invoke(\n",
    "          {\"messages\": [HumanMessage(content = question)]},\n",
    "          config={\"callbacks\": [langfuse_handler]}\n",
    "      )\n",
    "\n",
    "      # 返回结构是增量状态；此处取模型输出的 AI 消息作为工具答案\n",
    "      # 注意：索引 1 对应追加后的第二条消息（0 为 Human，1 为 AI）\n",
    "      span.update_trace(output= response[\"messages\"][1].content)\n",
    "\n",
    "  return response[\"messages\"][1].content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0PpMQXiEg-BF"
   },
   "source": [
    "最后，创建第二个 LangGraph 智能体，通过前面新增的 `langgraph_research` 工具完成协作。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "lhNPp4pmg-BF"
   },
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 主智能体：采用内置 ReAct 模式（推理-行动-反思），可自动选择工具\n",
    "llm = ChatOpenAI(model = \"gpt-4o\", temperature = 0.2)\n",
    "\n",
    "# 将子智能体封装的工具注入，主智能体即可在需要时调用\n",
    "main_agent = create_react_agent(\n",
    "    model=llm,\n",
    "    tools=[langgraph_research]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jyeGvSf3g-BF",
    "outputId": "14edd5b7-f48c-48e2-9187-6aee8ad6b582"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trace ID: 6b465860f8ba6a2504e5046d132369b4\n"
     ]
    }
   ],
   "source": [
    "user_question = \"什么是 Langfuse？\"\n",
    "\n",
    "# 🧭 使用预生成的 trace_id（通过 trace_context 注入）\n",
    "# 作用：让主/子智能体在 Langfuse 界面中聚合到同一条调用链上\n",
    "with langfuse.start_as_current_span(\n",
    "    name=\"🤖-main-agent\",\n",
    "    trace_context={\"trace_id\": predefined_trace_id}\n",
    ") as span:\n",
    "    # 记录入口输入，方便运维人员复盘\n",
    "    span.update_trace(input=user_question)\n",
    "\n",
    "    # 此处的 LangChain 执行都会归属于同一条追踪\n",
    "    response = main_agent.invoke(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": user_question}]},\n",
    "        config={\"callbacks\": [langfuse_handler]}\n",
    "    )\n",
    "\n",
    "    # 记录最终输出，可配合评分（Score）进行质量分析\n",
    "    span.update_trace(output=response[\"messages\"][1].content)\n",
    "\n",
    "print(f\"Trace ID: {predefined_trace_id}\")  # 可在后续评分或排查时使用\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "id": "alDFf_8RVG7X",
    "outputId": "823add00-dd87-4d46-a47e-9bbd8e4449ad"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## 可以使用 get_graph 方法配合相应的 “draw” 方法对图进行可视化。\n",
    "# 初学者提示：可视化有助于理解 ReAct 智能体内部的节点与边，\n",
    "# 快速定位执行瓶颈与错误发生位置。\n",
    "from IPython.display import Image, display\n",
    "display(Image(main_agent.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qzPZIqUWg-BF"
   },
   "source": [
    "### 在 Langfuse 中查看多智能体追踪\n",
    "\n",
    "![多智能体追踪示例](https://cdn.jsdelivr.net/gh/Fly0905/note-picture@main/imag/202509231446631.png)\n",
    "\n",
    "示例追踪链接：https://cloud.langfuse.com/project/cmequpe0j00euad07w6wrvkzg/traces?peek=a7d9c0badaccd67fccf2045c68fb01ec&timestamp=2025-09-23T06%3A37%3A08.963Z\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uybP4h8wGvWw"
   },
   "source": [
    "## 为追踪添加评分\n",
    "\n",
    "[评分（Score）](https://langfuse.com/docs/scores/overview) 用于评价单个观测（observation）或整条追踪（trace），可帮助你在运行时执行自定义质量检查，或配合人工审核流程。\n",
    "\n",
    "下面的示例演示如何：\n",
    "\n",
    "- 为某个 span 记录一个数值型评分（如 `relevance`）\n",
    "- 为整条追踪记录一个分类型评分（如 `feedback`）\n",
    "\n",
    "这有助于系统化地评估与改进应用质量。\n",
    "\n",
    "**→ 想深入了解？请参阅 [Langfuse 自定义评分指南](https://langfuse.com/docs/scores/custom)。**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "pgAqYnQuGwCL"
   },
   "outputs": [],
   "source": [
    "from langfuse import get_client\n",
    "\n",
    "# 评分（Score）适用场景：\n",
    "# - 在线反馈：例如“用户是否满意/是否有帮助”等\n",
    "# - 质量度量：如准确性/相关性/安全性等离线指标\n",
    "# - A/B 实验：以 trace 为单位聚合对比\n",
    "langfuse = get_client()\n",
    "\n",
    "# 方案一：使用上下文管理器返回的 span 对象进行评分（推荐，最直观）\n",
    "with langfuse.start_as_current_span(name=\"🤖-sub-research-agent\") as span:\n",
    "    # ... 此处执行 LangGraph 逻辑 ...\n",
    "\n",
    "    # 直接通过 span.score_trace 记录评分\n",
    "    # name：评分项名称；value：数值；data_type：NUMERIC/TEXT/CATEGORICAL\n",
    "    span.score_trace(\n",
    "        name=\"user-feedback\",\n",
    "        value=1,\n",
    "        data_type=\"NUMERIC\",\n",
    "        comment=\"This was correct, thank you\"\n",
    "    )\n",
    "\n",
    "# 方案二：仍在上下文中，但不直接持有 span 对象时，可用 score_current_trace()\n",
    "with langfuse.start_as_current_span(name=\"🤖-sub-research-agent\") as span:\n",
    "    # ... LangGraph execution ...\n",
    "\n",
    "    langfuse.score_current_trace(\n",
    "        name=\"user-feedback\",\n",
    "        value=1,\n",
    "        data_type=\"NUMERIC\"\n",
    "    )\n",
    "\n",
    "# 方案三：已离开上下文，用 trace_id 直接创建评分（适合异步/后台批处理）\n",
    "langfuse.create_score(\n",
    "    trace_id=predefined_trace_id,\n",
    "    name=\"user-feedback\",\n",
    "    value=1,\n",
    "    data_type=\"NUMERIC\",\n",
    "    comment=\"This was correct, thank you\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cq_DeCcXSxwq"
   },
   "source": [
    "### 在 Langfuse 中查看带评分的追踪\n",
    "\n",
    "示例追踪：https://cloud.langfuse.com/project/cmequpe0j00euad07w6wrvkzg/traces?peek=a7d9c0badaccd67fccf2045c68fb01ec&timestamp=2025-09-23T06%3A37%3A08.963Z\n",
    "\n",
    "![包含评分的追踪展示](https://cdn.jsdelivr.net/gh/Fly0905/note-picture@main/imag/202509231502415.png)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (agent101)",
   "language": "python",
   "name": "agent101"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
