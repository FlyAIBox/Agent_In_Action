# 任务16：建立评估体系 - 用Langfuse追踪智能体执行过程

**时长：** 30分钟  
**难度：** ⭐⭐☆☆☆  
**交付成果：** 评估体系框架文档

---

## 第一部分：理解评估的必要性 (10分钟)

### 💡 核心痛点

**场景1：智能体上线后的困惑**
```
开发：老板，我们的AI客服上线了！
老板：效果怎么样？
开发：应该...还不错吧？
老板：什么叫"应该"？有数据吗？
开发：这个...😅
```

**场景2：出现问题时的无助**
```
用户投诉：你们的AI回答不对！
开发：哪里不对？
用户：就是不对！
开发：能给我看看对话记录吗？
用户：早就关掉了...
开发：...（如何复现和调试？）
```

**场景3：成本失控**
```
财务：这个月OpenAI账单暴涨！
开发：啊？为什么？
财务：你们用了多少tokens？
开发：不知道...没统计...
财务：😡
```

### 🎯 评估的价值

#### 1. **科学决策的基础**
```
没有评估：凭感觉做决定 ❌
有了评估：用数据说话 ✅
```

#### 2. **问题快速定位**
```
传统调试：
用户反馈 → 猜测原因 → 复现问题 → 修复 → 再次部署
耗时：数小时到数天

有追踪系统：
用户反馈 → 查看Trace → 定位问题 → 修复 → 部署
耗时：几分钟到几小时
```

#### 3. **持续优化的依据**
```
迭代循环：
部署 → 收集数据 → 分析瓶颈 → 优化 → 部署
    ↑                                    ↓
    └──────────── 数据驱动 ────────────┘
```

---

## 第二部分：评估指标体系设计 (10分钟)

### 📊 评估的三个维度

```
┌─────────────────────────────────────┐
│        评估体系金字塔                │
│                                     │
│         ┌─────────┐                │
│         │ 业务指标 │                │
│         └────┬────┘                │
│              │                     │
│       ┌──────┴──────┐             │
│       │   质量指标   │             │
│       └──────┬──────┘             │
│              │                     │
│     ┌────────┴────────┐           │
│     │   技术指标       │           │
│     └─────────────────┘           │
└─────────────────────────────────────┘
```

### 1. 技术指标（Technical Metrics）

#### a) 性能指标
```python
性能指标 = {
    "延迟（Latency）": {
        "定义": "从请求到响应的时间",
        "单位": "秒/毫秒",
        "目标": "< 3秒（聊天应用）",
        "监控": "P50、P95、P99延迟"
    },
    "吞吐量（Throughput）": {
        "定义": "单位时间处理的请求数",
        "单位": "请求/秒",
        "目标": "根据业务需求",
        "监控": "QPS、并发数"
    }
}
```

#### b) 成本指标
```python
成本指标 = {
    "Token消耗": {
        "输入Token数": "影响理解成本",
        "输出Token数": "影响生成成本",
        "总Token数": "总体成本",
        "计算公式": "成本 = 输入价格×输入Token + 输出价格×输出Token"
    },
    "API调用次数": {
        "成功调用": "正常消费",
        "失败调用": "浪费成本",
        "重试次数": "额外开销"
    }
}
```

#### c) 可靠性指标
```python
可靠性指标 = {
    "成功率": "成功请求 / 总请求",
    "错误率": "失败请求 / 总请求",
    "超时率": "超时请求 / 总请求",
    "可用性": "正常运行时间 / 总时间"
}
```

### 2. 质量指标（Quality Metrics）

#### a) 正确性（Correctness）
```python
评估方法 = {
    "精确匹配": "输出 == 预期答案",
    "语义相似度": "使用embedding计算相似度",
    "LLM作为评判": "使用另一个LLM评估输出质量",
    "人工标注": "专家评估（金标准）"
}
```

#### b) 相关性（Relevance）
```python
评估维度 = {
    "回答是否切题": "是否回答了用户的问题",
    "信息是否充分": "是否提供了足够的信息",
    "是否有多余内容": "是否包含无关信息"
}
```

#### c) 连贯性（Coherence）
```python
评估要点 = {
    "逻辑是否清晰": "论述是否有条理",
    "上下文是否一致": "前后是否矛盾",
    "表达是否流畅": "是否通顺易懂"
}
```

#### d) 简洁性（Conciseness）
```python
评估标准 = {
    "是否啰嗦": "有无重复内容",
    "是否直接": "是否直奔主题",
    "长度是否适当": "是否符合场景要求"
}
```

### 3. 业务指标（Business Metrics）

```python
业务指标 = {
    "用户满意度": {
        "点赞/点踩": "直接反馈",
        "NPS得分": "Net Promoter Score",
        "留存率": "用户是否继续使用"
    },
    "业务转化": {
        "任务完成率": "用户是否达成目标",
        "转化率": "查询到购买的转化",
        "客单价": "带来的业务价值"
    },
    "使用频率": {
        "DAU/MAU": "日活/月活",
        "使用时长": "平均会话时长",
        "交互次数": "平均对话轮数"
    }
}
```

### 📋 评估指标选择指南

| 应用场景 | 核心指标 | 次要指标 |
|:---|:---|:---|
| **聊天机器人** | 相关性、延迟、用户满意度 | 成本、简洁性 |
| **内容生成** | 质量、创造性、连贯性 | 成本、延迟 |
| **数据提取** | 准确性、完整性 | 延迟、成本 |
| **代码生成** | 正确性、可执行性 | 代码风格、效率 |
| **翻译系统** | 准确性、流畅性 | 延迟、成本 |

---

## 第三部分：评估vs监控vs调试 (5分钟)

### 🔍 三者的区别与联系

```
┌──────────────────────────────────────────────┐
│                 完整的可观测性体系              │
├──────────────────────────────────────────────┤
│                                              │
│  调试（Debugging）                            │
│  ├─ 目的：找到bug                            │
│  ├─ 时机：开发阶段、出现问题时                  │
│  ├─ 工具：Trace详情、日志、错误堆栈             │
│  └─ 特点：深入、细节、单次                     │
│                                              │
│  监控（Monitoring）                           │
│  ├─ 目的：实时掌握系统状态                     │
│  ├─ 时机：生产环境持续运行                     │
│  ├─ 工具：仪表板、告警、趋势图                  │
│  └─ 特点：实时、聚合、持续                     │
│                                              │
│  评估（Evaluation）                           │
│  ├─ 目的：量化系统质量                        │
│  ├─ 时机：上线前、迭代时、对比时                │
│  ├─ 工具：数据集、评分、A/B测试                 │
│  └─ 特点：系统性、可重复、有基准                │
│                                              │
└──────────────────────────────────────────────┘
```

### 📊 使用场景对比表

| 场景 | 调试 | 监控 | 评估 |
|:---|:---:|:---:|:---:|
| 开发新功能 | ✅ | ❌ | ✅ |
| 生产运行 | ❌ | ✅ | ✅ |
| 用户反馈问题 | ✅ | ✅ | ❌ |
| 版本迭代 | ✅ | ❌ | ✅ |
| 性能优化 | ✅ | ✅ | ✅ |
| 成本控制 | ❌ | ✅ | ✅ |
| A/B测试 | ❌ | ✅ | ✅ |

---

## 第四部分：Langfuse核心概念 (5分钟)

### 🏗️ Langfuse数据模型

```
Trace（追踪）
├── Span（跨度）
│   ├── Span（子跨度）
│   └── Generation（生成）
│       ├── Input（输入）
│       ├── Output（输出）
│       ├── Metadata（元数据）
│       └── Metrics（指标）
│           ├── Token Count
│           ├── Cost
│           └── Latency
├── Score（评分）
│   ├── Name（评分名称）
│   ├── Value（评分值）
│   └── Comment（评论）
└── Metadata（元数据）
    ├── User ID
    ├── Session ID
    ├── Tags
    └── Custom Fields
```

### 1. Trace（追踪）

**定义：** 一次完整的请求生命周期

```python
# Trace示例
{
    "id": "trace-abc-123",
    "name": "customer-support-chat",
    "timestamp": "2025-11-04T10:30:00Z",
    "user_id": "user-456",
    "session_id": "session-789",
    "metadata": {
        "channel": "web",
        "language": "zh-CN"
    },
    "spans": [...],  # 子步骤
    "scores": [...],  # 评分
    "cost": 0.003,  # 成本
    "latency": 2.5  # 延迟(秒)
}
```

**类比理解：**
```
Trace就像一次完整的外卖订单：
- 下单时间
- 订单号
- 用户信息
- 配送过程（spans）
- 用户评价（scores）
- 总费用
- 总时长
```

### 2. Span（跨度）

**定义：** Trace中的一个步骤或操作

```python
# Span示例
{
    "id": "span-def-456",
    "name": "search-knowledge-base",
    "start_time": "2025-11-04T10:30:00.100Z",
    "end_time": "2025-11-04T10:30:00.500Z",
    "input": {"query": "如何退款"},
    "output": {"results": [...]},
    "latency": 0.4,
    "parent_id": "trace-abc-123"
}
```

**类比理解：**
```
Span就像外卖配送的各个环节：
- 商家接单（span 1）
- 商家备餐（span 2）
- 骑手取餐（span 3）
- 骑手配送（span 4）
- 用户确认（span 5）
```

### 3. Generation（生成）

**定义：** 一次LLM模型调用

```python
# Generation示例
{
    "id": "gen-ghi-789",
    "model": "gpt-4o",
    "input": {
        "messages": [
            {"role": "system", "content": "你是客服助手"},
            {"role": "user", "content": "如何退款"}
        ]
    },
    "output": {
        "role": "assistant",
        "content": "退款流程如下：..."
    },
    "usage": {
        "input_tokens": 50,
        "output_tokens": 200,
        "total_tokens": 250
    },
    "cost": 0.00125,
    "latency": 1.8
}
```

**类比理解：**
```
Generation就像问大厨一个问题：
- 你问的话（input）
- 大厨的回答（output）
- 大厨思考的时间（latency）
- 消耗的材料（tokens）
- 材料的费用（cost）
```

### 4. Score（评分）

**定义：** 对Trace或Generation的评价

```python
# Score示例
{
    "trace_id": "trace-abc-123",
    "name": "user-satisfaction",
    "value": 5,  # 1-5分
    "data_type": "NUMERIC",
    "comment": "问题解决得很好",
    "timestamp": "2025-11-04T10:32:00Z"
}
```

**评分类型：**
```python
评分类型 = {
    "NUMERIC": {
        "描述": "数值型评分",
        "示例": "1-5分、0-100分",
        "用途": "定量分析、趋势观察"
    },
    "CATEGORICAL": {
        "描述": "分类型评分",
        "示例": "好/中/差、通过/不通过",
        "用途": "分类统计、比例分析"
    },
    "BOOLEAN": {
        "描述": "布尔型评分",
        "示例": "True/False、是/否",
        "用途": "简单判断、二元分类"
    }
}
```

### 📊 数据模型关系图

```
┌──────────────────────────────────────────┐
│              Trace（追踪）                │
│  ┌────────────────────────────────────┐  │
│  │ id: trace-abc-123                  │  │
│  │ name: "聊天会话"                    │  │
│  │ user_id: "user-456"                │  │
│  └────────────────────────────────────┘  │
│                                          │
│  ┌─────────────────────────────────────┐│
│  │          Spans（步骤）              ││
│  ├─────────────────────────────────────┤│
│  │ Span 1: 检索知识库                  ││
│  │   └─ input, output, latency        ││
│  │                                     ││
│  │ Span 2: 调用LLM（Generation）       ││
│  │   ├─ model: gpt-4o                 ││
│  │   ├─ tokens: 250                   ││
│  │   ├─ cost: $0.00125                ││
│  │   └─ latency: 1.8s                 ││
│  │                                     ││
│  │ Span 3: 格式化输出                  ││
│  │   └─ input, output, latency        ││
│  └─────────────────────────────────────┘│
│                                          │
│  ┌─────────────────────────────────────┐│
│  │        Scores（评分）               ││
│  ├─────────────────────────────────────┤│
│  │ • 用户满意度: 5/5                   ││
│  │ • 相关性: 0.95                      ││
│  │ • 安全性: PASS                      ││
│  └─────────────────────────────────────┘│
└──────────────────────────────────────────┘
```

---

## 第五部分：实战演练 - 创建第一个Trace

### 🎯 目标
通过简单示例理解Langfuse的基本用法

### 步骤1：环境准备

```bash
# 安装依赖
pip install langfuse==3.3.0 openai==1.107.0

# 设置环境变量
export LANGFUSE_PUBLIC_KEY="pk-lf-..."
export LANGFUSE_SECRET_KEY="sk-lf-..."
export LANGFUSE_HOST="https://cloud.langfuse.com"
export OPENAI_API_KEY="sk-..."
```

### 步骤2：最简单的追踪示例

```python
from langfuse import Langfuse

# 初始化客户端
langfuse = Langfuse()

# 创建一个追踪
trace = langfuse.trace(
    name="my-first-trace",
    user_id="user-123",
    metadata={"environment": "demo"}
)

# 添加一个生成记录
generation = trace.generation(
    name="simple-completion",
    model="gpt-4o",
    input={"messages": [{"role": "user", "content": "Hello!"}]},
    output={"content": "Hi there!"},
    usage={"input_tokens": 5, "output_tokens": 3}
)

# 添加评分
trace.score(
    name="quality",
    value=1,
    comment="Perfect response"
)

print("✅ Trace创建成功!")
print(f"🔗 查看链接: {trace.get_trace_url()}")
```

### 步骤3：在Langfuse控制台查看

1. 打开 https://cloud.langfuse.com
2. 进入 Traces 页面
3. 找到名为 "my-first-trace" 的记录
4. 点击查看详情

**你应该看到：**
- Trace的基本信息
- Generation的输入输出
- Token使用量
- 质量评分

---

## 💡 关键要点总结

### 1. 评估是智能体开发的必要环节
```
没有评估 = 盲目开发
有了评估 = 科学决策
```

### 2. 评估指标要分层设计
```
技术指标（底层）→ 质量指标（中层）→ 业务指标（顶层）
```

### 3. Langfuse三大核心概念
```
Trace（完整请求）→ Span（执行步骤）→ Generation（模型调用）
```

### 4. 评估、监控、调试各有侧重
```
评估 = 上线前的质量检查
监控 = 运行中的实时观察
调试 = 出问题时的深入排查
```

---

## 📚 延伸阅读

1. **Langfuse官方文档**
   - [Tracing概念](https://langfuse.com/docs/tracing)
   - [Scores指南](https://langfuse.com/docs/scores)

2. **评估方法论**
   - [LLM评估最佳实践](https://langfuse.com/blog/2025-03-04-llm-evaluation-101-best-practices-and-challenges)

3. **下一步学习**
   - 任务17：OpenAI SDK集成
   - 任务17：LangChain集成

---

## 🎯 课后练习

### 基础练习
1. 为你的AI项目设计3-5个评估指标
2. 注册Langfuse账户并创建第一个项目
3. 运行示例代码，在控制台查看Trace

### 进阶练习
1. 思考：你的项目最重要的3个指标是什么？为什么？
2. 设计：如果要做A/B测试，你会选择哪些指标对比？
3. 规划：如何在你的项目中引入评估体系？

---

**下一节：任务17 - Langfuse集成实战**


