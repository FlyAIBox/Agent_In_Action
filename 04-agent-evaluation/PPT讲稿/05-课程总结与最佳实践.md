# ç¬¬4å‘¨è¯¾ç¨‹æ€»ç»“ä¸æœ€ä½³å®è·µ

---

## ğŸ“š è¯¾ç¨‹å›é¡¾

### å­¦ä¹ è·¯å¾„å›¾

```
ç¬¬4å‘¨å®Œæ•´å­¦ä¹ è·¯å¾„
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ä»»åŠ¡16: å»ºç«‹è¯„ä¼°ä½“ç³» (30åˆ†é’Ÿ)
â”œâ”€â”€ ç†è§£è¯„ä¼°çš„å¿…è¦æ€§
â”œâ”€â”€ è®¾è®¡è¯„ä¼°æŒ‡æ ‡ä½“ç³»
â”œâ”€â”€ æŒæ¡Langfuseæ ¸å¿ƒæ¦‚å¿µ
â””â”€â”€ åˆ›å»ºç¬¬ä¸€ä¸ªTrace
         â†“
ä»»åŠ¡17: Langfuseé›†æˆå®æˆ˜ (30åˆ†é’Ÿ)
â”œâ”€â”€ OpenAI SDKé›†æˆ
â”œâ”€â”€ LangChainé›†æˆ
â”œâ”€â”€ è¿½è¸ªå·¥å…·è°ƒç”¨
â””â”€â”€ åˆ†æè¿½è¸ªæ•°æ®
         â†“
ä»»åŠ¡18: è¿½è¸ªLangGraphæ™ºèƒ½ä½“ (40åˆ†é’Ÿ)
â”œâ”€â”€ LangGraphåŸºç¡€
â”œâ”€â”€ é‚®ä»¶å¤„ç†Agent
â”œâ”€â”€ å¤šèŠ‚ç‚¹å·¥ä½œæµ
â””â”€â”€ å¤šæ™ºèƒ½ä½“åä½œ
         â†“
ä»»åŠ¡19: LLMå®‰å…¨ç›‘æ§ (40åˆ†é’Ÿ)
â”œâ”€â”€ å®‰å…¨å¨èƒè¯†åˆ«
â”œâ”€â”€ Promptæ³¨å…¥é˜²æŠ¤
â”œâ”€â”€ PIIä¿¡æ¯ä¿æŠ¤
â””â”€â”€ ç»¼åˆç›‘æ§ä½“ç³»
         â†“
      âœ… å®Œæˆ
```

---

## ğŸ¯ æ ¸å¿ƒçŸ¥è¯†ç‚¹æ€»ç»“

### 1. è¯„ä¼°ä½“ç³»ä¸‰ç»´åº¦

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         è¯„ä¼°æŒ‡æ ‡ä½“ç³»                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                     â”‚
â”‚  ä¸šåŠ¡æŒ‡æ ‡ï¼ˆé¡¶å±‚ï¼‰                    â”‚
â”‚  â”œâ”€ ç”¨æˆ·æ»¡æ„åº¦                      â”‚
â”‚  â”œâ”€ ä¸šåŠ¡è½¬åŒ–ç‡                      â”‚
â”‚  â””â”€ ä½¿ç”¨é¢‘ç‡                        â”‚
â”‚                                     â”‚
â”‚  è´¨é‡æŒ‡æ ‡ï¼ˆä¸­å±‚ï¼‰                    â”‚
â”‚  â”œâ”€ æ­£ç¡®æ€§                          â”‚
â”‚  â”œâ”€ ç›¸å…³æ€§                          â”‚
â”‚  â”œâ”€ è¿è´¯æ€§                          â”‚
â”‚  â””â”€ ç®€æ´æ€§                          â”‚
â”‚                                     â”‚
â”‚  æŠ€æœ¯æŒ‡æ ‡ï¼ˆåº•å±‚ï¼‰                    â”‚
â”‚  â”œâ”€ å»¶è¿Ÿ                            â”‚
â”‚  â”œâ”€ Tokenæ¶ˆè€—                       â”‚
â”‚  â”œâ”€ æˆæœ¬                            â”‚
â”‚  â””â”€ å¯é æ€§                          â”‚
â”‚                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. Langfuseæ•°æ®æ¨¡å‹

```python
æ•°æ®æ¨¡å‹å±‚æ¬¡ = {
    "Trace": {
        "å®šä¹‰": "å®Œæ•´çš„è¯·æ±‚ç”Ÿå‘½å‘¨æœŸ",
        "åŒ…å«": ["Spans", "Scores", "Metadata"],
        "ç”¨é€”": "æ•´ä½“æ€§èƒ½åˆ†æ"
    },
    "Span": {
        "å®šä¹‰": "Traceä¸­çš„ä¸€ä¸ªæ­¥éª¤",
        "åŒ…å«": ["Input", "Output", "Latency"],
        "ç”¨é€”": "ç»†ç²’åº¦è¿½è¸ª"
    },
    "Generation": {
        "å®šä¹‰": "LLMæ¨¡å‹è°ƒç”¨",
        "åŒ…å«": ["Tokens", "Cost", "Model"],
        "ç”¨é€”": "æˆæœ¬å’Œè´¨é‡åˆ†æ"
    },
    "Score": {
        "å®šä¹‰": "è´¨é‡è¯„åˆ†",
        "ç±»å‹": ["NUMERIC", "CATEGORICAL", "BOOLEAN"],
        "ç”¨é€”": "é‡åŒ–è¯„ä¼°"
    }
}
```

### 3. é›†æˆæ¨¡å¼å¯¹æ¯”

| é›†æˆæ–¹å¼ | OpenAI SDK | LangChain | LangGraph |
|:---|:---|:---|:---|
| **å¯¼å…¥æ–¹å¼** | `langfuse.openai import openai` | `CallbackHandler` | `CallbackHandler` + `@observe` |
| **é…ç½®ä½ç½®** | è‡ªåŠ¨ï¼ˆç¯å¢ƒå˜é‡ï¼‰ | `config={"callbacks"}` | ç¼–è¯‘æ—¶ + è¿è¡Œæ—¶ |
| **è¿½è¸ªç²’åº¦** | APIè°ƒç”¨çº§åˆ« | Chainçº§åˆ« | èŠ‚ç‚¹çº§åˆ« |
| **å¤æ‚åº¦** | â­â˜†â˜†â˜†â˜† | â­â­â­â˜†â˜† | â­â­â­â­â˜† |
| **é€‚ç”¨åœºæ™¯** | ç®€å•åº”ç”¨ | é“¾å¼è°ƒç”¨ | å¤æ‚å·¥ä½œæµ |

### 4. å®‰å…¨é˜²æŠ¤æ¶æ„

```
è¾“å…¥å®‰å…¨å±‚
â”œâ”€â”€ Promptæ³¨å…¥æ£€æµ‹ï¼ˆPromptInjectionï¼‰
â”œâ”€â”€ ç¦æ­¢ä¸»é¢˜æ£€æµ‹ï¼ˆBanTopicsï¼‰
â”œâ”€â”€ PIIè„±æ•ï¼ˆAnonymizeï¼‰
â””â”€â”€ æ¶æ„å†…å®¹è¿‡æ»¤
      â†“
   LLMå¤„ç†
      â†“
è¾“å‡ºå®‰å…¨å±‚
â”œâ”€â”€ æœ‰å®³å†…å®¹æ£€æµ‹
â”œâ”€â”€ PIIè¿˜åŸï¼ˆDeanonymizeï¼‰
â”œâ”€â”€ äº‹å®æ ¸æŸ¥
â””â”€â”€ è´¨é‡è¯„ä¼°
      â†“
Langfuseç›‘æ§
â”œâ”€â”€ å®æ—¶è¿½è¸ª
â”œâ”€â”€ å¼‚å¸¸æ£€æµ‹
â”œâ”€â”€ å‘Šè­¦é€šçŸ¥
â””â”€â”€ æŠ¥è¡¨åˆ†æ
```

---

## ğŸ† æœ€ä½³å®è·µ

### ä¸€ã€è¯„ä¼°æŒ‡æ ‡è®¾è®¡

#### âœ… DO - å¥½çš„åšæ³•

```python
# 1. åˆ†å±‚è®¾è®¡æŒ‡æ ‡
è¯„ä¼°æŒ‡æ ‡ = {
    "æŠ€æœ¯æŒ‡æ ‡": ["å»¶è¿Ÿ", "Token", "æˆæœ¬"],
    "è´¨é‡æŒ‡æ ‡": ["å‡†ç¡®æ€§", "ç›¸å…³æ€§", "æµç•…æ€§"],
    "ä¸šåŠ¡æŒ‡æ ‡": ["æ»¡æ„åº¦", "è½¬åŒ–ç‡", "ç•™å­˜ç‡"]
}

# 2. ä½¿ç”¨æœ‰æ„ä¹‰çš„å‘½å
langfuse.score(
    name="answer-relevance",  # æ¸…æ™°çš„åç§°
    value=0.95,
    comment="é«˜åº¦ç›¸å…³"  # æ·»åŠ è¯´æ˜
)

# 3. è®¾ç½®åˆç†çš„é˜ˆå€¼
if latency > 3.0:  # æ˜ç¡®çš„æ€§èƒ½è¦æ±‚
    alert("å“åº”è¿‡æ…¢")
```

#### âŒ DON'T - é¿å…çš„åšæ³•

```python
# 1. æŒ‡æ ‡è¿‡äºç¬¼ç»Ÿ
langfuse.score(name="quality", value=0.8)  # "quality"å¤ªæ¨¡ç³Š

# 2. æ²¡æœ‰åŸºå‡†å¯¹æ¯”
print(f"æˆæœ¬: ${cost}")  # æ— æ³•åˆ¤æ–­å¥½å

# 3. å¿½ç•¥ç”¨æˆ·åé¦ˆ
# åªçœ‹æŠ€æœ¯æŒ‡æ ‡ï¼Œä¸å…³æ³¨ç”¨æˆ·æ»¡æ„åº¦
```

---

### äºŒã€è¿½è¸ªæ•°æ®ç®¡ç†

#### âœ… DO - å¥½çš„åšæ³•

```python
# 1. ä½¿ç”¨æœ‰æ„ä¹‰çš„åç§°
openai.chat.completions.create(
    name="customer-support-v2",  # ç‰ˆæœ¬åŒ–å‘½å
    # ...
)

# 2. æ·»åŠ ä¸°å¯Œçš„å…ƒæ•°æ®
metadata={
    "environment": "production",
    "version": "v2.1.0",
    "feature": "customer-service",
    "user_tier": "premium",
    "session_id": session_id,
    "user_id": user_id
}

# 3. ä½¿ç”¨æ ‡ç­¾åˆ†ç±»
metadata={
    "langfuse_tags": ["important", "customer-facing", "v2"]
}

# 4. åŠæ—¶åˆ·æ–°æ•°æ®
langfuse.flush()  # ç¡®ä¿æ•°æ®å†™å…¥
```

#### âŒ DON'T - é¿å…çš„åšæ³•

```python
# 1. ä¸è®¾ç½®name
openai.chat.completions.create(...)  # éš¾ä»¥è¯†åˆ«

# 2. å…ƒæ•°æ®è¿‡å°‘
metadata={}  # æ— æ³•åˆ†æ

# 3. å¿˜è®°flush
# çŸ­æœŸè¿è¡Œçš„è„šæœ¬å¯èƒ½ä¸¢å¤±æ•°æ®
```

---

### ä¸‰ã€æ€§èƒ½ä¼˜åŒ–

#### âœ… DO - å¥½çš„åšæ³•

```python
# 1. å¼‚æ­¥å¤„ç†æé«˜å¹¶å‘
async def process_batch(items):
    tasks = [process_item(item) for item in items]
    return await asyncio.gather(*tasks)

# 2. æ‰¹é‡å¤„ç†é™ä½å¼€é”€
results = chain.batch(
    inputs,
    config={"callbacks": [langfuse_handler]}
)

# 3. ç¼“å­˜å¸¸ç”¨ç»“æœ
@lru_cache(maxsize=1000)
def expensive_operation(input):
    return llm.invoke(input)

# 4. é€‰æ‹©åˆé€‚çš„æ¨¡å‹
if task_complexity == "simple":
    model = "gpt-3.5-turbo"  # ä¾¿å®œå¿«é€Ÿ
else:
    model = "gpt-4o"  # å¤æ‚ä»»åŠ¡
```

#### âŒ DON'T - é¿å…çš„åšæ³•

```python
# 1. åŒæ­¥å¤„ç†å¤§é‡è¯·æ±‚
for item in large_list:  # ä¸²è¡Œï¼Œæ…¢
    process(item)

# 2. é‡å¤è°ƒç”¨LLM
for i in range(10):
    llm.invoke(same_prompt)  # æµªè´¹

# 3. æ€»æ˜¯ä½¿ç”¨æœ€è´µçš„æ¨¡å‹
model = "gpt-4o"  # æ— è®ºä»»åŠ¡ç®€å•å¤æ‚
```

---

### å››ã€å®‰å…¨é˜²æŠ¤

#### âœ… DO - å¥½çš„åšæ³•

```python
# 1. å¤šå±‚é˜²æŠ¤
def secure_generate(prompt):
    # è¾“å…¥æ£€æŸ¥
    if is_prompt_injection(prompt):
        return "æ£€æµ‹åˆ°å®‰å…¨é£é™©"
    
    # PIIè„±æ•
    sanitized = anonymize(prompt)
    
    # LLMè°ƒç”¨
    output = llm.invoke(sanitized)
    
    # è¾“å‡ºæ£€æŸ¥
    if has_harmful_content(output):
        return "è¾“å‡ºä¸å®‰å…¨"
    
    # PIIè¿˜åŸ
    return deanonymize(output)

# 2. è®¾ç½®é˜ˆå€¼å‘Šè­¦
with langfuse.start_as_current_span("security") as span:
    span.score("risk-score", risk_score)
    if risk_score > 0.8:
        send_alert()

# 3. è®°å½•æ‰€æœ‰å®‰å…¨äº‹ä»¶
if blocked:
    langfuse.trace(
        name="security-block",
        metadata={
            "reason": "prompt-injection",
            "risk_score": 0.95,
            "user_id": user_id
        }
    )
```

#### âŒ DON'T - é¿å…çš„åšæ³•

```python
# 1. åªæ£€æŸ¥è¾“å…¥ä¸æ£€æŸ¥è¾“å‡º
if is_safe(prompt):
    return llm.invoke(prompt)  # è¾“å‡ºå¯èƒ½ä¸å®‰å…¨

# 2. ç¡¬ç¼–ç æ•æ„Ÿä¿¡æ¯
API_KEY = "sk-..."  # ä¸è¦è¿™æ ·åšï¼

# 3. å¿½ç•¥ä½é£é™©å‘Šè­¦
if risk_score < 0.9:
    pass  # å¯èƒ½ç§¯ç´¯æˆå¤§é—®é¢˜
```

---

### äº”ã€æˆæœ¬æ§åˆ¶

#### âœ… DO - å¥½çš„åšæ³•

```python
# 1. ç›‘æ§Tokenä½¿ç”¨
def track_usage(response):
    usage = response.usage
    cost = calculate_cost(usage)
    
    if cost > threshold:
        send_cost_alert()
    
    return response

# 2. ä¼˜åŒ–æç¤ºè¯é•¿åº¦
# ç®€æ´çš„system message
system_msg = "ä½ æ˜¯åŠ©æ‰‹"  # âœ…

# è€Œä¸æ˜¯
system_msg = """
ä½ æ˜¯ä¸€ä¸ªéå¸¸æœ‰å¸®åŠ©çš„AIåŠ©æ‰‹...
ï¼ˆ500å­—è¯´æ˜ï¼‰
"""  # âŒ

# 3. ä½¿ç”¨max_tokensé™åˆ¶
openai.chat.completions.create(
    max_tokens=200,  # é˜²æ­¢è¿‡é•¿è¾“å‡º
    # ...
)

# 4. å®šæœŸåˆ†ææˆæœ¬
langfuse_dashboard = langfuse.get_metrics()
high_cost_traces = langfuse_dashboard.filter(cost > 0.01)
```

#### âŒ DON'T - é¿å…çš„åšæ³•

```python
# 1. ä¸è®¾ç½®max_tokens
# LLMå¯èƒ½ç”Ÿæˆè¿‡é•¿å†…å®¹

# 2. ä¸ç›‘æ§æˆæœ¬
# ç›´åˆ°è´¦å•åˆ°æ¥æ‰å‘ç°

# 3. æ‰€æœ‰åœºæ™¯ç”¨åŒä¸€æ¨¡å‹
model = "gpt-4o"  # æ— è®ºä½•æ—¶éƒ½ç”¨æœ€è´µçš„
```

---

## ğŸ“ è¿›é˜¶æŠ€å·§

### 1. A/Bæµ‹è¯•æ¡†æ¶

```python
import random

def ab_test_model(prompt, user_id):
    """ç®€å•çš„A/Bæµ‹è¯•æ¡†æ¶"""
    
    # æ ¹æ®user_idåˆ†é…å®éªŒç»„
    group = "A" if hash(user_id) % 2 == 0 else "B"
    
    # é€‰æ‹©ä¸åŒé…ç½®
    if group == "A":
        model = "gpt-4o"
        temperature = 0.7
    else:
        model = "gpt-3.5-turbo"
        temperature = 0.5
    
    # æ‰§è¡Œå¹¶æ ‡è®°
    result = openai.chat.completions.create(
        name=f"ab-test-{group}",
        model=model,
        temperature=temperature,
        messages=[{"role": "user", "content": prompt}],
        metadata={
            "experiment": "model-comparison",
            "group": group,
            "user_id": user_id
        }
    )
    
    return result

# åœ¨Langfuseä¸­æŒ‰groupåˆ†æç»“æœ
```

### 2. è‡ªå®šä¹‰è¯„ä¼°å™¨

```python
from langfuse import observe

@observe
def custom_evaluator(trace_id: str):
    """è‡ªå®šä¹‰è¯„ä¼°å‡½æ•°"""
    
    # è·å–traceæ•°æ®
    trace = langfuse.get_trace(trace_id)
    
    # è‡ªå®šä¹‰è¯„ä¼°é€»è¾‘
    input_length = len(trace.input)
    output_length = len(trace.output)
    
    # ç®€æ´æ€§è¯„åˆ†
    if output_length < input_length * 2:
        conciseness_score = 1.0
    else:
        conciseness_score = 0.5
    
    # è®°å½•è¯„åˆ†
    langfuse.score(
        trace_id=trace_id,
        name="custom-conciseness",
        value=conciseness_score,
        comment=f"è¾“å…¥{input_length}å­—ï¼Œè¾“å‡º{output_length}å­—"
    )

# å¼‚æ­¥æ‰¹é‡è¯„ä¼°
for trace in recent_traces:
    custom_evaluator(trace.id)
```

### 3. å®æ—¶å¼‚å¸¸æ£€æµ‹

```python
class AnomalyDetector:
    """å¼‚å¸¸æ£€æµ‹å™¨"""
    
    def __init__(self, thresholds):
        self.thresholds = thresholds
        self.baselines = {}
    
    def check_anomaly(self, trace):
        """æ£€æŸ¥å¼‚å¸¸"""
        anomalies = []
        
        # å»¶è¿Ÿå¼‚å¸¸
        if trace.latency > self.thresholds['latency']:
            anomalies.append(f"å»¶è¿Ÿè¿‡é«˜: {trace.latency}s")
        
        # æˆæœ¬å¼‚å¸¸
        if trace.cost > self.thresholds['cost']:
            anomalies.append(f"æˆæœ¬è¿‡é«˜: ${trace.cost}")
        
        # Tokenå¼‚å¸¸
        if trace.tokens > self.thresholds['tokens']:
            anomalies.append(f"Tokenè¿‡å¤š: {trace.tokens}")
        
        # å‘é€å‘Šè­¦
        if anomalies:
            self.send_alert(trace.id, anomalies)
        
        return anomalies

# ä½¿ç”¨
detector = AnomalyDetector({
    'latency': 5.0,
    'cost': 0.01,
    'tokens': 2000
})

# åœ¨æ¯æ¬¡è°ƒç”¨åæ£€æŸ¥
@observe
def monitored_call(prompt):
    result = llm.invoke(prompt)
    
    # è·å–å½“å‰traceå¹¶æ£€æŸ¥å¼‚å¸¸
    trace_id = langfuse.get_current_trace_id()
    trace = langfuse.get_trace(trace_id)
    detector.check_anomaly(trace)
    
    return result
```

---

## ğŸ“Š æˆåŠŸæ¡ˆä¾‹åˆ†æ

### æ¡ˆä¾‹1ï¼šæˆæœ¬ä¼˜åŒ– - é™ä½70%APIè´¹ç”¨

**èƒŒæ™¯ï¼š**
- æœˆAPIè´¹ç”¨ï¼š$10,000
- ä¸»è¦ä½¿ç”¨gpt-4æ¨¡å‹
- å¤§éƒ¨åˆ†æŸ¥è¯¢æ˜¯ç®€å•é—®ç­”

**ä¼˜åŒ–æ–¹æ¡ˆï¼š**
1. **åˆ†ç±»è·¯ç”±**
   ```python
   def route_by_complexity(prompt):
       complexity = estimate_complexity(prompt)
       
       if complexity == "simple":
           return "gpt-3.5-turbo"  # ä¾¿å®œ10å€
       else:
           return "gpt-4o"
   ```

2. **ç¼“å­˜å¸¸è§é—®é¢˜**
   ```python
   @lru_cache(maxsize=1000)
   def answer_faq(question):
       return llm.invoke(question)
   ```

3. **ä¼˜åŒ–æç¤ºè¯**
   ```python
   # å‰ï¼š800 tokensçš„system message
   # åï¼š100 tokensçš„ç²¾ç®€ç‰ˆ
   # èŠ‚çœï¼š87.5% input tokens
   ```

**ç»“æœï¼š**
- æˆæœ¬é™ä½ï¼š70%ï¼ˆ$10,000 â†’ $3,000/æœˆï¼‰
- å»¶è¿Ÿæ”¹å–„ï¼š30%ï¼ˆä½¿ç”¨æ›´å¿«çš„æ¨¡å‹ï¼‰
- è´¨é‡ä¿æŒï¼š95%+ï¼ˆæŒ‰å¤æ‚åº¦è·¯ç”±ï¼‰

---

### æ¡ˆä¾‹2ï¼šæ€§èƒ½ä¼˜åŒ– - æå‡3å€ååé‡

**èƒŒæ™¯ï¼š**
- ä¸²è¡Œå¤„ç†ï¼š100 req/min
- ç”¨æˆ·æŠ•è¯‰å»¶è¿Ÿé«˜
- æœåŠ¡å™¨CPUåˆ©ç”¨ç‡ä½

**ä¼˜åŒ–æ–¹æ¡ˆï¼š**
1. **å¼‚æ­¥å¹¶å‘**
   ```python
   # å‰ï¼šåŒæ­¥å¤„ç†
   for item in items:
       process(item)  # 100 req/min
   
   # åï¼šå¼‚æ­¥å¹¶å‘
   await asyncio.gather(*[
       process(item) for item in items
   ])  # 300 req/min
   ```

2. **æ‰¹é‡å¤„ç†**
   ```python
   # ä½¿ç”¨batchå‡å°‘ç½‘ç»œå¼€é”€
   results = chain.batch(inputs)
   ```

3. **æµå¼è¾“å‡º**
   ```python
   # ç”¨æˆ·ç«‹å³çœ‹åˆ°éƒ¨åˆ†ç»“æœ
   for chunk in chain.stream(input):
       yield chunk
   ```

**ç»“æœï¼š**
- ååé‡ï¼š3å€æå‡ï¼ˆ100 â†’ 300 req/minï¼‰
- ç”¨æˆ·æ„ŸçŸ¥å»¶è¿Ÿï¼š50%é™ä½
- æœåŠ¡å™¨åˆ©ç”¨ç‡ï¼š20% â†’ 60%

---

### æ¡ˆä¾‹3ï¼šå®‰å…¨åŠ å›º - é˜»æ­¢98%æ”»å‡»

**èƒŒæ™¯ï¼š**
- æ¯æ—¥é­å—çº¦100æ¬¡Promptæ³¨å…¥æ”»å‡»
- æ›¾å‘ç”ŸPIIæ³„éœ²äº‹ä»¶
- é¢ä¸´åˆè§„å‹åŠ›

**é˜²æŠ¤æ–¹æ¡ˆï¼š**
1. **å¤šå±‚æ£€æµ‹**
   ```python
   # è¾“å…¥å±‚ï¼š3é“é˜²çº¿
   - Promptæ³¨å…¥æ£€æµ‹
   - PIIè„±æ•
   - ç¦æ­¢ä¸»é¢˜è¿‡æ»¤
   
   # è¾“å‡ºå±‚ï¼š2é“é˜²çº¿
   - æœ‰å®³å†…å®¹æ£€æµ‹
   - PIIè¿˜åŸéªŒè¯
   ```

2. **å®æ—¶ç›‘æ§**
   ```python
   # Langfuseå‘Šè­¦è§„åˆ™
   if security_score > 0.8:
       - é˜»æ­¢è¯·æ±‚
       - è®°å½•è¯¦æƒ…
       - å‘é€å‘Šè­¦
       - äººå·¥å®¡æ ¸
   ```

3. **æŒç»­ä¼˜åŒ–**
   ```python
   # æ¯å‘¨åˆ†ææ”»å‡»æ¨¡å¼
   # æ›´æ–°æ£€æµ‹è§„åˆ™
   # è®­ç»ƒæ£€æµ‹æ¨¡å‹
   ```

**ç»“æœï¼š**
- æ”»å‡»é˜»æ­¢ç‡ï¼š98%
- è¯¯æŠ¥ç‡ï¼š< 2%
- PIIæ³„éœ²ï¼š0æ¬¡
- åˆè§„å®¡è®¡ï¼šé¡ºåˆ©é€šè¿‡

---

## ğŸš€ ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²æ¸…å•

### ä¸Šçº¿å‰æ£€æŸ¥

```
â–¡ ç¯å¢ƒé…ç½®
  â–¡ APIå¯†é’¥å®‰å…¨å­˜å‚¨
  â–¡ ç¯å¢ƒå˜é‡æ­£ç¡®è®¾ç½®
  â–¡ æ—¥å¿—çº§åˆ«é…ç½®

â–¡ è¿½è¸ªé…ç½®
  â–¡ Langfuseæ­£ç¡®åˆå§‹åŒ–
  â–¡ æ‰€æœ‰å…³é”®è·¯å¾„å·²è¿½è¸ª
  â–¡ å…ƒæ•°æ®è®¾ç½®å®Œæ•´

â–¡ è¯„ä¼°ä½“ç³»
  â–¡ æ ¸å¿ƒæŒ‡æ ‡å·²å®šä¹‰
  â–¡ é˜ˆå€¼å·²è®¾ç½®
  â–¡ å‘Šè­¦è§„åˆ™å·²é…ç½®

â–¡ å®‰å…¨é˜²æŠ¤
  â–¡ è¾“å…¥éªŒè¯å·²å¯ç”¨
  â–¡ è¾“å‡ºæ£€æŸ¥å·²éƒ¨ç½²
  â–¡ PIIå¤„ç†å·²å®ç°

â–¡ æ€§èƒ½ä¼˜åŒ–
  â–¡ ç¼“å­˜ç­–ç•¥å·²å®æ–½
  â–¡ å¹¶å‘æ§åˆ¶å·²é…ç½®
  â–¡ è¶…æ—¶è®¾ç½®åˆç†

â–¡ ç›‘æ§å‘Šè­¦
  â–¡ ä»ªè¡¨æ¿å·²æ­å»º
  â–¡ å‘Šè­¦é€šé“å·²æµ‹è¯•
  â–¡ å€¼ç­æµç¨‹å·²ç¡®å®š

â–¡ æ–‡æ¡£å®Œå–„
  â–¡ è¿ç»´æ‰‹å†Œå·²ç¼–å†™
  â–¡ æ•…éšœå¤„ç†æµç¨‹
  â–¡ è”ç³»äººä¿¡æ¯
```

---

## ğŸ“– å­¦ä¹ èµ„æºæ¨è

### å®˜æ–¹æ–‡æ¡£
1. [Langfuse Documentation](https://langfuse.com/docs)
2. [OpenAI API Reference](https://platform.openai.com/docs)
3. [LangChain Docs](https://python.langchain.com/)
4. [LangGraph Guide](https://langchain-ai.github.io/langgraph/)

### è¿›é˜¶å­¦ä¹ 
1. [Prompt Engineering Guide](https://www.promptingguide.ai/)
2. [LLM Security Best Practices](https://llmsecurity.net/)
3. [System Design for AI](https://github.com/chiphuyen/dmls-book)

### ç¤¾åŒºèµ„æº
1. [Langfuse GitHub](https://github.com/langfuse/langfuse)
2. [LangChain Community](https://github.com/langchain-ai/langchain)
3. [AI Safety Forum](https://www.aisafety.com/)

---

## ğŸ‰ ç»“è¯­

æ­å–œä½ å®Œæˆç¬¬4å‘¨çš„å…¨éƒ¨å­¦ä¹ ï¼ä½ å·²ç»æŒæ¡äº†ï¼š

âœ… å»ºç«‹å®Œæ•´çš„è¯„ä¼°ä½“ç³»  
âœ… ä½¿ç”¨Langfuseè¿½è¸ªæ™ºèƒ½ä½“  
âœ… é›†æˆOpenAI/LangChain/LangGraph  
âœ… æ„å»ºå®‰å…¨ç›‘æ§ç³»ç»Ÿ  
âœ… ä¼˜åŒ–æ€§èƒ½å’Œæˆæœ¬  

### ä¸‹ä¸€æ­¥å»ºè®®

1. **å®è·µé¡¹ç›®**
   - ä¸ºè‡ªå·±çš„é¡¹ç›®æ·»åŠ å®Œæ•´çš„ç›‘æ§
   - å®æ–½A/Bæµ‹è¯•
   - æ„å»ºè‡ªåŠ¨åŒ–è¯„ä¼°æµæ°´çº¿

2. **æŒç»­å­¦ä¹ **
   - å…³æ³¨Langfuseæ–°ç‰¹æ€§
   - å­¦ä¹ é«˜çº§è¯„ä¼°æ–¹æ³•
   - ç ”ç©¶AIå®‰å…¨å‰æ²¿

3. **ç¤¾åŒºå‚ä¸**
   - åˆ†äº«ä½ çš„ç»éªŒ
   - è´¡çŒ®å¼€æºé¡¹ç›®
   - å¸®åŠ©å…¶ä»–å­¦ä¹ è€…

### ä¿æŒè”ç³»

å¦‚æœ‰é—®é¢˜æˆ–æƒ³æ³•ï¼Œæ¬¢è¿ï¼š
- ğŸ“§ åœ¨è¯¾ç¨‹è®ºå›æé—®
- ğŸ’¬ åŠ å…¥æŠ€æœ¯äº¤æµç¾¤
- ğŸ› æäº¤Issueåé¦ˆ

**ç¥ä½ åœ¨AIæ™ºèƒ½ä½“çš„æ—…ç¨‹ä¸­ä¸æ–­è¿›æ­¥ï¼** ğŸš€


