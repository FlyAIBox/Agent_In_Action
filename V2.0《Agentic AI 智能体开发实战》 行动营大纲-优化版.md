## 🎯 课程简介

AI Agent（智能体）正在成为 2025 年最炙手可热的技术方向。如何快速入场？本课程将通过 **5 周实战行动营**，带你从零构建企业级 AI 智能体系统。

基于 **DeepSeek、GPT** 等最新大模型，采用 **MCP、LangGraph、Langfuse、LlamaFactory** 等前沿技术栈，通过真实项目实战，掌握智能体开发的完整技能链路。


---

## 💡 课程设计思路

### 这门课是讲给谁的？

**主要目标群体：**

* 有 1-3 年开发经验的工程师（Python/JavaScript）

* 希望学习大模型和智能体应用开发的技术人员

* 对 Agentic AI 技术感兴趣的后端/全栈工程师

* 希望从传统软件开发转向 AI 应用开发的工程师

**基础要求：**

* 具备 Python 或 JavaScript 编程基础，能够阅读和编写代码

* 了解基本的 Web 开发知识（API、HTTP 协议等）

* 对深度学习和大语言模型有初步了解

* 熟悉 Linux 基本操作和 Docker 容器技术


---

## 🎓 学习目标

通过 5 周的系统学习和实战训练，你将掌握：

✅ **智能体构建**：从单一工具调用到多角色协作的完整开发能力  

✅ **系统部署**：容器化部署、生产环境运维的工程化实践  

✅ **质量评估**：建立评估监控体系，持续优化智能体性能  

✅ **模型微调**：垂直领域模型定制，提升专业场景表现  

✅ **项目实战**：获得 6 个企业级智能体项目经验


---

## 📋 课程特点

### 🔥 实战驱动

* **25+ 节课**实战带练，每节课掌握一个明确技能点

* **15+ 小时**视频课，分步骤实现核心功能

* **5 次直播课**，串讲知识点、作业点评、总结复盘

* **2 个大作业**，闭环学习，深化技能

### 🚀 技术前沿

* 展示开源 LLM（DeepSeek、GPT）和 AI Agent 开发的最新成果

* 展示 MCP、LangGraph、vLLM、LlamaFactory 等前沿技术

* 展示智能体在旅游规划、深度研究等场景的实际应用

### 💼 工程化实践

* 基于真实业务需求和实战案例驱动

* 涵盖从开发到部署的完整工程链路

* 提供可直接用于商业项目的代码和部署方案

* 掌握 AI 应用开发技能，提升职场竞争力


---

## 📚 课程大纲

### 📦 课程总览

|周次|模块名称|核心技术|交付成果|配套代码|
|:----|:----|:----|:----|:----|
|**第 1 周**|掌握工具调用，让智能体接入真实世界|Function Call, MCP, Context Engineering|构建天气查询助手、手搓智能体框架|01-agent-tool-mcp/|
|**第 2 周**|构建多角色协作系统，实现复杂任务自动化|LangGraph, LangChain|部署 DeepResearch 深度研究助手|02-agent-multi-role/|
|**第 3 周**|打造全栈智能体应用，一键部署到生产环境|FastAPI, Streamlit, Docker|上线 AI 旅行规划系统|03-agent-build-docker-deploy/|
|**第 4 周**|建立评估监控体系，保障智能体质量与安全|Langfuse, LangSmith|搭建 Agent追踪、评估和安全监控平台|04-agent-evaluation/|
|**第 5 周**|微调垂直领域模型，打造专业 Agentic AI |LlamaFactory, LoRA, vLLM|定制医疗领域专家模型并私有化部署|05-agent-model-finetuning/|


---

## 📅 详细课程安排

### 🔧 第 1 周：掌握工具调用，让智能体接入真实世界

**本周目标：**

* 掌握 Function Calling 的原理和实现方法

* 理解 MCP 协议，实现标准化工具集成

* 掌握提示词工程和上下文管理技巧

* 不使用框架构建一个简单的 Agent

**📂 配套代码：** `01-agent-tool-mcp/`


---

#### 任务 01 | 解锁智能体核心能力：用 Function Call 实现文件搜索工具

**核心痛点：** 大模型的知识有时效性，无法获取实时信息，如何突破知识边界？

**解决方案：** 通过 Function Calling 机制，让大模型能够调用外部工具和 API，获取实时数据。

**本节课你将掌握：**

* Function Calling 的工作原理和触发机制

* 工具函数的定义和参数设计规范

* 工具调用的完整流程（定义→调用→返回→解析）

* 多工具组合和链式调用技巧

* 错误处理和容错机制设计

**实战内容：**

* ✅ 实现文件搜索工具（list_files）

* ✅ 实现文件读取工具（read_file）

* ✅ 构建带工具调用的智能助手

* ✅ 实现多轮对话中的工具调用

**配套代码：**

* `tool-use/01-AgentWithTools.ipynb` - 带工具的智能体

* `tool-use/02-AgentLoopWithFunctionCalling.ipynb` - 函数调用循环

**交付成果：** 能够独立实现工具函数并集成到 AI 应用中

**时长：** 40 分钟


---

#### 任务 02 | 掌握 MCP 协议：标准化接入天气查询工具

**核心痛点：** 不同工具的接口各异，集成成本高，如何标准化管理外部工具？

**解决方案：** 使用 MCP（Model Context Protocol）协议，实现标准化的工具接入和管理。

**本节课你将掌握：**

* MCP 协议的设计理念和架构

* Server-Client 模式的工作原理

* 资源(Resources)、工具(Tools)、提示(Prompts) 三大核心概念

* stdio 模式的通信机制

**实战内容：**

* ✅ 构建 MCP 天气服务器（基于和风天气 API）

* ✅ 实现天气查询工具（get_weather）

* ✅ 测试 MCP 服务端的独立运行

**配套代码：**

* `mcp-demo/server/weather_server.py` - MCP 服务端
* `mcp-demo/client/mcp_client.py` - MCP 客户端

**交付成果：** 能够开发标准化的 MCP 工具服务器

**时长：** 40 分钟


---

#### 任务 03 | MCP 客户端实战：集成 DeepSeek 和 LangChain 框架

**核心痛点：** MCP 服务端开发完成后，如何在智能体中调用这些工具？如何与主流框架集成？

**解决方案：** 开发 MCP 客户端，将 MCP 工具集成到 DeepSeek 等大模型和 LangChain 框架中。

**本节课你将掌握：**

* MCP 客户端开发实践

* 将 MCP 工具转换为 LLM Function Call 格式

* MCP 与 DeepSeek/GPT 的集成方法

* MCP 与 LangChain 的整合方法

* 将 MCP 工具转换为 LangChain Tool

* 工具调用的完整流程

**实战内容：**

**Part 1：DeepSeek 集成**

* ✅ 实现 MCP 客户端连接天气服务器

* ✅ 实现工具格式转换器

* ✅ 集成 DeepSeek 模型进行天气查询

* ✅ 测试多轮对话中的工具调用

**Part 2：LangChain 集成**

* ✅ 实现 MCP 到 LangChain 的工具转换

* ✅ 构建基于 LangChain 的智能体

* ✅ 集成天气查询工具到 LangChain Agent

**配套代码：**

* `mcp-demo/client/mcp_client_deepseek.py` - DeepSeek 集成

* `mcp-demo/client/mcp_client_langchain.py` - LangChain 集成

**交付成果：** 掌握 MCP 在不同模型和框架中的集成方法

**时长：** 40 分钟


---

#### 任务 04 | 深入理解智能体：手搓一个Agentic AI的最小框架

**核心痛点：** 

* LangChain、LangGraph 等框架功能强大，但"黑盒"难以理解底层原理？

* 遇到问题不知道如何调试和定制？

* 如何从零构建一个清晰可控的智能体架构？

**解决方案：** 基于 GAME 设计法，手搓一个最小可复用的智能体框架，深入理解智能体的核心运行机制。

**本节课你将掌握：**

**GAME 架构设计：**

* **G (Goals)**: 目标与指令 - 定义智能体要实现的结果和策略

* **A (Actions)**: 动作/工具 - 定义智能体可调用的能力接口

* **M (Memory)**: 记忆 - 跨回合保留上下文，支持多轮对话

* **E (Environment)**: 环境 - 动作在真实世界的执行载体

**智能体循环 (Agent Loop)：**

* Prompt 构造：整合 Goals、Actions Schema、Memory 历史

* LLM 调用：发送 Prompt 并获取工具调用决策

* 环境执行：在 Environment 中执行动作并获取结果

* 记忆更新：将决策和结果写入 Memory

* 终止判断：检查是否执行了终止型动作

**实战内容：**

* ✅ 实现 Prompt 数据结构和 LLM 调用封装

* ✅ 实现 Goal（目标）和 Action（动作）抽象

* ✅ 实现 ActionRegistry（工具注册表）

* ✅ 实现 Memory（记忆管理）

* ✅ 实现 Environment（环境执行器）

* ✅ 实现 AgentLanguage（提示词生成器）

* ✅ 实现完整的 Agent Loop（智能体主循环）

* ✅ 测试文件操作场景：列出文件、读取文件、终止会话

**配套代码：**

* `ASimpleAgentFramework.ipynb` - GAME 框架完整实现

**学习收获：**

* 深入理解智能体的底层运行机制

* 掌握工具调用的完整流程

* 理解记忆管理和上下文传递

* 具备自定义智能体框架的能力

* 为后续使用 LangGraph 等框架打下坚实基础

**交付成果：** 能够从零构建智能体框架，深入理解底层原理

**时长：** 40 分钟


---

#### 任务 05（直播）| 提示词工程实战：让智能体精准理解你的需求

**核心痛点：** 

* 模型理解偏差，如何精准表达需求？

* 对话越长越乱，如何管理上下文窗口？

* 如何设计高质量的提示词模板？

**解决方案：** 

* 系统化的提示词工程方法论

* 高效的上下文管理策略

* 实战案例演示

**知识点：**

**提示词工程：**

* 提示词的基本原则：清晰性、具体性、结构化

* 零样本(Zero-shot)、少样本(Few-shot) 提示技巧

* 思维链(Chain-of-Thought) 提示方法

* 角色扮演和情境设定技巧

* 提示词模板化和复用

**上下文工程：**

* 上下文窗口的限制和优化策略

* 长文本的分块和检索方法

* 上下文的压缩和精简技巧

* 记忆管理和对话历史优化

**实战案例：**

* 从简单对话到复杂任务的提示词演进

* 多轮对话的上下文优化

**时长：** 60分钟（直播）


---

### 🤖 第 2 周：构建多角色协作系统，实现复杂任务自动化

**本周目标：**

* 掌握 LangGraph 的核心概念和开发方法

* 理解状态管理、记忆持久化、路由决策

* 掌握人机协同和并行协作的设计模式

* 完成深度研究助手项目的部署和测试

**📂 配套代码：** `02-agent-multi-role/`


---

#### 任务 06 | 从链式到图状态：LangGraph 入门实战

**核心痛点：** 单一 LLM 调用无法处理复杂任务，如何构建多角色协作系统？

**解决方案：** 使用 LangGraph 框架，通过图状态机实现复杂的智能体协作。

**本节课你将掌握：**

* LangChain 的核心概念：Chain、Agent、Memory、Tools

* LangGraph 的设计理念：从链式到图状态

* 节点(Node)和边(Edge)的定义

* 状态管理和数据流转

**实战内容：**

* ✅ 构建第一个简单的 LangGraph 应用

* ✅ 实现链式执行流程

* ✅ 理解状态机的工作原理

**配套代码：**

* `langgraph/1-Base/01-simple-graph.ipynb` - 简单图构建

* `langgraph/1-Base/02-chain.ipynb` - 链式执行

**交付成果：** 掌握 LangGraph 基础，能够构建简单图应用

**时长：** 40 分钟


---

#### 任务 07 | 智能路由与记忆管理：构建可决策、能记忆的智能体

**核心痛点：** 

* 如何让智能体根据用户输入自动选择不同的处理路径？

* 如何让智能体记住对话历史，实现真正的多轮对话？

**解决方案：** 

* 使用 LangGraph 的条件路由机制，实现智能决策

* 实现记忆持久化和外部存储机制

**本节课你将掌握：**

**智能路由：**

* 路由决策和条件分支

* 条件边(Conditional Edge)的实现

* 动态路由的设计模式

**记忆管理：**

* 记忆持久化技术

* 外部存储集成（Redis、PostgreSQL）

* 对话历史的管理策略

**实战内容：**

**Part 1：智能路由**

* ✅ 实现条件路由（根据用户意图选择不同处理路径）

* ✅ 构建智能客服路由系统

* ✅ 实现动态决策逻辑

**Part 2：记忆管理**

* ✅ 实现对话记忆管理

* ✅ 集成外部存储

* ✅ 实现会话状态持久化

**配套代码：**

* `langgraph/1-Base/03-router.ipynb` - 路由机制

* `langgraph/1-Base/04-agent-memory.ipynb` - Agent 记忆

* `langgraph/1-Base/05-chatbot-external-memory.ipynb` - 外部记忆

**交付成果：** 掌握智能路由和记忆管理的完整技术栈

**时长：** 40 分钟


---

#### 任务 08 | 人机协同与并行协作：构建可控、可扩展的智能体系统

**核心痛点：** 

* 智能体决策失误，如何让人类介入审核和纠正？

* 多个智能体同时工作，如何避免混乱和冲突？

**解决方案：** 

* 实现人机协同的中断和断点机制

* 设计并行协作的子图架构

**本节课你将掌握：**

**人机协同核心技术：**

* 中断(Interrupt)机制的原理

* 断点(Breakpoint)的设置方法

* 状态编辑和人工干预

* 动态断点的实现

* Time Travel 和状态回溯

**并行协作技术：**

* 角色分工的设计原则

* 并行执行 vs 串行执行

* 子图(Sub-graph)的组织方法

* Agent 间的通信机制

* 冲突解决和决策融合

**实战内容：**

**Part 1：人机协同**

* ✅ 实现旅行方案的人工审核

* ✅ 实现预算超支的确认机制

* ✅ 实现动态断点（根据条件触发）

* ✅ 实现状态回溯和重新执行

**Part 2：并行协作**

* ✅ 实现多角色并行协作

* ✅ 构建 AI 旅行规划多角色系统（预览）

* ✅ 实现角色间的消息传递

**配套代码：**

* `langgraph/2-Advance/01-breakpoints.ipynb` - 断点设置

* `langgraph/2-Advance/02-dynamic-breakpoints.ipynb` - 动态断点

* `langgraph/2-Advance/03-time-travel.ipynb` - 时间旅行

* `langgraph/2-Advance/05-sub-graph.ipynb` - 子图构建

**交付成果：** 掌握人机协同和多角色并行协作的完整技术

**时长：** 40 分钟


---

#### 任务 09 | 实战项目：DeepResearch 深度研究助手创建与配置

**核心痛点：** 如何构建一个能够自主进行文献调研和深度分析的智能体系统？

**解决方案：** 使用 LangGraph 构建多角色协作的深度研究助手。

**系统设计：**

* **需求场景**：研究人员需要快速了解某个领域的研究现状

* **核心能力**：

   * 自动搜索相关文献和资料

   * 智能筛选和排序信息

   * 深度分析和总结归纳

   * 生成结构化研究报告

   * 支持多轮交互式提问

**智能体架构：**

1. **搜索智能体**：负责在多个数据源搜索相关信息

2. **分析智能体**：对搜索结果进行深度分析和评估

3. **总结智能体**：将分析结果整合为结构化报告

4. **交互智能体**：处理用户的追问和深入探讨

**本节课你将完成：**

* ✅ 使用 LangGraph 创建研究助手应用

* ✅ 配置多角色协作工作流

* ✅ 集成 Tavily Search API

* ✅ 定义状态和数据模型

**配套代码：**

* `deepresearch/01-deploy-deepresearch-creating.ipynb` - 创建研究助手

* `deepresearch/deployment/research_assistant.py` - 核心代码

**交付成果：** 完成研究助手的创建和配置

**时长：** 40 分钟


---

#### 任务 10 | 实战项目：DeepResearch 容器化部署与测试

**核心痛点：** 如何将研究助手部署到生产环境并进行测试？

**解决方案：** 使用 Docker Compose 容器化部署，并通过 API 进行测试。

**本节课你将完成：**

* ✅ 使用 Docker Compose 容器化部署

* ✅ 配置环境变量和 API 密钥

* ✅ 通过 API 连接和测试智能体

* ✅ 评估研究报告的质量并优化

* ✅ 测试多轮对话和深度提问

**配套代码：**

* `deepresearch/02-deploy-deepresearch-connecting.ipynb` - 连接和测试

* `deepresearch/deployment/docker-compose.yml` - Docker 配置

**交付成果：** 完成研究助手的部署和测试

**作业 1 布置：** 

* 基于 LangGraph 构建一个多角色智能体系统（自选场景：客服、教育、医疗等）

* 要求：至少 3 个角色、状态管理、工具调用、记忆持久化

**交付成果：** 掌握大规模并行处理和 LangGraph 高级开发技巧

**时长：** 40 分钟


---

#### 任务 11（直播）| LangGraph 高级技巧与作业点评

Map-Reduce 模式：掌握大规模并行处理

**核心痛点：** 

* 如何高效处理需要并行执行的大量任务？

* 如何将大任务拆分为多个子任务并行处理？

* 如何收集和聚合并行任务的结果？

**解决方案：** 使用 LangGraph 的 Map-Reduce 模式，实现任务的并行处理和结果聚合。

**本节课你将掌握：**

**Map-Reduce 核心概念：**

* Map 阶段：将大任务拆分为多个可并行处理的小任务

* Reduce 阶段：收集所有并行任务的结果并进行聚合

* LangGraph 中的实现方式（使用 Send 和 Join）

* 适用场景：批量数据处理、多源信息聚合、并行搜索等

**Send 机制详解：**

* `Send` 的作用：动态创建并行执行流

* 如何向目标节点传递局部状态

* 局部状态 vs 全局状态的区别

* 动态并行数量的处理

**状态管理进阶：**

* 全局状态（OverallState）设计

* 局部状态（JokeState）设计

* 使用 `Annotated[list, operator.add]` 实现列表聚合

* 状态归约器（Reducer）的工作原理

* 结构化输出与 Pydantic 模型

**实战内容：**

* ✅ 构建智能笑话生成与评选系统

* ✅ 实现 Map 阶段：并行生成多个笑话

* ✅ 实现 Reduce 阶段：评选最佳笑话

* ✅ 使用 LangSmith 追踪并行执行过程

**实际应用场景：**

* **多文档摘要**：并行处理多个文档，最后生成综合摘要

* **多源信息搜索**：同时搜索多个数据源，聚合结果

* **批量内容生成**：并行生成多个创意内容，筛选最佳

* **分布式任务处理**：将大任务拆分为小任务并行执行

**配套代码：**

* `map-reduce.ipynb` - Map-Reduce 完整实现

**作业 1 点评：** 

* 点评学员提交的作业案例

* 分享创新设计和优化建议

* 架构设计的最佳实践

* LangGraph 开发的常见问题和解决方案

**交付成果：** 掌握大规模并行处理和 LangGraph 高级开发技巧

**时长：** 60 分钟（直播）


---

### 🏗️ 第 3 周：打造全栈智能体应用，一键部署到生产环境

**本周目标：**

* 掌握智能体系统的架构设计方法

* 使用 FastAPI 构建高性能后端服务

* 使用 Streamlit 构建交互式前端界面

* 掌握 Docker 容器化部署和生产环境运维

**📂 配套代码：** `03-agent-build-docker-deploy/`


---

#### 任务 12 | 架构设计实战：设计可扩展的智能体系统

**核心痛点：** Demo 能跑通，但系统混乱，如何设计可扩展的企业级架构？

**解决方案：** 采用分层架构设计，建立清晰的模块边界。

**本节课你将掌握：**

**架构设计：**

* 分层架构设计：前端、后端、智能体层、工具层

* 模块化设计原则

* API 接口设计规范(RESTful)

* 数据模型设计

* 配置管理和环境隔离

**实战内容：**

* ✅ 设计 AI 旅行规划智能体系统架构

* ✅ 定义模块边界和职责

* ✅ 设计 API 接口规范

* ✅ 设计数据模型和状态管理

**配套文档：**

* `docs/architecture_diagram.md` - 架构设计文档

* `docs/api_documentation.md` - API 接口文档

**交付成果：** 完成系统架构设计和接口定义

**时长：** 40 分钟


---

#### 任务 13 | 全栈开发实战：FastAPI 后端 + Streamlit 前端

**核心痛点：** 

* 后端接口复杂，如何高效开发和管理？

* 前端界面简陋，如何快速构建美观交互界面？

**解决方案：** 

* 使用 FastAPI 构建标准化后端服务

* 使用 Streamlit 快速构建前端界面

**本节课你将掌握：**

**后端开发（FastAPI）：**

* FastAPI 框架基础和核心特性

* API 路由和请求处理

* 异步编程和并发处理

* 数据验证和错误处理

* API 文档自动生成（Swagger UI）

* WebSocket 实时通信

**前端开发（Streamlit）：**

* Streamlit 框架基础

* 交互组件的使用（输入框、按钮、选择器、滑块等）

* 状态管理和会话管理

* 流式输出和实时反馈

* 界面布局和样式定制

* 与后端 API 的集成

**实战内容：**

**Part 1：后端开发**

* ✅ 实现智能体 API 接口（规划、查询、修改）

* ✅ 开发配置管理系统

* ✅ 集成工具调用层（天气、地图、酒店、搜索）

* ✅ 实现异步任务处理

* ✅ 集成 LangGraph 智能体

**Part 2：前端开发**

* ✅ 设计用户输入界面（目的地、预算、偏好等）

* ✅ 实现对话历史展示和管理

* ✅ 实现旅行方案可视化展示

* ✅ 实现实时状态反馈和进度条

* ✅ 集成后端 API 接口

* ✅ 实现流式输出和动态更新

**配套代码：**

**后端代码：**

* `backend/api_server.py` - API 服务器主程序

* `backend/agents/` - 智能体实现

   * `travel_agent.py` - 旅行规划智能体

   * `coordinator.py` - 协调器

   * `tools_agent.py` - 工具调用智能体

* `backend/tools/` - 工具集成

   * `weather_tool.py` - 天气查询

   * `search_tool.py` - 搜索工具

* `backend/config/` - 配置管理

* `backend/models/` - 数据模型

**前端代码：**

* `frontend/streamlit_app.py` - 前端主程序

* `frontend/components/` - UI 组件

   * `chat_interface.py` - 对话界面

   * `plan_viewer.py` - 方案展示

* `frontend/utils/` - 工具函数

   * `api_client.py` - API 客户端

**交付成果：** 完成前后端全栈开发和系统集成

**时长：** 40 分钟


---

#### 任务 14 | Docker 容器化实战：一键部署智能体系统

**核心痛点：** 

* 本地开发环境正常，部署到服务器就出问题？

* 环境依赖混乱，如何实现一键部署？

**解决方案：** 

* 使用 Docker 容器化技术实现环境隔离

* 使用 Docker Compose 实现多容器编排

**本节课你将掌握：**

**容器化部署：**

* Docker 基础概念和命令

* Dockerfile 编写最佳实践

* Docker Compose 多容器编排

* 环境变量和配置注入

* 容器网络和数据卷

* 镜像优化和分层构建

**实战内容：**

* ✅ 编写后端服务 Dockerfile

* ✅ 编写前端服务 Dockerfile

* ✅ 配置 Docker Compose 一键部署

* ✅ 设置环境变量和配置管理

* ✅ 测试容器化部署

**配套代码：**

* `backend/Dockerfile` - 后端容器配置

* `frontend/Dockerfile` - 前端容器配置

* `docker-compose.yml` - 编排配置

**交付成果：** 实现系统的容器化部署

**时长：** 40 分钟


---

#### 任务 15（直播）| 生产环境部署实战与问题排查

**核心痛点：** 

* 容器化部署遇到各种问题，如何排查和解决？

* 生产环境如何实现高可用和自动化运维？

**解决方案：** 

* 系统讲解生产环境部署的最佳实践

* 演示完整的部署流程和问题排查

**知识点：**

**生产环境实战：**

* 负载均衡和自动扩缩容

* 日志收集和监控告警

* 数据备份和容灾方案

* 性能优化和资源管理

**问题排查：**

* 常见部署问题及解决方案

* 容器日志查看和分析

* 网络连接问题排查

* 性能瓶颈定位

**实战演示：**

* 完整的生产环境部署流程

* 常见问题的排查和解决

* 监控和告警配置

**时长：** 60 分钟（直播）


---

### 📊 第 4 周：建立评估监控体系，保障智能体质量与安全

**本周目标：**

* 建立智能体评估体系和指标设计方法

* 掌握 Langfuse 追踪和评估技术

* 构建 LLM 安全监控系统

* 实现生产环境的持续监控和优化

**📂 配套代码：** `04-agent-evaluation/`


---

#### 任务 16 | 建立评估体系：用 Langfuse 追踪智能体执行过程

**核心痛点：** 智能体上线后不知道效果如何，如何科学评估和持续优化？

**解决方案：** 建立完整的评估体系，使用 Langfuse 进行追踪和评估。

**本节课你将掌握：**

**评估体系：**

* 评估的必要性和价值

* 评估指标体系设计

* 评估 vs 监控 vs 调试

* 端到端评估框架

**Langfuse 核心概念：**

* Trace、Span、Generation 的含义

* 追踪数据的结构和分析

**实战内容：**

* ✅ 设计智能体评估指标体系

* ✅ 注册 Langfuse 账号并配置

* ✅ 理解 Langfuse 的数据模型

**交付成果：** 建立评估体系框架

**时长：** 30 分钟


---

#### 任务 17 | Langfuse 集成实战：追踪 OpenAI 和 LangChain 调用

**核心痛点：** 如何将 Langfuse 集成到现有的智能体系统中？

**解决方案：** 掌握 Langfuse 的多种集成方法。

**本节课你将掌握：**

* OpenAI SDK 集成方法

* LangChain 集成方法

* 追踪多轮对话的执行过程

**实战内容：**

* ✅ 集成 Langfuse 到 OpenAI SDK

* ✅ 集成 Langfuse 到 LangChain

* ✅ 追踪工具调用和对话流程

* ✅ 分析追踪数据

**配套代码：**

* `langfuse/01_01_integration_openai_sdk.ipynb` - OpenAI 集成
* `langfuse/01_02_integration_langchain.ipynb` - LangChain 集成
* `langfuse/01_03_integration_langgraph.ipynb` - LangGraph 集成

**交付成果：** 掌握 Langfuse 的基础集成方法

**时长：** 30 分钟


---

#### 任务 18 | Langfuse 高级集成：追踪 LangGraph 多角色智能体

**核心痛点：** 如何追踪复杂的 LangGraph 多角色协作流程？

**解决方案：** 使用 Langfuse 追踪 LangGraph 应用。

**本节课你将掌握：**

* LangGraph 集成方法

* 多角色协作的追踪和可视化

* 评估旅行方案质量

**实战内容：**

* ✅ 集成 Langfuse 到 LangGraph 智能体

* ✅ 追踪多角色协作的执行过程

* ✅ 分析工具调用的性能

* ✅ 评估智能体输出质量

**配套代码：**


* `langfuse/02_evaluation_with_langchain.ipynb` - LangChain 评估

* `langfuse/03_example_langgraph_agents.ipynb` - LangGraph Agent 监控

**交付成果：** 掌握复杂智能体的追踪方法

**时长：** 40 分钟


---

#### 任务 19 | 安全监控实战：构建 LLM 攻击检测系统

**核心痛点：** 

* 如何防范 Prompt 注入攻击？

* 如何避免敏感信息泄露？

* 如何监控异常行为并实时告警？

**解决方案：** 构建完整的 LLM 安全监控系统，实时检测和防范安全风险。

**本节课你将掌握：**

**安全监控：**

* Prompt 注入攻击检测

* 敏感信息泄露防护

* 有害内容过滤

* 异常行为检测

* 实时告警机制

**评估指标：**

* 准确性(Accuracy)评估

* 相关性(Relevance)评估

* 安全性(Safety)评估

* 成本(Cost)评估

* 延迟(Latency)评估

* 自定义评估器的开发

**实战内容：**

* ✅ 构建 LLM 安全监控系统

* ✅ 实时检测恶意输入（Prompt 注入）

* ✅ 敏感信息脱敏处理

* ✅ 设置告警规则

* ✅ 分析用户行为数据

**配套代码：**

* `langfuse/04_example_llm_security_monitoring.ipynb` - 安全监控

**交付成果：** 构建完整的安全监控系统

**时长：** 40 分钟


---


---

#### 任务 20（直播）| 生产环境持续监控与性能优化实战

**核心痛点：** 智能体上线后性能劣化，用户投诉增多，如何持续监控和优化？

**解决方案：** 建立完整的生产环境监控体系，实现持续优化闭环。

**知识点：**

* 实时监控仪表盘

* 性能指标采集

* 异常检测和告警

* 用户反馈收集

* 持续优化迭代

* A/B 测试和效果对比

**实战内容：**

* ✅ 构建智能体监控仪表盘

* ✅ 设置性能告警规则

* ✅ 分析性能瓶颈

* ✅ 优化工具调用延迟

* ✅ 优化 Prompt 和上下文

* ✅ 降低 API 调用成本

**课程答疑：**

* 解答学员在评估和监控方面的疑问

* 分享生产环境的实战经验

**时长：** 60 分钟（直播）


---

### 🎯 第 5 周：微调垂直领域模型，打造专业 Agentic AI

**本周目标：**

* 理解模型微调的适用场景和价值

* 掌握 LoRA/PEFT 高效微调技术

* 使用 LlamaFactory 进行模型微调

* 掌握微调数据集构建和效果评估

* 完成垂直领域模型的微调和部署

**📂 配套代码：** `05-agent-model-finetuning/`


---

#### 任务 21 | 模型微调入门：用 LoRA 低成本优化垂直领域模型

**核心痛点：** 通用大模型在特定领域表现不佳，全量微调成本太高，如何低成本优化？

**解决方案：** 使用 LoRA/PEFT 技术进行参数高效微调，只训练少量参数即可获得优秀效果。

**本节课你将掌握：**

**微调决策：**

* 通用模型 vs 垂直领域模型

* 微调的适用场景和价值

* 微调 vs Prompt Engineering vs RAG

* 成本收益分析

* 微调策略选择

**高效微调：**

* 全量微调 vs 参数高效微调(PEFT)

* LoRA(Low-Rank Adaptation)原理

* QLoRA 量化微调技术

* Adapter、Prefix Tuning 等其他 PEFT 方法

* 微调显存优化策略

**实战内容：**

* ✅ GPT-2 模型的 LoRA 微调实践

* ✅ 垃圾短信分类任务微调

* ✅ 显存优化和参数调整

* ✅ 微调效果对比

**配套代码：**

* `lora-demo.ipynb` - LoRA 微调示例

**交付成果：** 掌握 LoRA 微调的基本方法

**时长：** 40 分钟


---

#### 任务 22 | 数据集构建实战：用 Easy Dataset 快速准备微调数据

**核心痛点：** 训练数据不足，如何快速准备高质量数据？

**解决方案：** 使用 Easy Dataset 方法高效构建领域知识数据集。

**本节课你将掌握：**

**数据集构建：**

* 数据集格式：Alpaca、ShareGPT 等

* 数据清洗和预处理

* 数据增强技术

* 数据质量评估

* Easy Dataset 方法

**实战内容：**

* ✅ 使用 Easy Dataset 构建医疗领域数据集

* ✅ 数据格式转换和验证

* ✅ 数据质量检查

**配套代码：**

* `llamafactory/01-llm-fine-tuning/dataset/` - 数据集目录

**配套文档：**

* `llamafactory/00-docs/02-LLaMA Factory：Easy Dataset 让大模型高效学习领域知识.md`

**交付成果：** 掌握高质量数据集的构建方法

**时长：** 30 分钟


---

#### 任务 23 | LlamaFactory 微调实战：微调 Qwen/DeepSeek 模型

**核心痛点：** 微调工具复杂，上手困难，如何快速进行模型微调？

**解决方案：** 使用 LlamaFactory 框架快速进行模型微调。

**本节课你将掌握：**

**LlamaFactory 实战：**

* LlamaFactory 框架介绍和架构

* 配置文件的编写方法

* 训练参数的调整策略

* 多 GPU 训练和分布式训练

* 模型合并和导出

**实战内容：**

* ✅ 使用 LlamaFactory 微调 Qwen/DeepSeek 模型

* ✅ 配置训练参数

* ✅ 启动训练并监控进度

* ✅ 模型合并和保存

**配套代码：**

* `llamafactory/01-llm-fine-tuning/llamafactory/configs/` - 配置文件

**交付成果：** 完成模型微调训练

**时长：** 40 分钟


---

#### 任务 24 | 模型评估与优化：科学评估微调效果

**核心痛点：** 微调完成后不知道效果如何，如何科学评估？

**解决方案：** 建立科学的微调效果评估方法。

**本节课你将掌握：**

**效果评估：**

* 评估指标选择：Loss、Perplexity、BLEU、ROUGE 等

* 测试集设计和验证方法

* 对比测试：微调前 vs 微调后

* 过拟合和欠拟合的诊断

* 超参数调优策略

* 模型版本管理

**实战内容：**

* ✅ 设计测试集

* ✅ 评估微调效果

* ✅ 对比微调前后的性能

* ✅ 分析问题并优化

**交付成果：** 掌握科学的模型评估方法

**作业 2 布置：** 

* 选择一个垂直领域（医疗、金融、教育、法律等），完成以下任务：

   * 构建至少 500 条高质量训练数据

   * 使用 LlamaFactory 进行模型微调

   * 评估微调效果（提供对比测试）

   * 将微调模型部署为 API 服务

   * 将微调模型集成到智能体系统中

**时长：** 30 分钟


---

#### 任务 25（直播）| 模型部署与智能体集成实战

**核心痛点：** 

* 如何将微调模型部署到生产环境？

* 如何优化推理性能和降低成本？

* 如何将微调模型集成到智能体系统？

**解决方案：** 

* 使用 vLLM 进行高性能推理部署

* 优化推理性能和成本

* 完成端到端的智能体微调项目

**知识点：**

**模型部署：**

* 模型导出和格式转换

* LoRA 权重的合并与加载

* vLLM 推理服务的部署方式

* 推理服务器配置优化

* 性能优化和加速技巧

* 推理成本优化

* 测试推理性能和吞吐量

**智能体集成：**

* 将微调模型集成到智能体系统

* API 接口封装

* 性能测试和优化

**作业 2 点评：**

* 回顾作业 2 的完成情况和要求

* 讲解优秀作业的实现思路

* 分享微调和部署的最佳实践

**课程总结：**

* 回顾 5 周学习内容

* 职业发展建议

* 后续学习路径

**时长：** 60 分钟（直播）


---

## 📦 作业设计

### 作业 1：多角色智能体系统开发（第 2 周后）

**作业目标：** 基于 LangGraph 构建一个多角色协作的智能体系统

**功能要求：**

* 至少包含 3 个不同角色的智能体

* 实现状态管理和数据传递

* 集成至少 2 个外部工具（可使用 MCP）

* 实现记忆持久化（支持多轮对话）

* 实现条件路由和动态决策

* （可选）实现人机协同交互

**场景参考：**

* 智能客服系统：接待员、问题分析师、解决方案专家

* 教育辅导系统：课程顾问、学习规划师、作业批改助手

* 医疗咨询系统：问诊助手、诊断分析师、健康建议专家

* 金融顾问系统：客户经理、风险分析师、投资顾问

* 内容创作系统：选题策划、内容撰写、质量审核

**提交内容：**

1. 完整的代码实现（GitHub 仓库）

2. 系统架构设计文档

3. 演示视频（3-5 分钟）

4. 项目 README（包含安装和运行说明）

**评分标准：**

* 功能完整性（40%）

* 代码质量（20%）

* 架构设计（20%）

* 创新性（10%）

* 文档完善度（10%）


---

### 作业 2：垂直领域智能体微调与部署（第 5 周后）

**作业目标：** 为特定领域构建定制化智能体，包含数据构建、模型微调、部署上线全流程

**功能要求：**

* 选择一个垂直领域（医疗、金融、教育、法律等）

* 构建至少 500 条高质量训练数据

* 使用 LlamaFactory 进行模型微调

* 评估微调效果（提供对比测试）

* 将微调模型部署为 API 服务

* 将微调模型集成到智能体系统中

* （可选）集成 Langfuse 进行评估和监控

**提交内容：**

1. 完整的代码实现（包含数据集）

2. 微调配置文件和训练日志

3. 效果评估报告（微调前后对比）

4. 部署文档和 API 接口说明

5. 演示视频（3-5 分钟）

**评分标准：**

* 数据质量（25%）

* 微调效果（25%）

* 部署完整性（20%）

* 评估科学性（15%）

* 系统集成（10%）

* 文档完善度（5%）


---

## 🛠️ 技术栈与环境要求

### 💻 开发环境

|组件|推荐配置|最低配置|
|:----|:----|:----|
|**操作系统**|Ubuntu 22.04 LTS|Ubuntu 20.04+ / Windows 10+ / macOS 12+|
|**CPU**|8 核心|4 核心|
|**内存**|16 GB|8 GB|
|**存储**|200 GB SSD|100 GB|
|**GPU**|NVIDIA RTX 3090/4090 (24GB)|NVIDIA GTX 1080 (8GB) 或无 GPU|
|**Python**|3.10.x|3.10+|

### 🔑 API 密钥准备

|API 服务|用途|获取方式|是否必需|
|:----|:----|:----|:----|
|**OpenAI API**|GPT-4/GPT-3.5|[https://platform.openai.com](https://platform.openai.com/)|可选|
|**DeepSeek API**|DeepSeek-R1/Chat|[https://platform.deepseek.com](https://platform.deepseek.com/)|推荐|
|**和风天气 API**|MCP 天气工具|[https://dev.qweather.com](https://dev.qweather.com/)|第 1 周必需|
|**Tavily API**|LangGraph 搜索|[https://tavily.com](https://tavily.com/)|第 2 周推荐|
|**Langfuse**|评估监控|[https://cloud.langfuse.com](https://cloud.langfuse.com/)|第 4 周必需|
|**LangSmith**|LangChain 监控|[https://smith.langchain.com](https://smith.langchain.com/)|第 4 周可选|

### 🖥️ 一键部署虚拟机环境

**为了让零基础学员快速上手，我们提供了配置完整的虚拟机环境：**

**环境说明：**

* ✅ 预装 Python 3.10、Docker、Git 等开发工具

* ✅ 预配置课程所需的所有依赖包

* ✅ 包含完整的课程代码和数据集

* ✅ 支持 VMware Workstation、VirtualBox 等虚拟机软件

* ✅ 基于 Ubuntu 22.04 LTS，8GB 内存，50GB 存储

**下载方式：**

* **虚拟机镜像（OVF 格式）**：[下载链接见课件首页]

* **百度网盘**：[备用链接]

* **阿里云盘**：[备用链接]

**使用说明：**

1. 下载虚拟机镜像（OVF 格式）

2. 使用 VMware Workstation 或 VirtualBox 导入镜像

3. 启动虚拟机，默认用户名：`agent` 密码：`agent101`

4. 配置 API 密钥（在 `.env` 文件中）

5. 开始学习之旅！

**适用人群：**

* 不熟悉 Linux 环境配置的学员

* 希望快速开始实战的学员

* 遇到环境问题难以解决的学员


---

## 🎓 学习目标检查清单

### ✅ 第 1 周：掌握工具调用，让智能体接入真实世界

* ☐ 掌握 Function Calling，能够集成外部工具

* ☐ 理解 MCP 协议，能够开发 MCP 服务端和客户端

* ☐ 掌握提示词工程的基本原则和方法

* ☐ 掌握上下文管理和优化策略

* ☐ 能够手搓一个简单的智能体框架

### ✅ 第 2 周：构建多角色协作系统，实现复杂任务自动化

* ☐ 理解 LangGraph 的核心概念和设计理念

* ☐ 能够设计和实现复杂的状态管理方案

* ☐ 掌握记忆持久化技术

* ☐ 能够实现条件路由和动态决策

* ☐ 掌握人机协同的中断机制

* ☐ 能够构建多角色并行协作的智能体系统

* ☐ 完成深度研究助手项目部署

* ☐ 完成作业 1：多角色智能体系统开发

### ✅ 第 3 周：打造全栈智能体应用，一键部署到生产环境

* ☐ 能够设计可扩展的智能体系统架构

* ☐ 掌握 FastAPI 后端开发

* ☐ 掌握 Streamlit 前端开发

* ☐ 能够使用 Docker 进行容器化部署

* ☐ 理解企业级部署的最佳实践

* ☐ 完成完整系统的部署和上线

### ✅ 第 4 周：建立评估监控体系，保障智能体质量与安全

* ☐ 理解评估体系的必要性和价值

* ☐ 能够集成 Langfuse 进行追踪和评估

* ☐ 掌握各类评估指标的定义和计算

* ☐ 能够构建 LLM 安全监控系统

* ☐ 掌握生产环境的持续监控和优化方法

### ✅ 第 5 周：微调垂直领域模型，打造专业 Agentic AI

* ☐ 理解模型微调的适用场景

* ☐ 掌握 LoRA 和 PEFT 技术

* ☐ 能够使用 LlamaFactory 进行模型微调

* ☐ 掌握微调数据集的构建方法

* ☐ 能够评估微调效果并进行优化

* ☐ 能够将微调模型部署到生产环境

* ☐ 完成作业 2：垂直领域模型微调与部署


---

## 🎯 课程总结与职业发展

### 🏆 课程收获

通过 5 周的系统学习和实战训练，你将获得：

**1. 核心技能**

* ✅ 工具集成能力：掌握 Function Call、MCP 协议、上下文工程

* ✅ 系统设计能力：掌握 LangGraph 多角色协作、状态管理、人机交互

* ✅ 工程实践能力：掌握 FastAPI、Streamlit、Docker 等技术栈

* ✅ 评估优化能力：掌握 Langfuse 评估、LLM 安全监控

* ✅ 模型定制能力：掌握 LoRA/LlamaFactory 微调技术


**2. 实战项目**（6 个完整项目）

**第 1 周实战项目：**

* ✅ **MCP 天气工具系统**：基于 Model Context Protocol 的标准化工具集成

   * 技术栈：MCP SDK、和风天气 API、Python

   * 应用场景：天气查询、位置服务、信息检索

   * 学习收获：掌握 MCP 协议的 Server-Client 模式、工具标准化接入

* ✅ **GAME 智能体框架**：手搓可复用的最小智能体框架

   * 技术栈：OpenAI API、纯 Python 实现

   * 应用场景：文件操作、任务执行、自定义智能体

   * 学习收获：深入理解 Goals/Actions/Memory/Environment 四大组件

**第 2 周实战项目：**

* ✅ **DeepResearch 深度研究助手**：多角色协作的文献研究系统

   * 技术栈：LangGraph、LangChain、Tavily Search API

   * 应用场景：学术研究、市场调研、竞品分析、行业报告

   * 学习收获：掌握多智能体协作、状态管理、人机协同

**第 3 周实战项目：**

* ✅ **AI 旅行规划智能体**：企业级全栈智能体系统

   * 技术栈：FastAPI、Streamlit、Docker、LangGraph

   * 应用场景：旅行规划、行程定制、预算管理、推荐服务

   * 学习收获：掌握前后端开发、容器化部署、生产环境运维

**第 4 周实战项目：**

* ✅ **LLM 安全监控系统**：智能体评估与风险防控平台

   * 技术栈：Langfuse、Prompt 注入检测、实时告警

   * 应用场景：安全监控、质量评估、性能优化、合规审计

   * 学习收获：掌握评估体系设计、安全监控、性能优化

**第 5 周实战项目：**

* ✅ **垂直领域微调模型**：医疗/金融领域定制化智能体

   * 技术栈：LlamaFactory、LoRA/PEFT、vLLM

   * 应用场景：医疗问答、金融分析、法律咨询、教育辅导

   * 学习收获：掌握数据集构建、模型微调、推理部署

**课程作业：**

* ✅ **作业 1**：多角色智能体系统开发（自选场景）

* ✅ **作业 2**：垂直领域智能体微调与部署（完整链路）


**3. 职业能力**

* ✅ **AI 工程师岗位**：能够独立开发和部署 AI 应用

* ✅ **智能体架构师**：能够设计复杂的多角色协作系统

* ✅ **AI 产品经理**：深度理解 AI 技术实现和商业化路径

* ✅ **技术团队负责人**：能够评估技术方案和管理 AI 项目

* ✅ **AI 创业者**：掌握从 0 到 1 构建 AI 产品的完整技能


---

## ❓ 常见问题 FAQ

### Q1: 我没有 GPU，能学习这门课程吗？

**A:** 可以！大部分内容都可以在 CPU 环境下学习：

* 第 1-4 周：完全不需要 GPU，使用云端 API 即可

* 第 5 周（微调）：需要使用 GPU，可以选择：

* **虚拟机环境**：我们提供的虚拟机可以帮助你快速完成除微调外的所有内容

### Q2: 这门课需要多长时间学完？

**A:** 课程设计为 5 周行动营：

* **全职学习**：5 周完成全部内容（每天 2-3 小时）

* **业余学习**（每天 1-2 小时）：7-8 周完成核心内容

* **深度实践**：建议预留 2-3 个月时间，结合作业深化理解

**学习建议：**

* 每节课 40 分钟，建议配合动手实践

* 直播课集中答疑，解决学习中的问题

* 作业完成后可获得完整项目经验

### Q3: 课程代码支持哪些大模型？

**A:** 课程设计具有很好的模型兼容性：

* **支持的 LLM**：OpenAI GPT 系列、DeepSeek、Claude、Qwen、Llama、GLM 等

* **推荐使用**：

   * **DeepSeek**（性价比高，中文友好，推荐）

   * **GPT-4**（效果最好，成本较高）

   * **Qwen**（国产开源，可本地部署）

* **替换方式**：代码采用统一的 LLM 接口，切换模型只需修改配置

### Q4: 作业必须完成吗？

**A:** 强烈建议完成：

* ✅ 作业是学习闭环的重要环节

* ✅ 通过实战巩固知识，深化理解

* ✅ 获得可写入简历的项目经验

* ✅ 作业会在直播课中点评和答疑

* ✅ 优秀作业将获得展示机会

**作业提交方式：**

* GitHub 仓库（推荐）

* 操作文档

### Q5: 课程项目能否用于商业项目？

**A:** 可以！但需要注意：

* ✅ **代码许可**：项目采用 MIT 协议，可自由使用和修改

* ⚠️ **API 费用**：生产环境需要自行承担 API 调用费用

* ⚠️ **模型许可**：确认使用的大模型支持商业使用

* ⚠️ **数据合规**：确保用户数据处理符合隐私法规（GDPR、个人信息保护法等）

### Q6: 如何获得学习支持？

**A:** 多种支持渠道：

* **专属学习群**：课程学员专属交流群，讲师和助教在线答疑


* **直播答疑**：每周直播课进行集中答疑（共 5 次）

* **代码注释**：项目代码有详细的中文注释

* **配套文档**：每个模块都有完整的技术文档

* **虚拟机环境**：提供配置完整的虚拟机，遇到环境问题可快速恢复

### Q7: 虚拟机环境如何使用？

**A:** 虚拟机环境使用指南：

**适用场景：**

* 不熟悉 Linux 环境配置

* 遇到环境依赖问题

* 希望快速开始学习

* Windows 用户（推荐）

**使用步骤：**

1. 下载虚拟机镜像（OVF 格式，约 15GB）

2. 安装 VMware Workstation 或 VirtualBox

3. 导入虚拟机镜像

4. 启动虚拟机（用户名：`agent` 密码：`agent101`）

5. 配置 API 密钥（在 `~/.env` 文件中）

6. 开始学习！

**环境内容：**

* ✅ Ubuntu 22.04 LTS

* ✅ Python 3.10 + 所有依赖包

* ✅ Docker + Docker Compose

* ✅ 完整的课程代码

* ✅ JupyterLab（已配置）

* ✅ VS Code（已配置）

**注意事项：**

* 虚拟机需要至少 8GB 内存

* 推荐分配 4 核 CPU

* 需要 150GB 磁盘空间

### Q8: 学完课程能找到工作吗？

**A:** 课程设计对标企业级技能要求：

**适合岗位：**

* AI 应用开发工程师（15-30K）

* AI Agent 开发工程师（20-40K）

* 全栈 AI 工程师（25-45K）

* AI 产品经理（20-35K）

**职业建议：**

* 完成 2 个作业，获得完整项目经验

* 将项目部署到云端，提供在线 Demo

* 在 GitHub 展示项目代码和文档

* 在简历中突出实战经验和技术栈

* 准备好讲解项目的技术细节
