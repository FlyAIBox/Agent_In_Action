## 自我介绍

<div style="display: flex; gap: 10px;">
  <img src="https://cdn.jsdelivr.net/gh/Fly0905/note-picture@main/imag/202508091136542.png" style="width: 60%; height: auto;">
  <img src="https://cdn.jsdelivr.net/gh/Fly0905/note-picture@main/imag/202508091123568.jpg" style="width: 40%; height: auto;">
</div>
### 《萤火AI百宝箱》

<div style="display: flex; gap: 10px;">
  <img src="https://cdn.jsdelivr.net/gh/Fly0905/note-picture@main/imag/202508091509667.png" style="width: 50%; height: auto;">
  <img src="https://cdn.jsdelivr.net/gh/Fly0905/note-picture@main/imag/202508091510436.png" style="width: 50%; height: auto;">
</div>


### 《企业大模型实战》

<div style="display: flex; gap: 10px;"> <img src="https://cdn.jsdelivr.net/gh/Fly0905/note-picture@main/imag/202508091123923.jpg" style="width: 50%;  height: auto;"> <img src="https://cdn.jsdelivr.net/gh/Fly0905/note-picture@main/imag/202508091123483.jpg" style="width: 50%;  height: auto;">  </div> 



## 培训内容

### 大模型微调、推理、压测与评估

#### 一、 微调（Fine-tuning）的基本概念与训练流程

大模型（如 DeepSeek-R1）在预训练阶段通过**海量通用文本学习了广泛的语言知识和世界常识**。

然而，这些模型**并不能直接完美地解决眼科领域的特定问题**，比如精准回答青光眼病人的疑问，或从眼科病历中提取关键信息。

**1. 微调的定义与技术要点**

**微调**是一种将预训练模型适应到特定任务和领域的技术。它利用特定领域的小规模高质量数据集，在预训练模型的基础上进行进一步训练，使其能够更好地理解和处理特定任务。这就像给一个通才医生进行专科培训，使其成为一名优秀的眼科专家。

**核心技术要点：**

- **参数高效微调（PEFT）：** 传统的微调方法需要更新模型的所有参数，计算和显存开销巨大。PEFT 技术，如 **LoRA (Low-Rank Adaptation)**，通过在模型中注入少量可训练的参数矩阵，大幅减少了训练所需的计算资源，同时保持了接近全参数微调的效果。这对于使用 L20 GPU 等有限硬件资源的企业非常重要。
- **分布式训练：** 对于参数量巨大的模型，单张显卡往往无法承载。**DeepSpeed ZeRO-3** 等技术可以将模型的**参数、梯度和优化器状态**分散到多张 GPU 卡上，极大地降低了单张卡的显存需求，使得在有限硬件条件下训练大型模型成为可能。

**2. 数据准备与预处理**

微调的效果高度依赖于数据的质量。高质量、高相关性的数据集是成功的关键。

- **数据收集：** 收集眼科领域的问答对、结构化病历数据、医疗文献摘要等。这些数据必须是真实且准确的。
- **数据清洗：** 去除重复、错误或不相关的数据。处理特殊字符、拼写错误等。
- **数据标注：** 根据微调任务（如问答、信息抽取），对数据进行格式化标注。例如，问答对数据通常需要遵循 `<指令>`、`<输入>`、`<输出>` 的格式。
- **数据增强：** 在数据量有限时，可以通过同义词替换、句子重组等方式扩充数据集，以提高模型的泛化能力。
- **工具支持：** 使用 **Easy Dataset** 等工具可以帮助快速完成数据集的构建和格式化，大大降低了数据准备的门槛。

> **微调数据集构建方式：**
>
> **主要构建方式：**
>
> 1. **获取公开数据集** - 包括HuggingFace、Kaggle等主流平台
> 2. **基于特定领域文献合成数据集** - 使用Easy DataSet等工具
>
> **核心构建流程：**
>
> - 数据源获取 → 文本块切分 → QA对生成 → 质量校验 → 格式转换
>
> **关键技术要点：**
>
> - 上下文处理技术（分块策略、重叠窗口）
> - 去重与质量控制（语义相似度、自动评估）
>
> **重要注意事项：**
>
> - 数据使用协议的合规性检查
> - 常见格式转换（Alpaca、ShareGPT、COT等）

**3. 微调模型的训练与评估**

- 训练流程： 1.  选择一个合适的微调工具（如 Llamafactory）。
  2. 导入准备好的数据集。
  3. 配置训练参数，如学习率（Learning Rate）、批处理大小（Batch Size）和训练轮数（Epochs）。
  4. 选择微调方法（如 LoRA）和分布式训练策略（如 DeepSpeed ZeRO-3）。
  5. 开始训练，实时监控训练损失（Loss）等指标。
- **模型评估：** 训练完成后，需要对模型进行评估，以判断其在特定任务上的表现。
  - **自动评估：** 使用 Bleu、Rouge 等指标对生成文本进行量化评分。
  - **人工评估：** 这是最重要、最可靠的评估方式。让眼科专家对模型生成的答案进行打分，评价其准确性、流畅性和专业性。通过人工评估可以发现模型在特定场景下的不足，为下一轮优化提供方向。

------

#### 二、 微调技术在企业中的应用

**1. 处理行业特定问题的微调方法**

- **需求分析：** 与医院各部门沟通，明确需要解决的痛点。例如：
  - **智能问答：** 针对患者的常见问题提供专业、一致的回答。
  - **病历摘要：** 自动提取患者病历中的关键信息，如诊断结果、用药情况、手术记录等。
  - **文献检索与摘要：** 帮助医生快速从海量医学文献中找到相关信息并生成摘要。
- **定制化数据集：** * 根据上述需求，构建包含“问题-答案”、“病历-摘要”等特定格式的定制数据集。
  - 数据来源可以是医院内部的脱敏病历、医生撰写的诊疗指南、以及专业的医学问答库等。

**2. 如何定制化训练大模型以满足行业需求**

- **定制化训练方案：**
  - **任务导向的训练：** 明确每个微调任务的具体目标，避免训练一个“万金油”模型。
  - **增量训练：** 随着业务发展，不断收集新的数据，对模型进行增量微调，使其能力持续提升。
  - **迭代优化：** 将“需求分析 - 数据准备 - 模型训练 - 评估 - 优化”作为一个闭环流程，持续迭代，逐步提高模型的性能。

------

#### 三、 推理、压测与评估

微调后的模型需要部署到生产环境中，才能真正发挥价值。推理、压测和评估是确保模型稳定、高效运行的关键环节。

**1. 高性能推理：**

- **推理引擎：** 使用 **vLLM** 等高性能推理框架。vLLM 针对大模型推理进行了深度优化，例如通过连续批处理（Continuous Batching）等技术，显著提高了模型的吞吐量，降低了延迟，让模型可以同时处理更多用户的请求。
- **部署：** 将微调后的模型文件部署到推理服务中，通过 API 接口对外提供服务。

**2. 压测（Stress Testing）：**

- **目的：** 模拟高并发的用户请求，测试模型在实际应用中的性能极限。
- **关注指标：**
  - **吞吐量（Throughput）：** 模型在单位时间内能处理的请求数量。
  - **延迟（Latency）：** 从发送请求到接收到响应所需的时间。
  - **资源占用：** CPU、GPU、内存等资源的消耗情况。
- **方法：** 使用专业的压测工具，模拟多用户同时访问，记录上述指标，以确定服务能稳定支持的并发量，为生产环境的资源规划提供依据。

**3. 评估（Post-deployment Evaluation）：**

- **持续监控：** 部署后并非一劳永逸。需要持续监控模型的运行状态，如错误率、回答质量等。
- **用户反馈：** 建立用户反馈机制，收集医生和护士对模型使用体验的意见，将其作为模型迭代优化的重要输入。
- **A/B 测试：** 在不同的用户群体中部署不同版本的模型，对比其性能和效果，科学地选择最佳的模型版本。

## 四、QA

### 数据集

> https://huggingface.co/
>
> https://www.kaggle.com/
>
> https://modelscope.cn/datasets/AI-ModelScope/medical-o1-reasoning-SFT/file/view/master/medical_o1_sft_Chinese.json?id=60382&status=2
>
> https://www.scnet.cn/ui/mall/search/goods?common1=DATA&common2=DATA-330

### 算力显存计算

> https://modal.com/blog/how-much-vram-need-fine-tuning