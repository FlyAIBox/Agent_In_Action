{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64f7fbb4-e992-4d5d-b7c7-c2309fc0bc31",
   "metadata": {},
   "source": [
    "# ä½¿ç”¨LLaMA Factoryå¾®è°ƒLlama3æ¨¡å‹\n",
    "\n",
    "[LLaMA Factory](https://github.com/hiyouga/LLaMA-Factory)æ˜¯ä¸€æ¬¾å¼€æºä½ä»£ç å¤§æ¨¡å‹å¾®è°ƒæ¡†æ¶ï¼Œé›†æˆäº†ä¸šç•Œæœ€å¹¿æ³›ä½¿ç”¨çš„å¾®è°ƒæŠ€æœ¯ï¼Œæ”¯æŒé€šè¿‡Web UIç•Œé¢é›¶ä»£ç å¾®è°ƒå¤§æ¨¡å‹ï¼Œç›®å‰å·²ç»æˆä¸ºå¼€æºç¤¾åŒºå†…æœ€å—æ¬¢è¿çš„å¾®è°ƒæ¡†æ¶ï¼ŒGitHubæ˜Ÿæ ‡è¶…è¿‡2ä¸‡ã€‚æœ¬æ•™ç¨‹å°†åŸºäºMeta AIå¼€æºçš„Llama-3 8Bæ¨¡å‹ï¼Œä»‹ç»å¦‚ä½•ä½¿ç”¨PAIå¹³å°åŠLLaMA Factoryè®­ç»ƒæ¡†æ¶å®Œæˆæ¨¡å‹çš„ä¸­æ–‡åŒ–ä¸è§’è‰²æ‰®æ¼”å¾®è°ƒå’Œè¯„ä¼°ã€‚ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe138c06-db8f-4422-b502-62bfcfca19e2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## è¿è¡Œç¯å¢ƒè¦æ±‚\n",
    "\n",
    "- GPUæ¨èä½¿ç”¨24GBæ˜¾å­˜çš„A10ï¼ˆ`ecs.gn7i-c8g1.2xlarge`ï¼‰æˆ–æ›´é«˜é…ç½®\n",
    "- é•œåƒé€‰æ‹©DSWå®˜æ–¹é•œåƒ`modelscope:1.18.0-pytorch2.3.0-gpu-py310-cu121-ubuntu22.04`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9fdf00-1e2c-45b9-8d56-6302d943f0f4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## ç³»ç»Ÿç¯å¢ƒæ£€æŸ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd803045-f131-448a-8023-de15d7574774",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T07:06:39.334377Z",
     "iopub.status.busy": "2025-11-25T07:06:39.333920Z",
     "iopub.status.idle": "2025-11-25T07:06:43.691259Z",
     "shell.execute_reply": "2025-11-25T07:06:43.690795Z",
     "shell.execute_reply.started": "2025-11-25T07:06:39.334352Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple/\n",
      "Requirement already satisfied: pandas==2.2.2 in /usr/local/lib/python3.10/site-packages (2.2.2)\n",
      "Requirement already satisfied: tabulate==0.9.0 in /usr/local/lib/python3.10/site-packages (0.9.0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/site-packages (from pandas==2.2.2) (2024.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/site-packages (from pandas==2.2.2) (2024.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/site-packages (from pandas==2.2.2) (2.9.0.post0)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/site-packages (from pandas==2.2.2) (1.26.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas==2.2.2) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "### ç¯å¢ƒä¿¡æ¯\n",
      "| é¡¹ç›®         | ä¿¡æ¯                                                                              |\n",
      "|:-------------|:----------------------------------------------------------------------------------|\n",
      "| æ“ä½œç³»ç»Ÿ     | Linux Ubuntu 22.04.4 LTS                                                          |\n",
      "| CPU ä¿¡æ¯     | Intel(R) Xeon(R) Platinum 8369B CPU @ 2.70GHz (4 physical cores, 8 logical cores) |\n",
      "| å†…å­˜ä¿¡æ¯     | 28.91 GB (Available: 27.44 GB)                                                    |\n",
      "| GPU ä¿¡æ¯     | NVIDIA A10 (23028 MiB)                                                            |\n",
      "| CUDA ä¿¡æ¯    | 12.1                                                                              |\n",
      "| Python ç‰ˆæœ¬  | 3.10.14                                                                           |\n",
      "| Conda ç‰ˆæœ¬   | Conda not found                                                                   |\n",
      "| ç‰©ç†ç£ç›˜ç©ºé—´ | Total: 97.87 GB, Used: 0.86 GB, Free: 97.00 GB                                    |\n"
     ]
    }
   ],
   "source": [
    "# ğŸ” ç¯å¢ƒä¿¡æ¯æ£€æŸ¥è„šæœ¬\n",
    "#\n",
    "# æœ¬è„šæœ¬çš„ä½œç”¨ï¼š\n",
    "# 1. å®‰è£… pandas åº“ç”¨äºæ•°æ®è¡¨æ ¼å±•ç¤º\n",
    "# 2. æ£€æŸ¥ç³»ç»Ÿçš„å„é¡¹é…ç½®ä¿¡æ¯\n",
    "# 3. ç”Ÿæˆè¯¦ç»†çš„ç¯å¢ƒæŠ¥å‘Šè¡¨æ ¼\n",
    "#\n",
    "# å¯¹äºåˆå­¦è€…æ¥è¯´ï¼Œè¿™ä¸ªæ­¥éª¤å¸®åŠ©ä½ ï¼š\n",
    "# - äº†è§£å½“å‰è¿è¡Œç¯å¢ƒçš„ç¡¬ä»¶é…ç½®\n",
    "# - ç¡®è®¤æ˜¯å¦æ»¡è¶³æ¨¡å‹è¿è¡Œçš„æœ€ä½è¦æ±‚\n",
    "# - å­¦ä¹ å¦‚ä½•é€šè¿‡ä»£ç è·å–ç³»ç»Ÿä¿¡æ¯\n",
    "\n",
    "# å®‰è£… pandas åº“ - ç”¨äºåˆ›å»ºå’Œå±•ç¤ºæ•°æ®è¡¨æ ¼\n",
    "# pandas æ˜¯ Python ä¸­æœ€æµè¡Œçš„æ•°æ®å¤„ç†å’Œåˆ†æåº“\n",
    "%pip install pandas==2.2.2 tabulate==0.9.0\n",
    "\n",
    "import platform # å¯¼å…¥ platform æ¨¡å—ä»¥è·å–ç³»ç»Ÿä¿¡æ¯\n",
    "import os # å¯¼å…¥ os æ¨¡å—ä»¥ä¸æ“ä½œç³»ç»Ÿäº¤äº’\n",
    "import subprocess # å¯¼å…¥ subprocess æ¨¡å—ä»¥è¿è¡Œå¤–éƒ¨å‘½ä»¤\n",
    "import pandas as pd # å¯¼å…¥ pandas æ¨¡å—ï¼Œé€šå¸¸ç”¨äºæ•°æ®å¤„ç†ï¼Œè¿™é‡Œç”¨äºåˆ›å»ºè¡¨æ ¼\n",
    "import shutil # å¯¼å…¥ shutil æ¨¡å—ä»¥è·å–ç£ç›˜ç©ºé—´ä¿¡æ¯\n",
    "\n",
    "# è·å– CPU ä¿¡æ¯çš„å‡½æ•°ï¼ŒåŒ…æ‹¬æ ¸å¿ƒæ•°é‡\n",
    "def get_cpu_info():\n",
    "    cpu_info = \"\" # åˆå§‹åŒ– CPU ä¿¡æ¯å­—ç¬¦ä¸²\n",
    "    physical_cores = \"N/A\"\n",
    "    logical_cores = \"N/A\"\n",
    "\n",
    "    if platform.system() == \"Windows\": # å¦‚æœæ˜¯ Windows ç³»ç»Ÿ\n",
    "        cpu_info = platform.processor() # ä½¿ç”¨ platform.processor() è·å– CPU ä¿¡æ¯\n",
    "        try:\n",
    "            # è·å– Windows ä¸Šçš„æ ¸å¿ƒæ•°é‡ (éœ€è¦ WMI)\n",
    "            import wmi\n",
    "            c = wmi.WMI()\n",
    "            for proc in c.Win32_Processor():\n",
    "                physical_cores = proc.NumberOfCores\n",
    "                logical_cores = proc.NumberOfLogicalProcessors\n",
    "        except:\n",
    "            pass # å¦‚æœ WMI ä¸å¯ç”¨ï¼Œå¿½ç•¥é”™è¯¯\n",
    "\n",
    "    elif platform.system() == \"Darwin\": # å¦‚æœæ˜¯ macOS ç³»ç»Ÿ\n",
    "        # åœ¨ macOS ä¸Šä½¿ç”¨ sysctl å‘½ä»¤è·å– CPU ä¿¡æ¯å’Œæ ¸å¿ƒæ•°é‡\n",
    "        os.environ['PATH'] = os.environ['PATH'] + os.pathsep + '/usr/sbin' # æ›´æ–° PATH ç¯å¢ƒå˜é‡\n",
    "        try:\n",
    "            process_brand = subprocess.Popen(['sysctl', \"machdep.cpu.brand_string\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            stdout_brand, stderr_brand = process_brand.communicate()\n",
    "            cpu_info = stdout_brand.decode().split(': ')[1].strip() if stdout_brand else \"Could not retrieve CPU info\"\n",
    "\n",
    "            process_physical = subprocess.Popen(['sysctl', \"hw.physicalcpu\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            stdout_physical, stderr_physical = process_physical.communicate()\n",
    "            physical_cores = stdout_physical.decode().split(': ')[1].strip() if stdout_physical else \"N/A\"\n",
    "\n",
    "            process_logical = subprocess.Popen(['sysctl', \"hw.logicalcpu\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            stdout_logical, stderr_logical = process_logical.communicate()\n",
    "            logical_cores = stdout_logical.decode().split(': ')[1].strip() if stdout_logical else \"N/A\"\n",
    "\n",
    "        except:\n",
    "            cpu_info = \"Could not retrieve CPU info\"\n",
    "            physical_cores = \"N/A\"\n",
    "            logical_cores = \"N/A\"\n",
    "\n",
    "    else:  # Linux ç³»ç»Ÿ\n",
    "        try:\n",
    "            # åœ¨ Linux ä¸Šè¯»å– /proc/cpuinfo æ–‡ä»¶è·å– CPU ä¿¡æ¯å’Œæ ¸å¿ƒæ•°é‡\n",
    "            with open('/proc/cpuinfo') as f:\n",
    "                physical_cores_count = 0\n",
    "                logical_cores_count = 0\n",
    "                cpu_info_lines = []\n",
    "                for line in f:\n",
    "                    if line.startswith('model name'): # æŸ¥æ‰¾ä»¥ 'model name'å¼€å¤´çš„è¡Œ\n",
    "                        if not cpu_info: # åªè·å–ç¬¬ä¸€ä¸ª model name\n",
    "                            cpu_info = line.split(': ')[1].strip()\n",
    "                    elif line.startswith('cpu cores'): # æŸ¥æ‰¾ä»¥ 'cpu cores' å¼€å¤´çš„è¡Œ\n",
    "                        physical_cores_count = int(line.split(': ')[1].strip())\n",
    "                    elif line.startswith('processor'): # æŸ¥æ‰¾ä»¥ 'processor' å¼€å¤´çš„è¡Œ\n",
    "                        logical_cores_count += 1\n",
    "                physical_cores = str(physical_cores_count) if physical_cores_count > 0 else \"N/A\"\n",
    "                logical_cores = str(logical_cores_count) if logical_cores_count > 0 else \"N/A\"\n",
    "                if not cpu_info:\n",
    "                     cpu_info = \"Could not retrieve CPU info\"\n",
    "\n",
    "        except:\n",
    "            cpu_info = \"Could not retrieve CPU info\"\n",
    "            physical_cores = \"N/A\"\n",
    "            logical_cores = \"N/A\"\n",
    "\n",
    "    return f\"{cpu_info} ({physical_cores} physical cores, {logical_cores} logical cores)\" # è¿”å› CPU ä¿¡æ¯å’Œæ ¸å¿ƒæ•°é‡\n",
    "\n",
    "\n",
    "# è·å–å†…å­˜ä¿¡æ¯çš„å‡½æ•°\n",
    "def get_memory_info():\n",
    "    mem_info = \"\" # åˆå§‹åŒ–å†…å­˜ä¿¡æ¯å­—ç¬¦ä¸²\n",
    "    if platform.system() == \"Windows\":\n",
    "        # åœ¨ Windows ä¸Šä¸å®¹æ˜“é€šè¿‡æ ‡å‡†åº“è·å–ï¼Œéœ€è¦å¤–éƒ¨åº“æˆ– PowerShell\n",
    "        mem_info = \"Requires external tools on Windows\" # è®¾ç½®æç¤ºä¿¡æ¯\n",
    "    elif platform.system() == \"Darwin\": # å¦‚æœæ˜¯ macOS ç³»ç»Ÿ\n",
    "        # åœ¨ macOS ä¸Šä½¿ç”¨ sysctl å‘½ä»¤è·å–å†…å­˜å¤§å°\n",
    "        process = subprocess.Popen(['sysctl', \"hw.memsize\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE) # è¿è¡Œ sysctl å‘½ä»¤\n",
    "        stdout, stderr = process.communicate() # è·å–æ ‡å‡†è¾“å‡ºå’Œæ ‡å‡†é”™è¯¯\n",
    "        mem_bytes = int(stdout.decode().split(': ')[1].strip()) # è§£æè¾“å‡ºï¼Œè·å–å†…å­˜å¤§å°ï¼ˆå­—èŠ‚ï¼‰\n",
    "        mem_gb = mem_bytes / (1024**3) # è½¬æ¢ä¸º GB\n",
    "        mem_info = f\"{mem_gb:.2f} GB\" # æ ¼å¼åŒ–è¾“å‡º\n",
    "    else:  # Linux ç³»ç»Ÿ\n",
    "        try:\n",
    "            # åœ¨ Linux ä¸Šè¯»å– /proc/meminfo æ–‡ä»¶è·å–å†…å­˜ä¿¡æ¯\n",
    "            with open('/proc/meminfo') as f:\n",
    "                total_mem_kb = 0\n",
    "                available_mem_kb = 0\n",
    "                for line in f:\n",
    "                    if line.startswith('MemTotal'): # æŸ¥æ‰¾ä»¥ 'MemTotal' å¼€å¤´çš„è¡Œ\n",
    "                        total_mem_kb = int(line.split(':')[1].strip().split()[0]) # è§£æè¡Œï¼Œè·å–æ€»å†…å­˜ï¼ˆKBï¼‰\n",
    "                    elif line.startswith('MemAvailable'): # æŸ¥æ‰¾ä»¥ 'MemAvailable' å¼€å¤´çš„è¡Œ\n",
    "                         available_mem_kb = int(line.split(':')[1].strip().split()[0]) # è§£æè¡Œï¼Œè·å–å¯ç”¨å†…å­˜ï¼ˆKBï¼‰\n",
    "\n",
    "                if total_mem_kb > 0:\n",
    "                    total_mem_gb = total_mem_kb / (1024**2) # è½¬æ¢ä¸º GB\n",
    "                    mem_info = f\"{total_mem_gb:.2f} GB\" # æ ¼å¼åŒ–è¾“å‡ºæ€»å†…å­˜\n",
    "                    if available_mem_kb > 0:\n",
    "                        available_mem_gb = available_mem_kb / (1024**2)\n",
    "                        mem_info += f\" (Available: {available_mem_gb:.2f} GB)\" # æ·»åŠ å¯ç”¨å†…å­˜ä¿¡æ¯\n",
    "                else:\n",
    "                     mem_info = \"Could not retrieve memory info\" # å¦‚æœè¯»å–æ–‡ä»¶å‡ºé”™ï¼Œè®¾ç½®é”™è¯¯ä¿¡æ¯\n",
    "\n",
    "        except:\n",
    "            mem_info = \"Could not retrieve memory info\" # å¦‚æœè¯»å–æ–‡ä»¶å‡ºé”™ï¼Œè®¾ç½®é”™è¯¯ä¿¡æ¯\n",
    "    return mem_info # è¿”å›å†…å­˜ä¿¡æ¯\n",
    "\n",
    "# è·å– GPU ä¿¡æ¯çš„å‡½æ•°ï¼ŒåŒ…æ‹¬æ˜¾å­˜\n",
    "def get_gpu_info():\n",
    "    try:\n",
    "        # å°è¯•ä½¿ç”¨ nvidia-smi è·å– NVIDIA GPU ä¿¡æ¯å’Œæ˜¾å­˜\n",
    "        result = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total', '--format=csv,noheader'], capture_output=True, text=True)\n",
    "        if result.returncode == 0: # å¦‚æœå‘½ä»¤æˆåŠŸæ‰§è¡Œ\n",
    "            gpu_lines = result.stdout.strip().split('\\n') # è§£æè¾“å‡ºï¼Œè·å– GPU åç§°å’Œæ˜¾å­˜\n",
    "            gpu_info_list = []\n",
    "            for line in gpu_lines:\n",
    "                name, memory = line.split(', ')\n",
    "                gpu_info_list.append(f\"{name} ({memory})\") # æ ¼å¼åŒ– GPU ä¿¡æ¯\n",
    "            return \", \".join(gpu_info_list) if gpu_info_list else \"NVIDIA GPU found, but info not listed\" # è¿”å› GPU ä¿¡æ¯æˆ–æç¤ºä¿¡æ¯\n",
    "        else:\n",
    "             # å°è¯•ä½¿ç”¨ lshw è·å–å…¶ä»– GPU ä¿¡æ¯ (éœ€è¦å®‰è£… lshw)\n",
    "            try:\n",
    "                result_lshw = subprocess.run(['lshw', '-C', 'display'], capture_output=True, text=True)\n",
    "                if result_lshw.returncode == 0: # å¦‚æœå‘½ä»¤æˆåŠŸæ‰§è¡Œ\n",
    "                     # ç®€å•è§£æè¾“å‡ºä¸­çš„ product åç§°å’Œæ˜¾å­˜\n",
    "                    gpu_info_lines = []\n",
    "                    current_gpu = {}\n",
    "                    for line in result_lshw.stdout.splitlines():\n",
    "                        if 'product:' in line:\n",
    "                             if current_gpu:\n",
    "                                 gpu_info_lines.append(f\"{current_gpu.get('product', 'GPU')} ({current_gpu.get('memory', 'N/A')})\")\n",
    "                             current_gpu = {'product': line.split('product:')[1].strip()}\n",
    "                        elif 'size:' in line and 'memory' in line:\n",
    "                             current_gpu['memory'] = line.split('size:')[1].strip()\n",
    "\n",
    "                    if current_gpu: # æ·»åŠ æœ€åä¸€ä¸ª GPU çš„ä¿¡æ¯\n",
    "                        gpu_info_lines.append(f\"{current_gpu.get('product', 'GPU')} ({current_gpu.get('memory', 'N/A')})\")\n",
    "\n",
    "                    return \", \".join(gpu_info_lines) if gpu_info_lines else \"GPU found (via lshw), but info not parsed\" # å¦‚æœæ‰¾åˆ° GPU ä½†ä¿¡æ¯æ— æ³•è§£æï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "                else:\n",
    "                    return \"No GPU found (checked nvidia-smi and lshw)\" # å¦‚æœä¸¤ä¸ªå‘½ä»¤éƒ½æ‰¾ä¸åˆ° GPUï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "            except FileNotFoundError:\n",
    "                 return \"No GPU found (checked nvidia-smi, lshw not found)\" # å¦‚æœæ‰¾ä¸åˆ° lshw å‘½ä»¤ï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "    except FileNotFoundError:\n",
    "        return \"No GPU found (nvidia-smi not found)\" # å¦‚æœæ‰¾ä¸åˆ° nvidia-smi å‘½ä»¤ï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "\n",
    "\n",
    "# è·å– CUDA ç‰ˆæœ¬çš„å‡½æ•°\n",
    "def get_cuda_version():\n",
    "    try:\n",
    "        # å°è¯•ä½¿ç”¨ nvcc --version è·å– CUDA ç‰ˆæœ¬\n",
    "        result = subprocess.run(['nvcc', '--version'], capture_output=True, text=True)\n",
    "        if result.returncode == 0: # å¦‚æœå‘½ä»¤æˆåŠŸæ‰§è¡Œ\n",
    "            for line in result.stdout.splitlines():\n",
    "                if 'release' in line: # æŸ¥æ‰¾åŒ…å« 'release' çš„è¡Œ\n",
    "                    return line.split('release ')[1].split(',')[0] # è§£æè¡Œï¼Œæå–ç‰ˆæœ¬å·\n",
    "        return \"CUDA not found or version not parsed\" # å¦‚æœæ‰¾ä¸åˆ° CUDA æˆ–ç‰ˆæœ¬æ— æ³•è§£æï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "    except FileNotFoundError:\n",
    "        return \"CUDA not found\" # å¦‚æœæ‰¾ä¸åˆ° nvcc å‘½ä»¤ï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "\n",
    "# è·å– Python ç‰ˆæœ¬çš„å‡½æ•°\n",
    "def get_python_version():\n",
    "    return platform.python_version() # è·å– Python ç‰ˆæœ¬\n",
    "\n",
    "# è·å– Conda ç‰ˆæœ¬çš„å‡½æ•°\n",
    "def get_conda_version():\n",
    "    try:\n",
    "        # å°è¯•ä½¿ç”¨ conda --version è·å– Conda ç‰ˆæœ¬\n",
    "        result = subprocess.run(['conda', '--version'], capture_output=True, text=True)\n",
    "        if result.returncode == 0: # å¦‚æœå‘½ä»¤æˆåŠŸæ‰§è¡Œ\n",
    "            return result.stdout.strip() # è¿”å› Conda ç‰ˆæœ¬\n",
    "        return \"Conda not found or version not parsed\" # å¦‚æœæ‰¾ä¸åˆ° Conda æˆ–ç‰ˆæœ¬æ— æ³•è§£æï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "    except FileNotFoundError:\n",
    "        return \"Conda not found\" # å¦‚æœæ‰¾ä¸åˆ° conda å‘½ä»¤ï¼Œè®¾ç½®æç¤ºä¿¡æ¯\n",
    "\n",
    "# è·å–ç‰©ç†ç£ç›˜ç©ºé—´ä¿¡æ¯çš„å‡½æ•°\n",
    "def get_disk_space():\n",
    "    try:\n",
    "        total, used, free = shutil.disk_usage(\"/\") # è·å–æ ¹ç›®å½•çš„ç£ç›˜ä½¿ç”¨æƒ…å†µ\n",
    "        total_gb = total / (1024**3) # è½¬æ¢ä¸º GB\n",
    "        used_gb = used / (1024**3) # è½¬æ¢ä¸º GB\n",
    "        free_gb = free / (1024**3) # è½¬æ¢ä¸º GB\n",
    "        return f\"Total: {total_gb:.2f} GB, Used: {used_gb:.2f} GB, Free: {free_gb:.2f} GB\" # æ ¼å¼åŒ–è¾“å‡º\n",
    "    except Exception as e:\n",
    "        return f\"Could not retrieve disk info: {e}\" # å¦‚æœè·å–ä¿¡æ¯å‡ºé”™ï¼Œè®¾ç½®é”™è¯¯ä¿¡æ¯\n",
    "\n",
    "# è·å–ç¯å¢ƒä¿¡æ¯\n",
    "os_name = platform.system() # è·å–æ“ä½œç³»ç»Ÿåç§°\n",
    "os_version = platform.release() # è·å–æ“ä½œç³»ç»Ÿç‰ˆæœ¬\n",
    "if os_name == \"Linux\":\n",
    "    try:\n",
    "        # åœ¨ Linux ä¸Šå°è¯•è·å–å‘è¡Œç‰ˆå’Œç‰ˆæœ¬\n",
    "        lsb_info = subprocess.run(['lsb_release', '-a'], capture_output=True, text=True)\n",
    "        if lsb_info.returncode == 0: # å¦‚æœå‘½ä»¤æˆåŠŸæ‰§è¡Œ\n",
    "            for line in lsb_info.stdout.splitlines():\n",
    "                if 'Description:' in line: # æŸ¥æ‰¾åŒ…å« 'Description:' çš„è¡Œ\n",
    "                    os_version = line.split('Description:')[1].strip() # æå–æè¿°ä¿¡æ¯ä½œä¸ºç‰ˆæœ¬\n",
    "                    break # æ‰¾åˆ°åé€€å‡ºå¾ªç¯\n",
    "                elif 'Release:' in line: # æŸ¥æ‰¾åŒ…å« 'Release:' çš„è¡Œ\n",
    "                     os_version = line.split('Release:')[1].strip() # æå–ç‰ˆæœ¬å·\n",
    "                     # å°è¯•è·å– codename\n",
    "                     try:\n",
    "                         codename_info = subprocess.run(['lsb_release', '-c'], capture_output=True, text=True)\n",
    "                         if codename_info.returncode == 0:\n",
    "                             os_version += f\" ({codename_info.stdout.split(':')[1].strip()})\" # å°† codename æ·»åŠ åˆ°ç‰ˆæœ¬ä¿¡æ¯ä¸­\n",
    "                     except:\n",
    "                         pass # å¦‚æœè·å– codename å¤±è´¥åˆ™å¿½ç•¥\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        pass # lsb_release å¯èƒ½æœªå®‰è£…ï¼Œå¿½ç•¥é”™è¯¯\n",
    "\n",
    "full_os_info = f\"{os_name} {os_version}\" # ç»„åˆå®Œæ•´çš„æ“ä½œç³»ç»Ÿä¿¡æ¯\n",
    "cpu_info = get_cpu_info() # è°ƒç”¨å‡½æ•°è·å– CPU ä¿¡æ¯å’Œæ ¸å¿ƒæ•°é‡\n",
    "memory_info = get_memory_info() # è°ƒç”¨å‡½æ•°è·å–å†…å­˜ä¿¡æ¯\n",
    "gpu_info = get_gpu_info() # è°ƒç”¨å‡½æ•°è·å– GPU ä¿¡æ¯å’Œæ˜¾å­˜\n",
    "cuda_version = get_cuda_version() # è°ƒç”¨å‡½æ•°è·å– CUDA ç‰ˆæœ¬\n",
    "python_version = get_python_version() # è°ƒç”¨å‡½æ•°è·å– Python ç‰ˆæœ¬\n",
    "conda_version = get_conda_version() # è°ƒç”¨å‡½æ•°è·å– Conda ç‰ˆæœ¬\n",
    "disk_info = get_disk_space() # è°ƒç”¨å‡½æ•°è·å–ç‰©ç†ç£ç›˜ç©ºé—´ä¿¡æ¯\n",
    "\n",
    "\n",
    "# åˆ›å»ºç”¨äºå­˜å‚¨æ•°æ®çš„å­—å…¸\n",
    "env_data = {\n",
    "    \"é¡¹ç›®\": [ # é¡¹ç›®åç§°åˆ—è¡¨\n",
    "        \"æ“ä½œç³»ç»Ÿ\",\n",
    "        \"CPU ä¿¡æ¯\",\n",
    "        \"å†…å­˜ä¿¡æ¯\",\n",
    "        \"GPU ä¿¡æ¯\",\n",
    "        \"CUDA ä¿¡æ¯\",\n",
    "        \"Python ç‰ˆæœ¬\",\n",
    "        \"Conda ç‰ˆæœ¬\",\n",
    "        \"ç‰©ç†ç£ç›˜ç©ºé—´\" # æ·»åŠ ç‰©ç†ç£ç›˜ç©ºé—´\n",
    "    ],\n",
    "    \"ä¿¡æ¯\": [ # å¯¹åº”çš„ä¿¡æ¯åˆ—è¡¨\n",
    "        full_os_info,\n",
    "        cpu_info,\n",
    "        memory_info,\n",
    "        gpu_info,\n",
    "        cuda_version,\n",
    "        python_version,\n",
    "        conda_version,\n",
    "        disk_info # æ·»åŠ ç‰©ç†ç£ç›˜ç©ºé—´ä¿¡æ¯\n",
    "    ]\n",
    "}\n",
    "\n",
    "# åˆ›å»ºä¸€ä¸ª pandas DataFrame\n",
    "df = pd.DataFrame(env_data)\n",
    "\n",
    "# æ‰“å°è¡¨æ ¼\n",
    "print(\"### ç¯å¢ƒä¿¡æ¯\") # æ‰“å°æ ‡é¢˜\n",
    "print(df.to_markdown(index=False)) # å°† DataFrame è½¬æ¢ä¸º Markdown æ ¼å¼å¹¶æ‰“å°ï¼Œä¸åŒ…å«ç´¢å¼•"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50ba54e-fade-4d44-ad4b-6545643bc15c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## æ£€æŸ¥è½¯ç¡¬ä»¶ä¾èµ–\n",
    "| å¿…éœ€é¡¹        | è‡³å°‘     | æ¨è      |\n",
    "| ------------ | ------- | --------- |\n",
    "| python       | 3.9     | 3.10      |\n",
    "| torch        | 2.0.0   | 2.6.0     |\n",
    "| torchvision  | 0.15.0  | 0.21.0    |\n",
    "| transformers | 4.49.0  | 4.50.0    |\n",
    "| datasets     | 2.16.0  | 3.2.0     |\n",
    "| accelerate   | 0.34.0  | 1.2.1     |\n",
    "| peft         | 0.14.0  | 0.15.1    |\n",
    "| trl          | 0.8.6   | 0.9.6     |\n",
    "\n",
    "| å¯é€‰é¡¹        | è‡³å°‘     | æ¨è      |\n",
    "| ------------ | ------- | --------- |\n",
    "| CUDA         | 11.6    | 12.2      |\n",
    "| deepspeed    | 0.10.0  | 0.16.4    |\n",
    "| bitsandbytes | 0.39.0  | 0.43.1    |\n",
    "| vllm         | 0.4.3   | 0.8.2     |\n",
    "| flash-attn   | 2.5.6   | 2.7.2     |\n",
    "\n",
    "### ç¡¬ä»¶ä¾èµ–\n",
    "\n",
    "\\* *ä¼°ç®—å€¼*\n",
    "\n",
    "| æ–¹æ³•                             | ç²¾åº¦ |   7B  |  14B  |  30B  |   70B  |   `x`B  |\n",
    "| ------------------------------- | ---- | ----- | ----- | ----- | ------ | ------- |\n",
    "| Full (`bf16` or `fp16`)         |  32  | 120GB | 240GB | 600GB | 1200GB | `18x`GB |\n",
    "| Full (`pure_bf16`)              |  16  |  60GB | 120GB | 300GB |  600GB |  `8x`GB |\n",
    "| Freeze/LoRA/GaLore/APOLLO/BAdam |  16  |  16GB |  32GB |  64GB |  160GB |  `2x`GB |\n",
    "| QLoRA                           |   8  |  10GB |  20GB |  40GB |   80GB |   `x`GB |\n",
    "| QLoRA                           |   4  |   6GB |  12GB |  24GB |   48GB | `x/2`GB |\n",
    "| QLoRA                           |   2  |   4GB |   8GB |  16GB |   24GB | `x/4`GB |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7aab387-96a7-4d4d-ae9d-e0395dfa0f52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T07:06:52.953358Z",
     "iopub.status.busy": "2025-11-25T07:06:52.952983Z",
     "iopub.status.idle": "2025-11-25T07:06:53.993075Z",
     "shell.execute_reply": "2025-11-25T07:06:53.992554Z",
     "shell.execute_reply.started": "2025-11-25T07:06:52.953339Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "ğŸ› ï¸  ç¯å¢ƒä¾èµ–æ£€æµ‹æŠ¥å‘Š (åŸºäºæ‚¨æä¾›çš„æœ€æ–°æ ‡å‡†)\n",
      "=================================================================\n",
      "[ å¿…éœ€é¡¹ ]\n",
      "\u001b[92mâœ… python          | å½“å‰: å®Œç¾ (3.10.14)    | å¿…éœ€: >=3.9      | æ¨è: >=3.10\u001b[0m\n",
      "\u001b[93mâš ï¸ torch           | å½“å‰: è¾¾æ ‡ (2.3.1)      | å¿…éœ€: >=2.0.0    | æ¨è: >=2.6.0\u001b[0m\n",
      "\u001b[93mâš ï¸ torchvision     | å½“å‰: è¾¾æ ‡ (0.18.1)     | å¿…éœ€: >=0.15.0   | æ¨è: >=0.21.0\u001b[0m\n",
      "\u001b[92mâœ… transformers    | å½“å‰: å®Œç¾ (4.57.1)     | å¿…éœ€: >=4.49.0   | æ¨è: >=4.50.0\u001b[0m\n",
      "\u001b[93mâš ï¸ datasets        | å½“å‰: è¾¾æ ‡ (2.20.0)     | å¿…éœ€: >=2.16.0   | æ¨è: >=3.2.0\u001b[0m\n",
      "\u001b[92mâœ… accelerate      | å½“å‰: å®Œç¾ (1.11.0)     | å¿…éœ€: >=0.34.0   | æ¨è: >=1.2.1\u001b[0m\n",
      "\u001b[92mâœ… peft            | å½“å‰: å®Œç¾ (0.17.1)     | å¿…éœ€: >=0.14.0   | æ¨è: >=0.15.1\u001b[0m\n",
      "\u001b[92mâœ… trl             | å½“å‰: å®Œç¾ (0.9.6)      | å¿…éœ€: >=0.8.6    | æ¨è: >=0.9.6\u001b[0m\n",
      "\n",
      "[ å¯é€‰é¡¹ ]\n",
      "\u001b[93mâš ï¸ cuda            | å½“å‰: è¾¾æ ‡ (12.1)       | å¿…éœ€: >=11.6     | æ¨è: >=12.2\u001b[0m\n",
      "\u001b[93mâš ï¸ deepspeed       | å½“å‰: è¾¾æ ‡ (0.14.4)     | å¿…éœ€: >=0.10.0   | æ¨è: >=0.16.4\u001b[0m\n",
      "\u001b[92mâœ… bitsandbytes    | å½“å‰: å®Œç¾ (0.43.2)     | å¿…éœ€: >=0.39.0   | æ¨è: >=0.43.1\u001b[0m\n",
      "\u001b[90mâšª vllm            | å½“å‰: æœªå®‰è£… (å¯é€‰)        | å¿…éœ€: >=0.4.3    | æ¨è: >=0.8.2\u001b[0m\n",
      "\u001b[93mâš ï¸ flash-attn      | å½“å‰: è¾¾æ ‡ (2.5.9.post1) | å¿…éœ€: >=2.5.6    | æ¨è: >=2.7.2\u001b[0m\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import platform\n",
    "import importlib.metadata\n",
    "from packaging import version\n",
    "import torch\n",
    "\n",
    "# ================= æ‚¨çš„æœ€æ–°é…ç½®è¦æ±‚ =================\n",
    "REQUIRED_PACKAGES = {\n",
    "    \"python\":       (\"3.9\",    \"3.10\"),\n",
    "    \"torch\":        (\"2.0.0\",  \"2.6.0\"),\n",
    "    \"torchvision\":  (\"0.15.0\", \"0.21.0\"),\n",
    "    \"transformers\": (\"4.49.0\", \"4.50.0\"),\n",
    "    \"datasets\":     (\"2.16.0\", \"3.2.0\"),\n",
    "    \"accelerate\":   (\"0.34.0\", \"1.2.1\"),\n",
    "    \"peft\":         (\"0.14.0\", \"0.15.1\"),\n",
    "    \"trl\":          (\"0.8.6\",  \"0.9.6\"),\n",
    "}\n",
    "\n",
    "OPTIONAL_PACKAGES = {\n",
    "    \"cuda\":         (\"11.6\",   \"12.2\"),\n",
    "    \"deepspeed\":    (\"0.10.0\", \"0.16.4\"),\n",
    "    \"bitsandbytes\": (\"0.39.0\", \"0.43.1\"),\n",
    "    \"vllm\":         (\"0.4.3\",  \"0.8.2\"),\n",
    "    \"flash-attn\":   (\"2.5.6\",  \"2.7.2\"),\n",
    "}\n",
    "\n",
    "# ================= æ£€æµ‹é€»è¾‘ =================\n",
    "def get_package_version(package_name):\n",
    "    try:\n",
    "        if package_name == \"python\": return platform.python_version()\n",
    "        elif package_name == \"cuda\": return torch.version.cuda if torch.cuda.is_available() else None\n",
    "        elif package_name == \"flash-attn\": return importlib.metadata.version(\"flash_attn\")\n",
    "        else: return importlib.metadata.version(package_name)\n",
    "    except importlib.metadata.PackageNotFoundError: return None\n",
    "\n",
    "def check_requirement(name, constraints, is_optional=False):\n",
    "    min_v, rec_v = constraints\n",
    "    current_v = get_package_version(name)\n",
    "    \n",
    "    if current_v is None:\n",
    "        status, msg, color = (\"âšª\", \"æœªå®‰è£… (å¯é€‰)\", \"\\033[90m\") if is_optional else (\"âŒ\", \"æœªå®‰è£… !!\", \"\\033[91m\")\n",
    "    else:\n",
    "        try:\n",
    "            curr_p, min_p, rec_p = version.parse(current_v), version.parse(min_v), version.parse(rec_v)\n",
    "            if curr_p >= rec_p:   status, msg, color = (\"âœ…\", f\"å®Œç¾ ({current_v})\", \"\\033[92m\")\n",
    "            elif curr_p >= min_p: status, msg, color = (\"âš ï¸\", f\"è¾¾æ ‡ ({current_v})\", \"\\033[93m\")\n",
    "            else:                 status, msg, color = (\"âŒ\", f\"è¿‡ä½ ({current_v})\", \"\\033[91m\")\n",
    "        except: status, msg, color = (\"â“\", f\"è§£æé”™è¯¯\", \"\\033[93m\")\n",
    "\n",
    "    print(f\"{color}{status} {name:<15} | å½“å‰: {msg:<15} | å¿…éœ€: >={min_v:<8} | æ¨è: >={rec_v}\\033[0m\")\n",
    "\n",
    "print(\"=\"*65)\n",
    "print(f\"ğŸ› ï¸  ç¯å¢ƒä¾èµ–æ£€æµ‹æŠ¥å‘Š (åŸºäºæ‚¨æä¾›çš„æœ€æ–°æ ‡å‡†)\")\n",
    "print(\"=\"*65)\n",
    "print(\"[ å¿…éœ€é¡¹ ]\")\n",
    "for k, v in REQUIRED_PACKAGES.items(): check_requirement(k, v)\n",
    "print(\"\\n[ å¯é€‰é¡¹ ]\")\n",
    "for k, v in OPTIONAL_PACKAGES.items(): check_requirement(k, v, True)\n",
    "print(\"=\"*65)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb110e1-2cf0-4ca4-98bd-d8c38322e944",
   "metadata": {},
   "source": [
    "## 1. å®‰è£…LLaMA Factory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e76f4d-15a3-4efe-9a32-190b63972e45",
   "metadata": {},
   "source": [
    "é¦–å…ˆï¼Œæ‹‰å–LLaMA-Factoryé¡¹ç›®åˆ°DSWå®ä¾‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38481631-eeea-4d5f-abdc-f9aeeee439ae",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-11-25T07:35:14.478190Z",
     "iopub.status.busy": "2025-11-25T07:35:14.477862Z",
     "iopub.status.idle": "2025-11-25T07:35:14.482013Z",
     "shell.execute_reply": "2025-11-25T07:35:14.481420Z",
     "shell.execute_reply.started": "2025-11-25T07:35:14.478170Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ç›®å½• 'LLaMA-Factory' ä¸å­˜åœ¨ï¼Œå‡†å¤‡æ–°å»º...\n"
     ]
    }
   ],
   "source": [
    "# å®šä¹‰ä»“åº“æ–‡ä»¶å¤¹åç§°\n",
    "repo_name = \"LLaMA-Factory\"\n",
    "\n",
    "# 1. åˆ¤æ–­æ–‡ä»¶å¤¹æ˜¯å¦å­˜åœ¨\n",
    "if os.path.exists(repo_name):\n",
    "    print(f\"âš ï¸ æ£€æµ‹åˆ°æ—§ç›®å½• '{repo_name}'ï¼Œæ­£åœ¨åˆ é™¤...\")\n",
    "    # å¼ºåˆ¶åˆ é™¤ (ç›¸å½“äº rm -rf)\n",
    "    shutil.rmtree(repo_name) \n",
    "    print(\"ğŸ—‘ï¸ æ—§ç›®å½•å·²æ¸…é™¤ï¼\")\n",
    "else:\n",
    "    print(f\"âœ… ç›®å½• '{repo_name}' ä¸å­˜åœ¨ï¼Œå‡†å¤‡æ–°å»º...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "53537470-82d5-4bbe-b47c-0d756c7dd8dd",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-11-25T07:35:17.382652Z",
     "iopub.status.busy": "2025-11-25T07:35:17.382340Z",
     "iopub.status.idle": "2025-11-25T07:35:29.414159Z",
     "shell.execute_reply": "2025-11-25T07:35:29.413669Z",
     "shell.execute_reply.started": "2025-11-25T07:35:17.382631Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ­£å…‹éš†åˆ° 'LLaMA-Factory'...\n",
      "remote: Enumerating objects: 24474, done.\u001b[K\n",
      "remote: Counting objects: 100% (36/36), done.\u001b[K\n",
      "remote: Compressing objects: 100% (28/28), done.\u001b[K\n",
      "remote: Total 24474 (delta 17), reused 8 (delta 8), pack-reused 24438 (from 3)\u001b[K\n",
      "æ¥æ”¶å¯¹è±¡ä¸­: 100% (24474/24474), 12.15 MiB | 1.17 MiB/s, å®Œæˆ.\n",
      "å¤„ç† delta ä¸­: 100% (17639/17639), å®Œæˆ.\n",
      "æ³¨æ„ï¼šæ­£åœ¨åˆ‡æ¢åˆ° 'e2299e261be852304bb1d370515078193ab12bd8'ã€‚\n",
      "\n",
      "æ‚¨æ­£å¤„äºåˆ†ç¦»å¤´æŒ‡é’ˆçŠ¶æ€ã€‚æ‚¨å¯ä»¥æŸ¥çœ‹ã€åšè¯•éªŒæ€§çš„ä¿®æ”¹åŠæäº¤ï¼Œå¹¶ä¸”æ‚¨å¯ä»¥åœ¨åˆ‡æ¢\n",
      "å›ä¸€ä¸ªåˆ†æ”¯æ—¶ï¼Œä¸¢å¼ƒåœ¨æ­¤çŠ¶æ€ä¸‹æ‰€åšçš„æäº¤è€Œä¸å¯¹åˆ†æ”¯é€ æˆå½±å“ã€‚\n",
      "\n",
      "å¦‚æœæ‚¨æƒ³è¦é€šè¿‡åˆ›å»ºåˆ†æ”¯æ¥ä¿ç•™åœ¨æ­¤çŠ¶æ€ä¸‹æ‰€åšçš„æäº¤ï¼Œæ‚¨å¯ä»¥é€šè¿‡åœ¨ switch å‘½ä»¤\n",
      "ä¸­æ·»åŠ å‚æ•° -c æ¥å®ç°ï¼ˆç°åœ¨æˆ–ç¨åï¼‰ã€‚ä¾‹å¦‚ï¼š\n",
      "\n",
      "  git switch -c <æ–°åˆ†æ”¯å>\n",
      "\n",
      "æˆ–è€…æ’¤é”€æ­¤æ“ä½œï¼š\n",
      "\n",
      "  git switch -\n",
      "\n",
      "é€šè¿‡å°†é…ç½®å˜é‡ advice.detachedHead è®¾ç½®ä¸º false æ¥å…³é—­æ­¤å»ºè®®\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. å…‹éš†ä»“åº“ï¼ˆä½¿ç”¨å›½å†…é•œåƒï¼‰\n",
    "!git clone -b v0.9.2 https://github.com/hiyouga/LLaMA-Factory.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca0122b-7f5a-4f45-8e8f-5f3dbcd9ff0f",
   "metadata": {},
   "source": [
    "æ¥ç€ï¼Œæˆ‘ä»¬å®‰è£…LLaMA-Factoryä¾èµ–ç¯å¢ƒã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a159cf2-7e19-44e5-8b86-7e8eb437a992",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2025-11-25T07:38:19.008790Z",
     "iopub.status.busy": "2025-11-25T07:38:19.008459Z",
     "iopub.status.idle": "2025-11-25T07:38:28.430624Z",
     "shell.execute_reply": "2025-11-25T07:38:28.430083Z",
     "shell.execute_reply.started": "2025-11-25T07:38:19.008768Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'LLaMA-Factory'\n",
      "/mnt/workspace/demos/llama_factory/LLaMA-Factory/LLaMA-Factory\n",
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple/\n",
      "Requirement already satisfied: pip in /usr/local/lib/python3.10/site-packages (25.3)\n",
      "\u001b[33mWARNING: Error parsing dependencies of pytorch-lightning: .* suffix can only be used with `==` or `!=` operators\n",
      "    torch (>=1.9.*)\n",
      "           ~~~~~~^\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping pai-easycv as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping autoawq as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping ms-swift as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping lmdeploy as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://mirrors.aliyun.com/pypi/simple/\n",
      "Obtaining file:///mnt/workspace/demos/llama_factory/LLaMA-Factory/LLaMA-Factory\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: transformers!=4.46.*,!=4.47.*,!=4.48.0,<=4.49.0,>=4.41.2 in /usr/local/lib/python3.10/site-packages (from llamafactory==0.9.2) (4.49.0)\n",
      "Requirement already satisfied: datasets<=3.2.0,>=2.16.0 in /usr/local/lib/python3.10/site-packages (from llamafactory==0.9.2) (2.20.0)\n",
      "Requirement already satisfied: accelerate<=1.2.1,>=0.34.0 in /usr/local/lib/python3.10/site-packages (from llamafactory==0.9.2) (1.2.1)\n",
      "Requirement already satisfied: peft<=0.12.0,>=0.11.1 in /usr/local/lib/python3.10/site-packages (from llamafactory==0.9.2) (0.12.0)\n",
      "Requirement already satisfied: trl<=0.9.6,>=0.8.6 in /usr/local/lib/python3.10/site-packages (from llamafactory==0.9.2) (0.9.6)\n",
      "Requirement already satisfied: tokenizers<=0.21.0,>=0.19.0 in /usr/local/lib/python3.10/site-packages (from llamafactory==0.9.2) (0.21.0)\n",
      "Requirement already satisfied: gradio<=5.21.0,>=4.38.0 in /usr/local/lib/python3.10/site-packages (from llamafactory==0.9.2) (5.21.0)\n",
      "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.10/site-packages (from llamafactory==0.9.2) (2.2.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/site-packages (from llamafactory==0.9.2) (1.12.0)\n",
      "Requirement already satisfied: einops in /usr/local/lib/python3.10/site-packages (from llamafactory==0.9.2) (0.8.0)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/site-packages (from llamafactory==0.9.2) (0.2.0)\n",
      "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/site-packages (from llamafactory==0.9.2) (0.7.0)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/site-packages (from llamafactory==0.9.2) (3.20.3)\n",
      "Requirement already satisfied: uvicorn in /usr/local/lib/python3.10/site-packages (from llamafactory==0.9.2) (0.30.3)\n",
      "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/site-packages (from llamafactory==0.9.2) (2.10.6)\n",
      "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/site-packages (from llamafactory==0.9.2) (0.122.0)\n",
      "Requirement already satisfied: sse-starlette in /usr/local/lib/python3.10/site-packages (from llamafactory==0.9.2) (2.1.2)\n",
      "Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.10/site-packages (from llamafactory==0.9.2) (3.9.0)\n",
      "Requirement already satisfied: fire in /usr/local/lib/python3.10/site-packages (from llamafactory==0.9.2) (0.6.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/site-packages (from llamafactory==0.9.2) (24.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/site-packages (from llamafactory==0.9.2) (6.0.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/site-packages (from llamafactory==0.9.2) (1.26.3)\n",
      "Requirement already satisfied: av in /usr/local/lib/python3.10/site-packages (from llamafactory==0.9.2) (12.3.0)\n",
      "Requirement already satisfied: librosa in /usr/local/lib/python3.10/site-packages (from llamafactory==0.9.2) (0.10.2.post1)\n",
      "Requirement already satisfied: tyro<0.9.0 in /usr/local/lib/python3.10/site-packages (from llamafactory==0.9.2) (0.8.10)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/site-packages (from llamafactory==0.9.2) (3.8.1)\n",
      "Requirement already satisfied: jieba in /usr/local/lib/python3.10/site-packages (from llamafactory==0.9.2) (0.42.1)\n",
      "Requirement already satisfied: rouge-chinese in /usr/local/lib/python3.10/site-packages (from llamafactory==0.9.2) (1.0.3)\n",
      "Requirement already satisfied: torch>=1.13.1 in /usr/local/lib/python3.10/site-packages (from llamafactory==0.9.2) (2.3.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/site-packages (from accelerate<=1.2.1,>=0.34.0->llamafactory==0.9.2) (5.9.8)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/site-packages (from accelerate<=1.2.1,>=0.34.0->llamafactory==0.9.2) (0.36.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/site-packages (from accelerate<=1.2.1,>=0.34.0->llamafactory==0.9.2) (0.4.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from datasets<=3.2.0,>=2.16.0->llamafactory==0.9.2) (3.14.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/site-packages (from datasets<=3.2.0,>=2.16.0->llamafactory==0.9.2) (17.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/site-packages (from datasets<=3.2.0,>=2.16.0->llamafactory==0.9.2) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/site-packages (from datasets<=3.2.0,>=2.16.0->llamafactory==0.9.2) (0.3.8)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/site-packages (from datasets<=3.2.0,>=2.16.0->llamafactory==0.9.2) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/site-packages (from datasets<=3.2.0,>=2.16.0->llamafactory==0.9.2) (4.66.4)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/site-packages (from datasets<=3.2.0,>=2.16.0->llamafactory==0.9.2) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/site-packages (from datasets<=3.2.0,>=2.16.0->llamafactory==0.9.2) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/site-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets<=3.2.0,>=2.16.0->llamafactory==0.9.2) (2024.5.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/site-packages (from datasets<=3.2.0,>=2.16.0->llamafactory==0.9.2) (3.9.5)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/site-packages (from gradio<=5.21.0,>=4.38.0->llamafactory==0.9.2) (23.2.1)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/site-packages (from gradio<=5.21.0,>=4.38.0->llamafactory==0.9.2) (4.4.0)\n",
      "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/site-packages (from gradio<=5.21.0,>=4.38.0->llamafactory==0.9.2) (1.0.0)\n",
      "Requirement already satisfied: gradio-client==1.7.2 in /usr/local/lib/python3.10/site-packages (from gradio<=5.21.0,>=4.38.0->llamafactory==0.9.2) (1.7.2)\n",
      "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.10/site-packages (from gradio<=5.21.0,>=4.38.0->llamafactory==0.9.2) (0.1.2)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/site-packages (from gradio<=5.21.0,>=4.38.0->llamafactory==0.9.2) (0.27.0)\n",
      "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/site-packages (from gradio<=5.21.0,>=4.38.0->llamafactory==0.9.2) (3.1.4)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/site-packages (from gradio<=5.21.0,>=4.38.0->llamafactory==0.9.2) (2.1.5)\n",
      "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/site-packages (from gradio<=5.21.0,>=4.38.0->llamafactory==0.9.2) (3.11.4)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.10/site-packages (from gradio<=5.21.0,>=4.38.0->llamafactory==0.9.2) (10.2.0)\n",
      "Requirement already satisfied: pydub in /usr/local/lib/python3.10/site-packages (from gradio<=5.21.0,>=4.38.0->llamafactory==0.9.2) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.10/site-packages (from gradio<=5.21.0,>=4.38.0->llamafactory==0.9.2) (0.0.20)\n",
      "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.10/site-packages (from gradio<=5.21.0,>=4.38.0->llamafactory==0.9.2) (0.14.6)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.10/site-packages (from gradio<=5.21.0,>=4.38.0->llamafactory==0.9.2) (0.1.7)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/site-packages (from gradio<=5.21.0,>=4.38.0->llamafactory==0.9.2) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.10/site-packages (from gradio<=5.21.0,>=4.38.0->llamafactory==0.9.2) (0.50.0)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.10/site-packages (from gradio<=5.21.0,>=4.38.0->llamafactory==0.9.2) (0.13.3)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/site-packages (from gradio<=5.21.0,>=4.38.0->llamafactory==0.9.2) (0.12.3)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/site-packages (from gradio<=5.21.0,>=4.38.0->llamafactory==0.9.2) (4.15.0)\n",
      "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.10/site-packages (from gradio-client==1.7.2->gradio<=5.21.0,>=4.38.0->llamafactory==0.9.2) (12.0)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio<=5.21.0,>=4.38.0->llamafactory==0.9.2) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio<=5.21.0,>=4.38.0->llamafactory==0.9.2) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio<=5.21.0,>=4.38.0->llamafactory==0.9.2) (1.2.1)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.10/site-packages (from fastapi->llamafactory==0.9.2) (0.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/site-packages (from pandas>=2.0.0->llamafactory==0.9.2) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/site-packages (from pandas>=2.0.0->llamafactory==0.9.2) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/site-packages (from pandas>=2.0.0->llamafactory==0.9.2) (2024.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/site-packages (from pydantic->llamafactory==0.9.2) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.10/site-packages (from pydantic->llamafactory==0.9.2) (2.27.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate<=1.2.1,>=0.34.0->llamafactory==0.9.2) (1.2.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/site-packages (from transformers!=4.46.*,!=4.47.*,!=4.48.0,<=4.49.0,>=4.41.2->llamafactory==0.9.2) (2024.5.15)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio<=5.21.0,>=4.38.0->llamafactory==0.9.2) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio<=5.21.0,>=4.38.0->llamafactory==0.9.2) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio<=5.21.0,>=4.38.0->llamafactory==0.9.2) (13.7.1)\n",
      "Requirement already satisfied: docstring-parser>=0.16 in /usr/local/lib/python3.10/site-packages (from tyro<0.9.0->llamafactory==0.9.2) (0.16)\n",
      "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.10/site-packages (from tyro<0.9.0->llamafactory==0.9.2) (1.7.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets<=3.2.0,>=2.16.0->llamafactory==0.9.2) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets<=3.2.0,>=2.16.0->llamafactory==0.9.2) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets<=3.2.0,>=2.16.0->llamafactory==0.9.2) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets<=3.2.0,>=2.16.0->llamafactory==0.9.2) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets<=3.2.0,>=2.16.0->llamafactory==0.9.2) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/site-packages (from aiohttp->datasets<=3.2.0,>=2.16.0->llamafactory==0.9.2) (4.0.3)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/site-packages (from httpx>=0.24.1->gradio<=5.21.0,>=4.38.0->llamafactory==0.9.2) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/site-packages (from httpx>=0.24.1->gradio<=5.21.0,>=4.38.0->llamafactory==0.9.2) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.24.1->gradio<=5.21.0,>=4.38.0->llamafactory==0.9.2) (0.14.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/site-packages (from matplotlib>=3.7.0->llamafactory==0.9.2) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/site-packages (from matplotlib>=3.7.0->llamafactory==0.9.2) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/site-packages (from matplotlib>=3.7.0->llamafactory==0.9.2) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib>=3.7.0->llamafactory==0.9.2) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib>=3.7.0->llamafactory==0.9.2) (3.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->llamafactory==0.9.2) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests>=2.32.2->datasets<=3.2.0,>=2.16.0->llamafactory==0.9.2) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests>=2.32.2->datasets<=3.2.0,>=2.16.0->llamafactory==0.9.2) (2.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio<=5.21.0,>=4.38.0->llamafactory==0.9.2) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio<=5.21.0,>=4.38.0->llamafactory==0.9.2) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio<=5.21.0,>=4.38.0->llamafactory==0.9.2) (0.1.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/site-packages (from torch>=1.13.1->llamafactory==0.9.2) (1.12.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/site-packages (from torch>=1.13.1->llamafactory==0.9.2) (3.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/site-packages (from torch>=1.13.1->llamafactory==0.9.2) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/site-packages (from torch>=1.13.1->llamafactory==0.9.2) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/site-packages (from torch>=1.13.1->llamafactory==0.9.2) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/site-packages (from torch>=1.13.1->llamafactory==0.9.2) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/site-packages (from torch>=1.13.1->llamafactory==0.9.2) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/site-packages (from torch>=1.13.1->llamafactory==0.9.2) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/site-packages (from torch>=1.13.1->llamafactory==0.9.2) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/site-packages (from torch>=1.13.1->llamafactory==0.9.2) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/site-packages (from torch>=1.13.1->llamafactory==0.9.2) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/site-packages (from torch>=1.13.1->llamafactory==0.9.2) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/site-packages (from torch>=1.13.1->llamafactory==0.9.2) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/site-packages (from torch>=1.13.1->llamafactory==0.9.2) (2.3.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.1->llamafactory==0.9.2) (12.6.68)\n",
      "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/site-packages (from fire->llamafactory==0.9.2) (2.4.0)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/site-packages (from librosa->llamafactory==0.9.2) (3.0.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/site-packages (from librosa->llamafactory==0.9.2) (1.5.0)\n",
      "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/site-packages (from librosa->llamafactory==0.9.2) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/site-packages (from librosa->llamafactory==0.9.2) (4.4.2)\n",
      "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/site-packages (from librosa->llamafactory==0.9.2) (0.60.0)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/site-packages (from librosa->llamafactory==0.9.2) (0.12.1)\n",
      "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/site-packages (from librosa->llamafactory==0.9.2) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/site-packages (from librosa->llamafactory==0.9.2) (0.4.0)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/site-packages (from librosa->llamafactory==0.9.2) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/site-packages (from librosa->llamafactory==0.9.2) (1.0.8)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/site-packages (from numba>=0.51.0->librosa->llamafactory==0.9.2) (0.43.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/site-packages (from pooch>=1.1->librosa->llamafactory==0.9.2) (4.2.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/site-packages (from scikit-learn>=0.20.0->librosa->llamafactory==0.9.2) (3.5.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/site-packages (from soundfile>=0.12.1->librosa->llamafactory==0.9.2) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa->llamafactory==0.9.2) (2.22)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/site-packages (from sympy->torch>=1.13.1->llamafactory==0.9.2) (1.3.0)\n",
      "Building wheels for collected packages: llamafactory\n",
      "  Building editable for llamafactory (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for llamafactory: filename=llamafactory-0.9.2-0.editable-py3-none-any.whl size=25820 sha256=ea4c02997d779dfa72602f8a261f75bd31c69f3d7634c3b6f89650bce129c406\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-y2iw4es5/wheels/9f/39/78/cf31139d4a5de9f6586e31fdc7f2a6240817e7c6a901a723ff\n",
      "Successfully built llamafactory\n",
      "\u001b[33mWARNING: Error parsing dependencies of pytorch-lightning: .* suffix can only be used with `==` or `!=` operators\n",
      "    torch (>=1.9.*)\n",
      "           ~~~~~~^\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: llamafactory\n",
      "  Attempting uninstall: llamafactory\n",
      "    Found existing installation: llamafactory 0.9.2\n",
      "    Uninstalling llamafactory-0.9.2:\n",
      "      Successfully uninstalled llamafactory-0.9.2\n",
      "Successfully installed llamafactory-0.9.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# 1. ã€å…³é”®ã€‘ä½¿ç”¨ %cd è¿›å…¥ç›®å½• (ä¸è¦ç”¨ !cd)\n",
    "%cd /mnt/workspace/demos/llama_factory/LLaMA-Factory\n",
    "\n",
    "# 2. å»æ‰æ— å…³ä¾èµ–\n",
    "!pip install --upgrade pip\n",
    "!pip uninstall -y pai-easycv\n",
    "!pip uninstall -y autoawq\n",
    "!pip uninstall -y ms-swift\n",
    "!pip uninstall -y lmdeploy\n",
    "\n",
    "# 3. å®‰è£…é¡¹ç›®ä¾èµ–\n",
    "# è¿™ä¼šè‡ªåŠ¨å®‰è£… v0.9.2 æ‰€éœ€çš„å…¶ä»–åº“\n",
    "!pip install -e \".[torch,metrics]\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14da143a-1457-4b45-8847-3ad80b98e3b7",
   "metadata": {},
   "source": [
    "è¿è¡Œå¦‚ä¸‹å‘½ä»¤ï¼Œå¦‚æœæ˜¾ç¤ºllamafactory-cliçš„ç‰ˆæœ¬ï¼Œåˆ™è¡¨ç¤ºå®‰è£…æˆåŠŸã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9865b7f4-016c-441b-94fe-0436a65e398a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T07:40:02.494074Z",
     "iopub.status.busy": "2025-11-25T07:40:02.493729Z",
     "iopub.status.idle": "2025-11-25T07:40:11.090353Z",
     "shell.execute_reply": "2025-11-25T07:40:11.089761Z",
     "shell.execute_reply.started": "2025-11-25T07:40:02.494052Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-11-25 15:40:06,420] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n",
      "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3\n",
      "\u001b[93m [WARNING] \u001b[0m using untested triton version (2.3.1), only 1.0.0 is known to be compatible\n",
      "----------------------------------------------------------\n",
      "| Welcome to LLaMA Factory, version 0.9.2                |\n",
      "|                                                        |\n",
      "| Project page: https://github.com/hiyouga/LLaMA-Factory |\n",
      "----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "!llamafactory-cli version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3507f4d9-5cef-45a3-96bd-a2bbd4d4a90d",
   "metadata": {},
   "source": [
    "## 2. ä¸‹è½½æ•°æ®é›†"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464f2e63-865a-47ec-90a8-7e5af46b4d33",
   "metadata": {},
   "source": [
    "LLaMA-Factoryé¡¹ç›®å†…ç½®äº†ä¸°å¯Œçš„æ•°æ®é›†ï¼Œæ”¾åœ¨äº†`data`ç›®å½•ä¸‹ã€‚æ‚¨å¯ä»¥è·³è¿‡æœ¬æ­¥éª¤ï¼Œç›´æ¥ä½¿ç”¨å†…ç½®æ•°æ®é›†ã€‚æ‚¨ä¹Ÿå¯ä»¥å‡†å¤‡è‡ªå®šä¹‰æ•°æ®é›†ï¼Œå°†æ•°æ®å¤„ç†ä¸ºæ¡†æ¶ç‰¹å®šçš„æ ¼å¼ï¼Œæ”¾åœ¨`data`ä¸‹ï¼Œå¹¶ä¸”ä¿®æ”¹`dataset_info.json`æ–‡ä»¶ã€‚\n",
    "\n",
    "æœ¬æ•™ç¨‹å‡†å¤‡äº†ä¸€ä»½å¤šè½®å¯¹è¯æ•°æ®é›†ï¼Œè¿è¡Œä¸‹è¿°å‘½ä»¤ä¸‹è½½æ•°æ®ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748944fd-0545-4cdc-877a-1a5abcf50298",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%cd LLaMA-Factory\n",
    "!wget https://atp-modelzoo-sh.oss-cn-shanghai.aliyuncs.com/release/tutorials/llama_factory/data.zip\n",
    "!mv data rawdata && unzip data.zip -d data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eea1416-c9e6-4177-b6c9-8a75b6c64519",
   "metadata": {},
   "source": [
    "æ•°æ®é›†ä¸­çš„æ ·æœ¬ä¸ºå¤šè½®å¯¹è¯å½¢å¼ï¼Œæ¯è½®å¯¹è¯éƒ½ç”±ä¸€æ¡ç”¨æˆ·æŒ‡ä»¤å’Œä¸€æ¡æ¨¡å‹å›ç­”ç»„æˆï¼Œå¾®è°ƒè¿‡ç¨‹ä¸­æ¨¡å‹ä¸æ–­å­¦ä¹ æ ·æœ¬ä¸­çš„å›ç­”é£æ ¼ï¼Œä»è€Œè¾¾åˆ°ä¸­æ–‡åŒ–ä¸è§’è‰²æ‰®æ¼”çš„ç›®çš„ã€‚è¯¥æ•°æ®é›†åˆ†ä¸ºè®­ç»ƒé›†å’ŒéªŒè¯é›†ä¸¤ä¸ªæ–‡ä»¶ï¼Œå…¶ä¸­è®­ç»ƒé›†å…±åŒ…å«320ç»„å¤šè½®å¯¹è¯æ ·æœ¬ï¼ŒéªŒè¯é›†å…±åŒ…å«30ç»„å¤šè½®å¯¹è¯æ ·æœ¬ï¼Œæ•°æ®æ ·ä¾‹å¦‚ä¸‹æ‰€ç¤ºï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d450ebf-b743-4dd1-a2fb-f222870089cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "[\n",
    "{\n",
    "    \"conversations\": [\n",
    "      {\n",
    "        \"from\": \"human\",\n",
    "        \"value\": \"æ¨¡ä»¿è¥¿æ¸¸è®°çš„å­™æ‚Ÿç©ºçš„è¯­æ°”å’Œæˆ‘èŠå¤©ã€‚å¦‚æœä½ æŠŠæ°´å†»ä½ï¼Œä½ ä¼šå¾—åˆ°ä»€ä¹ˆï¼Ÿ\"\n",
    "      },\n",
    "      {\n",
    "        \"from\": \"gpt\",\n",
    "        \"value\": \"å“ˆå“ˆï¼Œè¿™é—®é¢˜è¿˜éš¾å€’ä¿ºè€å­™å—ï¼ŸæŠŠæ°´å†»ä½å°±æ˜¯å˜æˆå†°å•¦ï¼ä¸è¿‡è‹¥æ˜¯åœ¨å–ç»çš„è·¯ä¸Šç”¨å¾—ç€è¿™å†°æ¥åšå•¥ï¼Œæ¯”å¦‚è¿‡ç«ç„°å±±æ—¶ï¼Œé‚£å¯å°±æ˜¯è§£æ¸´æ¶ˆæš‘çš„å¥½ä¸œè¥¿äº†ï¼ä½ è§‰å¾—å‘¢ï¼Ÿè¿˜æœ‰æ²¡æœ‰æ›´æœ‰è¶£çš„é—®é¢˜è®©ä¿ºè€å­™æ¥è§£ç­”ï¼Ÿ\"\n",
    "      },\n",
    "      {\n",
    "        \"from\": \"human\",\n",
    "        \"value\": \"é‚£æ€ä¹ˆåšæ‰å¯ä»¥æŠŠæ°´å†»ä½\"\n",
    "      },\n",
    "      {\n",
    "        \"from\": \"gpt\",\n",
    "        \"value\": \"å“ˆå“ˆï¼Œå¯¹ä¿ºè€å­™æ¥è¯´ï¼Œè¿™å¯æ˜¯è½»è€Œæ˜“ä¸¾çš„äº‹æƒ…ï¼åªéœ€å°†æ°´æ”¾åœ¨å‡‰å¿«çš„åœ°æ–¹ï¼Œæˆ–è€…ä½¿ç”¨æ³•åŠ›ï¼Œä¸€å¹ä»™æ°”ï¼Œæ°´ä¾¿èƒ½è¿…é€Ÿç»“å†°å•¦ï¼å½“ç„¶ï¼Œåœ¨ä½ çš„ä¸–ç•Œé‡Œï¼ŒæŠŠæ°´æ”¾è¿›å†°ç®±çš„å†·å†»å®¤é‡Œç­‰ä¸€é˜µå­ï¼Œæ°´å°±ä¼šå˜æˆå†°å—äº†ã€‚è¦æ˜¯å«Œæ…¢ï¼Œå¯ä»¥å°è¯•ç”¨ç‚¹å¹²å†°æˆ–æ¶²æ°®ä»€ä¹ˆçš„ï¼Œä¸è¿‡å¾—å°å¿ƒä½¿ç”¨å“ˆï¼æ¯•ç«Ÿä¸åƒä¿ºè€å­™æœ‰æŠ—å¯’æ³•åŠ›ã€‚\"\n",
    "      }\n",
    "    ]\n",
    "}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c2c80e-4828-4c00-baf2-4d79e056263e",
   "metadata": {},
   "source": [
    "## 3. æ¨¡å‹å¾®è°ƒ\n",
    "### 3.1 å¯åŠ¨Web UI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bcd446-eb8d-4a28-9909-98e08e5e57e9",
   "metadata": {},
   "source": [
    "åšå¥½å‰åºå‡†å¤‡å·¥ä½œåï¼Œç›´æ¥è¿è¡Œä¸‹è¿°å‘½ä»¤å°±å¯ä»¥å¯åŠ¨Web UIã€‚è¿™é‡Œç”¨åˆ°çš„ç¯å¢ƒå˜é‡è§£é‡Šå¦‚ä¸‹ï¼š\n",
    "- `USE_MODELSCOPE_HUB`è®¾ä¸º1ï¼Œè¡¨ç¤ºæ¨¡å‹æ¥æºæ˜¯ModelScopeã€‚ä½¿ç”¨HuggingFaceæ¨¡å‹å¯èƒ½ä¼šæœ‰ç½‘ç»œé—®é¢˜ã€‚\n",
    "\n",
    "ç‚¹å‡»è¿”å›çš„URLåœ°å€`http://0.0.0.0:7860`ï¼Œè¿›å…¥Web UIé¡µé¢ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f3d0bf-668b-43e9-a146-33369c69a86a",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-11-25T07:40:22.797991Z",
     "iopub.status.busy": "2025-11-25T07:40:22.797648Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-11-25 15:40:26,710] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n",
      "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3\n",
      "\u001b[93m [WARNING] \u001b[0m using untested triton version (2.3.1), only 1.0.0 is known to be compatible\n",
      "* Running on local URL:  http://0.0.0.0:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    }
   ],
   "source": [
    "!export USE_MODELSCOPE_HUB=1 && \\\n",
    "llamafactory-cli webui"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bb212f-24d8-46a1-b4d1-8345f4f5531f",
   "metadata": {},
   "source": [
    "### 3.2 é…ç½®å‚æ•°\n",
    "è¿›å…¥WebUIåï¼Œå¯ä»¥åˆ‡æ¢åˆ°ä¸­æ–‡ï¼ˆzhï¼‰ã€‚é¦–å…ˆé…ç½®æ¨¡å‹ï¼Œæœ¬æ•™ç¨‹é€‰æ‹©LLaMA3-8B-Chatæ¨¡å‹ï¼Œå¾®è°ƒæ–¹æ³•åˆ™ä¿æŒé»˜è®¤å€¼loraï¼Œä½¿ç”¨LoRAè½»é‡åŒ–å¾®è°ƒæ–¹æ³•èƒ½æå¤§ç¨‹åº¦åœ°èŠ‚çº¦æ˜¾å­˜ã€‚\n",
    "![image.png](_html/finetune_model.jpg)\n",
    "\n",
    "æ•°æ®é›†ä½¿ç”¨ä¸Šè¿°ä¸‹è½½çš„`train.json`ã€‚\n",
    "![image.png](_html/finetune_data.jpg)\n",
    "\n",
    "å¯ä»¥ç‚¹å‡»ã€Œé¢„è§ˆæ•°æ®é›†ã€ã€‚ç‚¹å‡»å…³é—­è¿”å›è®­ç»ƒç•Œé¢ã€‚\n",
    "![image.png](_html/finetune_preview.jpg)\n",
    "\n",
    "è®¾ç½®å­¦ä¹ ç‡ä¸º1e-4ï¼Œæ¢¯åº¦ç´¯ç§¯ä¸º2ï¼Œæœ‰åˆ©äºæ¨¡å‹æ‹Ÿåˆã€‚å¦‚æœæ˜¾å¡æ˜¯V100ï¼Œè®¡ç®—ç±»å‹ä¿æŒä¸ºfp16ï¼›å¦‚æœä½¿ç”¨äº†A10ï¼Œå¯ä»¥æ›´æ”¹è®¡ç®—ç±»å‹ä¸ºbf16ã€‚\n",
    "![image.png](_html/finetune_params.jpg)\n",
    "\n",
    "ç‚¹å‡»LoRAå‚æ•°è®¾ç½®å±•å¼€å‚æ•°åˆ—è¡¨ï¼Œè®¾ç½®LoRA+å­¦ä¹ ç‡æ¯”ä¾‹ä¸º16ï¼ŒLoRA+è¢«è¯æ˜æ˜¯æ¯”LoRAå­¦ä¹ æ•ˆæœæ›´å¥½çš„ç®—æ³•ã€‚åœ¨LoRAä½œç”¨æ¨¡å—ä¸­å¡«å†™allï¼Œå³å°†LoRAå±‚æŒ‚è½½åˆ°æ¨¡å‹çš„æ‰€æœ‰çº¿æ€§å±‚ä¸Šï¼Œæé«˜æ‹Ÿåˆæ•ˆæœã€‚\n",
    "![image.png](_html/finetune_lora.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0f6dac-54af-4f83-90a6-922c7054301d",
   "metadata": {},
   "source": [
    "### 3.3 å¯åŠ¨å¾®è°ƒ\n",
    "å°†è¾“å‡ºç›®å½•ä¿®æ”¹ä¸º`train_llama3`ï¼Œè®­ç»ƒåçš„LoRAæƒé‡å°†ä¼šä¿å­˜åœ¨æ­¤ç›®å½•ä¸­ã€‚ç‚¹å‡»ã€Œé¢„è§ˆå‘½ä»¤ã€å¯å±•ç¤ºæ‰€æœ‰å·²é…ç½®çš„å‚æ•°ï¼Œæ‚¨å¦‚æœæƒ³é€šè¿‡ä»£ç è¿è¡Œå¾®è°ƒï¼Œå¯ä»¥å¤åˆ¶è¿™æ®µå‘½ä»¤ï¼Œåœ¨å‘½ä»¤è¡Œè¿è¡Œã€‚\n",
    "\n",
    "ç‚¹å‡»ã€Œå¼€å§‹ã€å¯åŠ¨æ¨¡å‹å¾®è°ƒã€‚\n",
    "![image.png](_html/finetune_start.jpg)\n",
    "\n",
    "å¯åŠ¨å¾®è°ƒåéœ€è¦ç­‰å¾…ä¸€æ®µæ—¶é—´ï¼Œå¾…æ¨¡å‹ä¸‹è½½å®Œæ¯•åå¯åœ¨ç•Œé¢è§‚å¯Ÿåˆ°è®­ç»ƒè¿›åº¦å’ŒæŸå¤±æ›²çº¿ã€‚æ¨¡å‹å¾®è°ƒå¤§çº¦éœ€è¦20åˆ†é’Ÿï¼Œæ˜¾ç¤ºâ€œè®­ç»ƒå®Œæ¯•â€ä»£è¡¨å¾®è°ƒæˆåŠŸã€‚\n",
    "![image.png](_html/finetune_result.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2484967d-f3a1-4f44-851e-39b378dda452",
   "metadata": {},
   "source": [
    "## 4. æ¨¡å‹è¯„ä¼°\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1647de-2b53-4874-917e-9469aaa645c0",
   "metadata": {},
   "source": [
    "å¾®è°ƒå®Œæˆåï¼Œç‚¹å‡»é¡µé¢é¡¶éƒ¨çš„ã€Œåˆ·æ–°é€‚é…å™¨ã€ï¼Œç„¶åç‚¹å‡»é€‚é…å™¨è·¯å¾„ï¼Œå³å¯å¼¹å‡ºåˆšåˆšè®­ç»ƒå®Œæˆçš„LoRAæƒé‡ï¼Œç‚¹å‡»é€‰æ‹©ä¸‹æ‹‰åˆ—è¡¨ä¸­çš„train_llama3é€‰é¡¹ï¼Œåœ¨æ¨¡å‹å¯åŠ¨æ—¶å³å¯åŠ è½½å¾®è°ƒç»“æœã€‚\n",
    "![image.png](_html/evaluate_adaptor.jpg)\n",
    "\n",
    "é€‰æ‹©ã€ŒEvaluate&Predictã€æ ï¼Œåœ¨æ•°æ®é›†ä¸‹æ‹‰åˆ—è¡¨ä¸­é€‰æ‹©ã€Œevalã€ï¼ˆéªŒè¯é›†ï¼‰è¯„ä¼°æ¨¡å‹ã€‚æ›´æ”¹è¾“å‡ºç›®å½•ä¸º`eval_llama3`ï¼Œæ¨¡å‹è¯„ä¼°ç»“æœå°†ä¼šä¿å­˜åœ¨è¯¥ç›®å½•ä¸­ã€‚æœ€åç‚¹å‡»å¼€å§‹æŒ‰é’®å¯åŠ¨æ¨¡å‹è¯„ä¼°ã€‚\n",
    "![image.png](_html/evaluate_start.jpg)\n",
    "\n",
    "æ¨¡å‹è¯„ä¼°å¤§çº¦éœ€è¦5åˆ†é’Ÿå·¦å³ï¼Œè¯„ä¼°å®Œæˆåä¼šåœ¨ç•Œé¢ä¸Šæ˜¾ç¤ºéªŒè¯é›†çš„åˆ†æ•°ã€‚å…¶ä¸­ROUGEåˆ†æ•°è¡¡é‡äº†æ¨¡å‹è¾“å‡ºç­”æ¡ˆï¼ˆpredictï¼‰å’ŒéªŒè¯é›†ä¸­æ ‡å‡†ç­”æ¡ˆï¼ˆlabelï¼‰çš„ç›¸ä¼¼åº¦ï¼ŒROUGEåˆ†æ•°è¶Šé«˜ä»£è¡¨æ¨¡å‹å­¦ä¹ å¾—æ›´å¥½ã€‚\n",
    "![image.png](_html/evaluate_result.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb18065-a0f2-4106-8c98-e35e4455e4d4",
   "metadata": {},
   "source": [
    "## 5. æ¨¡å‹å¯¹è¯"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df83adb-3fdc-4029-9ee9-24eec0a38b0e",
   "metadata": {},
   "source": [
    "é€‰æ‹©ã€ŒChatã€æ ï¼Œç¡®ä¿é€‚é…å™¨è·¯å¾„æ˜¯`train_llama3`ï¼Œç‚¹å‡»ã€ŒåŠ è½½æ¨¡å‹ã€å³å¯åœ¨Web UIä¸­å’Œå¾®è°ƒæ¨¡å‹è¿›è¡Œå¯¹è¯ã€‚\n",
    "![image.png](_html/chat_params.jpg)\n",
    "\n",
    "åœ¨é¡µé¢åº•éƒ¨çš„å¯¹è¯æ¡†è¾“å…¥æƒ³è¦å’Œæ¨¡å‹å¯¹è¯çš„å†…å®¹ï¼Œç‚¹å‡»ã€Œæäº¤ã€å³å¯å‘é€æ¶ˆæ¯ã€‚å‘é€åæ¨¡å‹ä¼šé€å­—ç”Ÿæˆå›ç­”ï¼Œä»å›ç­”ä¸­å¯ä»¥å‘ç°æ¨¡å‹å­¦ä¹ åˆ°äº†æ•°æ®é›†ä¸­çš„å†…å®¹ï¼Œèƒ½å¤Ÿæ°å½“åœ°æ¨¡ä»¿è¯¸è‘›äº®çš„è¯­æ°”å¯¹è¯ã€‚\n",
    "![image.png](_html/chat_result1.jpg)\n",
    "\n",
    "ç‚¹å‡»ã€Œå¸è½½æ¨¡å‹ã€ï¼Œç‚¹å‡»â€œÃ—â€å·å–æ¶ˆé€‚é…å™¨è·¯å¾„ï¼Œå†æ¬¡ç‚¹å‡»ã€ŒåŠ è½½æ¨¡å‹ã€ï¼Œå³å¯ä¸å¾®è°ƒå‰çš„åŸå§‹æ¨¡å‹èŠå¤©ã€‚\n",
    "![image.png](_html/chat_uninstall.jpg)\n",
    "\n",
    "é‡æ–°å‘æ¨¡å‹å‘é€ç›¸åŒçš„å†…å®¹ï¼Œå‘ç°åŸå§‹æ¨¡å‹æ— æ³•æ¨¡ä»¿è¯¸è‘›äº®çš„è¯­æ°”ç”Ÿæˆä¸­æ–‡å›ç­”ã€‚\n",
    "![image.png](_html/chat_result2.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bf8e55-95ce-460c-ace9-a7996824b9e3",
   "metadata": {},
   "source": [
    "## 6. æ€»ç»“\n",
    "\n",
    "æœ¬æ¬¡æ•™ç¨‹ä»‹ç»äº†å¦‚ä½•ä½¿ç”¨PAIå’ŒLLaMA Factoryæ¡†æ¶ï¼ŒåŸºäºè½»é‡åŒ–LoRAæ–¹æ³•å¾®è°ƒLlama-3æ¨¡å‹ï¼Œä½¿å…¶èƒ½å¤Ÿè¿›è¡Œä¸­æ–‡é—®ç­”å’Œè§’è‰²æ‰®æ¼”ï¼ŒåŒæ—¶é€šè¿‡éªŒè¯é›†ROUGEåˆ†æ•°å’Œäººå·¥æµ‹è¯•éªŒè¯äº†å¾®è°ƒçš„æ•ˆæœã€‚åœ¨åç»­å®è·µä¸­ï¼Œå¯ä»¥ä½¿ç”¨å®é™…ä¸šåŠ¡æ•°æ®é›†ï¼Œå¯¹æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œå¾—åˆ°èƒ½å¤Ÿè§£å†³å®é™…ä¸šåŠ¡åœºæ™¯é—®é¢˜çš„æœ¬åœ°é¢†åŸŸå¤§æ¨¡å‹ã€‚"
   ]
  }
 ],
 "metadata": {
  "dsw_sample": {
   "buildId": "1175",
   "pipeline": "pai-dsw-examples-master"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "share": {
   "datetime": "2024-05-08T07:37:10.242Z",
   "image": {
    "name": "modelscope:1.14.0-pytorch2.1.2-gpu-py310-cu121-ubuntu22.04",
    "url": "dsw-registry-vpc.cn-hangzhou.cr.aliyuncs.com/pai/modelscope:1.14.0-pytorch2.1.2-gpu-py310-cu121-ubuntu22.04"
   },
   "instance": "dsw-d03c4949959b7041",
   "spec": {
    "id": "ecs.gn7i-c8g1.2xlarge",
    "type": "GPU"
   },
   "uid": "1157703270994901"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
